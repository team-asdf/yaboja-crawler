title,content,url,source,keyword,image,createdAt
신규 포인트 시스템 전환기 #2 - 오픈 준비 단계,"이 글은 이전편에서 이어집니다.기존에 프로시저만 수행되던 시스템을 API 기반으로 전환하기 위해서 모든 API는 2개씩 준비해야만 했습니다.이렇게 구성한 이유는 다음과 같습니다.만약 프로시저 랩핑 API가 없다면 다음과 같은 큰 위험이 있습니다.이건 너무나 큰 위험입니다. 그래서 레거시 프로시저를 랩핑한 API가 선 오픈하고 운영 환경에서 충분히 테스트 한 뒤, 다른 서비스들이 하나씩 프로시저를 호출하는 코드를 API를 호출하도록 전환하도록 진행되었습니다.모든 준비와 검증은 2번씩 수행되었습니다.성능 테스트의 경우 네이버에서 만든 Ngrinder와 Pinpoint를 사용했습니다.(Ngrinder)(pinpoint)여러 좋은 툴이 있지만, 이 2개를 선택한 이유는 익숙해서입니다.Pinpoint는 이미 팀내에서 공식 모니터링툴로 계속해서 사용해오던 상태였으며, Ngrinder는 Spock, Gradle 등으로 Groovy 문법이 눈에 익은 상태여서 테스트 시나리오를 작성하기에 좋은 선택지였습니다.개인 프로젝트에서도 이 둘을 계속해서 사용해오던 상태였어서 다른 선택지를 굳이 찾을 필요가 없었습니다.위에서 언급한대로 성능 테스트는 두번 진행했습니다.특히 1번 테스트가 중요했습니다. 이제는 신규 구축하는 포인트 시스템에서 모든 요청을 처리해야하는데, 기존에 서비스 별로 나눠처리 했던 프로시저 요청으로는 정확한 부하 예측이 어려웠기 때문입니다.그래서 주말 피크타임 주문수 * 5배의 TPS를 성능 테스트의 기준으로 정했습니다. 포인트 적립과 가용 포인트 조회가 가장 많은 사용이 있을 것이며, 이 요청은 주문수에 비례하기 때문에 주문수를 기준으로 정했습니다.성능 테스트 방식은 대부분 비슷할것 같습니다.Ngrinder에서 다음과 같이 User수와 TPS를 조정하며 부하를 주고,(TPS 1000부터 시작한 것입니다.)Pinpoint에서는 다음과 같이 각 요청의 응답 중 튀는 것이 있는지, 튄다면 어느 부분에서 많이 소요되었는지, 평균 응답 속도는 얼마나 걸리는지 등등을 확인합니다.그리고 RDS의 사양은 해당 TPS 기준으로 CPU나 처리되는 쿼리가 얼마나 되는지 등등을 같이 확인합니다.이외에도 다양한 테스트를 진행했습니다.각 서비스마다의 아키텍처와 도메인에 따라 성능 테스트 시나리오가 다르기 때문에 꼭 이렇게 검증해야하는 것은 아닙니다.혹시나 성능 테스트를 전혀 안해보신 분들이라면 성능 테스트에 대한 튜토리얼을 개인 블로그에 작성했으니 한번 참고해보셔도 좋을것 같습니다.JVM 어플리케이션의 경우 Warm up Time이 존재합니다.처음 Java 어플리케이션을 실행할 경우 HotSpot 컴파일러의 최적화 작업으로 성능이 느립니다. 이는 성능 테스트시 주의해야할 점인데요. 첫번째 테스트 결과만 보면 대부분은 성능이 안좋기 때문입니다. 이미 충분히 Warm up한 뒤에 테스트해야만 정상적인 성능 테스트로 볼 수 있습니다.그래서 포인트 시스템의 성능 테스트시 항상 같은 설정으로 첫번째 테스트는 Warmup용으로 버리고 2번째 이후 테스트들만 성능 비교를 하였습니다.좀 더 자세한 내용을 알고 싶으신 분들은 아래 DZone 기사를 참고해보세요!기본적으로 Pinpoint는 HTTP Request가 올때 추적을 시작합니다. 하지만 SQS와 같은 메세징 큐 서비스를 사용할때는 HTTP Request가 아닙니다. 그러다보니 Pinpoint의 기본 설정으로는 추적이 안됩니다.Pinpoint에서는 이런 상황을 대비해서 EntryPoint 설정이 가능합니다.(pinpoint.config)entrypoint에는 패키지명을 포함해서 Full Path로 메소드명을 기입해야합니다. 여러 메소드를 지정해야할 경우 ,로 구분해서 등록하시면 됩니다.위와 같이 설정할 경우 지정된 메소드가 호출되면 추적이 시작됩니다. 저는 @SqsListener가 지정된 메소드들을 모두 entrypoint로 지정했습니다.이렇게 설정하게 되면 이제 지정된 메소드가 실행되면 Pinpoint의 추적이 시작됩니다.더 많은 설정 방법은 Pinpoint의 공식 Document를 참고해보세요!대략 1억건 정도가 마이그레이션 되었을때, 도메인 모델의 변경이 필요한 것을 발견하였습니다. 1억건 정도면 사실 엄청나게 많은 양은 아닙니다. 또한 이전에 IDC에 구축한 DB에서 1억건 정도의 테이블에 Alter를 쳤을때 10분이내로 끝나기도 했어서 바로 Alter Table를 수행했었는데요.R4.2xlarge 환경에서 진행했더니 2시간이 지나도 끝나지 않았습니다.RDS 사양의 문제인가 싶어 잠깐 최고 사양인 8xlarge로 올려서 수행해도 전혀 개선이 되지 않았습니다. 왜 이런가 싶어 다른 팀의 수석님께 이상한것 같다고 여쭤보니 Cloud Watch를 같이 확인해주셨습니다. 확인 결과! 놀랍게도 Alter Table을 수행하는 동안 굉장히 많은 Network Throughput이 발생한 것을 발견하였습니다.이상하다 싶어 RDS Compare 사이트를 찾아보니 RDS R3의 경우 로컬 스토리지를 사용하지만, R4는 EBS를 사용하는 것을 확인하였습니다.(RDS Compare)혹시나 싶어 R3.2xlarge로 변경 후 Alter Table을 수행하니 10분도 안되서 완료 되었습니다.테스트로 R3와 R4를 번갈아가며 Alter Table을 수행했는데 여전히 R4에서는 2시간이상, R3에서는 몇분 이내에 명령어가 수행되었습니다.아마도 R4에서는 Alter Table을 하기 위해 원격 저장소와 네트워크 통신을 굉장히 많이 수행하다보니 2시간이 넘게 걸린것 같습니다.이외에도 몇가지 이슈가 되는 점들이 발견되어, 신규 포인트 시스템은 R3 시리즈를 선택해 사용중입니다.물론 R4의 사양은 R3보다 훨씬 더 좋습니다. (위 그림에서 보신것처럼 CPU Processor가 차이 납니다.)아래는 성능 테스트 중에 두 RDS간의 성능을 비교한 Pinpoint 결과표입니다.명확한 비교를 위해 높은 수치로 테스트를 수행했습니다.R3.8xlarge로 평균 3 ~ 5초 정도 수행되는 Application이 R4.8xlarge로 수행할 경우 평균 2 ~ 3초로 개선되는 것을 확인할 수 있었습니다.그래서 꼭 R3를 써야하는건 아니고, 상황 및 테스트 결과에 따라 R3와 R4 사이에 선택하시면 좋을것 같습니다.QA 역시 성능 테스트와 마찬가지로 레거시 프로시저 API 버전과 신규 도메인 API 버전 2가지를 모두 테스트했습니다.(TC 목록)이때 QA 분들께 정말 죄송했던 것이, 레거시 API와 신 API를 각각 테스트해야한다는 것을 미리 얘기해드리지 못해 안그래도 부족했던 QA 일정을 더 촉박하게 만들었던 점입니다. 그럼에도 불구하고 기간 내에 정말 꼼꼼하게 QA를 완료해주셔서 정말 감사했습니다.QA 기간 중에, 가끔 가용 포인트가 적립 내역과 다르다는 내용이 나왔습니다. 정말 간혹 발생하는 문제라서 어떤 상황일때 발생하는지 재현하기가 어려웠습니다. 몇가지 가설을 세웠습니다.두개 경우를 검증하기 위해 Redis에 저장된 메세지를 확인해보니, 실제로 갱신은 진행 되었습니다. 갱신이 분명히 진행되었는데, 왜 새로 적립된 내용이 계산에 포함되지 않았던걸까 고민 하던중! 코드에서 큰 문제가 있음을 발견했습니다.아래와 같이 적립 이벤트를 진행하는 earn메소드에서는 메인 도메인 처리가 끝나고 마지막에 Redis 이벤트를 수신하는 Redis Worker 로 포인트 갱신 메세지를 발행합니다.코드를 보시면 바로 아시겠지만, 포인트 적립이 DB에 반영 되는 것은 트랜잭션이 끝난 시점입니다. Redis Worker로 메세지를 발행하는 것은 트랜잭션이 반영되기 전입니다. 그러다보니 트랜잭션이 끝나기 전에 Worker에서 메세지를 수신하는 경우가 종종 발생하고, 그럴 경우에 계산 로직이 수행되면 아직 DB에는 새로 적립된 포인트가 없기 때문에 누락된 것입니다.이 문제를 해결하기 위해서는 DB에 트랜잭션이 반영된 뒤에, 메세지를 발행하도록 변경하면 됩니다.서비스 메소드에서 메세지 발행을 처리하지 않고, 서비스의 상위인 Listener에서 트랜잭션이 끝난 후, Redis Worker로 메세지를 발행하는 코드로 변경하였습니다.이렇게 변경후 문제가 더이상 발생되지 않았습니다.포인트 시스템은 기존에 API가 없었기 때문에 모든 서비스들이 각자 프로시저를 수행하고 있었습니다. 그래서 가장 먼저 모든 시스템들이 하나의 End Point를 보도록 전환하는 것이 최우선 과제 였습니다. 이를 위해서 다음과 같은 구조를 그렸습니다.(전체 구조)그리고 이 구조 안에서 오픈 전략을 세웠습니다.7월 17일 레거시 프로시저를 랩핑한 API를 선 오픈했습니다. 이때의 오픈은 진짜 개편 오픈이기 보다는, 롤백을 위한 방어선 느낌의 오픈이였습니다.신규 도메인, 기능을 전혀 오픈에 포함시키지 않고, 오로지 프로시저를 사용하는 코드들만 전부 API로 감싸서 오픈했기 때문에 비지니스상 문제가 크게 발생하지는 않았습니다.그리고 차례로 그동안 포인트 프로시저를 사용했던 다른 시스템들이 API를 사용하는 패치가 진행되었습니다.모든 Endpoint가 레거시 API로 전환된 것을 확인하고 더이상의 문제가 없음을 확인 후, 7월 25일 2차 버전인 레거시 우선순위 API로 전환했습니다.이번 버전은 모든 API에 대한 요청은 기존의 프로시저로 처리하되, 신규 도메인 API에도 이벤트 메세지를 발송해서 두 시스템간에 Sync하는 버전이였습니다.여기서 한가지 큰 문제점이 있었는데요. 신규 API를 위해서 모든 데이터가 신규 도메인으로 마이그레이션 완료 되어있어야만 했습니다.이는 신규 포인트 시스템의 도메인이 Insert 모델이라 이전부터 쌓여있던 데이터들이 있어야만 현재 가용포인트가 되기 때문인데요.그러다보니 시스템 오픈 사이에 쌓이는 데이터들은 어떡하지? 라는 고민이 있었습니다. 오픈 시간 동안 쌓인 데이터만 나중에 마이그레이션 하는건 문제가 있었습니다. 포인트를 계속 재사용 할 수 있기 때문입니다.이 문제를 해결하기 위해 다음과 같은 전략을 세웠습니다.이렇게 할 경우 주문, 결제에는 전혀 문제가 없고, 포인트 적립,취소 등도 30분 뒤에는 처리가 되기 때문에 실제 프로세스와 유사하게 운영할 수 있습니다. 또한, 오픈 시간 동안 (약 30분) 포인트 시스템에는 전혀 데이터가 추가되지 않기 때문에 깔끔하게 전환 할 수 있습니다.이 전략으로 포인트 API 전환 오픈을 시작했습니다.이번 전환 배포로 모든 포인트 관련 이벤트는 구 DB와 신 DB가 동시에 데이터가 쌓이게 되었고, 마이그레이션은 더이상 사용하지 않아도 되었습니다.레거시 우선 순위였기 때문에 신규 도메인에 문제가 있어도 일단은 무시하고 프로시저 처리는 진행하도록 두었습니다. 신규 도메인에 문제가 있다고해서 운영되고 있는 포인트 적립이나 사용이 안될수는 없기 때문에 신규 도메인 문제는 모두 예외처리하였습니다. 대신 실패한 메세지는 로그로 Json 형태 그대로 남기게 하여, 어떤 문제가 있어 실패했는지 확인 후  다시 SQS로 재전송 하였습니다.대망의 마지막 전환입니다!7월 30일까지 확인 후, 신규 도메인에서도 문제가 없음을 확인하고 31일에 신규 API 우선 순위로 전환하였습니다. 이때는 신규 도메인이 성공하면 레거시 도메인은 무시하도록 하였습니다. 대신 프로시저를 실행은 했습니다.신규 도메인 위주로 전환 되었음에도 레거시 도메인을 일정 기간 유지한 이유는 기존에 사용되던 월 집계 통계 데이터 등등에서 레거시 도메인과 신규 도메인을 비교 & 검증하기 위함이였습니다.신규 도메인으로 모든 포인트 처리가 되는 것을 확인하고, 드디어! 기존 레거시를 바라보던 모든 코드를 제거했습니다.그리고 포인트 시스템이 완전히 개편되었습니다!(드디어 끝!!)신규 포인트 시스템이 일정내에 오픈하는데 있어 가장 중요했던 것은 다른 팀의 전폭적인 지지와 지원이였습니다.다른 팀 역시 굉장히 바쁜 상황임에도 포인트 시스템 오픈에 맞춰 프로시저 호출 코드를 모두 API코드로 전환해주셨습니다.저희가 다소 급하게 일정을 요청했음에도 기간내에 완료해주시고 배포까지 해주셔서 정말 감사할 따름입니다.오픈 뒤에 아시아 올림픽 축구 경기가 있었습니다! 아쉽게도 월드컵은 겪지 못했지만 아시아 올림픽 축구 경기 역시 많은 주문이 발생했고, 그만큼 포인트 요청도 많았었는데요. 장애나 응답 지연 없이 아주 깔끔하게 신규 포인트 시스템은 이벤트에 대응을 하였습니다. 3개월간 스트레스 받고 고민했던 일들이 아주 잘 마무리 되어서 너무나 상쾌했습니다.부족함이 많은 글임에도 끝까지 읽어주셔서 감사합니다. 그럼, 다음에 또 뵙겠습니다. 감사합니다!(사용된 모든 짤은 레진코믹스의 레바툰입니다.)",http://woowabros.github.io/experience/2018/10/15/new_point_story_2.html,woowabros,,NULL,2018-10-15
신규 포인트 시스템 전환기 #1 - 개발 단계,"안녕하세요? 우아한 형제들에서 결제/정산 (+포인트와 비즈머니) 시스템을 개발하고 있는 이동욱입니다.‘사내 블로그에 글을 더 쓸 일이 있을줄이야’ 라는 마음으로 VS Code로 글을 쓰고 있습니다.저는 이번 시간에 올해 4월 중순부터 시작해 7월 말까지 진행된 포인트 시스템을 개편했던 경험을 공유하려고 합니다.기존에는 포인트라는 서비스 자체가 구축되어 있지 않았습니다. 중앙 DB에 존재하는 포인트 테이블과 프로시저만 존재했습니다. 그러다보니 모든 서비스가 필요하면 포인트 프로시저를 수행하고 개별적으로 사용하는 구조였습니다.기존에 구성된 도메인 모델과 프로시저 등에 계속해서 문제가 발생하고 있었고, 시스템 확장성도 굉장히 떨어졌기 때문에 개편은 피할 수 없었습니다.기존에 시스템화 되어 있지 않고, 테이블과 프로시저만 있던 상태에서 신규 시스템을 오픈한다는 것은 서버, 배포 환경, 도메인 모델, 어플리케이션 등을 완전히 제로에서 새로 만들어야 함을 의미했습니다.그 과정에서 저희가 했던 고민들을 공유하면 비슷한 상황에 있으신 분들에게 조금이나마 도움이 되지 않을까 싶어 작성했습니다.내용은 크게 2파트로 나눴습니다.자! 그럼 신나게 글을 시작해보겠습니다(편하게 봐주세요!)신규 포인트 시스템의 기술 스택은 다음과 같습니다.어플리케이션쪽은 기존 Java & Spring 개발자분들이 쓰시는 기술 스택과 크게 차이가 안날것 같습니다. 이외 나머지 기술들을 선택했던 이유들을 하나씩 소개하겠습니다.처음 구축 할때는 AWS Beanstalk을 선택했습니다.이 2가지 이유로 Beanstalk을 선택 하고 실제 오픈까지 진행했습니다.하지만 오픈하고 난 뒤부터 Beanstalk의 단점이 하나씩 보이기 시작했습니다. (사실 그전에도 보였습니다만 애써 모른척했습니다.)특히 마지막 2개 단점이 치명적이였습니다.AWS Beanstalk의 경우 한대 서버에 배포하는 시간이 5분이 필요합니다. 5대에 배포해야 할 경우 5 * 5 = 총 25분이 필요했습니다. 서버 교체가 아닌 단순히 Application만 배포하는데도 한 대당 5분씩 걸리는 것은 문제가 있다고 생각했습니다.배포 대수를 30% 혹은 50%로 선택하기엔 무리가 있었습니다. 배포하는 순간에 남은 서버들의 부하가 크게 증가하기 때문입니다.그래서 이 문제를 회피하기 위해 같은 설정의 Beanstalk를 하나더 생성해 반대편 환경에 100%로 배포하고 ELB를 스위칭 하는 방법 등을 고려했습니다. 하지만 배포하는게 이렇게 번거로워야하나? 라는 아주 근본적인 생각이 들었습니다.또한 특정 서버만 다른 환경 설정이 어렵다는 것도 큰 문제였습니다. 저희는 모니터링툴로 Newrelic과 핀포인트를 함께 쓰고 있습니다. 두 솔루션에는 문제점이 하나 있었는데요. Newrelic APM (인프라스트럭쳐 X) 와 핀포인트를 같이 사용할 수 없습니다.IDC를 사용할때는 큰 문제가 없었습니다. 1번 서버는 Newrelic APM을, 나머지 서버들에는 핀포인트를 설치해서 쓰면 됐기 때문입니다. 하지만 Beanstalk은 같은 환경 내의 특정 서버만 다른 설정을 갖도록 하는 것이 정말 어렵습니다. 불가능한 것은 아니지만, 사실상 쉘스크립트로 다 짜야하는 상황이였습니다.이런 문제점들로 인해 시스템 오픈 하고 난 뒤, 팀의 개발자분이 직접 Code Deploy 전환을 진행하셨습니다.(크.. 진짜 좋습니다 여러분 꼭 전환해보시길!)현재 모든 포인트 시스템은 AWS Beanstalk을 제거하고 ASG (Auto Scaling Group) & Code Deploy로 완전히 전환되었습니다. 그리고 위에서 언급한 단점들이 모두 해결되어 큰 문제없이 사용중입니다.Spring과 Beanstalk을 쓰고 있는 상황에서 AWS SQS에서 메세지를 수신할 수 있는 방법은 크게 2가지가 있습니다.Beanstalk Worker에 대해 간단하게 소개드리면 Beanstalk 내부에 SQS 메세지 리스너 데몬을 두고 해당 데몬이 어플리케이션으로 SQS 메세지를 HTTP API로 요청을 보내는 환경을 얘기합니다.(좀 더 자세한 내용은 AWS의 공식 문서를 참고하시면 더욱 좋습니다.)AWS Beanstalk에서 제공하는 Worker 서비스를 사용하면 몇가지 장점이 있습니다.하지만 저희는 Spring Cloud AWS 에서 제공하는 @SqsListener를 선택했습니다.Beanstalk과 완전히 무관하게 구현한 결과, 시스템 전환하기가 정말 편했습니다. 실제로 이렇게 구축한 덕분에 시스템 안정화 이후 ASG & Code Deploy로 시스템 환경을 변경할때 큰 번거로움없이 진행될 수 있었습니다.만약 Beanstalk Worker를 사용했다면 Worker에서 해주는 부분을 어플리케이션에서 다시 구현해야 하고, 이 부분에 대한 성능 테스트와 QA를 또 했어야 했기 때문에 시도하지 못했을 것입니다.개인 프로젝트에서는 AWS Code Pipeline을 사용하고 있습니다.아무래도 Code Build & Code Deploy & Code Pipeline으로 구축할 경우 빌드 & 배포 시간에만 비용이 청구되기 때문에 비용도 절약할 수 있고, 별도로 CI 시스템 구축할 필요도 없어서 선호했습니다.하지만 이번 포인트 시스템에서는 Jenkins + Beanstalk (현재는 Jenkins + Code Deploy로 전환)를 선택했습니다.그 이유는 다음과 같은데요.마지막 이유가 가장 중요했습니다. 결과적으로 팀의 모두가 CI/CD 환경을 다룰 수 있어야하는데, Jenkins 외에 다른 시스템을 도입할 경우 팀에 부담을 주는 일이 될 수 있기 때문입니다.아마 팀 CI툴이 Teamcity였다면 마찬가지로 Teamcity를 선택했을 것입니다. 어찌 됐든 이런 인프라 환경은 팀 컨벤션을 맞추는게 중요하다 생각해 기존과 최대한 유사한 환경을 선택했습니다.신규 포인트 시스템은 Update와 Delete가 없는 도메인으로 구성하였습니다. 포인트는 일종의 기업 부채 혹은 재화와 비슷한 의미로 사용되기 때문에 그 이력은 아주 정확하고 상세하게 관리되어야만 했습니다.기존 시스템의 경우 Update가 있었기 때문에 왜 이 회원의 포인트가 이 금액이 되었는지 정확히 추적하기가 어려웠습니다 현재 가용포인트와 실제로 적립/사용된 포인트의 계산이 안맞는 경우도 있었으며, 이럴 경우 틀어진 데이터를 수정해야하는데, 한번 틀어진 데이터를 다시 맞추기가 너무 어려웠습니다.그래서 모든 포인트 데이터는 Insert만 존재하는 도메인 모델로 구현하였습니다. 이 모델로 구현하면서 기본적인 기능인 적립이나 조회에 대해서는 크게 어려움이 없었습니다. 하지만 몇몇 경우에선 문제가 되었습니다.예를 들어 1000원의 포인트를 유저가 사용했다면 단순하게 생각하면 -1000원이란 포인트 데이터를 한줄 추가하면 된다고 할 수 있습니다. 하지만 그럴수가 없었습니다. 바로 유효기간만료 때문입니다. 예를 들어 50원이 적립되었고, 이 50원 중 40원이 쓰여졌다면, 10원이 남아있으니 유효 기간이 지나면 10원만 만료처리가 되어야만 합니다. 단순한 Insert 모델에서는 이런 처리에 대해서 처리하기가 어려워 상세 도메인을 추가하였습니다.그리고 포인트 차감에 관련된 이벤트는 다음과 같은 룰을 정했습니다.예를 들어 다음과 같은 케이스라고 보시면 됩니다.위처럼 메인 이벤트가 발생하면 적립된 순서대로 다음과 같이 상세 테이블에 이벤트가 쌓이게 됩니다.이렇게 되면 a1과 a2는 Group By 하게 되면 0원이 되어 이후의 계산 로직에서는 모두 제외 됩니다.유효기간만료 이벤트 처리도 아주 쉽게 해결됩니다. 적립 ID를 기준으로 Group by 해서 0원이 아닌 금액은 모두 만료 처리를 하면 됩니다.앞서 사용 이벤트로 10원이 남은 사용자의 남은 포인트는 10원입니다. (a3의 남은 적립 포인트 금액) 이 10원의 유효기간이 지나면 10원에 해당하는 금액만큼만 만료 시키면 됩니다.포인트의 경우 다양한 케이스가 있습니다만, Insert & 상세 이벤트 모델로 모든 경우를 대응할 수 있게 되었습니다. 특히 이 도메인 모델로 인해 누락된 이벤트 처리가 아주 쉽게 처리 됩니다 누락되었으면 해당 이벤트를 한줄 추가만 하면 되기 때문입니다.이번 포인트 시스템의 아키텍처 기조는 DB가 죽어도 문제 없는 서비스였습니다. 이를 위해서 AWS SQS를 적극적으로 사용했습니다.이 구조로 가져가면서 얻은 장점은 다음과 같습니다.특히 포인트 시스템을 가장 중요하게 사용하는 주문 시스템과 결제 시스템도 마찬가지로 SQS로 비동기 시스템이 구축되어 있습니다.그래서 포인트의 모든 서비스가 죽는다 하더라도, 주문 시스템과 결제 시스템은 자체 SQS에 메세지를 계속 담아두고 포인트 시스템이 다시 실행되면 그때 메세지를 일괄 발송하면 되므로 고가용성 시스템을 구축할 수 있었습니다.포인트 시스템의 전체 아키텍처를 간단하게 그려보면 다음과 같습니다.이 구조에서 기본적인 이벤트 구조는 다음과 같습니다.여기서 한가지 다른 점은 포인트 사용 이벤트는 SQS를 쓰지 않고 바로 데이터베이스에 반영한다는 점입니다. 만약 포인트가 사용되는 이벤트가 즉시 처리 되지 않으면, 사용자는 서버가 메세지를 수신 받기전에 다시 같은 포인트를 사용할 수 있습니다. 이를 막기 위해 포인트 사용 이벤트는 즉시 처리되도록 구현하였습니다.DB에 즉시 반영 후, 포인트 변경이 있었기 때문에 가용포인트 갱신을 위한 SQS 메세지만 보내면 됩니다. 다만, 사용 취소의 경우 즉시 처리할 필요가 없기 때문에 기본 방식 그대로 SQS 기반으로 처리하도록 구성했습니다.스프링 배치를 통한 이벤트 처리 역시 point-edge 모듈을 통해서 처리되도록 했습니다.API, Admin 뿐만 아니라 Batch에서도 point-edge 모듈을 보게 함으로써 포인트의 모든 End Point가 point-edge에 집중되어, SQS 기반의 이벤트 아키텍처가 완성되었습니다.SQS 기반의 아키텍처 구성에 있어 가장 주의해야할 점은 SQS는 순서가 보장되지 않는다는 점입니다. 그래서 주문 한 뒤, 바로 취소를 할 경우 상황에 따라 취소가 먼저 오고, 적립이 다음에 올 수 있습니다. 이럴 경우 적립된 대상이 아직 없기 때문에 취소 이벤트는 실패하게 됩니다.이걸 해결하기 위해 취소할 대상이 없는 경우 처리하지 않도록 구성하였습니다. (다시 SQS로 돌려보낸다라는 의미입니다) 대신 5번 실패하게 되면 DLQ(Dead Letter Queue) 로 보내어 이만큼 실패했다면 진짜 잘못된 메세지로 보도록 구성하였습니다. DLQ(Dead Letter Queue) 로 빠진 메세지는 이후 확인후 오류 수정 혹은 재전송 등을 통해 후처리를 하고 있습니다.전혀 테스트 코드가 없었던 레거시 프로시저와 완전히 새롭게 변경된 도메인, 이 2가지는 개편에 있어 막연한 두려움을 주었습니다. 예상치 못했던 문제가 어디서 나올지 알 수 없었기 때문에 테스트 코드를 굉장히 빡빡하게 작성하였습니다.단위 테스트 & 통합 테스트 도구로는 Junit4와 Spock을 같이 사용했습니다. 팀에서 테스트 도구를 Spock으로 점차 넘어가는 중이지만, 아직 Junit4가 익숙하신 분이 계셔 Junit4를 사용해도 무방하다는 룰을 정했습니다. Spock을 연습하면서 프로젝트를 진행하기에는 시간이 그렇게 넉넉하지 않았기 때문입니다.단위 테스트와 통합 테스트를 모두 필수로 작성하면서 프로젝트를 진행했습니다. 단위 테스트는 필수, 통합 테스트는 선택으로 해도 좋지 않을까 싶었습니다.아직 테스트 코드와 코드 디자인에 대해서 높은 수준이 아니다보니 단위 테스트가 통과해도 통합 테스트에서 실패하는 경우가 종종 있었습니다. 특히 단위 테스트 작성을 위해 과한 Mocking과 잘못된 단위 설정등이 몇번 발생하다보니 통합 테스트도 필수로 짜서 실제 전체 프로세스를 수행해도 문제가 없는 것을 확인하는 것까지로 결정했습니다.조금 부담스럽긴 했지만, QA기간에 기본적인 기능 조차 제대로 통과 못하는 것보다는 훨씬 낫다는 생각에 결정했고 짧은 QA 일정으로 프로젝트를 끝낼 수 있었습니다.신규 포인트 프로젝트의 큰 기조 중 하나는 “Git Clone 받으면 바로 로컬 개발 환경 & 테스트가 실행될 수 있어야 한다” 입니다. 프로젝트 받은 뒤에 A도 해야하고, B도 해야하고, C도 해야만 로컬에서 실행할 수 있는 환경은 절대 하지 않기로 했습니다.하지만 이런 환경을 구축하는데 큰 걸림돌이 Spring Cloud AWS 코드의 테스트 환경 구축입니다. AWS RDS와 Elastic Cache에 대한 통합 테스트를 작성하는데는 큰 문제가 없었습니다. Embedded 솔루션들이 존재했기 때문입니다.하지만 SQS에 대한 Embedded 솔루션이 없었습니다.이 문제를 해결하기 위해서 공용 계정을 쓰면 안됩니다. 실제로 우아한 형제들에서는 자유롭게 AWS를 사용하고 테스트 할 수 있게 놀이터라는 샌드 박스 계정이 존재합니다. 보통 로컬 환경에서 AWS를 테스트할 때는 이 놀이터 계정을 맘껏 사용하는데요. 포인트 시스템 개편에서 SQS를 놀이터 계정을 이용하는건 문제가 있었습니다.개발자 A가 로컬에서 발송한 SQS 메세지가 개발자 B의 로컬에서 혹은 Jenkins등 다른 곳에서 메세지를 수신해버려 개발자 A에서는 제대로 기능을 테스트 해볼수가 없습니다. 즉, 모두가 접근할 수 있는 공용 저장소를 사용하는 순간 서로가 서로의 테스트를 침범하게 되어 격리된 테스트 환경 구축을 못하게 되버렸습니다.이건 굉장히 큰 문제라 생각했습니다. 그래서 어떻게 하면 H2, Embedded Redis와 같이 격리된 SQS를 구축할 수 있을까 고민 하던 중, ElasticMQ를 발견했습니다.Scala, Akka 기반의 Elastic MQ를 팀에서 좀 더 쉽게 사용하기 위해 Spring Boot용 랩핑 라이브러리를 만들어 사용하였습니다.이제는 의존성만 추가하면 H2 사용하듯이 SQS를 사용할 수 있게 되었습니다.(Redis로 포인트 갱신 이벤트가 제대로 발생하는지 검증하는 테스트코드)해당 라이브러리 사용후 다음과 같은 검증 문제가 모두 해결되었습니다.특히 통합 테스트의 경우 정말로 SQS 메세지 발송 혹은 수신까지가 모두 테스트 코드로만 검증할 수 있게 되어 더욱 튼튼한 테스트 구조를 만들 수 있었습니다.신규 도메인은 모두 JPA를 사용하고, 모든 로직은 어플리케이션에 있었기 때문에 H2를 사용해도 문제가 없었습니다.즉, Database에서 로직을 처리하는 password(), now(), 스토어드 프로시저 등을 전혀 사용하지 않습니다.하지만 기존 레거시 시스템의 프로시저를 검증하기 위한 테스트 코드를 작성하는데 문제가 있었습니다. H2는 MSSQL의 프로시저를 지원하지 않기 때문입니다.이 문제를 어떻게 해결할까 고민하다가 이 레거시 프로시저와 관련된 코드들을 테스트 할때만 Docker를 사용하기로 결정했습니다.그래서 레거시 프로시저용 API를 담당하시는 개발자분의 개인 PC와 지속적인 테스트를 진행할 젠킨스 서버에 Docker로 MSSQL을 설치하고 기존 시스템의 프로시저를 모두 생성했습니다.그리고 이렇게 작성한 테스트 코드와 Docker는 시스템이 더이상 이전 프로시저를 지원하지 않아도 되는 순간 일괄 삭제하여 깨끗한 프로젝트로 구성을 하였습니다.일반적으로 개발 서버에 배포된 서비스의 HTTP API 테스트는 Postman을 사용합니다. (배포 전의 테스트는 당연히 단위 테스트 or 통합테스트 코드로 진행합니다.)저희는 팀 모두가 IntelliJ Ultimate 버전을 사용하고 있었기에 IntelliJ의 .http를 사용하기로 결정했습니다. 그 이유는 아래와 같습니다.특히 HTTP API 테스트를 코드로 남긴다는 점이 중요합니다. 버전 관리, 이력 추적등등 팀 단위의 개발에서 정말 많은 장점을 주기 때문에 Postman을 선택할 이유가 하나도 없었습니다.(포인트 시스템의 .http 코드)IntelliJ의 .http에 대한 상세한 설명은 이전에 작성한 글이 있으니 참고하셔도 좋을것 같습니다.주문, 빌링, 정산, 회원, 쿠폰, 메인 프론트 등 여러 팀에서 포인트의 API를 사용해야 했기 때문에 API문서는 필수였습니다. 수동으로 작성하는 것은 언젠간 코드와 문서간에 간격이 발생해서 문서 자동화에 대해 고민했었습니다. API 문서 자동화에 관한 솔루션들은 많습니다.이 중에서 저희는 Spring Rest Docs를 선택했습니다. 나머지 문서 자동화 솔루션들에는 개인적으로 생각하는 큰 단점들이 있었습니다.Apidoc의 경우 2가지 단점이 있었습니다.Swagger의 경우도 비슷한 단점이 존재했습니다.반대로 Spring Rest Docs의 장점은 다음과 같습니다.Spring Rest Docs는 그간 제가 문서 자동화 솔루션들에 갖고 있던 불만을 모두 해결해주었습니다. 즉, 테스트가 깨지면 문서가 만들어지지 않기 때문에 잘못된 API 문서가 발행될 일이 사전에 차단됩니다. 특히, 저희 팀은 테스트 코드 작성이 팀 규칙상 필수였기 때문에 테스트 코드 기반의 문서 자동화 솔루션인 Spring Rest Docs는 아주 좋은 선택지였습니다.(Rest Docs로 만든 포인트의 API 문서)다만 단점도 있었는데요.선언되지 않은 필드는 오류로 보고 바로 테스트가 깨져버리기 때문에 모든 필드를 테스트 코드에서 선언해야만 했습니다. 이것외에는 아직까지 단점이라고 느껴진게 없으니 한번쯤 고려해보시는것도 좋을것 같습니다.Spring Rest Docs를 사용하는 방법은 크게 2가지가 있습니다. AsciiDoc과 Markdown입니다. 처음 Rest Docs를 고려했을때는 Markdown 타입을 사용하려고 했습니다. 팀 전체가 AsciiDoc 보다는 Markdown에 더 친숙하기 때문이였습니다.하지만 Markdown 버전의 Spring Rest Docs를 한번 사용해 보고는 바로 포기했습니다.그래서 AsciiDoc 버전으로 결정했습니다. 현재는 포인트 시스템의 문서 자동화가 굉장히 잘 되어서 다른 서비스인 빌링, 정산 역시 문서를 Spring Rest Docs로 전환 중입니다.Spring Rest Docs 사용 방법은 블로그에 정리했으니 참고하시면 좋을것 같습니다.저희 팀은 Git Branch 전략을 사용하고 있었습니다. 하지만 포인트 시스템을 구축하는 과정에서는 이 전략을 사용하지 않았습니다.특히 각자 진행해야할 모듈을 명확히 분리해서 구현하고 있었고, 테스트 대상도 분리되어 있어 굳리 Branch로 분리 할 필요가 없던 상태였습니다.(프로젝트 모듈 구성)그러다보니 브랜치 전략이 굳이 필요할까에 대해서 고민하게 되었습니다. 고민의 결과 저희는 단일 브랜치 전략을 선택했습니다. 즉, master 브랜치만 유지하고 모든 커밋을 master에만 하였습니다. (물론 현재는 Git Branch 전략을 사용중입니다.)해당 전략으로 진행하면서 특별히 문제가 느껴진게 없었습니다. 꼭 알려진 Branch 전략들을 선택하지 않고, 상황에 따라 유동적으로 정해도 되겠다는 것을 깨닫게 되었습니다.포인트 시스템 개편기 1탄이 마무리 되었습니다! 이 시리즈는 2탄까지 있습니다.(야호)다음편에서는 성능테스트, QA, 서비스 다운 없는 신규 시스템 교체 등등이 포함될 예정입니다! 2편도 기대해주세요! 감사합니다.",http://woowabros.github.io/experience/2018/10/12/new_point_story_1.html,woowabros,"mysql,php,mongodb,java",NULL,2018-10-12
Real-time Service Configuration으로 Consul을 신주소 서비스에 적용한 사례,"안녕하세요. 배민프론트서버개발팀 박제현입니다.주소 검색 서비스를 개선하면서 Real-time Service Configuration으로 consul을 적용한 사례를 공유하고자 합니다.먼저 제가 속한 팀부터 소개해볼까 합니다.저희 팀에는 고객과 밀접하게 운영되고 있는 서비스가 많다 보니 쉽게 개선하기 어려운 레거시 시스템이 많은데요.맘 같아서는 쉽게 수정해서 바꿔버리고 싶지만, 한 부분만 고치려 해도 여러 군데 엮여있어서 작업이 쉽지 않습니다. 그러다 다른 우선순위에 밀려 개선하지 못하는 사이 그 시스템에서 장애가 빵 터지는 경우가 많죠. ㅠㅠ어느 날, 팀 회식이어서 쌀통닭을 맛있게 냠냠하고 있었는데 주소 검색 서비스에 장애가 났다고 마구 알림이 떴습니다. ‘주소 검색이 안 된다고??? 왜???’ 하면서 급하게 노트북을 꺼내서 살펴봤는데…저희가 해결할 방법이 없었습니다.주소 검색 서비스는 A사의 지도 API에 전적으로 의존하다 보니, 당장 사용자들이 배달 주소지를 설정하지 못해 불편을 겪는 상황에서도 A사에서 장애 상황을 해결할 때까지 발만 동동 구르고 있었죠.   그러던 중 갑자기 의문이 들었습니다.“진짜 우리가 할 수 있는 게 아무것도 없을까?”위 이미지의 내용은 김범준 부사장님께서 장애 후속 조치와 관련하여 개발 조직 전체에 보내신 메일을 캡쳐한 부분입니다.네. 우리는 계속 겪는 장애에서 배워나가야 합니다. 장애가 발생할 가능성이 남아있는 서비스에서 장애가 해결되었다고 ‘이제 잘 되겠지’라는 막연한 생각으로 넘어간다면, 그 문제는 나중에 더 큰 장애로 큰 타격을 줄 겁니다.반복되는 A사 Map API 장애에도 우리 서비스는 정상 작동해야 합니다. 우리 서비스가 외부서비스에 영향을 받아 문제가 생기더라도 짧은 시간 내에 다시 정상으로 복구되어야 합니다.이 장애를 통해 우리는 한 발자국 더 나아가야 합니다.언제 또 장애가 발생할지 모르는 불안한 상황이지만 정신 똑띠차리고, 주소 검색 서비스와 단기적 과제를 먼저 정리합니다.조사해보니 B사 Map API에는 A사의 Poi API 역할을 하는 API가 없었습니다. 이럴 수가..따라서, B사 Map API 3개를 조합하여 A사의 Poi API와 같은 데이터를 내려주도록 작업을 해야 합니다. 또한, Response는 A사의 Poi API를 사용할 때와 같도록 Converting 작업을 꼭 해주어야 합니다.아… 너무 복잡하고 진행도 잘 안 되는 어려운 작업이었는데요. 설명하기조차 괴로우니 과감히 설명을 생략하도록 합니다.^^힘들게 작업한 B사 Map API 주소 검색 서비스를 새로운 Target Group에 배포합니다. 이렇게 설정해두면 ALB에서 우선순위만 변경해서 바로 B사 Map API로 전환할 수 있게 되는 거죠.이후 A사 Map 서비스의 방화벽 작업 등의 순단현상이 발생할 수 있는 상황에서 B사 Map API로의 전환을 통해 순조롭게 상황을 넘길 수 있었습니다. 마음 한편의 불안감이 잠시나마 해소되었죠!하지만 여전히 A사 Map API에 장애가 발생하면 AWS에 접속해서 Target Group을 마우스 클릭으로 변경해야 합니다.   음…아직 뭔가 후련하지가 않습니다.본격적인 과제 논의를 위해 팀원분들께 미팅콜을 마구 날려봅니다. (띵동띵동)팀원분들의 도움으로 장기적 과제 목록이 챡챡 정리되었습니다.하..이 어려운 걸 하라고 하시네요ㅠㅠ잠깐 몇 가지 정리 좀 하고 갈까요? 간단히 조사를 좀 해봤습니다. 아무것도 모르는 상태로 진행하면 개발이 산으로 갈 테니까요!RCS란 Client에서 필요한 환경구성 속성들을 외부에 저장하고 관리하는 서버입니다.환경설정 속성들은 주로 dev, beta, prod 등과 같이 여러 개의 프로파일로 운영됩니다. 이런 속성들은 마이크로서비스 인스턴스가 많을 땐 관리가 어려워지는데요. 이 속성들을 외부화하고 중앙 집중화해서 여러 환경에 배포되는 Client에 적절하게 사용할 수 있습니다.또한, 안정적인 배포를 위해서도 Feature Toggle을 많이 사용하는데요. 새로운 기능을 배포할 때 해당 기능의 ON/OFF 상태를 즉시 변경하는 데에도 사용할 수 있습니다. 이를 real-time으로 변경하기 위해서 고가용성의 Configuration Management를 사용합니다.Run-time Service Configuration 서비스에는 feature flags 또는 maintenance mode와 같이 실시간으로 전파되어야 하는 많은 런타임 구성이 있습니다. configuration management를 사용하거나 서비스를 재배포하여 이러한 업데이트를 진행하기 위해서는 몇 분에서 몇 시간이 걸릴 수 있습니다.  이러한 Rollout 기간 동안 인프라가 동기화되지 않고 서비스 구성이 올바르지 않을 수 있습니다.Real-time Service Configuration 전 세계에 분산되어있는 수많은 서비스에서 실시간으로 서비스 구성을 업데이트할 수 있습니다.  Configuration은 계층형 Key/Value Store에 저장되며 효율적인 Edge Trigger는 응용 프로그램에 대한 변경 내용을 신속하게 푸시하게 됩니다.장기적 과제라고 여유 부리면 안됩니다. 해야 할 작업이 많아요. ㅠㅠ전체 아키텍쳐 입니다. 하나씩 순서대로 설명을 해드릴요.제 설명이 많이 부족해서 이해가 잘 안 될 수도 있습니다. ㅠㅠ 아래 설명들을 더 보시면 이해가 되실 거예요! 이제 아키텍쳐 흐름 순서대로 구현을 해보도록 합니다.아! RCS 서비스의 이름을 정해봤는데요. 시시각각 자유자재로 피부를 변화시키는 카멜레온의 이름을 따서 카멜레온 서비스라고 팀내 명칭을 통일했습니다. (나중에 알았는데 Netflix의 Archaius도 카멜레온의 한 종류의 이름을 따온 거라네요!)Jenkins Job을 생성 String Parameter 설정 GitHub hook trigger 체크 Shell script 설정 OutboundListenersHealth CheckTags 추가A사 Map API는 “내비게이션 용”이고 B사 Map API는 “검색용” 이어서 추상화하기에는 많은 어려움이 있었는데요. 백업 Plan으로 B사 Map API를 도입하면서 구현했던 로직을 참고하여 A, B 사의 Map API를 추상화했습니다.Flow Sequence Diagram 마지막으로 환경 구성 정보 변경 시 Client Service에 적용되기까지의 시간을 테스트해봤는데요. 목표했던 1분보다 더 빠르게 적용됨을 확인할 수 있었습니다!Client Service에 환경 구성 정보가 변경되어 AMapService 100%를 BMapService 100%로 적용되기까지 시간 측정드디어 주소 검색 서비스를! PHP 레거시의 일부를! JAVA로 전환했습니다!!! 주소 검색 서비스 외에도 여러 도메인을 JAVA로 전환하고 있는데 노하우가 생기는지 점점 속도가 붙고 있습니다. 아! 그리고 PHP가 안 좋은 언어라서 JAVA로 변경하는 것은 아닙니다! 오해는 없었으면 좋겠네요.^^ 할많하않;제 글은 여기까지입니다.긴 글 읽어주셔서 감사합니다.",http://woowabros.github.io/tools/2018/10/08/location-service-with-rcs.html,woowabros,,NULL,2018-10-08
"새로운 오피스, 작은집","안녕하세요무더운 폭염과 장마가 지나고 난 후 벌써 선선한 바람이 부는 계절 어느덧 가을이 훌쩍 다가왔네요.아침 저녁으로 일교차가 크네요, 여러분들 모두 감기 조심하세요~오늘은 우아한형제들의 새로운 오피스 공간에 대해서 소개해dream~‘사옥을 이동 했나요?’아닙니다~대부분 저희 우아한형제들의 사옥은 ‘몽촌토성역’ 에 있는 사옥을 떠올리시겠지만,새로운 구성원들이 더욱 더 늘어남에 따라 새로운 오피스에 대한 니즈가 생기게 되었지요.그리하여, 2018년 7월 16일 개발 조직과 일부 구성원이 ‘삼성생명 잠실빌딩’ 으로 새로 입주 했어요~!잠실역 2호선 8번 출구 약 200m에 있기 때문에 출퇴근에 아주 용이하고, 사무실 통유리로 보이는 롯데타워가 한눈에..(잠실역 8호선 9번 출구에서는 약 100m 거리라는건 안 비밀~)기존에 몽촌토성역에 있는 우아한형제들이 입주해있는 사옥은 ‘큰집’이라고 하구요이번에 저희가 새로 입주하게 된 곳은 ‘작은집’ 입니다~저희 작은집의 인테리어는 우아한형제들의 공간디자인실과 디자인팀에서 직접 디자인과 설계를 맡아 진행 했습니다.참고로 “큰집” 역시 입주 당시에 저희 공간디자인실과 디자인팀에서 공간 디자인을 진행 했었는데요,2018 IF (Interior Architecture) Design Award의 Office/Work Space부문에서 혁신성을 인정 받아명성있고 권위있는 디자인 어워드에서 상을 받았었다는 사실~레알~팩트~트루~“우아한 오피스”큰집에 이어 이번 작은집까지 디자인 설계를 직접 했다고 하니 너무 기대되지 않아요?우아한형제들의 ‘큰집’ 디자인 당시 올림픽공원 건너편에 자리한 만큼각 층당 혁신을 이룬 스포츠인 들을 컨셉으로 잡아 디자인 하였는데요, 못보셨다면 ▶랜선 집들이 클릭작은집 역시 제한된 면적에서 어떻게 하면 효율적으로 모두에게꼭 필요한 공간의 면적을 확보하고, 최대한 효율적인 공간을 만들 수 있을까를 고민 했다고 합니다.또 우아한오피스의 가장 큰 매력인 코워킹 스페이스 공간을 더욱 신경 써 디자인 했고,그래서 더 쉽고, 더 창의적이며, 더 깊은 커뮤니케이션을 '작은집'에서도 하고 있습니다.'공간은 넓지 않지만 생각은 넓다'“네, 저희는 자리에 혼자 앉아있는 것을 별로 좋아하지 않아요. 구성원이 한군데서 일하는 것을 지양하고, 계속해서 노트북을 들고 여기저기 왔다 갔다 하면서 일하는걸 지향해요. 기존의 회사들은 자기 자리에 앉아서 오랫동안 있으면 일을 열심히 한다고 생각 하지만, 저희는 ‘저 사람 왜 대화를 하지 않을까?’ ‘저 사람들은 왜 섞여서 일하지 않을까?’ 이렇게 재밌는 공간들이 많은데 왜 다이나믹하게 움직이지 않지? 이런 생각들이 들죠.”""우리의 공간은 넓지 않습니다. 그래서, 우리의 생각은 더 넓어질 수 있었습니다.""끊임 없는 혁신 마인드를 계속해서 잊지 않기 위해 큰집과 동일한 ‘스포츠 혁신가’를 테마로 잡아각 층별 개성 넘치는 컨셉을 더해 매력적인 공간으로 구성 했습니다.오브라이언 투구덕다이빙롱스트로크양1/양2/양3본레스………위 명칭들은 뭘까요 ?바로~ 작은집의 각 층별 회의실 명칭 입니다.그리고, 실제로 해당 스포츠 종목에 혁신을 더한 기술 명칭들이자 회의실명 입니다.아래 사진을 자세히 보시면 회의실 명 아래에 이세상 모든 맛있는 음식들을 찾는 쏠쏠한 재미까지 ㅋㅋㅋ(가끔씩 점심 뭐 먹을지 고민할 때 저기서 찾으면 꿀잼)뿐만 아니라, 앞에서 잠깐 말씀 드렸던 코워킹 스페이스 View도 보여드릴께요아.. 짠내나는 투어를 다니는 프로그램에서 유민상씨가 했던 말이 생각 나요.정말 절경이네요정말 장관이고요~정말 신이 주신 선물이네요.(어느정도 길래?)첫번째 사진과 두번째 사진 월드타워와 교통회관이 보이는 곳은 특히 저 역시도 아주 좋아하고모든 구성원 분들도 좋아하는 빈백이 깔려있는 코워킹 스페이스에요!빈백에 기대어 업무를 하기도 하고, 쉬고 싶을때에도 빈백에 누워 통유리 바깥으로 보이는 뷰가정말 절경이구요, 장관이구요, 신이 주신 선물 같은 느낌!ㅋㅋㅋ그리고 회의실이 아니더라도 어디에서든 구성원들과 편안히 앉아서 퀵 미팅을 진행할 수 있도록코워킹 스페이스 곳곳에 퀵 미팅 데스크가 있다는 사실!아직 끝이 아니죠! 각 층별 컨셉이 각각 다른 공간이므로 층별 사진들을 조금 더 보여 드릴께요한가지.. 혹시 이 사진에 특별한 점을 발견 하신 분? 보시다시피 이 사진은 앞에서 보신 것 과 같이 코워킹 스페이스 인데요,저희 작은집에 있는 여러 구역의 코워킹 스페이스 중 이 곳은 바로 높낮이 조절이 되는 “모션 스탠딩 데스크” 라는 점 !(책상이 전부 다 높이가 다르죠?)앉아서 일하다 보면 특히 허리가 뻐근하죠.. 저 역시도..다른 구성원과 함께 코워킹 할 때 물론 눈 높이를 맞추고 친근하게 코워킹을 하기에도 정말 좋구요,때로는 혼자 서서 일하고 싶을 때 다들 한번씩 있잖아요? 그리고 졸릴때도 좋아요 (소곤소곤)이번엔 업무공간에 대해서 짤막히 소개 할까 해요.이 곳 작은집은 특히 기획/개발 구성원들이 업무 하는 엄연한 R&D 센터이기에업무공간 사진은 많이 보여드리기 어려운 점 양해 부탁 드립니다 ㅠ_ㅠ잡담을 많이 나누는 것이 경쟁력이다.두번째 사진은 저희가 우아한 테크캠프 2기를 진행 할 당시의 업무공간이에요~(우아한 테크캠프가 궁금하시다면? 클릭)혹시 다른 회사들과의 업무공간과 다른 점을 눈치 채셨나요?…바로 파티션이 없다는 거에요. 업무 공간의 책상에 파티션이 없기 때문에저희는 바로 옆 동료와, 앞에 있는 동료와, 대각선에 있는 동료와 모두고개만 돌려도 바로 이야기할 수가 있어서 더욱 더 빠른 의사소통과 업무 협업이 가능해요!또 멀리에 있는 동료와도 바로 의견을 나누고 하고 싶은 얘기가 있다구요?우리는 곳곳에 비치 되어 있는 이 스툴을 가지고 직접 동료 옆 자리로 가서 바로 얘기를 나눠요!다음 공간은 구성원들에게 편안한 휴식을 주는 휴식 공간 입니다.휴게실은 남/여 별도로 휴게실이 각각 있고, 캡슐방, 안마의자, 샤워시설로 구성 되어 있어요.업무시간 혹은 점심시간에 피곤할 때 잠시 꿀잠을 잘 수 있어요~(온돌방과 매트리스방으로 반반 나눠져 있는 건 안비밀)이 곳은 저희 작은집에 방문하실 경우 제일 먼저 만나게 되는 얼굴이자 입구 입니다.안으로 들어가볼까요 ?이곳에서는 면접을 볼 수 있는 면접실과, 카페, 교육장, IT헬프데스크, 그리고 양평 같은 방 이 있는 곳이에요!‘양평같은방?’ 궁금하죠? 가장 마지막에 보여 드릴께요!먼저 문 안쪽으로 들어오게 되면 초록초록 벽이 산뜻하게 맞아주는데요,그거 아세요?…..심지어 전부 다 살아있는 생화 라는점…게다가 펌프 방식으로 이용해 위에서 아래로 물을 흐르게 하여 24시간 내내 관리가 된다는 점!굉장하죠. 아직 놀라긴 일러요, 다음으로 여러분을 맞이할 것은 바로 바로바로 로봇 커피머신 ! (Feat.달콤커피)이 로봇이 만드는 커피 맛은 의외로 기대보다 이상이라 아주 인기가 많구요,심지어 어플로 주문 하기 때문에 자리에서 주문 하고, 잠시 후에 Pick up 번호 4자리를입력하면 본인이 주문한 음료를 픽업 가능 하다는 점~~ 기다리지 않아도 된다구요~더군다나 방문하신 손님은 FREE!!우아한형제들에 면접을 보러 오신 분들을 위한 선수대기실 입니다.면접실은 총 5개가 있고, 면접을 앞두고 긴장하고 계실 면접자분들을 위해대기실에서 대기 후 편한 마음으로 면접을 볼 수 있도록 배려 하고 있습니다.캔 아이 핼퓨?그리고 면접실을 지나 한쪽편에는 임직원 분들의 자산 지급과 수리 등을 위한IT 헬프데스크 공간이 마련 되어 있습니다.다음, 만나볼 곳은 교육장과 회의실 공간인데요,개방감을 준 회의실과 행사 또는 교육 컨퍼런스를 진행 하기에도 부족하지 않은 교육장 입니다.사진으로 먼저 만나요 +_+보시다시피 답답하지 않고 개방감을 만끽하며 기분 좋게 회의를 할 수 있습니다~그리구 교육장은 구성원 누구나 교육 또는 회의를 위해 이용 가능하며,때로는 큰 규모의 타운홀 미팅 과 컨퍼런스 진행에도 부족함이 없습니다.김봉진 대표님과 김범준 CTO님께서 강연 세션을 진행할 당시의 사진입니다.잊어버릴 뻔 했네요! 마지막으로 소개해드릴 ‘양평 같은 방’ 입니다.여러분들 펜션 하면 어디가 생각 나세요? 양평? 가평?우아한형제들에는 양평과 가평이 모두 있습니다. (ㅋㅋㅋㅋ)큰집에는 ‘가평 같은 방’ 이 있고, 작은집에는 ‘양평 같은 방’ 이 있다는 사실…뭐하는 방인지 궁금하죠? 눈으로 확인하시길~엄훠놔~ 엄청나게 고급진 가정집? 아니쥬… 회의실이에요ㅋㅋㅋ일반적인 회의실은 아니지만, 업무 목적의 팀 워크숍, 혹은 마라톤 회의,동동동 모임 ( 동 아리 같은 동 아리 아닌 동 아리 같은 모임) 등의 활동을 하고자 할 때 사용 가능 한 회의실이에요.‘양평 같은 방’은 어떤 건지 한번에 느낌 딱 왔쥬? :D우아한형제들의 피플팀에 사전 신청 후 승인 받아 사용 가능한 공간 이라는 점!이곳에서 회의를 한다면 엄청 설레일 것 같아요.. (사실 저도 아직 안해봤다는건 비밀)이렇게 양평 같은 방을 끝으로 저희 우아한형제들이 새로 입주한 오피스 공간에 대해서 소개 해드렸는데요,사실 처음엔 어디서부터 어떻게 소개를 해야 할지 굉장히 막막 했어요.저 역시 여러분들께 소개해드리기 위해서 이곳 저곳 다시 돌아보며새로 입주한 오피스 공간에 대해서 또 알게 되고,배민다움에 대해 또 다시 많은걸 느낄 수 있는 시간이어서 너무 좋았습니다~저는 ‘멋진하루’를 매일매일 이 곳에서 느끼고 있습니다.여러분들도 느껴보시는 건 어떠세요?▶채용 공고 보러가기",http://woowabros.github.io/woowabros/2018/09/18/introduce-small-home.html,woowabros,,NULL,2018-09-18
JDBC로 실행되는 SQL에 자동으로 프로젝트 정보 주석 남기기,"이 글은 Java기반에서 JDBC와 이를 기반으로 한 Persistence Framework를 이용해 SQL을 실행할 수 있는 개발자를 대상으로 모든 JDBC를 통해 실행되는 SQL 구문에 애플리케이션 정보를 주석으로 넣는 법을 설명합니다.보통 Monolithic 아키텍처로 프로젝트를 진행하게 되면 모든 데이터를 하나의 데이터베이스에 다 넣는 방식으로 개발을 하게 됩니다. 서비스가 계속 Monolithic으로 유지 가능한 수준이라면 상관없지만 운 좋게도 폭발적으로 성장하여 버틸 수 없게 되면 마이크로서비스 아키텍처로 하나씩 분리를 하게 됩니다.이때 한 번에 모든 데이터베이스를 각각의 마이크로서비스에서 한 번에 나눠서 가져가면 좋겠지만 공통 데이터베이스에서 완전히 벗어나기에는 상당히 오랜 시간이 걸립니다.이 긴 고통의 시간 동안에 매우 많은 문제가 발생하게 됩니다.여러 프로젝트에서 하나의 공통 DB에 쿼리를 날리다 보니 어느 팀의 누군가가 인덱스 안 타는 쿼리를 잘못 짜거나 혹은 대규모의 데이터를 읽어들이는 Batch 성 작업을 수행했을 때 공통 DB는 CPU 100%를 치게 되고 고객들은 하염없이 기다려야 하는 일이 매우 자주 발생하게 됩니다.이때 빠르게 어떤 프로젝트의 쿼리가 문제를 일으켰는지 찾아내면 좋습니다만, 이게 그리 쉽지가 않습니다. IP 주소가 있더라도 그 IP의 서버에 가서 어느 팀의 무슨 프로젝트 서버인지를 확인하는 등의 복잡도가 추가됩니다.그래서 모든 SQL의 맨 앞에 어느 팀의 무슨 프로젝트에서 온 요청인지를 주석으로 남겨두면 느린 쿼리 로그를 보자마자 조금이라도 빠르게 해당 팀을 찾아가 문제를 해결할 수 있지 않을까요?사실 이에 관한 글을 몇 년 전에 쓴 적이 있습니다. JDBC SQL 구문에 클라이언트 정보 남기기 하지만 이 글은 Hibernate 그리고 MySQL JDBC 드라이버에 국한한 기법이었습니다.배달의 민족은 최소 두 가지 이상의 데이터베이스를 사용하며 Persistence Framework도 Hibernate, jOOQ, QueryDSL, MyBatis, Spring JDBCTemplate 등 다양하게 사용 중입니다.따라서 좀 더 보편적인 해결책이 필요합니다.Java의 데이터베이스 접속과 실행에 관한 API들(JDBC)은 DataSource, Connection, Statement, PreparedStatement 등의 인터페이스로 잘 추상화돼 있습니다.실행되는 SQL 구문이 결정되는 순간은 Connection.prepareStatement(""SQL 구문"") 이때거나, 혹은 Statement.execute(""SQL 구문""), Statement.executeQuery(""SQL 구문""), Statement.executeUpdate(""SQL 구문"") 이 정도입니다(사실 더 있지만…).Java의 모든 Connection Pool은 DataSource 인터페이스를 구현하고 있습니다.여기서 간단한 아이디어가 도출됩니다.처음부터 모든 Proxy를 직접 구현해도 상관은 없겠으나 좀 더 쉽게 가는 방법을 찾아보았습니다.Tomcat JDBC Connection Pool은 Tomcat과 함께 개발되고 있는 커넥션 풀로 HikariCP와 함께 요즘 가장 많이 사용되며(SpringBoot 1.x의 기본 커넥션 풀) 성능도 준수한 편입니다.이 Connection Pool에는 JDBC Interceptor라는 개념이 있습니다. 커넥션풀에서 자체적으로  DataSourceProxy와 ConnectionProxy를 제공해주고 SQL 실행을 가로채서 slow query 로그를 남기는 등의 일을 할 수 있습니다.문서를 보면 기본적으로 유용한 Interceptor 들을 몇 가지 제공해주고 있습니다.저는 일을 간단히 끝내고자 Tomcat JDBC Connection Pool을 사용하고 SQL 구문을 가로채어 설정한 프로젝트 이름을 주석으로 맨 앞에 넣어주는 JDBC Interceptor 를 만들었습니다.해당 소스코드는 woowabros/tomcat-jdbc-pool-sql-caller-info-comment라는 github 저장소에 공개해 두었습니다.실제 코드는 파일 한 개이므로 사용하실 분들은 SqlCallerInfoCommentInterceptor.java 파일을 복사하여 자신의 프로젝트에 넣고 Tomcat JDBC Connection Pool을 만들어주시면 됩니다.Spring Boot에서 YML로 설정한다면 다음과 같겠네요. baemin_in_woowabros 대신 자신이 넣고 싶은 정보를 넣습니다.혹은 Java Code로 직접 설정한다면위와 같이 설정하면 모든 SQL 구문은 맨 앞에 /* baemin_in_woowabros */ SELECT .... 형태로 주석이 붙은 상태로 전송됩니다.혹시나 몰라 SQL Injection에 대비하여 영문자/숫자/밑줄 등만 가능하게 하였습니다. 하지만 이 부분은 원하는 대로 코드를 변경해서 한글을 넣게 하셔도 무방합니다.tomcat connection pool의 JDBC Interceptor는 org.apache.tomcat.jdbc.pool.JdbcInterceptor를 상속해서 구현해야 합니다만, 또 귀찮으므로 최대한 많이 구현된 기본 구현체인 org.apache.tomcat.jdbc.pool.interceptor.StatementDecoratorInterceptor를 상속하였습니다.StatementDecoratorInterceptor는 기본적으로 DataSource Proxy와 Connection Proxy까지는 돼 있기 때문에 Connection.prepareStatement 메서드와 일반 Statement 생성시 SqlChangeStatementProxy라는 객체를 생성해주고 그 안에서 Statement.execute 등...이 호출될 때 SQL을 가로채어 바꿔치기하게 하였습니다.주석으로 프로젝트를 넣는 방법은 사용법이 너무나 간단하지만, 실제로 문제가 발생했을 때 상당한 도움을 줄 것으로 생각됩니다.여러 애플리케이션이 사용하는 공통 DB가 있다면 Java를 사용하지 않는 프로젝트라도 이런 기능을 만들면 좋을 것 같고, 그게 안 되더라도 직접 주석으로 DBA가 알아보고 바로 연락할 수 있는 정도의 주석을 SQL 앞단에 남겨주는 습관을 지니는 것이 좋을 것 같습니다.귀찮은 일을 줄이려고 Tomcat JDBC Connection Pool의 JdbcInterceptor를 사용하게 했더니 설정은 참 쉽지만, 코드를 이해하는 것은 오히려 더 어려워진 것 같습니다. 어디까지가 JdbcInterceptor가 해주는 것이고 어디부터가 직접 구현한 것인지 경계가 명확히 안 드러나 보여서 두 코드를 다 이해해야만 하게 되었습니다. 저도 막상 글을 쓰려고 코드를 다시 보다 보니 매우 헷갈립니다.DataSource 부터 모두 직접 Proxy를 만들어보는 것도 좋은 공부가 될 것 같고, 오히려 코드가 더 간결해질 것 같습니다. 또한 특정 Connection Pool에 의존하지도 않고요.저는 안 했지만 누군가는 하실 거라 믿으며… / 어서 빨리 DB 독립을 꿈꾸며 광복절 다음 날…긴 글 읽어주셔서 고맙습니다.",http://woowabros.github.io/tools/2018/08/16/jdbc-log-sql-projectinfo.html,woowabros,"mysql,php,angular,java,python,spring,android,react",NULL,2018-08-16
나를 술푸게 하는 고민들,"안녕하세요, 배민프론트서버개발팀의 개그 신동이자 귀염둥이 이신은입니다.저는 작년 12월 신입 개발자 공채를 통해, 백엔드 개발자로 우아한형제들에 합류했습니다. 취업준비생에서 7개월 차 삐약삐약 병아리개발자가 된 지금까지, 지난 1년을 돌아보며 제가 했던 고민을 나누고자 합니다. 한글보다는 수식이나 JAVA 언어로 표현하는 것이 더 편한 수학전공 개발자이지만, 저의 의도가 왜곡되지 않고 이 글을 보시는 분들에게 잘 전달되기를 바라며 펜을, 아니 키보드를 두드립니다.요즘 취업준비생들은 적게는 1~20개, 많게는 100여 개의 이력서를 제출합니다. 이력서를 제출한 모든 회사에 전력투구할 순 없을뿐더러 채용일정이 겹치는 경우가 왕왕 있기 때문에, 자신의 기준에 따라 회사들의 우선순위를 매기게 됩니다. 물론 서류, 인·적성/코딩테스트, 면접 등의 단계를 거치면서 이 우선순위가 뒤바뀌는 경우도 많죠.우아한형제들의 입사를 확정했을 때 저는, 취업준비 시작부터 거의 마지막까지도 최우선으로 생각했던 회사에 최종합격한 상태였고, 합숙면접까지 거쳐서 힘겹게 올라간 회사의 임원면접을 앞둔 상태였습니다. 자랑하고 싶어서 밝히는 것이 아니라, 이러한 상황에서 한 치의 망설임도 없이(사실 약간 망설였…) 우아한형제들을 선택한 이유를 얘기하려고 합니다.배달의민족 서비스는 알고 있었지만 한 번도 이용해보지 않았고, 4년 동안 (망령처럼) 연구실에만 틀어박혀 있던 대학원생에겐 너무나도 생소했던 우아한형제들이라는 회사 이름…. 광고 쪽 일을 하던 선배에게 신입 개발자 공채 소식을 전해 들었을 때만 해도, ‘내가 고작 배달 앱 만들려고 머리카락까지 빠져가면서 연구했나?’  라는 생각이 들더군요(건방이 극에 달했…). 밑져야 본전이라는 생각으로, 회사 이름을 가볍게 검색해보다가 낯익은 이름을 발견했습니다. 꽤 오래전 어떤 경로에서였는지 기억나진 않지만, 김범준 CTO님의 개인 블로그를 방문한 적이 있었습니다.나는 하나의 기계에서 어떻게 하면 최적화할 지를 고민하면서, 연속해서 읽어야 할 데이터는 X, X+1 주소에 저장하는 것이 아니라 memory bus bottleneck를 막기 위해 X, X+8에 저장해서  읽어 내고 있고, lock만 하더라도 spinlock을 쓸 지, readers-writer lock을 쓸 지, 그리고 lock을 거는 단위도 hash bucket head에 걸 때와 실제 hash bucket node에 걸 때를 구분해서 쓰고 있는데, 구글은 그런 류의 최적화가 아니라 몇 천대, 몇 만대의 서버를 분산 시스템으로 연결해서 서비스를 제공하고 있던 것이다. 그 순간 내가 하는 고민들이 너무 국지적인 최적화에 대한 고민이 아닐까 하는 생각과 내가 지금 열심히 쌓아 올린 지식들이라는 것이 상당히 많은 부분 쓸모없어질지도 모른다는 생각, 그리고 앞으로의 변화에 적절히 대응하지 않으면 도태되어 버릴 것 같다는 생각이 들었었다.[출처: 김범준 블로그]당시에 저도 대학원에서 통신 미들웨어 연구를 하면서 비슷한 고민을 하고 있었습니다. ‘내 연구가 시대의 흐름에 너무 뒤처지는 것은 아닌가?’, ‘내가 연구하던 프로토콜이 아닌 MQTT 및 CoAP가 IoT 표준, 이른바 대세 프로토콜이 되었다는데…. 앞으로 내가 해야 할 것은 무엇이지?’. 개인적으로 고민이 많은 편인데, 고민은 부정적인 것이 아니라 더 생산적이고 의미 있는 결과를 만들 수 있는 긍정적인 것이라고 생각합니다. 물론 좋은 결과를 만들기 위해서는, 고민하는 데 그치지 않고 해결하고자 하는 의지가 수반되어야 하죠. 따라서 지금 어떤 고민을 하는 건, 절대적으로 안 좋은 상황이 아니라 성장하고 있는 과정이라 믿고 있습니다.CTO님의 개인 블로그 글을 다시 찾아보면서, ‘이렇게 자아 성찰을 게을리하지 않으시는 분(게다가 엄청나게 똑똑하신 분! 딸랑딸랑)이 수장으로 계시는 개발조직은 어떤 모습일까?’ 하는 호기심이 생겼습니다. 면접을 앞두고 찾아보았던 기술 블로그에 있는 서비스와 기술에 대한 고민 그리고 면접 자리에서 마주한 면접관님들과의 심도 있는 대화를 통해, 호기심은 어느새 확신으로 바뀌어있었습니다. 다른 회사의 많은 개발자 또한 우리와 비슷한 고민을 하며 다양한 방식으로 성장하고 있을 것으로 생각합니다. 하지만 혼자 숨어서 하는 고민이 아니라 드러내놓고 공유하며, 자신만의 방식을 찾아내고 회고하는 모습이 제겐 참 인상적이었습니다.[내가 겪은 우아한형제들 인지도의 현주소]회사에 대한 어르신들의 낮은 인지도, 신입은 무조건 큰 회사를 가야 한다는 생각 등으로 인한 주변의 우려들이 있었지만, 제 선택을 좌지우지할 만한 요인들은 아니었습니다. 입사한 지 7개월이 지난 지금, 그 선택에 아주 만족하고 있습니다 :) 아직 회사 뽕에 취해있어서 그런가?우아한형제들에 입사하자마자 2개월 동안 신입 개발자 교육을 받은 후, 배민프론트서버개발팀에 배정받았습니다. 저는 분명 백엔드 개발자로 입사했는데, 프론트라는 단어를 듣고 직무가 바뀌었거나(프론트엔드를 교육해주셨던 코드스쿼드 크롱님이 Pick Me?) 행정 오류일 것으로 의심했습니다. 사실 팀 배정을 받기 몇 주 전에, 가벼운(줄 알았던) 식사 자리에서 CTO님께 ‘어떤 팀에서 어떤 일을 해보고 싶은지’  에 대한 질문을 받은 적이 있습니다. 신입 개발자 교육은 외부 전문기관에서 진행했기 때문에, 회사의 조직도도 모르고 각 팀의 R&R도 모르던 상태라 당당하게 평소 생각을 말씀드렸죠. “많은 일을 하면서 빨리 성장하고 싶고, 배달의민족의 (엄청난) 트래픽을 경험해보고 싶습니다! 정적인 팀은 제게 맞지 않죠. 우후훗”. 이 트랩 대화가 팀 배정에 지대한 영향을 미치리라고는 미처 생각하지 못한 채, 해맑은 얼굴로 초밥을 참 맛있게 먹었더랬습니다.그렇게…. 저는 그토록 꿈꾸던(?) 팀의 일원이 되었고, 팀장님과의 첫 미팅에서 ‘바빠서 못 챙겨주니 알아서 잘해라’ 는 막말 조언을 듣게 됩니다. 여기가 술을 퍼마시게 된 별 다섯 개의 뽀인트! 사실 말씀은 그렇게 하셨지만, 팀원들이 아마 팀장님만 빼고. ㅋㅋㅋ 많이 챙겨주셨습니다. 저를 왜 이 팀에 보내셨냐고 나중에 항의 여쭤봤더니, ‘그 팀에서 살아남을 신입이 신은님밖에 없을 것 같았다’ 며 어째서?!!! 왜?!!! 위로 아닌 위로를 해주셨던 CTO님.배달의민족 앱을 실행하면, 처음 호출하게 되는 것이 바로 우리 팀에서 제공하는 API들입니다. 가장 앞단에 위치하다 보니 트래픽에 적극적으로 대응해야 하는 것은 필수 불가결한 사실이고, 앱에서 필요로 하는 API들을 제공하는 역할이다 보니 하나의 도메인을 깊게 파고들기보다는 다양한 도메인을 동시다발적으로 진행해야 하는 경우가 많습니다.  [우리 팀에서 제공하는 일부 API들 - 배너 및 카테고리 / 이런 것도 배달돼요?! / 주소]처음에는 특정 도메인의 신규 로직을 개발하는 업무가 제게 주어졌지만, 시간이 지나면서 점차 운영 이슈와 장애 대응, 여러 도메인으로의 업무 확장이 진행되고 있습니다. ‘신입이라는 이유로 계속 단순 업무만 주고 중요한 업무에서는 배제하는 거 아닐까?’  하는 제 고민은 보기 좋게 빗나갔죠 :) 아직 인프라 지식이 부족하기 때문에 트래픽 이슈를 다루기도 너무 어렵고, (멀티코어를 장착하고 싶은 싱글코어러이다 보니) A를 개발하다가 급하게 B를 처리해야 할 때 Context Switching이 신속 정확하게 이루어지지 않습니다. 이럴 땐 ‘정말 개발자를 그만둬야 하나?’, ‘난 역시 개발자와 맞지 않아’, ‘무슨 부귀영화를 누리겠다고 서비스 회사에 들어왔나?’ 싶은 고민과 좌절을 경험합니다. 그렇지만, 배포에 성공했을 때, 어려운 업무를 해냈을 때, 동료들이 기술에 대한 조언을 구할 때, 기획자에게 감사 인사를 받았을 때 등등 스스로가 대견하게 느껴질 정도의 성취감을 느끼는 순간도 많습니다. 이러한 성공과 실패, 좌절과 성취를 느끼는 과정들을 통해, 더욱더 성장할 수 있으리라는 흔들림 없는 믿음이 생겼습니다.지난 7월 22일, 제2회 배민 치믈리에 자격시험이 성황리에 마무리되었습니다. 이를 홍보하기 위해서 앱 스플래시 화면에서 보여주던 치믈리에 포스터를 이제 내려달라는 업무 요청이 있었고, 스플래시 교체 건은 평소에도 제가 담당하던 익숙한 업무였죠. 스플래시 API는 모바일 기기의 정보를 받아 해상도에 맞는 이미지 URL을 반환하는 API입니다. 이번에는 스플래시 교체가 아닌 페이드아웃 요청이었지만, 교체할 이미지 URL 대신 빈 값을 넣어 반환하면 자연스럽게 스플래시가 페이드아웃 될 것이라는 가설을 세웠습니다. 가설에 맞게 코드를 수정한 후 제가 사용하는 아이폰에서 베타테스트를 해 보니, 매우 깔끔하게 메인화면에 진입되는 것을 보고 ‘역시 내 생각이 맞았어! 룰루랄라’  하는 자화자찬과 함께 해당 이슈의 상태를 배포 대기로 옮겼습니다. [바로 그 치믈리에 포스터]사실은 응답 데이터가 설계 목적과 달라지는 상황이라, iOS 및 안드로이드 개발자들과 적극적으로 업무를 공유하고 의견을 나눴어야 합니다. 하지만 협업 경험이 적고 소심한 성격 탓에 다른 팀에게 먼저 얘기를 꺼내기가 쉽지 않다는 이유로, ‘크게 바뀐 것도 아니고 사소한 기능인데 별일 없겠지!’ 하는 말도 안 되는 생각을 하게 됩니다. 또한, 업무에 익숙하지 않던 초기에는 간단한 로직 수정에도 동료들의 코드리뷰를 받고 여러 번의 테스트를 거쳤지만, 이제 업무가 조금씩 익숙해지고 바빠지면서 번거로운 단계는 알게 모르게, 은근슬쩍 생략하고 있었습니다. 각자의 업무는 스스로 해내는 것이 동료들을 편하게 해주는 것이라고 합리화하면서 말이죠. 이렇게 여러 단계의 안전장치를 무시해버린 채 운영에 배포되었고, (제가 테스트해보지 않았던) 안드로이드 기기의 사용자들은 장장 6분간 (무려 컵라면을 2개나 만들 수 있는 시간) 배달의민족 앱에 접속할 수 없는 사태가 발생했습니다. 예상치 못한 사태에 가슴이 먹먹하고 팔다리가 저리는 멘붕에 빠져있는 동안, 팀원들과 앱 개발자들이 발 빠르게 대처해주셔서 장애 상황이 더 길어지는 것은 막을 수 있었습니다.모든 장애를 미리 방지할 수 있으면 좋겠지만 사람이 하는 일이라 실수는 발생할 수 있다. 실수한 것에 대해 비난하지 않으니 너무 자책하지는 말되, 재발 방지를 위해 프로세스를 점검하고 문제점을 개선해야 한다. 같은 실수를 반복한다면 그것이 정말 부끄러워해야 할 일이다.[장애 후 들었던 조언]영화나 드라마를 보면, 경력 많은 주연급의 배우가 주인공이 아니고 몇 컷 등장하지도 않는 역할을 맡는 경우가 가끔 있습니다. 왜 이 역할을 수락했냐는 인터뷰어의 질문에 ‘시시한 역할은 없다. 시시한 배우만 있을 뿐’이라고 답하곤 합니다. 이는 비단 영화나 드라마계에만 해당하는 얘기가 아니라 우리 필드에도 적용되는 얘기입니다. 사소한 기능은 없고, 어떤 업무를 사소하다고 치부해버렸을 때 큰 문제가 되어 돌아올 수 있음을 느끼게 된 경험이었습니다.지난 몇 년간 내버려 두었던 SNS를 입사하면서 다시 시작했습니다. 고민이 있을 때마다 형식도 없고 맥락도 없이 편하게 글을 남기면, 다음날 동료들이 다가와서 수다 타임을 제안합니다. 리빙 포인트! 커피가 마시고 싶을 땐, 고민이 있는 척을 한다. 제가 우아한형제들에 들어와서 가장 감사한 것은, 바로 이러한 동료들을 만난 것입니다. 나의 고민을 나눌 수 있는 동료, 나를 믿어주는 동료, 내가 성장할 수 있도록 도와주는 동료들이 있기에, 마음껏 고민할 수 있고 마음껏 도전할 수 있습니다. 지금 여러분의 고민은 무엇인가요?",http://woowabros.github.io/woowabros/2018/08/05/my_worry.html,woowabros,,NULL,2018-08-05
파이썬으로 Linear Regression 해보기,"안녕하세요.우아한형제들 데이터서비스팀에서 섹시미 막내를 맡고 있는 김세환입니다.데이터를 보다보면 예측모델을 만들게 되는 경우가 많은데요,  대부분의 경우 모델을 만들기 위한 함수들이 라이브러리 형태로 구현이 되어있다보니, 이런 라이브러리를 가져다 쓰는 것이 일반적입니다. 이 때문에 모델을 만드는 데 있어 그 내용은 놓치고 지나가기 쉽습니다.이 포스트에서는 Linear Regression(선형회귀)를 파이썬으로 직접 풀어보고 내용을 한번 되짚어보며, 데이터를 통해 어떤 식으로 값을 예측을 할 수 있을지 간단하게 알아보려고 합니다.다음과 같은 데이터가 있다고 해 봅시다.각 배달건에 대해 배달거리와 배달시간을 기록해 둔 데이터인 듯 합니다.이 데이터를 보면 딱히 계산을 하지 않더라도,  “200m정도 떨어진 곳에서 배달시키려고 하는데, 몇 분정도 걸릴까?” 라는 질문에  “음… 30-40분 정도 걸릴 것 같은데?” 라고 말할 수 있을 겁니다.아마 100미터 거리가 20분, 150미터가 24분, 240미터가 32분… 과 같이 거리가 증가함에 따라 시간도 비슷한 속도로 증가하고 있는 패턴을 보이기 때문일겁니다.데이터를 시각화 해보면 그런 패턴이 한 눈에 보입니다.[파이썬 Matplotlib을 사용하면 쉽게 그래프를 그려볼 수 있다.]명확하지는 않지만 어느정도 패턴이 보입니다.  거리가 늘어남에 따라 시간도 비슷한 속도로 늘어나는 것을 볼 수 있습니다. [대에충 빨간 선 느낌]대에충 이런 느낌이면 50m거리에서는 13? 14분정도 걸린다고 예상할 수 있을 것 같습니다.  200m면 30분정도면 배달이 될 것 같네요.오늘 문제는 이런 선형패턴을 찾는 문제입니다.  이런 패턴을 찾으면, 다음에 배달이 있을 때 어느정도 시간이 걸릴지 예측해보는데 도움이 될겁니다. (맞을지 틀릴지는 모르지만요…)하지만 (대~충 그려보는 것 말고) 선형패턴을 찾으려면 어떻게 하는게 좋을까요?위 예제에서 볼 수 있는 것 처럼 데이터의 패턴을 비슷~하게 따라가는 선을 그을 수는 있지만 모든 점 위를 지나가는 하나의 선은 그을 수는 없습니다.  따라서 예측 값과 실제 값 사이에서 차이가 발생하게 됩니다. [점이 선에서 멀수록 오차가 큰 것]이 오차의 합을 최소한으로 줄이는 선을 찾는다면 예측을 가장 실제와 가깝게 하는 모델이라고도 할 수 있을 것 같습니다.  (실제로는 데이터에 따라 더 여러가지 기준이 있을 수 있습니다.)저희의 목표는 저 선과 점들의 거리의 합을 최소화 하는 것이기 때문에  +, -가 있는 오차의 합보다는 오차 제곱의 합을 구하는 것이 더 바람직해보입니다.이제 저희의 목표는 오차 제곱의 합이 최소화 되는 선을 찾는 것입니다.  [Linear Least Squares]사실 이런 선을 찾는 것은 배달거리 x와 배달시간 y 사이에 선형함수 $y = ax + b$가 있다고 생각하고 그 함수를 구하는 일입니다.만약 그런 함수 $f$가 있다면, 다음과 같은 식들을 만들 수 있을 겁니다.가진 배달데이터의 개수만큼 식을 가진 연립방정식이 나옵니다.  연립방정식은 행렬로도 표현할 수 있습니다.하지만 변수가 2개인데에 반해 식이 너무 많아서, $Ax = b$를 만족하는 $x$를 찾을 수는 없습니다.  그래서 같음을 의미하는 $=$ 를 쓰지 못하고 $\cong$를 썼습니다.  대신에 $Ax - b$를 최소화하는 $x$를 찾아야합니다. 위에서 그래프로 보았던 것 처럼요.그럼 이제 이걸 풀어야 하는데… 이걸 어떻게 풀죠?행렬 중 다음과 같은 특징을 가지는 행렬을 Orthogonal Matrix(직교행렬)이라고 부릅니다.T는 transpose(전치)를 나타내는 기호로, 열과 행을 교환해서 새로운 행렬을 얻는 연산입니다.  예를 들어 이런 식입니다.대각선 방향으로 스윽 돌리기만 하는거에요.행렬 $I$는 Indentity Matrix(단위행렬)로 대각선이 모두 1이고 나머지는 0인 행렬을 말합니다.이 Orthogonal Matrix가 가지는 특징 중 하나가 바로$Qv$의 크기(norm)는 $v$의 크기와 같다는 것인데요, $Q$를 임의의 백터에 곱해도 그 크기에는 영향을 주지 않는다는 것을 의미합니다.자세한 설명은 생략합니다.  이런 특성은 우리의 문제를 해결할 때 유용하게 쓰이니 기억해둡시다.아까 위에서 식을 다음과 같이 만들었습니다.그리고 $\left|Ax - b\right|$가 가장 작아지는 x를 찾는 것이 목표였죠.만약 여기서, $A$가 Upper Triangular Matrix면 문제를 풀기 간단해집니다.[Upper Triangular Matrix는 위 삼각형이 숫자, 아래 삼각형이 모두 0인 행렬을 말한다.]이런 경우 식을 위(숫자가 있는 부분), 아래(전부 0인 부분) 두개로 나누어서 생각할 수 있습니다.  위 숫자가 있는 삼각형으로만 식을 만들었을 때 그 식을 만족하는 단 하나의 $x$를 구할 수 있습니다.  그 밑에 전부 숫자가 $0$인 부분으로만 식을 만들었을 때는 어떤 $x$를 대입해도 $0$밖에 얻을 수 없습니다.따라서 위를 $Rx = b_1$, 아래를 $0x = b_2$라고 표현했을 때, $Rx = b_1$을 만족하는 $x$를 구하면 우리는 답을 얻게됩니다.오차의 크기는 $\left|Ax - b\right| = \left|b_2\right|^2_2$가 되겠죠.A-1), A-2)에서 얘기한 성질을 통해, 문제를 더 간단하게 만들 수 있는 힌트를 얻었습니다.[Q는 Orthogonal Matrix, R은 Upper Triangle Matrix] 를 만족하는 $Q$를 구하면, $Q^TA = R \rightarrow QQ^TA = QR \rightarrow A = QR$이 되고로 나타낼 수 있게 됩니다.이제 문제가 $Rx \cong Q^Tb$ 형태가 되었는데요, 이는 A-2)에서 봤던 것처럼 아주 풀기 쉬운 형태입니다.  A-1)에서 본 것처럼, $Q^T$를 $b$에 곱해도 그 크기에는 영향을 주지 않기 때문에 A-2)처럼 풀 수 있습니다.따라서, $A = QR$이 되는 $Q, R$을 찾기만 하면 문제는 아주 쉬워집니다.$A$를 $QR$ QR코드 , 두개의 행렬의 곱으로 분해하는 방법을 QR decomposition(QR분해) 라고 합니다.여기에는 몇가지 방법이 있는데, 오늘 소개해드리려고 하는건 Householder Transformation(하우스홀더변환)을 이용한 방법입니다.행렬 중 하우스홀더행렬이라고 불리는 행렬이 있습니다.  하우스홀더행렬은 길이가 1인 Unit Vector(단위벡터)$v$에 대해 다음과 같이 정의됩니다.이렇게 만들어진 행렬 $H$는 임의의 벡터$x$에 곱했을 때, 벡터$v$에 직교하는 평면에 대해 벡터$x$를 반전시킵니다.  따라서, $P = I - 2uu^T$일 때, 다음과 같은 그림을 그려볼 수 있습니다.[$Px$는 $x$를 $u$와 직교하는 평면에 대해 반전시킨 결과다.]이렇게 하우스홀더행렬은 벡터를 특정 평면에 대해 반전시킬 때 쓸 수 있습니다. 또, 하우스홀더행렬은 Orthogonal Matrix입니다.그럼 만약 벡터$x$를 unit vector $y$의 방향으로 변환시키고 싶을 때는 어떻게 할 수 있을까요?  벡터$x$를 unit vector $y$의 방향으로 변환시키면 $\left|x\right|y$가 될테니까, 벡터$x$와 벡터$\left|y\right|$를 양분하는 평면의 normal vector(법선벡터)를 구해 $v$라고 하고, 이 벡터로 하우스홀더행렬을 구해 $x$에 곱하면 됩니다.[벡터$v$ 는 $x - \left|x\right|y$의 unit vector로 둘 수 있다.$][벡터$v$를 $x - \left|x\right|y$의 unit vector로 두면 $x$를 $\left|x\right|y$로 변환시킬 수 있다.]여기서 만약 $y$가 첫번째 값이 $\pm 1$이고 나머지 값이 모두 $0$인 unit vector라면, $u = x - \left|x\right|y$라고 했을 때, $u$의 unit vector $v = \frac{u}{\left|u\right|}$라고 하고, 하우스홀더행렬 $Q_1 = I - 2vv^T$를 사용해 아래처럼첫번째 열을 처음빼고 전부 0인 행렬로 만들 수 있습니다. (대박)이걸 반복해서 하면 어떻게 될까요.  그러니까 첫번째 줄은 1번째 빼고 다 0으로 만들었으니, 이번엔 첫번째 열, 첫번째 행을 제외한 나머지 부분에 대해서도 같은 계산을 해볼 수 있습니다.[네모로 표시한 부분]$Q_1$과 같은 방법으로 나머지 행렬에 대한 하우스홀더행렬 $\hat{Q_2}$를 구하면 $Q_1$보다 행렬의 크기가 작을테니, $Q_2$는으로 정의해줍니다.이런 $Q_1$ , $Q_2$를 $A$에 곱하면 다음과 같은 결과를 얻을 수 있습니다.[Upper Trianglular Matrix를 얻었다!]여기서 $Q_1$ , $Q_2$은 모두 orthogonal matrix이기 때문에, $\hat{Q} = Q_2 Q_1$ 또한 orthogonal matrix입니다.  $Q = \hat{Q^T}$라고 할 때, $A$를 다음과 같이 표현할 수 있습니다.[대박사건…]이 과정을 파이썬으로 구현하면 다음과 같이 구현할 수 있습니다.[하우스홀더 변환을 이용한 QR분해 구현. 출처]드디어! $A = QR$의 형태를 얻었으니 이걸 이용해 원래 풀고 싶었던 문제인 $Ax \cong b$를 풀어 배달거리에 따른 배달시간 예측모델을 만들어볼 수 있습니다![파이썬 numpy를 사용해 간단하게 문제를 풀 수 있다.]그리고 얻은 결과를 그래프로 그려볼 수 있습니다.[slope: 0.092, intercept: 11.33][저 선 하나 그리려고 지금… ]짠! 배달시간을 얼추 예상해볼 수 있는 모델이 생겼네요.  $f(d) = 0.092d + 11.33$으로 거리 $d$에 따라 시간을 예상해볼 수 있겠습니다.물론 실제 배달시간은 배달거리 이외에도 음식 종류, 날씨, 교통상황, 배달원이 누군지 등등, 여러 변수의 영향을 받게 되므로 실제로는 더 복잡한 방식으로 예측하고 있습니다. 하지만 이에 대해서도 유사한 방식으로 선형모델을 시도해 볼 수 있습니다.이렇게 Linear Least Squares 문제를 파이썬으로 풀어보았습니다.  감사합니다!",http://woowabros.github.io/study/2018/08/01/linear_regression_qr.html,woowabros,,NULL,2018-08-01
우아한 개발자 경력 공채,"우아한형제들/우아한신선들에서 개발자 경력 공채를 진행합니다.많은 회사들과 마찬가지로, 우아한형제들에서도 개발자 분들을 열심히 채용하고 있습니다. 많은 좋은 분들이 함께 해 주고 계시지만, 사업과 서비스의 성장 속도가 더 빨라지고 있어서(2018년에도 성장 속도는 줄어들지 않고 더 빨라지고 있네요) 더 많은 분들이 필요한 상황입니다.최근에는 우아한테크캠프 2기를 진행하면서, 이 과정이 끝나고 서로 원할 경우, 코딩테스트/서류전형/1차면접을 모두 생략하고 이후 채용 절차를 진행하는 형태로 신입 개발자 분들을 뽑는 시도를 하고 있는데요.회사 내 개발자 분들과 얘기를 나누다 보니, 경력 개발자 분들도 공채라는 형태로 채용하는 것이 좋겠다는 생각을 하게 되었습니다. 한 달에도 몇 분씩 좋은 개발자 분들이 함께 해 주시는데, 이 분들이 조직에 빠르게 적응하고 성과를 내기 위해서는, 회사의 기존 시스템에 대한 교육과 함께 서로 편하게 얘기할 수 있는 네트워크가 있으면 좋겠다는 것이죠.이것은 작년에 공채로 채용한 신입개발자 분들을 보면서 많이 느낀 부분입니다. 아무래도 공채로 채용되다보니, 1) 회사에서 필요로 하는 프로그래밍 지식도 같이 교육받는 기회가 있고, 2) 회사와 서비스에 대한 이해를 높일 수 있는 여러 프로그램도 제공되었으며, 3) 또 서로가 잘 알다보니 업무를 풀어 나가는 데 있어서 훨씬 더 빠르게 적응하고 좋은 성과를 내는 모습을 살펴 볼 수 있었습니다. 그래서 경력 개발자 분들도 공채 형태로 채용하려는 생각을 하게 되었습니다.[우아한형제들 신입개발자 모집 영상]위에서 공채 형태의 경력직 개발자 채용을 생각하게 된 이유에 대해서 말씀 드렸는데요. 공채로 진행하는 또 한 가지 이유를 말씀 드린다면, 우아한형제들에서 개발자를 뽑고 있다는 사실을 알리기 위함입니다. 많은 분들이 우아한형제들이 개발자를 뽑는다는 사실을 알고는 있지만, 당장 지원할 것이 아니라면 그냥 스쳐 지나가는 생각이 되어 버리고 맙니다.아주 적극적으로 이직을 고민하는 분들이 아니라면, 누군가의 소개를 통해 지원한 것이 아니라면, 지금 다니는 회사와 하는 일 외에 특별히 외부 회사 동향에 신경을 쓴 분이 아니라면, 우아한형제들이 개발자를 적극적으로 뽑는다는 사실 자체를 모르실 수 있다고 생각했습니다.그래서 이번 경력 개발자 공채 시기에 맞춰서, 아래 사진에서 보시는 것과 같이 지하철 역과 버스 정류장 및 버스에 우아한형제들 개발자 모집을 알리는 활동을 병행하고 있습니다.   그리고 이번에 우아한형제들의 개발 조직 관련해서 또 한 가지 큰 변화가 있는데요. 서비스를 만드는 기획/디자인/개발 조직이 몽촌토성역 옆 사무실에서 나와서, 잠실역 근처로 새로운 사무실을 얻어서 이전한다는 것입니다. 아무래도 개발 조직의 경우, 여러 대의 모니터를 이용하다보니 책상과 같은 근무 환경이 좀 더 넓게 확보될 필요도 있었고, 우아한형제들이 워낙 빠르게 성장하다보니 현재 이용하는 사무실도 올해가 가기 전에 공간이 모자라서 새롭게 사무실을 얻게 되었습니다.그래서 이번에는 새로운 사무실 이전에 맞춰서, 분양 광고 컨셉을 패러디하여 우아한형제들 개발자 대모집을 알리는 채용 공고 영상을 제작하여 보았습니다. 아래 영상을 보고 재미있거나 맘에 드신다면, 주변의 개발자 분들도 한 번 보고 웃으시라고(그리고 지원을 생각하시라고 :-) 공유 부탁 드립니다.[우아한형제들 경력개발자 모집 영상]이번 공채는 우아한형제들/우아한신선들에서 배달의민족과 배민찬 서비스를 개발하실 분을 채용하는 과정입니다. 모집 분야는 다음과 같습니다.위 직무 중 서버프로그래머, 웹프론트엔드 프로그래머, 데이터엔지니어는 우아한신선들에서도 채용을 진행하며, 공채 지원 시에 두 회사 동시 지원 또는 한 회사 지원을 선택하시면 됩니다. 경력직 공채의 규모가 궁금하실 수 있는데, 이번 경력 개발자 공채를 통해 채용하고자 하는 목표 인원은 수십명 수준입니다. 위에서도 잠깐 공유 드렸다시피 영상 제작, 옥외 광고를 비롯하여 우아한 개발자 경력 공채 진행을 알리고 진행하기 위해 정말 많은 사람들이 고생하고 있는데요. 이 분들의 수고를 헛되이하지 않기 위해서라도 많은 분들이 지원했으면 하는 바람이 있습니다.이번 우아한개발자 경력 공채의 서류 접수 기간은 7월 23일부터 8월 5일까지입니다. 자세한 내용은 경력 개발자 공채 지원 페이지를 통해서 확인하실 수 있고, 우아한닷컴의 인재채용-경력개발자모집 링크를 통해서도 확인하실 수 있습니다.우아한형제들/우아한신선들이 왜 개발자를 많이 채용하려고 하고, 개발자 분들이 오시면 어떤 일을 할 수 있다고 생각하고 있으며, 개인 입장에서는 여기서 무엇을 얻을 수 있을 지에 대한 생각은 “우아한형제들의 Developer Relations”라는 글에서 설명을 드린 바 있는데요. 이번에 지원을 고민하시는 분들이라면, 공채 지원 페이지만 보지 마시고, 바로 앞에서 말씀 드린 글을 꼭 읽어 보시면 좋겠습니다.“우아한형제들의 Developer Relations” 글에서 이런 말씀을 드린 적이 있습니다.좋은 회사는 현재로서 완성된 좋은 모습을 갖추어서가 아니라, 어떤 것이 좋은 것인지, 더 좋은 것인지를 지속적으로 고민하고 실행에 옮길 수 있는, ‘좋음’의 모습이 현재 진행형인 회사라고 생각합니다. 우아한형제들이 매출이 가장 높은 회사여서가 아니라, 복지 혜택이 가장 좋아서가 아니라, 일을 더 잘 하기 위한 고민을 같이 나누고 변화시켜 나갈 수 있기에, 이 글을 보시는 많은 좋은 개발자 분들과 같이 일하고 싶다는 말씀 전하고 싶습니다.혁신이라는 것은 뭔가 멋진 것을 얘기하는 것이 아니라, 현재의 불편한 점을 꾸준히 개선하는 것을 반복할 때 이룰 수 있다고 믿습니다. 지금은 무모해보여도, 아주 작게나마 변화를 위한 다양한 시도를 할 때 이룰 수 있다고 믿습니다. 아래 영상은 2022년에 로봇이 가져올 수 있는 변화를 컨셉 영상으로 만들어 본 것입니다. 이 영상은 2022년보다 가까운 미래가 될 수도, 2022년보다 먼 미래가 될 수도 있습니다. 이러한 미래가 오기 위해서는, 같은 미래를 꿈꾸는 사람들이 필요하고, 단지 꿈꾸는 것에서 머무르는 것이 아니라 그 꿈을 이루기 위한 시도와 변화를 같이 만들어 갈 분들이 이런 경력 개발자 공채에 많이 관심 갖고 지원해 주시면 좋겠습니다.[배달의민족이 꿈꾸는 배달로봇 Life]",http://woowabros.github.io/woowabros/2018/07/02/woowahan_open_recruitment.html,woowabros,,NULL,2018-07-02
AWS에서 서버(EC2) 패킷 미러링 하기,"Public cloud의 문제점중 하나는, 가시성 확보가 어렵다 이다. 보안을 위해서 여러 Layer의 가시성 확보가 필요한대, 특히 Network 트래픽 데이터에 대해서는 필수이다. on-premise 환경에서는 TAP hardware 장비등을 이용하여 가시성 확보가 가능 했지만, Public cloud에서는 hardware를 사용할 수 없기때문에 다른 방법을 사용해야 한다. 리눅스 서버의 경우 iptables의 TEE module을 사용하여 간편하게 네트워크 트래픽을 미러링 할 수 있는데, 이 방법에 대해 기술하고자 한다.Public cloud의 보안을 하다보면 큰 문제에 부딪히는데, 바로 가시성 확보가 어렵다는 부분이다. 특히 네트워크 트래픽 데이터에 대한 검증은 필수 요소이나 L3/L4 수준의 가시성만 제공한다. 하지만 정확하고 정밀한 보안을 하려면 L7수준 까지의 확보가 필요하고, 아쉽게도 모든 Public cloud에서는 Network mirroring기능을 제공하지 않는다. 그렇다고 상용 솔루션을 구매해서 agent를 설치하자니 비용적으로나 운영측면에서 장애 요소가 부담 되는데, 이를 해결 할 수 있는 방법을 iptables에서 찾아보았다.   (Unix iptables man page에서 발췌)  Unix의 tee 명령은 특정 프로그램 실행 결과를 입력으로 받아서, 파일이나 스트링으로 출력 할 수 있다. 이것을 iptables에 접목한 것으로 iptables의 TEE module은 Network Interface card(NIC)에서 발생한 트래픽을 다른쪽(Server/NIC)으로 전달하고자 할때 사용할 수 있는데, 흡사 Network switch 또는 TAP 장비와 같이 mirroring이 가능하다.  테스트용 구성은, 외부망의 Laptop과 EC2(118.118.77.30)간 통신 트래픽을 IP주소 118.118.84.105 EC2에게 Mirroring 하도록 해서, 105번 인스턴스에서 laptop과 30번 인스턴스간 통신 내역을 확인 할 수 있도록 했다.1.1 118.118.77.30 EC2로 ssh 접속. 1.2 sudo iptables -t mangle -I POSTROUTING -j TEE –gateway 118.118.84.105 명령어 실행으로 내부 Private IP를 외부 Public IP로 변환 mirroring 정책 추가. 1.3 sudo iptables -t mangle -I PREROUTING -j TEE –gateway 18.118.84.105 명령어 실행으로 외부 Public IP를 내부의 사실IP로 변환 mirroring 정책 추가. 1.4 sudo /etc/init.d/iptables start 명령 실행으로 iptables 활성화. 1.5 sudo iptables -t mangle -L 명령 실행으로 1.2와 1.3의 정책이 잘 들어 갔는지 확인.   (정책이 잘 들어갔다면, 이렇게 확인 되어야 한다)  1.6 재부팅시 iptables 정책이 초기화 되는데, 이를 방지 하려면 sudo /etc/init.d/iptables save 명렁 실행.원하는 protocol, port를 필터링 하려면 URL 참조(http://www.packetinside.com/2012/08/iptables.html)2.1 AWS의 EC2 콘솔 접속. 2.2 promiscuous mode 활성화를 위해, Mirroring 받을 EC2 선택 후 Action → Networking → Change Source/Dest. Check → Disable 선택.기본적으로 EC2는 자기 자신을 향하는 트래픽이 아니면, 받지 않도록 되어 있다.    (Disable 버튼을 클릭하자)  3.1 mirroring 트래픽을 수신하는 EC2 접속. 3.2 sudo tcpdump -nni eth0 -A src 118.118.77.30 명령어로, 30번 EC2에서 들어오는 트래픽의 데이터만 볼 수 있도록 tcpdump 실행. 3.3 laptop에서 30번 EC2의 Public IP주소로 ping이나, ssh로 접속해서 외부의 웹사이트에 접속 해보기. 3.4 mirroring 트래픽을 수신하는 EC2에서, 30번 EC2의 트래픽이 tcpdump로 보인다면 성공! 만약, 안된다면 promiscuous mode 설정이 올바로 되었는지 확인.    (laptop에서 30번 EC2로 ping 보내는것을 105번 EC2에서 tcpdump로 확인 할 수 있다. )  mirroring 받은 트래픽을 활용 할 수 있는 방법은 많이 있다. suricata나 Bro와 같은 opensource IDS를 설치해서, VPC 내부 트래픽을 모니터링 하거나 요즘 문제가 되고 있는 AWS의 네트워크 품질에 대해서 packet들의 시퀸스 번호를 트래킹 한다면, 어느정도 loss가 발생하는지 등의 품질 측정도 가능하다.  끝!  ",http://woowabros.github.io/security/2018/06/29/aws-network-mirror.html,woowabros,"django,android,ruby",NULL,2018-06-29
라이더스 개발팀 모바일에서 CI/CD 도입,"이 글은 CI/CD를 안드로이드에 도입하게 되면서 정리한 내용입니다.   구축 및 운영하고자 하시는 분에게 경험을 공유하고자 합니다.안녕하세요 라이더스 개발팀 장인수 입니다.우선 라이더스 개발팀이 하는 일을 소개 합니다. 저희 라이더스 개발팀은 배달되지 않는 음식점의 음식을 민트색 헬멧을 쓴 라이더 분들이 오토바이를 이용하여 음식을 픽업 후 고객님에게 배달하는 일정 과정들을 원활하고 효율적으로 운영이 될 수 있도록 개발하는 팀 입니다.그중 모바일(app)은 라이더스 분들이 주문이 들어오면 주문을 확인 후 픽업 -> 배달까지 필요한 부분을 제공하고 빠르게 이용 할 수 있도록 개발하고 있습니다.라이더스는 B2B앱으로써 일반사용자를 위한 앱은 아니고 오직 라이어스 분들만을 위한 앱이라고 할 수 있습니다.Build , Test를 실시하는 프로세스를 말하며 이러한 통합 프로세스를 상시로 실시해 주는것을 CI라고 합니다.짧은 주기로 소프트웨어를 개발하는 소프트웨어 공학적 접근의 하나로, 소프트웨어가 언제든지 신뢰 가능한 수준으로  출시될 수 있도록 보증하기 위한 것이다. 소프트웨어를 더 빠르게, 더 주기적으로 빌드하고 테스트하고 출시하는  것을 목표로 한다.  이러한 접근은 더 많은 증분 업데이트를 업무 애플리케이션에 적용할 수 있게 함으로써 변경사항의 배포에 대한 비용,  시간, 위험을 줄일 수 있게 한다.짦은 주기로 개발중인 소프트웨어를 배포하고 그 과정을 자동화 하겠다는 뜻이다.수동으로 개발자의 손을 통해서 배포가 이루어지다 보니 Human Error 의 발생의 소지가 있고 앱은 서버의 배포와 달리 한번 잘못 배포가 되어지면 다시 배포하는 과정의 어려움이 작지 않아서 최대한 자동화를 이루고자 하는 마음에서 도입하게 되었습니다.CI/CD를 하기위해서는 여러가지 선택이 있습니다. Travis CI, Circle CI, BITRISE, Jenkins 등이 있지만, 아래 같은 장점을 가진 Jenkins 를 선택하게 되었습니다.그리고 도커를 선택한 이유는 젠킨스 서버를 띄우기 위해서는 여러가지의 서버 설정등과 설치등이 필요한데 이 모든 일련의 과정을 Dokerfile에 작성을 하고 손쉽게 띄울수 있는 도커를 선택에서 작업시간 및 운영에 오는 리소스를 줄이고자 선택하였습니다.아래 그림과 같이 도입하려고 했습니다.저희는 Slack 등을 사용하고 있어서 apk 를 타겟 시스템 별로 아래 그림과 같이 배포하도록 만들었습니다. Slack에서는 slack bot api등을 지원을 해줘서 어렵지 않도록 Slack bot을 만들고 사용할 수 있습니다. 여기서는 자세한 설명은 생략하고 위의 https://api.slack.com 로 가시면 자세한 사항을 만들어 볼 수 있습니다.저희는 Slack bot을 만들고 그것을 사용해서 아래 그림과 같이 배포하여서 사용하였습니다.Docker 는 docker hub 라는 repository가 있습니다. 개발자들은 다들 알고 계신 github와 비슷하다고 보시면 됩니다. 간단하게 jenkins official dockerfile 을 이용하고 약간의 추가 사항을 통해서 어렵지 않도록 Jenkins를 이용하기 위한 docker image 를 만들 수 있습니다.https://hub.docker.com 에 접속해서 jenkins를 검색하면 아래 그림과 같이 나옵니다.jenkins Official 이미지는 Android SDK 등이 포함 되지 않았으므로git repository 를 clone 해서 수정해서 사용하도록 합니다.공식 dockerfile 은 아래와 같고dockerfile link공식 dockerfile 에서 안드로이드에서 사용하기 위해서 Gradle , OpenJDK, Android SDK를 추가하도록 하겠습니다.위와 같이 하면은 Jenkins가 띄워지고 사용하실 수 있습니다.아직 한땀, 한땀 으로 공들여서 배포하시는 분들은 CI / CD 를 도입해서 아래와 같이 공지해주는 것에서 해방 되시기를 바랍니다.",http://woowabros.github.io/experience/2018/06/26/bros-cicd.html,woowabros,"kotlin,php,android,java,ruby",NULL,2018-06-26
우아한테크캠프를 통해 내가 얻은 것들,"안녕하세요! 작년 12월에 우아한형제들에 입사한 신입 개발자 배민프론트개발팀의 박예준입니다!딱 작년 이맘때에 즈음 우아한테크캠프 지원서를 작성하고 있었는데, 이렇게 기술 블로그에 글을 남기려니 기분이 이상하네요.2018우아한테크캠프를 앞두고 있습니다.  앞서 우아한테크캠프 참가자에서 우아한개발자가 되기까지 를 작성하신 전한나님과 함께 작년 우아한테크캠프 참가자로서 우아한개발자가 되기까지의 경험을 담은 글을 작성하면 우아한테크캠프를 준비하시는 분, 우아한개발자가 되기를 희망하시는 분들께 조금이나마 도움이 되지 않을까 하여 시리즈물을 기획하게 되었습니다.제 전공은 기술경영학입니다. 경영계열 학문으로 커리큘럼에 프로그래밍 포함되어있지 않지만, 제가 S/W 분야에 관심을 갖고 독학을 시작하게 된 계기를 만들어주었습니다.독학으로 웹 개발 공부를 진행하는 것은 쉽지 않았습니다.  생활코딩, gitbook, codecademy 등 수많은 채널들을 통해 독학을 도전했지만, 완주에 실패하기 일쑤였습니다.연속되는 작심삼일에 지칠 때 즈음 ‘멋쟁이 사자처럼’ 이라는 비전공자 대상 개발 교육 동아리에 참여하게 되었습니다. 멋쟁이 사자처럼에서 진행된 팀 프로젝트를 통해 하나의 서비스를 기획하고 개발하는 플로우를 처음으로 완주해보게 되었습니다. 저희 팀의 아이디어를 개발해나가는 과정에서 그동안 느껴보지 못했던 몰입감과 짜릿함을 느껴 볼 수 있었습니다.이 경험을 계기로 저에게 개발이란 막연히 배우고 싶었던 것에서 재미있는 것, 내가 잘 하고 싶은 것으로 다가왔습니다.개발이 점점 재밌어지면서 전공인 경영계열 직무를 선택하는 길과 개발을 심도있게 공부하여 개발자의 삶을 사는 것을 고민하던 중에 2017우아한테크캠프에 참여하게 되었습니다.제가 우아한테크캠프를 통해 얻고자 했던 것은 아래 두 가지였습니다.결론부터 말씀드리자면, 제가 얻고자 했던 것보다 더 많은 것을 얻을 수 있었습니다.우아한테크캠프의 수업은 일방적인 지식전달의 형태가 아닌, 미션을 바탕으로 한 피드백으로 이루어졌습니다.미션이 주어지면 이를 기간 내에 풀어오거나 답을 찾아오는 게 목표가 아니라 문제를 해결하기 위한 방안을 스스로 고민해보고 자신의 접근법을 설명할 수 있도록 하는 것이 목표였습니다.(프론트엔드 트랙의 경우에는) 아침마다 gist 로 제출한 과제물의 피드백을 나누는 시간을 가졌었습니다. 이 시간을 통해 제 해결방법의 모자란 점이 무엇이었는지, 어떤 것을 더 공부하면 좋을지 피드백을 받을 수 있었습니다.이러한 피드백 중심 커리큘럼은 문제 접근과정에서의 방향성을 스스로 살펴보는 좋은 습관을 가지게 해주었습니다.우아한테크캠프는 총 2개월의 기간 중 1개월의 강의와 1개월의 팀 프로젝트로 진행되었습니다. 길지 않은 기간이기 때문에 강의 진도가 꽤나 빠르게 진행되었습니다. (제 역량이 모자라서 더 짧다고 느껴진 것 같습니다..)  강의 진도를 맞추기만 하기엔 모자란 점이 너무 많아 거의 매일 남아서 공부하고 갔습니다. 스스로의 모자람을 채워나간다는 만족감과 성장의 뿌듯함이 큰 모티베이션이 되었던 것 같습니다.팀 프로젝트에 들어오고 나서는 이 몰입감은 더욱 깊어졌습니다. 거의 매일을 9 to 10 의 일정을 소화하는데도 개발을 하는 순간순간들이 너무 즐거워서 지치는 줄  몰랐습니다. 프로젝트 막바지 때 즈음에는 어떤 버그를 잡지 못해서 전전긍긍하다 잠에 들었는데, 잠결에 해결 방법이 생각나서 이걸 해결하고 다시 잠에 든 경험도 있었습니다 ㅎㅎ이렇게 즐겁게 몰입해봤던 경험은 개발자로서의 진로에 확신을 갖게 해주었습니다.제가 위에서 언급한 우아한테크캠프를 통해 얻고자 했던 리스트에선 협업과 관련한 내용이 없습니다. 사실 지원 당시에는 제 개발능력 향상에만 초점을 맞추다 보니 협업능력의 성장 부분을 간과했던 것 같습니다.프로젝트를 진행하면서 가장 많이 고민했던 부분은 협업과 관련한 것들이었습니다. 개발이란 것은 혼자 하는 것이 아니기에 서로 의견을 나누고 함께 문제를 해결하는 과정을 거쳐야만 했습니다. 교육을 담당했던 코드스쿼드의 마스터들이 항상 강조했던 협업의 중요성을 그제서야 진짜로 이해할 수 있었습니다.잘 싸워야 한다.교육과 프로젝트를 진행하면서 협업과 관련하여 가장 크게 느낀 점은, 잘 싸워야 한다는 것이었습니다.우아한테크캠프 교육을 담당했던 코드스쿼드의 마스터분들은 항상 싸우는 걸 피하지 말라고 하셨습니다.저는 의견 다툼을 가능한 피하려는 경향이 강했었는데, 불필요한 갈등을 만들지 않기 위한 나름의 희생(?)이라고 생각했습니다. 하지만 이 생각은 프로젝트를 진행하면서 바뀌게 되었습니다.논리적이고 타당한 근거가 있다면 충분히 상대방을 설득시킬 수 있는데, 이전에는 제 의견에 근거가 모자라서 상대방을 설득시키지 못했던 것이었습니다.  그리고 그것을 희생이라고 스스로 합리화했었습니다.의견 다툼은 결국 좋은 결과물을 만들어내기 위한 좋은 방법을 찾아가는 과정이었습니다. 의견 다툼을 피한다는 것은 좋은 결과물을 만들 방법에 대해 논의할 수 있는 좋은 기회를 날려버리게 된다는 것을 알게 되었습니다.우아한테크캠프 프로그램을 통해 개발에서 협업이 얼마나 중요한 부분인가를 느낄 수 있었고, 좋은 협업이란 무엇인가 고민하기 시작하게 되었습니다.보다 자세한 우아한테크캠프 이야기를 보고 싶으시다면이렇게 제가 성장하고 몰입할 수 있었던 것은 우아한테크캠프였기 때문에 가능했다고 생각합니다.이런 환경이 제공되었었기에 제 성장에 집중할 수 있었습니다.그리고 전 개인 역량의 성장은 물론, 진로의 확신까지 얻을 수 있었습니다.성장에 대한 욕심이 있으신 분들이라면, 우아한테크캠프를 통해 정말 많은 것을 얻고 성장해 나가실 수 있을 거라고 확신합니다.",http://woowabros.github.io/experience/2018/06/11/frrom_woowahna_techcamp.html,woowabros,"javascript,ruby",NULL,2018-06-11
배민찬은 Vue를 어떻게 사용하나요?,"이 글은 제이쿼리, PHP 기반의 쇼핑몰 서비스에 Vue를 도입한 사례를 정리한 내용입니다. 서비스에 Vue 도입을 고민 중이신 분들을 위해 경험기를 공유합니다.배민찬은 푸드 커머스 사업에 혁신을 만들어가는 스타트업 서비스다. 우리 개발팀은 솔루션 기반의 커스터마이징된 쇼핑몰을 시작으로 올해 3년 이상 레거시 코드와 분투 중이다.팀내 프론트엔드 개발자로서 리엑트, 앵귤러, 노드 같은 트렌디한 키워드가 떠올랐고, 하루라도 빨리 효율적인 기술 스택으로 갈아타고 싶었다. 제한된 개발 리소스에 빅뱅 방식의 개선은 비현실적이라고 판단. 조금씩 시도해 보고 빠르게 결과를 검증해 나가는 방법이 필요했다.점진적인(Progressive) 자바스크립트 프레임워크“점진적인”을 슬로건으로 내세운 Vue 프레임웍은 이러한 고민에 대한 일말의 해결책으로 보였다. 곧장 기술 조사와 안정성 검토 후 팀내 소프트 랜딩을 위한 전파 교육을 진행했고, 기존의 기술 부채를 조금씩 개선해 나가기 시작했다.한 페이지만 CDN으로 다운받아 사용해 보는 것을 시작으로 NPM 다운로드를 통해 좀 더 확대 적용하였다.  결국 .vue라는 단일파일컴포넌트(Single File Component)까지 들여왔고 하나의 파일에서 마크업, 스크립트, 스타일을 관리하는 방법으로 확대했다.  이것은 Vue가 주장하는 “점진적인” 방법을 활용하는 것이었고 운영중인 서비스에 안정적으로 기술을 도입하는 좋은 방법이었다.레거시의 가장 큰 문제는 코드의 중복! 하나의 코드로 다양한 디바이스에 동작하는 반응형 웹과는 달리, 배민찬은 디바이스별로 파일을 작성해야 하는 일반적인 웹이다.  [모바일과 데스크탑]모바일 페이지 개발을 마치고 비슷한 데스크탑 페이지를 만드는 것은 무척이나 지루한 일이다. 디바이스 크기별로 작성하는 마크업과 스크립트는 중복이 많았고 소프트웨어 공학 관점에서도 전혀 드라이(DRY)하지 않은 코드로 보였다.Vue의 컴포넌트 조합은 이러한 문제를 꽤나 효율적으로 해결할 수 있는 도구인데 가이드라인에 따르면 두 가지 방법이 있다.믹스인과 확장(extends)공통의 부모 컴포넌트를 만들고 이를 자식 컴포넌트가 상속하는 믹스인 방식보다는, 기존 컴포넌트를 확장해서 유사한 컴포넌트를 만들 수 있는 extends 옵션이 더 적합해 보였다.  모바일 컴포넌트를 먼저 만들고 이를 확장한 데스크탑 컴포넌트를 만들기 때문이다.코드로 보면, 먼저 모바일 컴포넌트를 이용해서 화면을 만든다.이러한 모바일 컴포넌트는 extends 옵션을 이용하면 단숨에 데스크탑 컴포넌트를 정의하는 데 재사용 될 수 있다.라이프사이클 훅과 메소드는 일정한 규칙에 따라 오버라이딩 되기 때문에 두 컴포넌트는 같은 코드를 공유하면서 비슷하게 동작한다.이러한 코드 재사용은 개발 속도를 비교적 빠르게 앞당겼고 무엇보다 신나는 일이었다!  컴포넌트 병합 옵션에 대한 몇 개 특성만 이해하면, 다중 뷰를 위한 효율적인 컴포넌트 설계는 그렇게 어려운 일이 아니라고 생각한다.  둘 간의 차이를 잘 살펴보고 사용하기 바란다. (병합 옵션에 대한 자세한 사항은 UI 컴포넌트 확장 참고)이미 Vue 기술을 도입한 깃랩은 블로그(번역)에서 언급한 것처럼 웬만하면 Vuex를 사용한다. 하지만 배민찬에서는 다소 부담되는 상황이다. 백엔드 개발자 위주의 팀에서 프론트엔드 기술(예를 들어 Flux) 이해에 대한 요구는 개별로 다르기 때문이다. 최대한 심플하게 뷰를 사용하고 싶었다. [웬만하면 단순하게]기술 도입에 앞서 먼저 동료들이 어떻게 Vue를 사용하는지 유심히 관찰했다.  SFC 개발환경까지 갖추었지만, 예상과 다르게 하나의 루트 컴포넌트로만 화면을 만들고 있었다. 제이쿼리 기반의 화면 개발에 지친 우리는 v-bind를 필두로 한 다양한 Vue 디렉티브 사용에 더 흥미를 느꼈던 것이다.돔(DOM) 조작으로 화면을 직접 제어하는 것은 복잡한 코드로 이어지기 쉽다. 반면, Vue 디렉티브는 데이터 기반의 사고를 유도하기 때문에 화면 로직과 맞닿아 있지는 않다.  데이터만 잘 다루면 화면은 Vue가 알아서 제어해 준다.UI 기반의 사고에서 데이터 기반의 사고 전환이것은 데이터를 다루는 백엔드 개발자가 Vue를 바라보는 매력 포인트라고 생각한다.그럼에도 불구하고 화면이 복잡해지면 컴포넌트로 쪼개야 하고 상태관리 솔루션을 도입하고 싶은 유혹이 생긴다. 아직은 충분히 Vue의 기본 기능에 익숙해져야 하는 단계라고 생각했고 대안이 필요했다.복잡한 페이지가 아닌 이상, 위의 두 가지 규칙만으로도 화면을 구성하는데는 충분했다. 나중에는 2단계로 분리한 컴포넌트(예를 들어 페이지네이션)를 공통 파일로 분리한 뒤 적재적소에 끼워 넣어 재활용할 수 있었다. [페이지네이션 컴포넌트를 재활용할 수 있다]데이터 중심의 화면 개발임에도 불구하고 돔을 직접 제어해야 하는 경우는 불가피했다. swiper 나 sticky-kit 같은 제이쿼리 기반의 플러그인이 그러한 경우다. 이것을 Vue로 직접 구현하기보다는 어떻게든 Vue에 녹여내는 게 더 효율적인 방법인데……Vue는 돔 접근을 위해 커스텀 디렉티브를 만들라고 안내한다. 슬라이드에 사용하는 swiper 디렉티브로 래핑한 예제를 보면 써드파티 라이브러리를 어떻게 사용하는지 알 수 있다.디렉티브 훅 함수(여기서는 inserted)를 적절히 이용해서 서드파티 라이브러리리가 돔에 접근하도록 도와줄 수 있다.이것을 컴포넌트에서 사용하려면 뷰 생성 객체에 directive 키로 전달하면 된다.한편 값을 변경하는 유틸리티성 함수는 Vue의 필터로 정의한다. 예를 들어 숫자 형식을 출력하는 필터를 다음과 같이 만들 수 있다.이것을 사용하려면 뷰 생성 객체의 filters 키로 추가해야 한다.디렉티브와 필터 모두 필요할 때마다 컴포넌트에 코드를 주입하여 재사용할 수 있다.뷰 스캐폴딩을 자동으로 만들어주는 vue-cli는 기본적으로 SPA를 위한 프로젝트를 생성한다. 그러나 배민찬 서비스는 각 페이지별로 자바스크립트를 로딩하는 고전적인 MPA 구조라서 다른 방법이 필요하다.처음에는 웹팩의 엔트리를 이렇게 수동으로 작성했다.화면별로 폴더를 나누고 (/mobile/home, /desktop/home) 이에 따라 자바스크립트 파일을 분류해서 생성한다.  화면을 추가할 때마다 엔트리 포인트 추가를 위한 웹팩 설정파일을 수정해야 하는 상황이다.자동화가 필요한 시점!규칙을 정했다.  화면별로 유일한 엔트리 포인트가 있는데 전부 같은 파일명(app.js)으로 만들고, 이러한 약속하에 엔트리 포인트를 자동 생성하는 코드를 추가했다.getEntries() 함수로 각 화면별 스크립트가 있는 최상위 폴더명과 번들 파일명의 꼬리표(prefix)를 전달한다. 그 결과 모든 폴더의 app.js 경로를 찾아 번들명을 키로 하는 엔트리 객체를 만들어 낼 수 있다.이렇게 자바스크립트 엔트리 포인트를 자동화함으로써 웹팩 수정 없이 자바스크립트를 추가할 수 있다.프로그레시브한 Vue는 앵귤러, 리엑트에 비해 사전작업이 거의 없다.  CDN 주소를 스크립트 태그에 로딩한 뒤 그냥 쓰면 된다. 익숙한 제이쿼리처럼 말이다.  이런 모습이 운영 중인 서비스에 Vue를 사용하는데 비교적 가볍게 느껴졌다. [Vue 홈페이지]뷰의 컴포넌트 확장 방법은 데스크탑과 모바일 페이지를 따로 개발해야 할 때 매우 효율적이다.  모바일 퍼스트라고 하지만 여전히 데스크탑을 무시할 수 없고 커머스라면 더욱 그렇다.  한정된 리소스로 두 개의 플랫폼을 개발해야 하는 상황이라면 컴포넌트 재사용은 꽤 효율적인 솔루션이다.화면 중심의 개발 방법에서 데이터 중심의 사고로 전환할 수 있다. 까다로운 화면 제어를 Vue에게 맡겨버리고 데이터 위주로 사고하면 UI 개발의 스트레스는 줄어들고 생산성은 향상된다.다른 UI 프레임웍과 달리 Vue SFC는 마크업과 스타일을 한 파일에 정의할수 있으므로, 컴포넌트를 잘만 설계한다면 퍼블리셔와의 협업도 기대해 볼 수 있다.배민찬에는 아직 할 일이 많다. 레거시를 탐험하고 멋진 코드로 개선하고 싶다면, 그리고 그런 경험이 절실하다면 우리 회사에 지원해 보는 것은 어떨까?// 꼼꼼하게 리뷰해 주신 기술블로그 파워 커미터 종립님께 감사드립니다 🙏",http://woowabros.github.io/experience/2018/06/07/vue-story-of-baminchan.html,woowabros,"react,angular",NULL,2018-06-07
장애와 관련된 XtraBackup 적용기,"안녕하세요. 우아한형제들에서 빌링시스템을 개발하고 있는 이주현입니다.입사한 이래로 2년 가까이 일하며 정말 다양한 문제를 마주하고 해결하며 소중한 경험을 쌓고 있습니다. 그중 얼마 전 MariaDB 백업 방식으로 적용한 XtraBackup에 대하여 이야기해보려고 합니다.  그전에 잠시 2016년으로 돌아가 보겠습니다.개발자가 언제 죽는다고 생각하나?  총알이 심장을 관통했을 때? 아니야.. 불치병에 걸렸을 때? 아니지! 맹독 버섯스프를 마셨을때? 아니다!! 그건 바로 메인 DB를 날렸을 때다.12월 27일 오후 3시결제시스템 모듈을 개발하던 중 저의 실수로 빌링 데이터베이스의 주요 테이블 9개가 DROP 되는 사고가 발생했습니다. 모니터링 시스템에 빨간불이 들어오고 각종 장애알림이 빗발치기 시작했습니다. 식은땀이 흐르고 머릿속이 새하얘지며 아무것도 생각나지 않습니다.  빨리 복구를 해야겠다는 생각은 가득한데 부끄럽게도 데이터베이스 시스템에 별다른 지식이 없던 저로서는 눈 앞이 캄캄해졌죠.결국 이 장애로 배달의민족 결제가 잠시 중단되었습니다. 그나마 다행인 건 애플리케이션에서 임시 데이터베이스를 바라보도록 수정하여 장애 시간이 길지는 않았다는 점입니다. ㅠㅠ우선 급한대로 Full Backup 데이터부터 복구 하기 시작했습니다.당시 장애 상황을 재현한 데이터로 실제와는 많은 차이가 있을 수 있습니다.빌링 데이터베이스는 매일 새벽 6시 mysqldump를 사용해 전체 데이터를 백업하고 있었습니다. 테이블별로 데이터를 SQL형식으로 생성한 뒤 압축한 형태였기 때문에 DROP 된 테이블을 쉽게 복구할 수 있었습니다.많은 분들께서 아시겠지만 gzip으로 압축된 sql내용의 파일은 아래와 같은 명령어로 DB에 실행할 수 있습니다. 결제 데이터가 많이 쌓여있던 상황이라 시간이 조금 걸리기는 했지만 빌링 시스템 Open ~ 새벽 6시까지의 데이터는 복구할 수 있었습니다.사실 중요한 점은 새벽 6시 ~ 15시까지의 데이터를 어떻게 복구하냐 였습니다. 어렴풋 MariaDB 서버에서 보았던 binary log가 도움이 되지 않을까 지푸라기라도 잡는 심정으로 구글링을 해보았습니다. 그 결과는 다행히 ‘가능하다’였습니다. binary log는 데이터 수정과 관련된 모든 정보가 담겨 있는 파일인데 크게 두 가지 중요한 목적이 있다고 합니다.2진 형식으로 기록된 binary log를 텍스트 파일로 복구하는 데는 mysqlbinlog 유틸을 이용합니다. mysqlbinlog에는 다양한 옵션이 존재합니다. 그 중에서도 --(start|stop)-position, --(start|stop)-datetime은 데이터 복구시 아주 유용합니다. 특정 position이나 시간에 대한 데이터를 뽑아낼 수 있기때문입니다.$ mysqlbinlog --start-datetime=.. | mysql -u root .. 와 같은 명령어로 복구된 이벤트 내용을 mysql에 직접 실행할 수 있습니다. 하지만 테이블 전반적인 내용들이 담겨있기 때문에 9개 테이블에 대한 필터링 작업이 필요하여 restore.log로 저장 후 수정 작업을 진행했습니다.주의할 점은 --stop-datetime에 대한 시간을 잘못 지정하여 ‘DROP TABLE..’쿼리가 다시 실행되면 안됩니다.이렇게 데이터가 모두 복구되었습니다.부끄럽지만 binary log존재의 필요성이나 사용법 등을 처음 알게 된 계기가 되었습니다. 복구 방법에 대해 확신이 없는 상태에서 끝까지 믿고 맡겨주신 팀원들에게 아직도 고맙습니다.위의 이야기는 하루에도 몇 번씩 회자(놀림)되고 있으며 제가 이 회사를 퇴사하는 순간까지 아니 퇴사 후에도 길이길이 남을 것 같습니다.빌링 데이터베이스 대규모 개편 작업에 있었습니다. 신규 DB서버를 구매하고 파티셔닝도 진행하는 큰 규모의 작업이었습니다. 저도 모르는 사이 저희 팀 공식 DBA가 되어있던 저는 기존 데이터베이스의 데이터를 신규 서버로 이관하는 작업을 맡았습니다. 진행 방식은 위에서 언급한 장애 복구 방법과 비슷했습니다. 테스트도 할 겸 테이블 백업 데이터를 신규 서버에 INSERT 하기 시작했습니다.그런데! 퇴근 시간이 지나도 끝날 기미가 보이지 않습니다. 주요 결제 테이블 한 개만 복구하는데도 엄청난 시간이 필요했습니다 (core가 32개인데 왜 사용하지를 못하니..). 그 동안 배달의민족 주문수가 급증하며 데이터가 많이 축적되었고 더이상 mysqldump를 통한 백업, 복구를 할 수 없다고 판단했습니다.  비슷한 장애가 발생했을 때 몇 십 시간씩 데이터 복구에 시간을 낭비 할 수는 없기 때문입니다. 그래서 이번 기회에 새로운 백업 방식을 알아보았습니다.XtraBackup은 Percona에서 개발된 오픈소스로 백업 도구입니다. mysqldump가 테이블 생성, 데이터 쿼리에 대한 SQL 생성문을 갖는 논리적 백업이라면 XtraBackup은 엔진 데이터를 그대로 복사하는 물리적 백업 방식입니다. MySQL 엔터프라이즈 라이센스에 포함된 백업 도구의 기능을 모두 제공할 뿐만 아니라 더 유용한 기능들도 제공합니다. XtraBackup의 백업 방식은 크게 전체 백업, 증분 백업, 개별(db, table) 백업, 압축(qpress) 백업, Encrypted 백업이 있습니다. 또한 stream을 지원하기 때문에 파이프(|)를 통하여 다른 프로그램의 표준 입력으로 리다이렉션이 가능합니다. 이 내용에서는 전체 백업 + stream을 이용한 백업과 복구 방법에 대하여 공유해보려고 합니다.Centos 6.x에 MariaDB는 10.2.x를 설치했습니다. 현재 최신버젼인 XtraBackup 2.4을 기준으로 합니다.XtraBackup은 xtrabackup, innobackupex두 가지 유틸을 지원합니다. 백업을 해준다는 점에서는 같지만 각각 기능과 사용할 수 있는 옵션값에 차이점이 존재했습니다.XtraBackup에서 innobackupex는 next major부터 삭제된다고 했으나 아직까지도 유지되고 있습니다. 관련 도서나 커뮤니티에서 대부분 innobackupex기준으로 설명하며 다양한 편의 기능이 포함되어 있기 때문에 innobackupex를 사용하여 설명 드리겠습니다.빌링 데이터베이스는 장애 시 복구 과정을 단순하게 하기 위해 증분 백업을 사용하지 않고 전체 백업을 하고 있습니다. 말 그대로 운영중인 데이터베이스를 통짜로 복사합니다.백업하는 동안에 table lock을 없애려면 --no-lock옵션을 추가해야 합니다. 하지만 InnoDB table이 아닌 상황에서는 경우에 따라서 일관성 없는 백업 결과가 나올 수 있으므로 사전에 확인이 필요합니다. 참고: cmdoption-innobackupex-no-lock위와 같은 명령어를 실행하면 /home/backup/xtrabackup/yyyy-MM-dd_HH-mm-ss경로에 테이블, 리두로그, XtraBackup관련 데이터들이 함께 백업된 것을 확인할 수 있습니다.XtraBackup은 qpress를 이용한 compress 백업을 지원합니다. 하지만 압축 효율성과 속도에 아쉬움이 있다면 stream + pigz를 사용할 수 있습니다.tar를 해제할 때는 -i 옵션을 추가하셔야 합니다. eg) $ tar -xizf backup.tar.gz 관련문서백업된 데이터를 그대로 사용하면 좋겠지만 항상 생각대로 되는 게 없습니다.. 백업이 특정 시점에 완벽하게 이루어지면 좋겠지만 데이터 크기와 서버의 성능에 따라 백업하는 시간도 수십 분 ~ 수 시간 걸릴 수 있습니다. 이때 INSERT, UPDATE, DELETE쿼리가 유입된다면 백업된 데이터와 일관성이 없어지게 됩니다. 복원 준비 단계는 백업 중 수행 된 트랜잭션 로그파일(xtrabackup_logfile)을 적용하여 데이터를 일관성 있게 만들어줍니다.준비 단계는 백업한 뒤 즉시 실행할 필요가 없습니다. 데이터 복구 전 실행하셔도 됩니다.복원 원리는 간단합니다. 준비된 백업 파일을 MariaDB의 datadir로 옮겨주면 끝입니다. 이와 관련된 옵션을 innobackupex에서 지원해줍니다. 그전에 주의할 점이 있다면 mysql 서비스를 종료하고 datadir에 내용이 남아있다면 다른 폴더에 백업을 한 뒤 비워줘야 합니다.위와 같이--copy-back명령어를 사용하면 백업된 내용을 원본 디렉토리(/var/lib/mysql)에 이동시켜줍니다.추가적으로 데이터 파일의 권한을 MariaDB 서비스 계정으로 수정이 필요할 수 있습니다.지난번과 같이 오후 3시에 관리자의 실수로 데이터베이스를 삭제했고 새벽 6시에 진행한 전체 백업 덕분에 데이터를 어느 정도 복구했다고 가정합니다. 이제 우리는 새벽 6시 ~ 오후 3시 데이터를 binary log를 통해 복구해야 합니다.그런데 binary log파일은 어떤 걸 사용해야 하고 백업을 종료지점은 어떻게 알아낼 수 있을까요? 그것은 바로.. 전체 백업 후 데이터를 준비하는 과정(--apply-log)에서 생성되는 xtrabackup_binlog_info파일에 있습니다. 해당 파일에는 백업에 사용된 binary log과 position값이 적혀있습니다.mysql-bin.000004파일의 551 position에서 오후 3시까지의 데이터를 복구하면 됩니다. 이 정보는 데이터 복구할 때뿐만 아니라 Slave서버를 추가적으로 구성하는데도 유용하겠죠.위에서 말씀드렸지만 테이블이 정확히 DROP 된 시간을 알아내는 건 중요합니다. 그렇지 않으면 같은 내용의 장애 쿼리(DROP..)가 다시 실행될 수 있습니다. 반드시 mysqlbinlog 결과 값을 새로운 파일로 리다이렉션 하시고 데이터를 확인하시기 바랍니다.이렇게 복원이 모두 완료되었습니다.데이터 사이즈가 크지 않다면 mysqldump를 사용하는 게 간단하며 복원 시에도 신경 써줘야 할 포인트가 적습니다 하지만 데이터 사이즈가 수십 ~ 수백 GB에 이르면 이야기가 달라집니다. 실제 빌링 데이터베이스에 적용한 결과 아래와 같은 차이를 얻어낼 수 있었습니다.이 글에서 직접 다루지는 않았지만 증분 백업, 테이블별 백업 등 여러분 들에게 좋은 선택이 될 수 있는 기능들을 제공하고 있으니 XtraBackup 공식 메뉴얼을 둘러보시는것도 좋을것 같습니다.데이터베이스의 서비스, 관리용 계정 분리하기. 쿼리 날리기 전 한번 더 확인하기. rm -rf막기 등 장애를 관리할 수 있는 포인트는 많이 있습니다. 아직까지도 전체 백업이나 binary log가 존재하지 않았으면 어떻게 됐을지 상상이 안됩니다. 혹시나 이 글을 보시는 다른 개발자분들도 장애 시 전체 복구 포인트가 존재하는지 점검하는 계기가 되었으면 좋겠습니다.회사가 빠르게 성장하고 있습니다. 데이터가 급격하게 늘어나니 개발에 있어서도 고민하고 해결해야 할 부분들이 많이 생깁니다. 이런 일을 제가 언제 또 맡아서 해볼 수 있을까요.성장할 수 있도록 좋은 서비스와 환경을 만들어주신.. 그리고 저를 믿고 맡겨주신 회사와 팀원들에게 너무 고맙습니다.(이력서 한 줄 추가욧!)mysqldump 소개mysqlbinlogxtrabackup innobackupex도서: DBA를 위한 MySQL 운영 기술도서: Real MySQL",http://woowabros.github.io/experience/2018/05/28/billingjul.html,woowabros,,NULL,2018-05-28
주소검색서버(woowahan-juso) 개발기(上),"안녕하세요 라이더스개발팀 정세빈 입니다 :)BROS(Baemin Riders Operating System)에 주소검색을 위한 주소검색서버 개발 및 배포 경험을 공유 드리려고 합니다.BROS는 배민라이더스의 주문 건을 배달하기 위한 라이더 운영 시스템입니다.라이더 분들이 배달할 때 픽업지 혹은 배달지의 위치가 굉장히 중요합니다. 해당 위치의 변경 및 확인을 위한 주소 검색서버가 필요했고, 여러 솔루션 중 직접 DB에 데이터를 쌓고 서버를 배포하는 것을 택하게 되었습니다. [주소 검색 및 변경 화면]위 화면처럼 주소 검색을 위한 서버가 (여러가지 이유로) 필요했었습니다. 그래서 저희는 SpringBoot Batch, Amazon CloudSearch, JPA등을 이용하여 woowahan-juso라는 주소검색 서버를 배포하였습니다. 사내에도 잘 모르시는 분들을 위해 공유 겸, 해당 서버를 구성하는 것들에 대한 개발 경험을 나눠 볼려고 합니다.는 아닙니다. 주소 검색서버(woowahan-juso) 개발에 쓰인 서버 스펙 중, 이번 글에서는 SpringBoot Batch를 이용하여 주소DB를 재구축한 부분에 대해서 포스팅하려고 합니다.그리고 SpringBoot Batch의 설정 및 사용방법 등 기술적 부분보다는 주소 데이터를 어떤식으로 다뤘는지, 왜 그렇게 했는지 등 경험을 중점적으로 다뤄 볼 예정입니다. (기술적인 부분은 역시 Reference Doc이죠)유심히(?) 보신 분들은 봤겠지만, 이번 글의 타이틀에 (上)을 붙였습니다. (下)에서는 재구축한 주소 DB를 이용하여 Amazon CloudSearch 서비스를 사용한 부분을 포스팅할 예정입니다. (Feat. 빅픽쳐)왜 이미 있는 주소 서비스를 사용하지 않고 DB를 새로 작업한건지, 왜 일반적인 batch 프로세스를 개발하지 않고 spring batch를 이용했는지에 대한 자체 Q&A를 진행해봤습니다.www.juso.go.kr 에 가면 주소검색 솔루션과 주소검색 API 그리고 txt형식의 주소 데이터를 제공해줍니다. 그중에서 몇 가지 이유로 txt형식의 주소데이터를 택해 새로운 주소DB를 구축했습니다.주소검색 API는 데이터를 정부에서 관리하고, 주소검색 솔루션은 주소 업데이트를 일정 기간 이상 하지 않으면 서비스가 중단되는 특징이 있습니다.BROS의 주소 현황과 배민의 주소 현황의 싱크를 유지해야하기 때문에, 늘 최신데이터를 업데이트 해야 하는 주소 서비스를 이용할 수 없었습니다.상시 운영상황에서의 테스트를 위한 주소가 존재하는데, 해당 주소를 DB차원에서 관리하려면 불가피하게 DB를 재구축해야 했습니다.만약 서비스의 운영환경에서 주소검색이 안되면 서비스의 에러상황으로 이어지게 됩니다. 하지만 www.juso.go.kr 에서 제공하는 서비스는 SLA에 대해서 보장해주지 않습니다. 이벤트 트래픽 혹은 갑작스런 장애상황 등에 SLA가 보장되지 않는 서비스가 껴있는건 서버 운영측면에서 리스크를 안고 가게 됩니다. 그래서 트래픽 대응, 장애대응 등 직접적으로 운영, 관리할 수 있는 주소 서버가 필요했습니다.Spring Batch의 특징은 굉장히 많지만 그 중에서도 주소 데이터를 넣는 Batch Job을 실행할 때 얻을 수 있던 장점에 대해 써보겠습니다.주소 txt파일을 읽어 주소데이터를 넣을 때 예상치 못한 에러로 Batch Job이 중 될 수도 있습니다.파일 라인중 특정 컬럼이 비어있어서 NPE가 날 수도 있으며, 예상과 달리 Unique특성이 깨지는 데이터가 있어서 SQL예외가 발생할 수도 있습니다.여러 데이터가 들어있는 주소txt파일은 전체로 보면 2천만이 넘는 row를 가지고 있습니다. 이런 많은 데이터를 전체적으로 valid체크하는 것도 어려움이 있고 valid하지 않다고 해서 필요없는 데이터라고 판단할 수도 없습니다. 또 실패했다고 처음부터 다시 job을 실행하기엔 데이터양이 많아 비효율적인 작업이 됩니다.Spring Batch를 통해 Application을 실행하면 BATCH_JOB_EXECUTION_CONTEXT, BATCH_STEP_EXECUTION_CONTEXT 라는 테이블이 생성되고, 이 테이블에는 특정 Job or Step의 실행을 지속할 수 있게하는 데이터가 업데이트 됩니다. 이를 통해 중간에 batch job이 중단되더라도 문제파악 후 실패시점부터 다시 실행할 수 있었고, 더불어 위의 문제점들을 해결 할 수 있었습니다.Spring Batch에서는 여러 형태의 데이터들(DB, 플랫파일)을 하나의 인터페이스(ItemReader, ItemWriter)로 Step을 구현할 수 있게 제공해줍니다. 그럼으로서 여러 형태의 데이터에 대한 직접적인 대응을 줄일 수 있었고, 교육 비용도 줄일 수 있었습니다.이 외에도 Batch Process를 처리할 때 Spring Batch의 기능, 특징으로 얻을 수 있는 장점이 많기 때문에 선택했습니다.Spring Batch에 대해서 모르시는 분들께 해당 글 이해를 위한 작업 실행구조를 간단히 설명하고 시작하겠습니다(이미 아시는 분들은 넘어가셔도 좋지만, 피드백은 언제나 감사합니다 :)JobRepository: 현재 실행 중인 프로세스의 meta data를 저장합니다.JobLauncher: Client로부터 요청을 받아 Job을 실행하는 객체입니다.Job: Step들의 컨테이너, Step들의 단계 혹은 재시작 가능성과 같은 모든 단계에 대한 전역 속성을 구성합니다.Step: 실제 batch처리를 정의, 제어하는 정보가 들어있는 도메인 객체입니다.ItemReader: 한 Step안에서 FlatFile, XML, DB 등 여러 input에서 Item을 읽어 들입니다.ItemProcessor: ItemReader로부터 읽어들인 Item을 DB에 Write하기 전에 필요한 로직을 처리를합니다.ItemWriter: ItemReader로부터 읽어 들인 Item을 Insert, Update 처리합니다.Spring Batch는 크게 위의 구조를 통해 동작합니다. 더 자세하게는 위 구조를 동작하기 위한 여러가지 설정과 DB, Object 등이 있지만, 이번 포스팅에서 다루기엔 너무 많고 어렵기 때문에 링크만 공유드립니다.(회피)각 데이터 별(주소, 지번, 부가, 도로명) 주소데이터 txt파일을 읽는 ItemReader, 주소DB에서 시도, 시군구 등 데이터를 읽는 ItemReader 구현합니다.ItemReader로 읽은 Item(도메인객체)들을 새로운 주소DB에 Insert할 ItemWriter를 구현합니다.ItemReader와 ItemWriter, 필요에 따라서는 ItemProcessor를 추가하여 데이터별 Step을 구현합니다.각 Step들을 플로우에 맞게 실행할 Job을 생성하고해당 Job name을 parameter로 JobLauncher에게 실행요청을 합니다.위에서 간단하게 설명한 실행 구조들을 실제로 어떻게 구현했고 사용했는지에 대해 코드와 함께 설명드리려고 합니다. 코드는 Java이고 실제 프로젝트의 코드가 아닌 포스팅용으로 수정한 코드임을 알려드립니다.우선 txt파일을 read해서 도메인 객체를 리턴할 ItemReader를 구현해야 합니다.우선 FlatFileItemReader를 이용하여 FlatFile(.txt)을 읽는 ItemReader Bean을 생성했습니다. 플랫파일을 라인단위로 읽은 후, LineTokenizer와 FileSetMapper를 이용하여 read한 각 라인을 도메인객체로 리턴받게 구현하였습니다.앞 단계에서 ItemReader를 이용해 txt파일로부터 Item을 읽은 후, 원하는 DB Table에 저장할 ItemWriter를 구현해야 합니다.JdbcBatchItemWriter를 이용하여 Jdbc모듈 형식으로 mysql에 접근하였습니다. 그 중 NamedParameterJdbcTemplate을 이용하여 read한 Item (도메인객체)을 namedParameter로 가져와 insert할 value를 셋팅했습니다.앞서 구현한 ItemReader와 ItemWriter를 통해 원하는 데이터를 read, write할 Step을 구현해야 합니다.각 데이터에 맞는 도메인 객체와, txt파일을 Resource객체로 변환 후 set했습니다. step에는 chunk size를 지정해 줄 수 있습니다. chunk size 만큼 ItemReader와 ItemWriter가 동작하여, 원하는 단위로 트랜잭션 커밋을 할 수 있습니다.주소 txt파일을 읽어 저장한 주소DB에는 약 800만개의 지번정보와 약 35만개의 도로명정보, 기타 부가정보들이 있습니다. 해당 파일에는 시도, 시군구, 행정동에 대한 정보를 따로 제공해주지 않아 전체 주소 정보로 부터 추출해야 합니다.앞서 구현한 것들과 달리, 이 Step은 DB로 부터 read와 write를 합니다.read, write과정이 앞 단계보다 간단해서 generic type을 이용하여 각 Step들을 구현했습니다. 각 데이터에 맞는 read sql, rowMapper를 parameter로 받아 JdbcCursorItemReader를 사용하였고, JPA Entity 객체를 통해 write하는 JpaItemWriter를 사용하였습니다.이제 구현한 Step들을 Job단위로 묶어 원하는 순서대로 실행할 Job을 만들어야 합니다.Sido, Sigungu, DongOfAdmin Step들은 4.에서 구현한 createStep method를 통해 만든 Step입니다.jusoStep을 먼저 실행하여 주소txt 파일로부터 DB에 데이터를 쌓고, 그 후에 시도, 시군구 등의 데이터를 다시 주소DB로 부터 추출해야 합니다.그래서 Job을 생성하고 start, next로 Step을 실행하였고, Job이 Step의 순서를 보장해 주어서 원하는 동작을 할 수 있었습니다.Application 실행 시 -Dspring.batch.job.names=jobName 으로 원하는 jobName을 넣어주면 JobLauncher가 parameter를 받아 해당 job을 실행하고, 원하는 주소 데이터들을 주소DB에 쌓을 수 있습니다.현재 운영중인 서버는 위 구현 과정을 통해 Job을 만들고 실행하여 원하는 주소 DB를 만들고 잘 사용중입니다. (다행이다)주소 검색서버의 목표는 www.juso.go.kr 메인의 검색 기능을 구현하는 것이었습니다. 해당 기능을 구현하기 위해 Amazon CloudSearch 서비스를 선택하였고, 그 부분을 다음 포스팅에 적어 볼 예정입니다.이렇게 개발했던 경험을 블로그로 포스팅한 건 이번이 처음입니다.역시 글을 쓰는 건 (정말)힘들고 (너무)어려웠지만 덕분에 다시 Spring Batch에 대해서 더 깊게 공부할 시간을 가져서 좋았습니다. 더불어 이 주소서버 개발을 할 때 처음으로 Spring Batch를 공부하며 진행했었는데, 이렇게 doc문서를 더 자세히 보면서 이전 코드를 보니 코드리뷰도 된 것 같아서 더 좋은 경험이 되었습니다.글을 마무리 지으려니 어떻게 지어야 할지 잘 모르겠네요. 그래서 급 마무리 인사드립니다.이렇게 누추한 글에 귀한 분들께서 읽어주셔서 감사합니다다음 포스팅에서 Amazon CloudSearch와 함께 돌아오겠습니다.[cause you are my girl~]",http://woowabros.github.io/experience/2018/05/26/woowahan-juso.html,woowabros,"php,java,python,html,css,json",NULL,2018-05-26
Google I/O 2018 에 다녀오다!,"안녕하세요. 배민서비스개발실 배민프론트개발팀에서 산업기능요원으로 iOS 개발을 하고 있는 강경완입니다.우아한형제들에서는 iOS 개발을 하고 있지만, GDG (Google Developer Groups) Korea Android 커뮤니티의 오거나이저로 활동하고 있어서 Google I/O 2018에 참여했습니다.먼 나라 미국까지 날아가서 2박 3일동안 전 세계의 개발자들을 만나며 무엇을 했는지를 짧게 공유해드리고자 합니다.저는 일단 산업기능요원 신분이기 때문에 출국이 자유롭지 않습니다. 그래서 국외여행 허가를 받아야 합니다.5월의 캘리포니아는 날씨가 매우 이상합니다. 샌프란시스코 쪽은 바람이 많이 불어서 춥고, 구글 I/O가 열리는 마운틴 뷰 쪽은 낮에는 강렬한 태양의 뜨거움과 태양이 없는 그늘에서는 추위를 느낄 수 있습니다. 그래서 개발자 반팔 티셔츠와 입고 벗기 편하게 후드집업을 챙겨가면 좋습니다.개발자 티와 후드집업으로 세계는 통한다Google I/O는 2박 3일 일정으로 진행되고, 메인 홀인 Amphitheatre과 Stage 7개에서 서로 다른 주제의 세션이 있습니다. 세션 외에도 각기 다른 주제로 이루어진 부스인 Sandbox가 A부터 I까지 총 9개의 부스가 마련되어 있습니다. 이 외에도 코드랩부스, Office Hour Time 등이 준비되어 있습니다.Sandbox로는 Android, Android Things, Wear OS, AI/ML, Google Cloud, Googld Assistant, Design, AR/VR 등이 있었습니다.Android 부스에는 KTX, Android Jetpack, Android P 등에 대한 전시와 함께 해당 분야 팀의 구글러가 옆에서 직접 설명해주거나 질문을 받아주었습니다.AI/ML 부스에서는 Tensorflow를 이용한 게임, Tensorflow Lite에 대한 간단한 데모 (Local에서 사물 판단하기)와 TPU v1, v2, v3 전시, 이미지 분석을 통한 자율 주행차 등을 전시해두었었습니다.Google Cloud 부스에서는 Firebase Test Lab에 대한 소개로 실제 Deck을 전시해두고 UITest가 어떻게 진행되는지를 전시해 두었습니다. 또한 Firebase에 추가된 ML킷에 대한 내용도 있었습니다.Google Assistant 부스에서는 Action on Smart Displays 같이 직접 Assistant를 체험할 수 있도록 해두었습니다.AR/VR 부스에서는 구글의 Daydream을 이용해서 직접 체험해볼 수 있었습니다.이렇게 큰 개발자 컨퍼런스의 매력은 역시 전 세계의 많은 개발자들이 한 자리에 모이는 것입니다.  물론 한국에서도 판교만 가도 개발자 같을 것 같으신 분들이 많이 돌아다니시고, 샌프란시스코 역시 마찬가지긴 하지만, 여기는 정말 10명 중 9명은 개발자이며 심지어 다양한 나라에서 날아오신 분들입니다.작년 I/O17를 다녀온 뒤 I/O에 대한 경험이 주니어 개발자에게 어떤 성장의 거름이 되었는지에 대해 발표를 한 적이 있습니다. 영어가 부족해서 하고 싶은 말이 많았지만 많은 대화를 나누지 못한 것에 대한 회고를 했었는데, 올해 I/O18 에서는 글로벌 친구들과 커뮤니케이션을 많이 하려고 노력했습니다.주로 안드로이드 개발자를 만나면 패턴이 비슷했는데…여담이지만 작년 I/O에서 Kotlin이 Android의 공식 지원언어가 되었고, Java와 Kotlin을 병기하여 나오던 예제코드들이 올해는 100% Kotlin 코드로 세션에서 발표가 되었었습니다. Kotlin 쓰고있냐고 안 물어보는 안드로이드 개발자를 만나지 못했어요다른 에피소드로는 개발 문화적인 차이도 있었습니다. 가령 예를들면 Flutter… 아프리카 지역의 학생 개발자 그룹에서 I/O에 참가하게 되었다고 소개한 대학생 두 명을 만났습니다. Flutter에 빠져있다고 하더군요.지금도 트위터에서는 native, pwa, react, flutter 등에 대한 discussion이 일어나고 있는 것 같습니다. (Dart 언어이기도 하고.. Flutter는 안써봐서 잘 모르겠습니다.)장애인들을 위해 Accessibility를 어떻게 더 잘 구현할 수 있을지에 대한 세션이 눈에 띄었습니다.[Session] What’s new in Android accessibility[Session] Accessibility for AR and VR[Session] What’s new in web accessibility[Session] An accessible process for inclusive design각 플랫폼 별로 1개씩 있었는데 AR, VR에 대한 Accessibility 세션은 자리가 없을 정도로 인기가 많았습니다. 작년 말에 배달의민족 앱도 accessibility 중 하나인  VoiceOver 지원에 대한 리뷰가 올라와서 대응을 한 적이 있었기 때문에 관심이 가는 주제였습니다. 동영상 자막으로 효과음 또는 그냥 흘러 지나갈 수 있는 대사가 아닌 배경 소리도 자막 처리를 하는 것이 청각장애인을 위한 것이었다는 것에 신선한 충격을 받았었는데, AR, VR 플랫폼도 accessibility 대응을 해야한 다는 생각을 전혀 못하고 있던 저에게 이 또한 신선한 충격이었습니다.Don't design for yourself or your situation  사용자 경험에 대해 다시 생각해보는 시간이 되었습니다.얼마 전 Tensorflow Summit에서 Javascript 버전의 Tensorflow JS을 발표하더니 이제는 Firebase 위에서 사용할 수 있는 모바일 버전의 ML Kit 을 발표했습니다.텍스트인식, 얼굴검출, 랜드마크 인식, 바코드 스캐닝, 라벨링 등 모바일 사용 환경에서 자주 쓸만한 머신러닝 모델들을 제공합니다.Firebase 클라우드 환경에 데이터를 전송해도 되고, 모바일 환경에서 네트워크 없이 사용할 수도 있습니다.iOS와 Android 모두 지원하는 ML KitML Kit 외에도 Tensorflow Lite 에 대한 시연을 샌드박스에서 볼 수 있었는데, Tensorflow 보다 가벼운 Tensorflow Lite를 라즈베리파이 같은 작은 기기에서 카메라 모듈을 이용해 라벨링을 하는 것을 볼 수 있었습니다.생각보다 잘 돌아갔던게, 선글라스와, 그냥 안경 두 가지 모델을 모두 넣었는데 구분해내더군요.이런 Tensorflow Lite에서 만든 모델을 ML kit에 추가해서 쓸 수도 있다고 합니다. 이젠 정말 모든 플랫폼 개발자가 머신러닝에 대해 공부하거나 준비해야될 때가 되지 않았나 싶었습니다.해외 컨퍼런스에 참여한다는 것은 사실 많은 것을 투자해야만 합니다. 비행기 삯과 컨퍼런스 티켓을 포함한 돈과 시간, 연차, 그리고 장기휴가이기 때문에 팀원들과 일정 조율 등등등.. 하지만 많은 것을 투자한 만큼 개인에게 있어 더 가치있고 큰 경험을 얻어갈 수 있는 기회였다고 생각합니다. 단순히 구글에서 발표하는 신기술을 누구보다 빠르게 세션을 통해 알게 되는 것 뿐만 아니라 전체적인 부분이랄까요? 음식점에서 행복을 느낄 때 평가하는 요소가 맛이 전부는 아니잖아요? 내년에는 올해보다 더 성장한 개발자가 되어 다시 가보고 싶습니다!!",http://woowabros.github.io/experience/2018/05/23/google-io.html,woowabros,"angular,ruby,java,python,django,android,react,ionic",NULL,2018-05-23
라이더스앱(iOS) 개발기,"안녕하세요 라이더스개발팀 박민 입니다. 배민라이더스의 라이더분들이 배달을 수행하기 위해 사용되는 애플리케이션 ‘라이더스’ 개발기를 적어보려 합니다.먼저 BROS(Baemin Riders Operating System)가 있습니다. (네! Geo-fence를 신선하고 유익하게 설명해주신 민철님의 글에서도 등장합니다.) 라이더스는 BROS에서 발생하는 배달을 라이더가 수행할 수 있도록 배차 요청을 비롯해 픽업, 전달 등의 배달업무를 처리하는 애플리케이션입니다. 플랫폼의 이름과 같은 Android 버전에서의 ‘BROS’에서 직관적인 이름의 ‘라이더스’로 변경되었습니다.늘어나는 주문을 처리하기 위해 우리는 많은 라이더분이 필요합니다. 그래서 모집공고를 통해 많은 예비라이더 분을 뵙게 되는데, 10명 중 2명은 아이폰을 사용하시기에 OS의 문턱에 발걸음을 돌리셨다고 합니다.(물론 업무용으로 따로 Android기기를 사용하시는 분도 계십니다.) 20%의 수치는 현재 아이폰 사용률, 특히 젊은 층의 사용률을 미루어 보았을 때 앞으로 더욱 높아질 수 있다고 생각했습니다. 그래서 우리는 앞으로 더 많은 예비라이더 분들을 놓치지 않기 위해 iOS 버전의 라이더스가 필요했습니다.iOS 버전 라이더스의 필요성은 충분히 공감했지만 저는 iOS 애플리케이션을 만들어 본 적이 한 번도 없었고, 하물며 우아한형제들과 일하게 되며 맥북을 처음 사용했습니다.(#새맥북#좋은개발환경) 그런 제게 Object-C, Swift는 낯설기만 했고 벽은 높아만 보였습니다.네이티브로 만드는 것이 닿지 않을 듯 멀게만 느껴지고, React Native가 힙해 보여서 사용하게 된 것은 아니었습니다. 선택에는 위 2가지 이유가 있었고, 우선 React Native로 개발 가능 여부를 빠르게 검토하고, 안 되겠구나싶으면 Object-C, Swift를 배워야겠다! 하는 마음으로 시작했습니다. 누가 시켜서 한건 절대로 아니에요. 다만 @재일님께서 해보라고 ‘권유’는 하셨습니다. ~(^^~)자바스크립트가 네이티브에서 동작하기 위해서는 네이티브 코드가 필요합니다. 버튼을 예로 들어보겠습니다. 먼저, 자바스크립트에서 버튼을 구성하고 네이티브에서의 버튼 기능을 수행할 컨트롤 과 bridge로 통신하면 됩니다.  잠깐만요? 네.. 네이티브의 벽은 높지만 구현 해야 합니다.  물론 React Native는 네이티브 경험 없이도 애플리케이션을 만들 수 있는 매력적인 플랫폼입니다. 그리고 화면 구성을 위한 정말 다양한 컴포넌트가 (Button,RefreshControl,WebView 등) 이미 제공되기 때문에 네이티브 개발을 줄여주고, 빠른 애플리케이션 개발을 도와줍니다.하지만 간단한 애플리케이션인 라이더스에서도 React Native가 제공하는 컴포넌트 이외의 화면이 필요했습니다.(간단하게는 지도화면부터, 애플리케이션을 환경(live, beta)별로 관리하거나, build를 할 때 필요한 네이티브의 설정들을 제공하는 네이티브 모듈들이 필요했습니다.)그리고 만약 저처럼 제공하지 않는 컴포넌트로 화면을 구성하기 위해서는 보통 2가지 방법이 있습니다.React Native는 네이티브 개발의 필요성을 줄여주지만, 여전히 네이티브 개발이 필요합니다. 그래서 네이티브 경험 없이 애플리케이션을 개발하는 것은 힘들게 느껴질 수 있겠지만, 오히려 제게는 네이티브를 통한 간편한 확장성이 React Native를 쉽게 선택할 수 있게 하는 장점이라고 생각합니다.(이가 없으면 잇몸으로!)React Native로 개발하며 흥미로웠던 부분은 네이티브와는 다른 React Native의 개발과정이었습니다. 예를 들어 네이티브의 경우에는 테스트 디바이스에 애플리케이션을 설치하고 확인하고, 다른 해상도의 테스트 디바이스에 설치하고.. ‘엇 어긋나네..?’ 수정하고, 다시 설치하고, 이전 기기에 또 설치하고.. 확인하고.. x100 React Native는 로컬의 노드 서버에서 published JavaScript 코드를 수행합니다. 그렇기 때문에 에뮬레이터를 비롯한 실제 디바이스에서의 변경사항 확인은 애플리케이션의 컴파일 없이 새로 고침으로 충분합니다.  조금만 자세하게 설명해보겠습니다혹시 네이티브 영역의 코드가 변경되야한다면! 네.. 다시 패키징하는 방법으로 배포해야합니다.앞서 말씀드린 것처럼 네이티브의 지식도 필요합니다. 그래서 iOS 경험이 없던 저는 Object-C도 함께 학습해야 했지만 제 생각에는 React에 대한 학습이 좋은 애플리케이션을 만드는데 더 많은 영향을 미치는 것 같았습니다. 서비스에 따라 네이티브의 영향이 큰 프로젝트도 많겠지만, 라이더스의 경우에는 빈번한 화면 render와 화면 전환이 중요한 부분이었고, (지도를 제외한 모든 화면이 React로 구성되었습니다.) 특히나 사용자에게는 네이티브로 개발된 Android 버전의 라이더스BROS가 비교 대상이었기 때문에 그만큼의 퍼포먼스가 요구되었습니다.React는 setState() 메서드를 통해 컴포넌트를 표현할 때 사용하는 state를 업데이트할 수 있습니다. setState() 메서드가 수행되면 컴포넌트에 Dirty로 마크되고, 다음 이벤트 루프 때 Dirty 컴포넌트를 다시 render하게 되는데, 이때 Dirty 컴포넌트의 하위 컴포넌트까지 render의 대상이 됩니다.컴포넌트를 표현하기 위한 state의 잦은 변경은 자칫 불필요하게 빈번한 화면 render를 수행하게 할 수 있습니다. 이를 효율적으로 처리하기 위해서는 적절한 shouldComponentUpdate를 활용해야 합니다. shouldComponentUpdate는 render가 수행되기 전에 render 필요 여부를 return 하는 React 생명주기의 일부입니다.물론 React에서는 shouldComponentUpdate를 이미 구현한 pureComponent도 제공을 합니다. 하지만 이 컴포넌트는 변경된 props와 state를 shallow level에서 비교한 결과로 render 여부를 판단하기 때문에 의도하지 않은 render가 발생할 수 있습니다. 만약 직접 shouldComponentUpdate를 구현한다면 주의할 점이 있습니다. 컴포넌트가 커지면 자연스럽게 사용되는 props와 state가 다양해집니다. 그렇다 보면 shouldComponentUpdate에서의 정확한 render 여부를 반환하기 위해 props와 state의 deep-compare 유혹에 빠지게 될 때가 있습니다.하지만 shouldComponentUpdate에서 deep-compare는 권장되는 행동이 아닙니다. we don’t recommend deep equality checks 요약해보면, shouldComponentUpdate에서 render 하지 않겠다고 판단하는 데 소비하는 시간이 render 하는 시간보다 길어질 것을 우려하기 때문입니다. 제 경험으로는 효율적인 render를 위해서 무엇보다 각 컴포넌트를 목적에 따라 작게 나누고, 컴포넌트는 필요한 props와 state만 다루는 것이 결국 render가 수행되어야 하는 시점을 쉽게 판단할 수 있도록 해주었습니다.다음은 라이더스를 만들며 사용한 React Native의 API와 유용한 라이브러리를 소개합니다.많은 이야기를 하고 싶은 마음과 절제하려는 열 손가락 사이에서 두서없는 글이 탄생하게 되었습니다. ㅠ_ㅠ 처음 개발 시작할 때 함께한 우려와 머뭇거림이 아직 프로젝트 곳곳에 고스란히 묻어있지만 이미 React Native로 개발된 iOS 버전의 라이더스는 릴리즈 되었고, Android 버전도 준비 중입니다. [React Native를 검색할 때 tutorial과 앞다투는 검색어]위 사진 속 우려의 검색어가 시작할 때 저를 주춤하게 한 가장 큰 걸림돌이었습니다. 만약 React Native를 시작하려 하시는 분이 계신다면, (추천하기에는 저는 아직 많이 배워가는 단계지만) 그저 애플리케이션을 개발하는 방법이 하나 더 생겼다는 마음으로 가볍게 마주하면 어떨까 싶습니다. 서툰 글을 읽어주셔서 감사합니다.  그리고 도움 주신 동료 iOS 개발자분들께 많은 감사드립니다.참고 사이트",http://woowabros.github.io/experience/2018/05/19/build-app-by-react-native.html,woowabros,"vue,reactjs,angular",NULL,2018-05-19
"결제 시스템 성능, 부하, 스트레스 테스트","안녕하세요. 우아한형제들에서 결제시스템을 개발하고 있는 권용근입니다. 입사한 지 4개월 만에, 드디어 우아한형제들 기술 블로그에 글을 남기게 되어 감회가 새롭습니다.저는 최근 결제 시스템의 개비를 진행하며 경험한 성능, 부하, 스트레스 테스트 경험을 작성해보려고 합니다.입사하고 보니 저에게는 결제 API 단순화, 결제 시스템 데이터베이스 분리 및 파티션 도입, 비동기 결제 시스템 개발 이라는 굵직굵직한 작업들이 기다리고 있었습니다.Java, Spring Framework, ORM 등의 기술 지식은 그간 해온 게 있기 때문에 (구글링이 있기 때문에) 파악하는데 어렵지 않았지만, 이미 구축되어 있는 시스템을 손대는 것은 쉬운 일이 아니었습니다.“거대 규모 프로젝트에서 내가 수정한 코드가 어떤 사이드 이펙트를 발생시킬지..”이래서 존재하는 것이 바로 테스트 코드 !! 다행히 테스트 코드를 지향하는 프로젝트였기에 작성된 테스트의 보호 아래 신나게 개발을 할 수 있었습니다.결국 테스트를 모두 통과시키며, 개발이 완료되었습니다!그리고 이때부터 본격적인 미지의 영역에 대한 공포가 시작되었습니다.내가 만든 이 시스템은 실제 장비에서전혀 감이 안 잡혔습니다. 이것은 흔히 말하는 localhost:8080 레벨에서는 확인할 수 없는 문제였습니다.위의 수많은 공포에 대하여, ‘내가 예상하는 데로’, ‘내가 정의해놓은 데로, 작성해놓은 데로 잘 동작하겠지’ 라고 믿을 수는 없었습니다. 호되게 당한 적도 있기도 하고, 실제 사용자의 돈이 움직이는 결제 시스템에서 전혀 보이지 않는 불안요소를 가지고 가기에는 너무나 두렵고 무서웠습니다.그래서 테스트 코드가 두려움을 해소해줬듯, 이번에도 두려움을 해소해줄 성능 테스트 환경을 만들게 되었습니다.결제 시스템은 사용자의 주문 비용을 각종 결제수단(PG사, 포인트, 쿠폰) 등의 시스템과 통신하여 지불처리하는 시스템입니다. 많은 부분을 생략하고 간단하게만 표현하면, 하나의 결제는 결제수단 시스템이란 외부 인터페이스를 거치게 됩니다.그래서 저는 결제수단 시스템을 Mock 처리해야 했습니다. 온전히 테스트 대상 시스템의 성능을 측정하기 위해서 외부 시스템은 항상 기대한 결과만을 반환하는 환경이 필요하기 때문입니다.1. 객체 Mocking객체 Mocking은 테스트 코드를 작성할 때 가장 많이 사용하는 방식이라 친숙할 것 입니다. 그러나 로직에 대해 검증을 하는 테스트와 달리, 성능 테스트는 어플리케이션 동작과 자원의 사용을 모두 보아야만 하는 테스트입니다.객체 Mocking 은 해당 객체의 행위 뒤로 들어가야 할 동작들을 무시해버리게 됩니다. 예를 들어 Spring Profile 을 사용하여 RestOpertation 을 객체를 Mock 처리하였을 때등등 성능 테스트에서 중요한 관점인 Thread 사용, 리소스 사용을 전부 무시하게 됩니다.외부 인터페이스를 Mocking 하는 것처럼 보이지만, 내부 인터페이스도 Mocking 해버리는 객체 Mocking 은 성능 테스트에서 피해야 합니다.2. 같은 어플리케이션에 Dummy Controller 생성이 방식도 아주 간혹 테스트 코드를 작성할 때 사용하는 방식입니다. 이 방식이 1번 방식과 다른 것은 실제로 요청을 보내고 받으며 자원을 사용한다는 것 입니다.그러나 Dummy Controller 의 로직은 테스트 시스템의 자원과 리소스를 같이 사용해버리게 됩니다. 테스트 대상 시스템이 더 늘어나 버리는 신뢰성이 굉장히 떨어지는 의미없는 성능 테스트를 하게 됩니다. 테스트를 위한 요소는 대상 시스템에 절대로 영향을 미쳐서는 안 됩니다.그래서 우리는 테스트 대상 시스템과 완벽히 분리된 Mock Server 를 띄워야 합니다.외부 인터페이스 Mock이 갖추어야 할 조건을 아래와 같이 정의했습니다.제가 만든 것은 가짜 PG사인 Gazua PAY 입니다. 요청 인터페이스는 기대한 결과와 퍼포먼스로 응답을 하도록 하는 값을 받도록 하였습니다.(개발 당시에는 코인 시장이 엄청 핫할 때 였습니다. 승인 결과의 message는 차트의 상승을 표현했는데 아무도 눈치채지 못했습니다.)저는 Spring 쟁이라 Spring Boot 로 아주 간단히 모든 요청에 기대한 결과, 퍼포먼스를 내는 Mock Application을 만들었습니다.이제 Mock Application 을 배포해야 합니다. 이럴 때 정말 유용했던 것은 AWS Elastic Beanstalk 입니다. (우아한형제들은 AWS 사용을 적극 지원해주기 때문에 마음껏 쓸 수 있었습니다.)(Elastic Beanstalk 홍보 영상 중..)Elastic Beanstalk 은 애플리케이션을 업로드하기만 하면 용량 프로비저닝, 로드 밸런싱, Auto Scaling, 애플리케이션 상태 모니터링에 대한 배포 정보를 자동으로 처리해줍니다.배포를 위한 스크립트를 작성하거나, 서버 설정을 해줄 필요 없이 클릭만으로 간단하게 하나의 환경을 만들 수 있고, Mock Server 에 병목이 생겨도 클릭만으로 Scale Out 하여 병목을 해소할 수 있습니다.이로써 병목이 되지 않는, 기대한 결과와 퍼포먼스를 반환하는 Mock Server 가 완성되었습니다.nGrinder 는 성능 측정 목적으로 개발된 오픈소스 프로젝트로등의 기능을 제공합니다.성능 측정 도구로 nGrinder 가 가장 좋았던 것은 groovy 스크립트로 테스트 시나리오를 작성할 수 있다는 것 입니다.groovy는 gradle, jenkins file, spock 등에서 자주 다루었던 친숙한 언어였기에 내가 원하는 테스트 시나리오를 쉽고 자유롭게 작성할 수 있었습니다.pinpoint 는 Java로 작성된 대규모 분산 시스템용 APM 도구입니다.사내에서 사용하고 있는 모니터링툴이기도 하며, Transaction 의 추적을 제공하는 APM 중 하나입니다.단일 Transaction의 Stack Trace 를 기록하여 직접적인 병목이나 문제를 빠르게 추적할 수 있고,Transaction 이 DOT 로 그려지는 응답시간/요청시간 그래프 Transaction View 는 테스트의 상태를 실시간으로 확인하여, 가장 빠르게 이상을 감지하도록 도와줍니다.Transaction View 는 패턴에 따른 어플리케이션 상태 예측에도 큰 몫을 하였습니다. A 구간의 병목을 보였을 때 보이는 패턴, 외부 인터페이스가 병목을 보였을 때 등등 예상 패턴을 통해 더 빠른 조치가 가능하기도 했습니다.실제로 테스트를 하며 수많은 이상 패턴들이 탄생하기도 하였습니다.(기영이 패턴)(L타워 패턴)그리고 노력 끝에 얻어진..(백설기 패턴)pinpoint 로 어플리케이션의 전반적인 상황을 파악할 수 있었지만, pinpoint 의 Trace 기능으로 모든 패키지와 클래스를 탐색 하는 것은 너무 과하며, Thread 간의 경합 으로 발생되는 예기치 않은 현상들을 탐지하기는 어렵습니다.이럴 때 우리는 Thread Dump 를 분석해야 합니다.저는 JVM 의 내장 명령 도구인 jstack 을 사용하여 쉽게 Thread Dump 를 획득할 수 있었습니다.이제 Tread Dump 를 분석하여 병목의 원인을 파악할 수 있습니다.(Tread Dump 를 보기 편하게 가공)우리가 만드는 시스템은 결국 하드웨어 위에서 동작하게 되고, 시스템의 리소스 자원 사용은 Scale Up, Scale Out, Scale Down 의 중요한 지표가 됩니다.그러므로 우리는 테스트를 통해 이 시스템은 리소스 자원을 최대한으로 사용하고 있다 라는 결론으로 도달해야 합니다.리소스 자원을 실시간으로 모니터링하기 위해 dstat 을 사용하였습니다.dstat 은 vmstat, iostat, ifstat, netstat 정보 등을 결합한 내용을 보여주고, 실시간성 통계를 제공해주어 성능 테스트 중 모니터링하기에 매우 적합했습니다.dstat 하나의 명령어로 대부분의 리소스를 모니터링할 수 있었습니다.dstat으로 모니터링 가능한 자원 : aio, cpu, cpu24, disk, disk24, disk24old, epoch, fs, int, int24, io, ipc, load, lock,         mem, net, page, page24, proc, raw, socket, swap, swapold, sys, tcp, time, udp, unix,         vmkingpoint 라는 도구를 아시나요? 제가 만든 것이라 당연히 모를 것 입니다. 비동기 어플리케이션의 완벽한 모니터링이 아직은 어렵기도 하며, 어플리케이션의 특성을 반영한 모니터링을 하기에도 쉽지 않았습니다.정말 보아야 하는 것이 있는데 그것을 지원하는 도구가 없다면, 테스트를 위한 요소가 실제 어플리케이션의 성능에 절대 영향을 주지 않는다는 것을 꼭 지키는 선에서 만들어보는 것도 나쁘지 않을 것 같습니다.비동기 대한 모니터링을 위해 요청과 완료 시점에 특정 key 값으로 통계를 전송하도록 하여, 분석한 지표를 chart.js 로 그려주는 간단한 모니터링 툴 입니다. 저는 이로인해 많은 두려움을 해소할 수 있었습니다.그래서 저는 아래와 같은 테스트들을 진행했습니다.Mock Server 를 올리고, 위의 도구들을 사용하여 수백 번의 테스트를 해본 것 같습니다. 점차 원하는 패턴, 안정적인 수치와 지표를 찾을 수 있었습니다.라는 미지의 영역을 개척할 수 있었습니다.지금까지 결제 시스템 개비를 진행하며 경험했던 성능, 부하, 스트레스 테스트 환경 구축 및 진행에 대한 내용이습니다.테스트를 했다고해서 이상적으로 동작하는 어플리케이션을 만든 것은 아닐 것 입니다. 많은 상황을 예방할 수 있겠지만, 언제나 전혀 예상치 못했던 상황들이 생깁니다.그러나 적어도 확인한 것, 확보한 지표 를 기반으로 장래의 부하, 장애를 최소한의 비용과 시간으로 합리적으로 대응할 수 있을 것 입니다.보았어야 했는데 보지 않았던 것, 더 쉽게 볼 수 있었는데 어렵게 보았던 것 등 많은 시행 착오가 있었지만, 환경을 만들고 테스트를 하면서 많은 자신감을 얻을 수 있었습니다.그래도 배포할 땐..긴 글 읽어주셔서 감사합니다.",http://woowabros.github.io/experience/2018/05/08/billing-performance_test_experience.html,woowabros,"mysql,php,vue,angular,android,react",NULL,2018-05-08
우아한테크캠프 참가자에서 우아한개발자가 되기까지,"2017 우아한테크캠프 참가자에서 우아한형제들에 입사하기까지의 경험을 공유합니다.안녕하세요, 2017년 12월 22일 입사 한 따끈따끈한 신입 개발자 배민플랫폼개발실 주문중계팀 전한나입니다.2017 우아한테크캠프를 준비하면서 기술 블로그를 읽고 참고했던게 벌써 1년의 시간이 흘렀습니다.2018 우아한테크캠프 모집기간입니다.제 경험이 우아한테크캠프를 준비하시는 분들에게 조금이나마 도움이 되고자 블로그를 작성합니다.저는 비전공자로, 우아한형제들과 인연이 깊은 코드스쿼드라는 교육기관에서 iOS 개발자의 꿈을 키웠습니다.코드스쿼드가 타 교육기관과 다른점은 기술적 조언들은 물론이고, 협업을 강조하는 교육을 진행한다는 점입니다.저는 이전까지 누군가와 함께 일을 하거나, 의견을 조율하는 등의 경험이 없었습니다.처음 동료와 협업을 해보고, 내가 아닌 다른사람과 함께 결과를 만들어 내는 과정이 쉽지 않다는 것을 알게되었습니다.팀원들과 감정적인 다툼도 있었고 힘든 과정이었지만 다른사람을 잘 설득시키고 잘 설득 당하는 방법을 터득할 수 있는 첫번째 단계였습니다.이 경험은 우아한테크캠프에 참여하면서 팀원들과 팀워크를 다지고, 의견을 조율하는데 큰 도움이 되었습니다.스스로 부족한 점이 많다고 생각하고 있었기 때문에 우아한테크캠프를 통해서 성장하고 싶은 욕심을 가지고 지원하였습니다.성장하고 싶은 욕심이 어필이 되었는지 우아한테크캠프에 합격소식을 받을 수 있었습니다.아직도 합격 메일을 확인했을 때의 그 짜릿함과 두근거림이 잊혀지지 않습니다.[감격의 합격메일]2017 우아한테크캠프는 iOS와 웹프론트엔드 두개의 트랙으로 진행되었습니다.트랙별로 12명이 참가하였고, iOS 2명 + 웹프론트엔드 2명 총 4명이 한 조로 프로젝트를 진행하였습니다.7월은 각 트랙별 교육을 진행하였고, 8월은 자유주제로 프로젝트를 진행하였습니다.코드스쿼드에서 했던 프로젝트에서는 서버가 필요했었기 때문에 iOS개발보다는 Node.js로 서버를 구축하는데 더 많은 역할을 맡았습니다.백엔드에 흥미가 생기면서 iOS개발과 백엔드개발 사이에서 진로를 고민하던 시기에 iOS를 더욱 깊에 공부해 보면서 진로를 결정하자는 생각으로 우아한테크캠프에 참가하였습니다.그렇기 때문에 iOS개발에 몰입하고, 최대한 우아한테크캠프 교육과정을 기반으로 프로젝트를 진행하고 싶었습니다.이 생각에 팀원들이 공감해 주고, 우아한테크캠프를 위해 회사에서 배달의민족 beta API를 제공해 주어서 프론트엔드에 집중할 수 있는 결과물을 만들 수 있었습니다.클라이언트에 집중하면서 사용자경험에 대한 많은 고민을 할 수 있었고, iOS개발자로 성장하는 발판이 되었습니다.팀원의 성장을 위해서, 그리고 나의 성장을 위해서 솔직한 피드백을 하자.팀원들 모두 프로젝트에 욕심이 있었기 때문에 프로젝트 과정에서 팀원들간의 의견 충돌 생길 수 밖에 없었습니다.프로젝트 첫 주에는 감정이 상하는 말들이 오가기도 하였고, 누군가는 항상 져주는 사람이 생기기도 했습니다.우아한테크캠프 마스터님들께서 항상 협업에 대해서 강조하시면서 솔직한 피드백이 중요하다고 말씀하셨습니다.마스터님들의 조언대로 매주 금요일 회고 시간을 적극 활용하여 팀원들과 팀에 대한 생각, 서로에 대한 생각, 기술적인 생각 등 팀과 프로젝트가 더 좋은 방향으로 나아가기 위한 생각들을 솔직하게 나누었습니다.솔직한 회고는 프로젝트 진행 과정에서 팀원들간의 감정적인 싸움없이 논리적으로 서로를 설득할 수 있게 된 계기가 되었습니다.또한 매주 받은 피드백을 수용하는 방법도 배우면서 매주 성장하고 성숙해져가는 팀원들의 모습을 볼 수 있었습니다.이렇게 적극 활용한 솔직한 회고를 배움으로써 협업에 대해 고민하고 성장 할 수 있는 두번째 단계였습니다.우아한테크캠프 지향점 by.코드스쿼드[2017 우아한테크캠프!][우아한형제들 공채 준비 스터디 기획서]우아한테크캠프가 끝나고 취업준비를 하는 캠프동기들과 함께 취업스터디를 진행했습니다.막연히 취업을 위한 스터디를 기획하던 중에 우아한형제들 공채를 진행한다는 소식을 듣게되었습니다.캠프에서의 좋은 경험들은 스터디원들에게 막연한 취업에서 우아한형제들의 개발자가 되고 싶다는 구체적인 목표를 갖게 해주었고, 스터디의 목표를 우아한형제들 공채 합격으로 바꾸게 되었습니다.스터디에서 가장 도움이 되었던 점은 동기들과의 모의면접이었습니다.혼자서 준비했다면 나의 장점과 단점, 보완해야할 부분과 어필해야 할 부분에 대해서 객관적으로 바라볼 수 없었을 것입니다.동기들과의 모의면접을 통해서 나를 객관적으로 바라봐주고 보완해야 할 점을 함께 고민하면서 동기들에게 많은 도움을 받았습니다.(물론 그대로 평탄하게 면접이 진행되진 않았…ㅠㅠ)[더 감격스러운 합격메일]우아한테크캠프에서의 좋은 기억들은 공채 준비과정에서 큰 동기부여가 되었고, 결국 좋은 결과를 얻을 수 있었습니다. [2018년 우아한신입개발자 & 우아한테크캠프 모집]2017 우아한테크캠프 참가자에서 우아한형제들의 구성원이 된 만큼 2018 우아한테크캠프가 누구보다 기대됩니다.제가 우아한테크캠프에서 많은 것들을 경험하고 성장한 것 처럼, 이번 캠프에 참가하시는 분들도 이루고자 하는 것을 캠프를 통해 이루시기를 바라며 좋은 경험이 되었으면 좋겠습니다.2018 우아한테크캠프 지원하러가기!",http://woowabros.github.io/woowabros/2018/05/01/from_woowahan_techcamp_to_woowahan_developer_hanna.html,woowabros,,NULL,2018-05-01
우아한개발자가 되기 위한 우아한테크캠프,"우아한(Woowa) 개발자가 되고 싶은 이들을 위한 우아한테크캠프 2기를 소개합니다.우아한테크캠프는 대학생들의 여름 방학 기간에 맞춰서 2017년에 진행했던 교육형 인턴 과정입니다. 한 달은 정해진 커리큘럼에 따라 개발 관련 지식을 익히고, 그 다음 달은 조를 짜서 프로젝트를 진행하면서 실제 서비스를 만들면서 필요한 개발 지식을 익히는 과정을 수행하는 프로그램입니다.작년에 진행한 우아한테크캠프 관련 글들은 아래 링크에서 볼 수 있습니다.올해의 우아한테크캠프는 작년 프로그램을 진행하면서 얻은 피드백을 바탕으로 그 내용과 형식이 수정되었는데요. 가장 크게 달라진 점은 교육 커리큘럼의 변화, 그리고 우아한형제들의 신입 개발자 공채 과정으로 활용된다는 것입니다.작년에는 웹프론트엔드와 iOS 프로그래밍을 중심으로 커리큘럼이 작성되었는데, 참가하신 분들의 피드백을 들어보면 백엔드와 프론트엔드를 모두 배울 수 있으면 좋겠다는 내용이 많았습니다. 좀 더 경력이 쌓이면 본인의 전문 분야를 택할 수 있겠지만, 신입 개발자 또는 주니어 개발자 입장에서는 전체적인 서비스를 구성하는 흐름과 연동 방식을 두루 경험할 수 있는 커리큘럼이면 좋겠다는 의견이 있었습니다.이번 우아한테크캠프는 서버 백엔드 4주, 웹프론트엔드 2주 교육 과정, 그리고 3주 동안의 프로젝트 수행 과정으로 이루어져 있어서, 하나의 작은 서비스를 이루는 전체 데이터의 흐름과 시스템의 구조를 파악할 수 있는 것을 목표로 진행합니다.웹프론트엔드는 작년 우아한테크캠프에도 참가하셨던 윤지수님이 맡아서 진행해 주실 예정이고, 서버 백엔드는 자바지기라는 필명으로 유명한 박재성님이 맡아서 진행하실 예정입니다. 윤지수님의 교육 관련해서는 웹 프론트엔드 개발자, 어떻게 준비해야 할까?라는 글을 읽어 보시고, 박재성님의 교육 관련해서는 패스트캠퍼스의 박재성님 강의 소개를 읽어 보시길 권해 드립니다.작년에는 우아한테크캠프와 우아한형제들의 신입 개발자 공채는 완전히 분리되어 있었습니다. 우아한테크캠프 신청자/참가자 분들이 이후 신입 개발자를 뽑을 때 우대사항이나 그런 것이 없냐고 여러 번 문의를 주셨는데, 두 가지 과정은 완전히 분리되어 진행된다고 말씀 드리고 진행했습니다.그런데 커리큘럼을 수정했던 것과 비슷하게, 저희가 우아한테크캠프를 처음 만들 때 생각했던 부분과 실제로 캠프에 참석하는 분들의 생각은 조금 다른 부분이 있었습니다. 커리큘럼의 경우는 백엔드 강화에 대한 의견을 꽤 많은 분들이 얘기해 주신 반면, 이것에 관한 의견은 반반으로 나뉘어졌는데요.이미 다니던 직장을 그만두고 우아한테크캠프에 참가하는 분들 또는 바로 취업을 해야 하는 대학교 졸업반의 경우, 우아한테크캠프 과정에 정말 참가하고 싶어도 본인이 실제로 취업할 수 있는 회사의 인턴을 하면서 보내는 것이 더 현실적인 선택일 수밖에 없다는 의견을 주었습니다.작년에 우아한테크캠프 과정을 만들면서 일부러 대학생으로 제한을 두지 않은 것은, 이미 개발일을 하고 있는데 정말 더 잘 하기 위해서 제대로 개발을 배워 보고 싶은 분들, 그리고 학벌이나 전공과 관계없이 본인이 관심을 갖고 잘 해 보고 싶은 분들에게 기회를 주고 싶었던 마음이 있었는데요. 우아한테크캠프가 취업이라는 과정과 연결 고리가 전혀 없다보니, 오히려 그 분들 입장에서는 인턴을 잘 수행하면 취업 시 우대점을 주는 프로그램을 택할 수밖에 없다는 점이 안타까웠습니다.이와 더불어, 우아한형제들에서 작년 말에 신입 개발자를 뽑으면서 느낀 고충도 있었는데요. 우아한테크캠프를 뽑는 것과 비슷한 노력과 과정을 한 번 더 반복해야 한다는 것이었습니다. 일의 횟수가 문제가 아니라, 우아한테크캠프 참가자들을 선발하기 위한 문제와 신입개발자를 선발하기 위한 문제는 어떻게 별도로 구성을 해야 하는지, 그리고 면접 과정은 어떻게 차이를 둘 것인지 등을 명확히 정리하는 것이 쉽지 않은 문제였습니다.캠프 참가자, 캠프에 참가하고 싶었는데 못했던 분들, 그리고 신입 개발자 공채 과정에 참여했던 분들과 내부에서 그 과정을 진행했던 분들의 의견을 모은 결과, 올해 진행하는 신입 개발자 공채는 우아한테크캠프를 통해서 진행하는 것으로 결정하였습니다. [2018년 우아한신입개발자 & 우아한테크캠프 모집]올해의 우아한테크캠프는 우아한형제들의 신입개발자 채용 과정이기도 하지만, 본질적으로는 작년에 말씀 드린 것처럼 IT 업계에 뛰어드는/뛰어든 많은 개발자 분들이 꼭 참가하고 싶은 캠프가 되고자 합니다.우아한형제들이라는 회사에 취업을 하고 싶은 분들도 (당연히) 환영하고, 당장 우아한형제들에 꼭 취업할 생각은 아니지만 개발을 잘 하기 위해서는 무엇이 필요하고 어떤 것을 배워야 하는지 궁금하고 경험해 보고 싶은 분들도 환영합니다.2017 우아한테크캠프에 참가했던 두 분의 후기, “넌 강해졌다, 돌격해!“와 “우아한테크캠프: 좋은 개발자가 되고 싶다면“를 읽어 보시면 어떤 캠프인지 좀 더 잘 아실 수 있으리라 생각합니다.작년과 마찬가지로 학력에 대한 제한은 전혀 없습니다. 이미 2-3년의 경력을 갖고 있는 분들이 지원하시는 것도 아무런 문제가 없습니다. 다만 7/2부터 8/31까지 우아한테크캠프에 전념할 수 있어야 하고, 9월 또는 12월 말에 취업이 가능한 상태여야 합니다.많은 회사들이 개발자를 뽑고 있습니다. 여러분들과 여러분의 주변 분들(특히 부모님들)은 삼성전자, SK텔레콤, 현대자동차, 현대카드와 같은 굴지의 대기업 또는 네이버, 카카오같이 인터넷 업계에서 가장 큰 회사를 선호하는 분들이 많이 있을 겁니다.신입 또는 주니어 개발자에게 좋은 회사란 어떤 회사일까요? 이 질문에도 여러 가지 답이 있겠지만, 본인이 하는 일과 본인이 속한 조직의 분위기에서 모두 배울 수 있는 점이 많은 회사가 좋은 회사라는 답변에는 딱히 반론은 없겠지요.우아한형제들은 이 블로그를 통해 여러 번 얘기했지만, 조직과 본인이 같이 성장할 수 있어야 그 성장이 건강하게 오래 지속될 수 있다고 생각합니다. 최근에 이 블로그에 게재된 우아한형제들의 Devloper Relations라는 글을 읽어 보시면, 우아한형제들이 어떤 고민을 하고 있고 개발자 분들과 어떻게 해결해 나가는지를 보실 수 있습니다. 그 외에도 조직과 개인의 성장 관련해서는 다음과 같은 글들을 보시길 권합니다.여러분이 우아한테크캠프에 참여하고 우아한형제들에 입사하게 되면, 신입개발자로서 여러분이 경험할 수 있는 최고의 교육 과정을 제공받을 수 있습니다. 우아한테크캠프만 참석하더라도, 그 두 달 간의 경험이 이후 여러분이 구직 활동을 할 때 큰 경험과 자산이 되어 줄 것입니다. (작년 캠프 참석자들은 우아한형제들을 비롯하여, 삼성전자, 넥슨, 티맥스 등 다양한 기업에 취업한 것으로 알고 있습니다.)우아한형제들에 입사하고 싶은 신입/주니어 개발자들이라면 우아한테크캠프가 유일한 선택이 될 것입니다.`우아한테크캠프가 진행되는 동안, 여러분들에게는 150만원의 인턴 비용이 지급되는데요. 월 수백만원을 지불하더라도 들을 수 없는 교육 과정 및 좋은 동료들과의 프로젝트 경험을, 오히려 돈을 받으면서 가질 수 있는 기회는 우아한테크캠프밖에 없다고 생각합니다. 꼭 우아한형제들에 입사하지 않더라도, 이 캠프를 통해서 만난 사람들이 또 하나의 좋은 인적 네트워크가 되어 줄 것이라 생각합니다.이번 캠프가 우아한형제들에서 원하는 신입 개발자들을 채용하는 수단으로써만이 아니라, 우아한테크캠프의 좋은 경험이 직간접적으로 널리 퍼져서 우리 나라의 많은 개발 조직이 새롭게 이 업계에 진입하는 신입/주니어 개발자들이 성장하는데 관심을 가지길 원합니다. 어떻게 하면 경력같은 신입을 뽑을지 고민하는 것이 아니라, 신입을 어떻게 하면 경력 개발자처럼 키울 수 있을지 고민하고 실행하기를 원합니다.‘우아한개발자가 되기 위한 우아한테크캠프’라는 이 글의 제목은 그래서 두 가지 의미를 가지고 있습니다. 우아한형제들에 입사하고 싶은 개발자를 위한 캠프라는 뜻 외에도, 꼭 이 회사에 입사하지 않고 어디서 어떤 일을 하더라도 개발을 잘 하고 싶은 사람들을 위한 캠프라는 뜻을 가지고 있습니다.Q ) 우아한테크캠프 모집 대상자는? A ) 3년차 이하의 경력을 가진 분들 중, 7/2~8/31까지 우아한테크캠프에 참석 가능하고, 9월 중 또는 12월 말에 취업이 가능한 분이면 됩니다.Q ) 우아한테크캠프 운영 시간 및 장소는? A ) 월요일 1시~6시, 화~금 9시~6시. 우아한형제들 사무실에서 진행됩니다. 우아한테크캠프를 위한 교육장 및 사무공간도 세팅되어 있습니다. :-)Q ) 우아한테크캠프 참가자에 지급되는 금액이 있나요?  A ) 월 150만을 지급합니다.Q ) 우아한테크캠프 진행 시 필요한 장비는 지원되나요?  A ) 장비는 회사에서 대여하여 캠프 시작시에 지급합니다.Q ) 코딩 테스트는 어떤 언어로, 어떻게 진행되나요?  A ) 프로그래밍 언어는 지원하시는 분들이 편한 것을 이용하시면 됩니다. 온라인으로 접속하시면 문제가 주어지고, 해당 웹사이트 내에서 프로그래밍하고 테스트하실 수 있습니다.Q ) 우아한테크캠프 참가자에 대한 입사 특전이 있나요?   A ) 2018년도 우아한형제들 신입 개발자 공채는 우아한테크캠프를 통해 진행됩니다. 캠프에 참석한 분들 중 신입 개발자를 선발할 예정이며, 선발 규모는 정해져 있지 않습니다. (캠프 참가자 전원을 선발할 수도 있습니다. :-)마지막으로 우아한형제들의 개발자 모집 영상으로 이 글을 마무리할까 합니다.이 영상에 소개된 내용이 우아한형제들이 다니기 좋은 회사임을 보여 드리는 것이라면, 그보다 더 중요한 것은 일하기 좋은 회사인가 하는 것일테데요. 그 부분은 우아한테크캠프를 통해서 느껴 보시는 건 어떨까요? :-)여러분의 많은 지원 부탁 드립니다.[우아한형제들 개발자 모집 영상]우아한형제들 또는 이번 우아한테크캠프에 대해 궁금한 부분들은 tech_hr@woowahan.com 으로 편하게 문의해 주시면 됩니다. 최대한 성실하게 답변 드리도록 하겠습니다.",http://woowabros.github.io/woowabros/2018/04/22/do_you_wanna_be_a_woowa_developer.html,woowabros,,NULL,2018-04-22
"Java, max user processes, open files","안녕하세요? 우아한 형제들에서 결제/정산 시스템을 개발하고 있는 이동욱입니다.올해 사내 블로그 포스팅 주제로 Linux의 open files, max user processes 설정에 대해 정리하게 되었습니다.계기는 단순했습니다. 팀에서 서버 작업하던 중 쓰레드와 관련해서 문제가 발생했는데요. 제가 진행하던 일이 아니라서 옆에서 해결하는 과정을 지켜봤습니다. 부끄럽게도 전혀 모르는 내용이 오고 갔습니다. 복기가 필요하단 생각에 정리를 진행 하던 중, 이왕 하는김에 회사 블로그에 올리면 좀 더 자세히 공부하지 않을까 하는 마음에 선택하게 되었습니다.(퀄리티는 에피타이저, 마음만은 메인 디쉬로 가겠습니다!)여기에서 사용된 코드는 실제 회사에서 사용한 코드는 아니며, 포스팅을 위해 최대한 유사하게 만들어진 별도의 샘플 코드임을 먼저 말씀드립니다.Linux에는 OS 레벨에서의 제한 설정이 있습니다. 보통 이를 ulimit (user limit) 이란 명령어로 확인하는데요. 2가지 옵션으로 대부분 확인합니다.톰캣을 이용해서 서버 운영 도중, 다음과 같이 OutOfMemoryError가 발생했다고 가정하겠습니다.더이상 쓰레드를 생성할 수 없다는 에러인데요. 뭐가 문제였는지 하나씩 확인해보겠습니다. 맨 처음 서버를 할당 받은 초기 상태 그대로라 ulimit -a는 아래와 같습니다.화면을 보시면 open files 와 max user processes의 값이 1024로 동일하게 잡혀있습니다. 쓰레드 생성에 문제가 발생한거라 max user processes가 문제인것 같지만, 확신할 수 없으니 테스트 환경을 구축해서 실험해보겠습니다.테스트용 서버는 AWS EC2의 t2.micro입니다. t2.micro로 생성후 ulimit -a로 확인해보겠습니다.t2.micro는 기본 설정이 open files가 1024, max user processes가 3902로 잡혀있다는 것을 알 수 있습니다.자 그럼 간단하게 추측할 수 있는 것이, 현재 설정에서 1024 <= 동시에 생성가능한 쓰레드수 <= 3902라면 max user processes가 부족해서 발생한 문제임을 알 수 있겠죠? 이를 확인하기 위해 간단한 스프링부트 프로젝트를 생성하겠습니다.코드는 간단합니다. /4000으로 HTTP 요청이 오면 비동기로 4천개의 쓰레드를 동시에 생성하고, 20분간 유지합니다.프로젝트를 테스트용 EC2에 배포하고 curl과  tail -f nohup으로 확인해보겠습니다.사진속을 보시면 3855번째에서 unable to create new native thread 에러 메세지가 발생했습니다. 즉, open file 제한인 1024개를 초과해서 쓰레드가 생성된 것입니다! max user processes만큼만 쓰레드가 생성된것을 확인할 수 있습니다.Linux에서는 프로세스와 쓰레드를 동일하게 봅니다.두번째로 위에 있던 open files 값은 어떤 값을 가리키는지 알아보겠습니다. open files에 관해 검색을 해보면 이 값이 프로세스가 가질 수 있는 소켓 포함 파일 개수를 나타낸다는 것을 알 수 있습니다.자 그럼 소켓을 open files 값 보다 많이 만들면 어떻게 되는지 테스트 해보겠습니다. 테스트 방법은 간단합니다.API 요청을 받아, 20분간 대기시켜줄 서버로 ec2를 한대 더 생성합니다.테스트에 사용한 코드는 다음과 같습니다.요청을 보낼 메소드요청을 받을 메소드자 그리고 동시에 1100개의 요청을 보낼수 있도록 간단한 비동기 요청 스크립트를 만듭니다.(실제 운영환경에선 Ngrinder등을 통해서 하겠지만, 여기선 간단한 테스트이니 스크립트로 대체합니다.)준비가 다 되었으니 한번 테스트를 진행해보겠습니다!…..테스트를 진행하자마자 바로 에러가 발생했습니다. 로그를 확인해보니단순 쓰레드 생성과 달리, EC2의 서버 메모리가 먼저 부족해져서 EC2 사양을 높여서 다시 실험하겠습니다.(t2.micro는 메모리가 1GB인지라, t2.large (8GB) 로 변경합니다.)업데이트된 EC2의 ulimit은 아래와 같습니다.AWS EC2의 사양을 올릴수록 max user processes가 적절한 값으로 증가하는 것을 확인할 수 있습니다. 이를 통해 알 수 있는 것은, AWS EC2를 사용하실 경우 max user processes AWS 내부에서 인스턴스 사양에 맞게 적절한 값을 세팅해주니, 굳이 저희가 손댈필요는 없다는 것입니다.자 그럼 다시 한번 테스트를 해보겠습니다. 테스트용 서버에 프로젝트를 배포하고, 해당 프로젝트가 생성한 open file count를 아래 명령어로 확인합니다.PID를 찾고,생성된 open file 리스트를 확인할 수 있습니다. 준비가 다 되었으니, 1100개 요청을 보내는 스크립트를 실행해봅니다!엇? 결과가 뭔가 이상합니다. 분명 open files의 값은 1024개로 되어있는데 1330개가 열려있다고 나오다니요.이상하다는 생각에 스크립트를 몇번 더 실행합니다. (한번 실행때마다 1100개의 요청이 간다고 생각하시면 됩니다.)2번을 추가로 더 실행해서 3300개의 요청이 갔음에도 에러없이 처리되고 있습니다. 언제 터지는지 확인하기 위해 추가로 더 요청해봅니다 (총 4400개가 갑니다.)드디어 Open File 에러가 발생했습니다! 보시면 4097개까지만 열린채로 에러가 발생한 것을 알 수 있는데요. 이전 요청이 3532개를 생성했으니 추가로 1100개를 요청하면 4600개 이상이 생성되어야하는데 왜 4097개까지만 생성된 것인지 궁금합니다.혹시나 하는 마음에 ulimit -aH로 soft가 아닌, hard옵션을 확인해봅니다.오? 마침 딱 4096개 입니다! 프로세스별 open file은 soft 값이 아닌 hard 값까지 생성가능한게 아닐까? 라는 추측이 됩니다. 검증하기 위해 hard의 open files를 5120개로 증가시킵니다. (soft 옵션은 그대로 1024개 입니다.)자 그리고 다시 요청을 진행해보겠습니다. 이번에 4096개가 넘는 요청이 가능해진다면 soft가 아닌, hard 값까지 생성 가능하다는걸 알수있겠죠?예상대로 4000개가 넘는 API 요청 (4635)이 가능해졌습니다!실제로 ulimit -a로 확인할 수 있는 soft 값으로 소켓 생성이 제한되지는 않는다는 것을 알 수 있습니다. 결국 소켓 생성 제한은 hard 옵션에 따라간다 라는 이야기가 됩니다….이 글을 마무리하려던중, 깜짝 놀랄 이야기를 들었습니다.파이썬은 안그러는데요?제보를 해주신 배민찬의 모 선임님과 함께 확인을 해봤습니다. soft limit으로 1024, hard limit으로 4096인걸 확인하고, 파이썬 스크립트로 file을 임의로 열어봅니다.여기서 3개를 빼야하는 이유는 stdin, stdout, stderr의 표준 입/출력이 포함됐기 때문입니다.1021개에서 1개를 더 추가하니 바로 Too many open files Error가 발생합니다! 헉? soft 옵션이 파이썬에서 잘 적용된걸까요?진짜 그런지 한번 더 확인해봅니다. open files soft 값을 2000으로 증가시킨후 다시 1997개가 넘는 file을 open 해봅니다.여기서도 마찬가지로 1997개 이상 file open시에 바로 Too many open files Error가 발생합니다.왜 파이썬은 soft옵션까지만 file이 오픈되고, Java에선 hard 옵션까지 file이 오픈되는건지 이상했습니다.이상하단 생각에 strace로 JVM 로그를 확인해보니!이렇게 setrlimit으로 limit을 업데이트하는 로그가 찍혀있습니다!왜 이런 로그가 발생했는지 오라클 Java 옵션을 찾아봤습니다. 문서에는 MaxFDLimit 라는 옵션이 있었는데요, 뭔가 file limit과 관련돼 보입니다.이 옵션이 뭔지 찾아보니 openjdk 코드에서 이 옵션이 true일 경우 setrlimit 으로 limit을 증가시키는 것을 확인할 수 있습니다.그리고 설치된 Java의 MaxFDLimit 기본값이 true임을 확인할 수 있습니다.즉, 리눅스 OS 환경에서는 JDK 실행시 자동으로 limit 사이즈를 증가시켜준다는 것을 알 수 있습니다.위 2개의 실험으로 얻은 결론입니다.참고로 Tomcat은 8 버전부터 기본 Connector 방식을 NIO로 사용합니다. (7 버전까지는 BIO) 그러다보니 maxConnections은 10,000, maxThreads는 200이 기본값입니다. (BIO에서는 둘의 값이 동일해야 합니다) 이번 테스트에서 사용되는 connection 수가 1만을 넘지 않기 때문에 기본옵션으로 진행했습니다.보통 soft limit과 hard limit을 다르게 설정하진 않습니다. 둘의 값을 동일하게 적용하는데요. 서버의 open files, max user processes등 옵션을 permanent (영구) 적용하기 위해선 /etc/security/limits.conf 을 수정하면 됩니다.맨 앞의 *가 있는 자리는 사용자 계정을 나타냅니다. ec2-user로 지정하시면 ec2-user 계정에서만 옵션이 적용되는데요. 이미지처럼 *로 지정하시면 모든 사용자 계정에 옵션이 적용됩니다.이렇게 적용후, 다시 접속해서 확인해보시면!옵션이 잘 적용되어있음을 확인할 수 있습니다.제가 준비한 내용은 여기까지입니다. 좋은 기회로 그 동안 막연하게 알고 있던 max user processes, open file를 제대로 정리해볼 수 있었습니다.부족함이 많은 글임에도 끝까지 읽어주셔서 감사합니다. 다음에도 이와 같이 기본적인 내용이지만, 프로젝트에서 도움을 받는 일이 발생한다면 잘 정리해서 공유드리겠습니다. 그럼, 다음에 또 뵙겠습니다. 감사합니다!(사용된 모든 짤은 레진코믹스의 레바툰입니다.)",http://woowabros.github.io/experience/2018/04/17/linux-maxuserprocess-openfiles.html,woowabros,,NULL,2018-04-17
우아한형제들의 Developer Relations,"투자가를 대상으로 한 IR(Investor Relations) 이야기가 아닌,  개발자를 대상으로 한 DR(Developer Relations) 이야기.Developer Relations라는 말은 다소 생소합니다.IR(Investor Relations)은 많이 들어보셨을 텐데요. IR은 투자자들을 대상으로 기업 설명 및 홍보 활동을 하여 투자 유치를 원활하게 하는 활동을 의미합니다.우아한형제들은 IR 만큼이나, DR(Developer Relations) 활동을 중요하게 생각합니다. 개발자들을 대상으로 기업을 설명하고 홍보하여 좋은 개발자 분들이 같이 할 수 있는 기회가 많아지기를 원합니다.IR과 DR 모두 대상자만 다를 뿐, 회사의 매력을 전달하는 것이 핵심입니다. 중요한 것은 내가 하고 싶은 얘기를 전달하는 것이 아니라, 상대가 궁금한 것을 전달해야 한다는 것입니다.최근에 여러 회사가 개발자 채용을 적극적으로 진행한다는 기사를 보았습니다. 월요일 1시 출근, 주35시간 근무, 연봉 5천만원 이상, 무제한 도서비 지원 등의 문구로 지하철 역에 광고가 나오기도 했더군요. 개인 입장에서 처우와 근무 조건/환경은 분명 중요한 요소라고 생각합니다. 우아한형제들도 작년에 이런 구인 동영상을 페이스북 페이지에 게재하기도 했고요. (이 자리를 빌어 멋진 동영상을 만들어준 영상디자인팀 분들께 감사 인사 드립니다. 잘 만들어진 동영상이니 꼭 한 번 봐 주세요 :-)개발자를 채용하는 회사들이 많아지면서, 개발자에 대한 처우가 개선되는 것은 고무적인 일입니다. 그러면 이런 상황에서 개발자는 어떤 기준으로 회사를 택해야 할까요? 회사는 어떤 부분을 개발자 분들에게 어필해야 할까요? 다시 말해 DR은 어떤 이야기를 전달해야 할까요? 이 부분을 생각해 보았습니다.모든 직군이 마찬가지지만, 개발자 분들은 특히 성장에 대한 욕구가 크다고 생각합니다. 어떤 처우를 받고, 어떤 근무 조건이냐도 중요하지만, 자신이 성장할 수 있는 환경인지를 무척 중요하게 여깁니다.문제는 이러한 환경인지 아닌지를, 개발자 입장에서 입사 전에 어떻게 알 수 있을 것이며, 회사 입장에서 어떻게 알릴 수 있냐는 것입니다. 모든 회사는 다 조직과 개인이 같이 성장하는 회사라고 얘기하니까요.제가 20년 가까이 일을 하면서 느낀 점은, 회사의 성장이 크지 않은 상황에서 개인이 성장하기는 힘들다는 것입니다. 이 말은 회사를 위해서 개인이 희생해야 한다는 것이 아니라, 개인의 성장 동력으로써 회사의 환경이 뒷받침되어야 한다는 것을 의미합니다. [우아한형제들 실적 추이]위 그림을 보시면, 우아한형제들의 2017년 매출은 전년 대비 92% 증가했고, 영업이익은 768% 증가했습니다. 2010년 6월 처음 서비스를 제공하고 7년차에서 8년차로 넘어가는 시점인데도 매출이 2배 가까이 성장했다는 것은 엄청난 증가폭입니다.배달의민족 서비스는 매출이 모두 온라인 서비스에서 나오기 때문에, 매출이 늘었다는 것은 서비스의 트래픽이 그만큼 늘었다는 것을 의미합니다. 제가 2015년 8월에 입사했는데, 전월의(2018년 3월) In-App Purchase 수를 그 때와 비교하면 무려 7.5배로 늘어났습니다. 주문 시도 기준으로 하루에 100만 건이 넘는 수치를 보인 날도 있고, 저녁 시간같은 peak time에는 시간당 10만 건이 넘는 수치를 보이기도 합니다.이러한 서비스 변화는 개발자들에게 도전 과제로 주어지게 됩니다. 1) 선착순 이벤트를 하면 1.89초 만에 마감되는 서비스, 2) PG사와 새롭게 연동했더니 PG사와의 전용선 bandwidth 제약에 걸리고, 그것을 해결했더니 PG사 서버가 다운되는 서비스, 3) 다른 서비스 플랫폼을 이용하여 프로모션을 했더니 해당 서비스가 죽어서 치도스라는 신조어를 만들어 낸 서비스. 이런 서비스가 문제 없이 돌아가게끔 하기 위해, 계속 새로운 시스템을 고민하고 개선해 나가야 합니다. [버스 정류장에 설치된 블랙 후라이드데이 포스터]사업과 서비스가 빠르게 성장하면서 개발자들이 기술적으로 해결해야 하는 과제가 계속 주어지는 회사에서는, 개인에게도 성장의 기회가 많이 주어질 수밖에 없습니다. 여기서 중요한 것은 이미 몇 년째 100만명, 1,000만명을 감당하고 있는 서비스 회사보다는, 이전에 1만명에서 10만명으로, 다시 100만명으로, 그리고 1,000만명을 담당하는 서비스로 성장하는 곳에 있는 것이 훨씬 더 개인의 성장에도 도움이 된다는 것입니다. 남들의 경험을 듣는 것보다, 본인이 직접 경험하는 것이야말로 온전히 자기 것이 될 수 있기 때문입니다.우리 나라의 여러 서비스 중에서 Read 성격의 요청이 아니라 한 시간에 10만 건 이상의 실제 주문을 처리하는 서비스가 얼마나 될까요? 이미 몇 년째 서비스의 트래픽이 비슷하거나 완만하게 유지되는 것이 아니라, 계속해서 2배 가까이 성장하면서도 저런 규모의 주문을 처리해야 하는 시스템이 얼마나 될까요? 이미 완성되어 운영되는 것이 아니라, 계속 기존 시스템을 개선하는 과제의 필요성이 절실히 존재하고 실제로 추진하고 작은 성공을 만들어 가는 곳이 얼마나 될까요?본인이 아무리 노력하더라도 회사의 사업/서비스가 본질적으로 필요로 하는 기술 과제가 없는 경우, 개인이 발전하는 것은 무척 힘들 겁니다. PT(Personal Training)를 받아 본 분들은 아실텐데요. 옆에서 누군가 계속 내가 운동을 하게끔 만드는 환경과, 혼자 의지만 갖고 운동하는 것과는 큰 차이가 있을 수밖에 없습니다. 정말 끈질긴 노력을 통해 뭔가를 만들었다고 해도, 피드백을 받지 못하는 상황에서는 제대로 한 것인지 알기 어렵습니다. 자신만을 위한 Over Engineering 과제로 남을 확률이 높습니다. 그래서 회사가 얼마나 성장하고 있는가 하는 것이, 개발자 입장에서 회사를 택할 때 무척 중요한 요소라고 생각합니다.어느 서비스나 장애가 발생하는 것은 심각한 상황입니다. 개발팀은 개발팀대로, 고객 응대를 하는 부서는 그 부서대로 심한 스트레스를 받게 되고, 장애가 해소된 이후에도 여러 가지 힘든 업무를 수행해야 합니다.개발자라면 잘 아시겠지만, 장애는 항상 날 수 있습니다. 장애를 줄이는 방법은 크게 보면 두 가지입니다. 하나는 비용을 들여서 시스템을 증설하여 확률을 줄이는 것이고, 또 하나는 근본적으로 특정 시스템에서 장애가 나더라도 전체 시스템에 문제가 없는 failure resilient한 시스템 구조를 만들고 구축하는 것입니다.그런데, 우리나라의 많은 회사에서는 두 가지 방법 모두 실행하기가 여의치 않습니다. 장애가 나는 것은 모든 회사가 싫어하지만, 그 상황이 지나가고 장애 복구 및 이후 대처 방안에 비용 증가가 수반될 경우 많은 회사들이 그 방안을 쉽게 채택하지 않습니다. 전체 시스템을 개선하는 방안은 더욱 실행하기 힘듭니다. 결국 인력이 투입되어야 하는데, 새로운 사업 요구 사항과 장애를 줄이는 두 가지 선택 중에서는 대부분 전자가 채택되기 마련이죠.많은 개발자들과 만나서 얘기해 보면, 구글, 페이스북, 넷플릭스 등이 failure resilient한 시스템을 구축하고 개선해 나가는 것에 대한 선망이 있습니다. 그들은 왜 그런(개발자들을 시스템 구조를 개선하는 일에 투입하는) 선택을 했을까요? 그건 그들의 사업에 있어서 그러한 투자가 훨씬 이득이 되기 때문입니다.구글, 페이스북, 넷플릭스는 장애로 인한 1%의 매출 하락을 방지하기 위해, 몇 백 명의 개발자들을 투입하는 것이 이득입니다. 한국에서는 사업과 서비스의 규모가 그 정도로 되는 회사가 정말 드물죠. 네이버의 검색 서비스와 카카오의 메신저 서비스 정도일 것 같네요. 이런 면에서 배민(배달의민족)은 그 규모는 앞서 말한 서비스들보다 작으면서도, 기술에 대한 요구 수준은 굉장히 높은 특이한 서비스입니다. [서비스 장애가 난 어느 주말의 트위터 풍경]위 스크린샷은 배민 서비스에 장애가 난 어느 주말 저녁에 올라온 트위터 글입니다. 다른 서비스라면, 특정 시간에 장애가 생기면 한 두 시간 뒤에 다시 시도하면 됩니다. 그런데, 배민은 먹는 서비스이다보니 사용자들은 내가 원하는 그 시간에 실행이 안 되는 것에 굉장히 민감해 합니다. 배민이 요기요나 배달통보다 훨씬 높은 점유율을 갖고 있기에 배민 서비스가 다운되면 요기요나 배달통도 다운되는 경우가 많다보니, 일부 사용자 분들은 흡사 전기나 수도가 끊긴 것과 비슷한 반응을 보일 때도 있습니다.일반 사용자 분들이 아닌, 배민에 광고비를 내시는 매장의 사장님들을 생각하면 훨씬 더 심각합니다. 배민의 핵심 비즈니스 모델이 한 달에 정해진 금액을 내는 광고 모델이다보니 장애가 일어난 시간에 대해 보상을 하고 있습니다. 문제는 주말 저녁의 경우 peak time이기 때문에, 단순히 한 달 720시간중 1시간에 대한 보상이 아니라, 사장님들 입장에서 그 날 준비한 장사에 여러 의미로 지장을 준 것에 대한 의미로 더 크게 보상을 하는 것으로 결정한 경우가 꽤 있다는 것입니다. (사장님들 입장에서는 이 보상도 탐탁치 않게 여기시지만요)배달의민족은 이러한 서비스의 특징 때문에, 시스템을 안정적으로 운영하기 위한 비용 지출과, failure resilient한 시스템으로 개선해 나가는 프로젝트 수행을 적극적으로 진행하고 있습니다. 우아한형제들이라는 회사가 기술을 중요하게 생각한다고 포장하고 싶어서가 아니라, 장애에 내성이 강한 시스템을 만드는 것이 실제 회사 차원에서 ROI가 나오는, 본질적으로 중요한 과제이기 때문입니다.위에서 회사의 성장과 개인의 성장에서도 했던 얘기지만, 회사 입장에서 본질적으로 중요하다고 생각하는 과제가 개발자 관점에서도 의미가 있는 과제일 때, 그것이 지속될 수 있고 성과를 만들어낼 수 있습니다. 회사의 메시지는 말이나 글로 읽는 것이 아니라, 그 회사가 시간과 비용을 어디에 쓰는가를 보면 알 수 있다고 생각합니다. 이런 관점에서 우아한형제들은 개발자 처우 수준을 높이고 시스템 비용을 아끼지 않고, 실질적인 시스템 개선을 위한 프로젝트를 수행하고 있다는 점을 개발자 분들이 알아 봐 주시면 좋겠습니다.외부 개발자 분들과 얘기하다 보면, 배민이 잘하는 것은 알겠지만 한계가 있을 것 같다는 얘기를 듣는 경우가 있습니다. 음식이라는 하나의 도메인에서 배민이라는 서비스만 제공해서 얻을 수 있는 매출에 한계가 있을 것 같다는 의견입니다.잘 아시다시피, 배민이라는 서비스는 이미 배달을 해 주던 업소들의 메뉴를 주문할 수 있는 서비스인데요. 작년 11월부터는 배민라이더스 서비스가 배민과 통합되어, (서울 지역에서는) 배민의 메인 화면에서 그동안 배달 음식점에서 보기 힘들었던 다양한 메뉴들이 노출되고 판매되고 있습니다.예전에는 배달을 직접 수행해야지만 배달 서비스를 제공할 수 있었으나, 배민라이더스를 이용해서 배달을 이용하여 매출을 증대시킨 많은 사장님들이 계속해서 배민라이더스 서비스에 문의를 주시고 매장이 늘어가고 있습니다. 모든 식사가 배달로 바뀌진 않겠지만, 원래 배달을 하지 않던 매장들이 빠르게 배달 서비스를 제공하면서 늘어나는 시장이 지금까지 만들어 왔던 시장보다 훨씬 더 클 것으로 예상하고 있습니다.이러한 사업기회의 확장은 단순히 매출이 늘어나는 것만을 의미하지 않습니다. 배민라이더스는 저희 회사와 계약 관계에 있는 라이더 분이 주문을 받으면 음식점으로 이동해서 음식을 수령한 후 고객님들에게 배달하는 서비스인데요. 가만히 생각해 보시면 이 서비스는 우버와 동작이 똑같습니다. 고객이 우버를 부르면(주문이 발생하면), 우버 기사는 고객에게 이동하여 태우고(라이더는 식당으로 이동하여 음식을 수령하고), 목적지로 이동한 후 승객을 내려주는(주문한 고객 위치로 이동한 후 음식을 전달하는) 동작과 거의 같습니다. 규모는 우버에 비할 바 못하겠지만, 실시간으로 움직이는 에이전트에 대한 스케줄링과 최적화 관점에서는 우버와 동일한 기술적 과제가 존재함을 의미합니다.배민라이더스 외에도 많은 분들이 알고 있는 서비스로, 배민찬 서비스가 있습니다. 배민찬 서비스는 배민프레시라는 이름으로 제공이 되다가, 작년부터 반찬이라는 카테고리에 집중하여 제공하고 있는 Food Commerce 서비스입니다. 반찬으로 집중한 후 2017년 한 해만 4배가 넘는 성장세를 보이고 있습니다.배민찬에서 일하는 개발자 분들이 경험을 공유해 준 글들로는 다음과 같은 글들이 있습니다.배민라이더스와 배민찬 외에도 배민상회라는 서비스도 제공하고 있는데요. 이 서비스는 사장님들을 위한 물품 구매 사이트입니다. 음식을 배달 제공할 때는, 숟가락, 젓가락, 비닐봉지서부터 여러 가지 물품이 필요한데, 바로 그런 물품들을 판매하는 사이트입니다. 사장님들 입장에서는 다른 곳보다 저렴하게 구입할 수 있고, 배달의민족 특유의 위트가 가미된 제품들로 인해 고객들이 좋아한다면, 배민상회 서비스를 이용하시지 않을 이유가 없겠죠. 이 서비스도 최근 1년 동안 30배 넘게 성장하는 모습을 보여 주고 있습니다. 아래는 배민상회의 스크린샷입니다. [배민상회 스크린샷]지금까지 소개해 드린 사업은, 이미 현재 제공하고 있어서 더 이상 숨길 이유도 없고 편하게 말씀 드릴 수 있는 것이었다면, 어떤 사업들은 이런 공간에서 오픈하고 말씀 드릴 수 없는 것들도 많이 있습니다. 그 중에서 배달로봇 관련된 것은 이미 신문기사를 통해 부분적으로 공개되었는데요. 로봇이 처음부터 끝까지 모든 작업을 다 할 수 있진 않더라도, 앞으로 다가올 자율주행차와 로봇을 결합하면 현재 배달이라는 작업을 수행하는데 들어가는 비용을 획기적으로 줄일 수 있을 거라고 생각하고, 꾸준히 계속 추진하려는 계획을 갖고 있습니다.오랜만에 회사에 대해 말씀 드리다보니, 글이 무척 길어졌네요. DR(Developer Relations)도 한꺼번에 하려고 하면 안 되고, 꾸준히 계속해야 한다는 것을 새삼 다시 느끼게 됩니다. :-)다시 찬찬히 읽어보니, 어찌보면 위에 적은 글들은, “우리 사업 잘 하고 있어요”라는 자화자찬인것 같아 부끄럽기만 합니다. 제가 정말 전하고 싶었던 말은, 우아한형제들이라는 회사가 일을 더 잘 하기 위한 고민을 끊임없이 계속한다는 것입니다. 사업과 서비스가 성장하면서 고민할 수밖에 없도록 요구받고 있고, 고민하고 일해야지만 해결할 수 있는 과제들이 충분히 많이 놓여 있습니다.이것은 일 자체에 대해서만이 아니라, 일을 잘 하기 위한 메타적인 일에도 적용이 됩니다. 우리가 일하는 환경을 더 낫게 만들려면 어떻게 해야 할 지 고민하다가, 서비스를 만드는 기획/디자인/개발 조직은 몽촌토성역이 아닌 잠실역에 새로운 공간을 얻어서 이동하는 것으로 결정한 것처럼 말이죠. 공간과 일하는 방식 모든 것을 고민의 대상으로 삼고 있습니다.좋은 회사는 현재로서 완성된 좋은 모습을 갖추어서가 아니라, 어떤 것이 좋은 것인지, 더 좋은 것인지를 지속적으로 고민하고 실행에 옮길 수 있는, ‘좋음’의 모습이 현재 진행형인 회사라고 생각합니다.우아한형제들이 매출이 가장 높은 회사여서가 아니라, 복지 혜택이 가장 좋아서가 아니라, 일을 더 잘 하기 위한 고민을 같이 나누고 변화시켜 나갈 수 있기에, 이 글을 보시는 많은 좋은 개발자 분들과 같이 일하고 싶다는 말씀 전하고 싶습니다. :-)채용공고는 우아한형제들 홈페이지를 참고하시면 되고, 개발자 채용 관련해서 궁금하신 사안은 tech_hr@woowahan.com 으로 메일 보내 주시면 답변 드릴 수 있도록 하겠습니다.감사합니다.",http://woowabros.github.io/woowabros/2018/04/15/developer-relations.html,woowabros,ruby,NULL,2018-04-15
"Hello, Geo-fence!","안녕하세요 라이더스개발팀 박민철 입니다. BROS(Baemin Riders Operating System)에 Geo-fence를 도입한 경험을 적어보겠습니다. (BROS는 라이더를 배차하고 음식을 픽업하여 고객에게 전달하는 서비스를 지원하는 배달 플랫폼 입니다.)‘geo-fencing’ 으로 불리기도 하는데, 지도위에 가상의 도형들의 영역을 말합니다. [이런식으로 그리면 혼나요]기존에는 지점(관제센터)의 행정동코드 기반으로 배달 가능 여부를 판단하였습니다. 고객의 행정동코드와 지점의 배달 가능한 행정동코드를 매핑하여, 배달 가능한 지점이 존재하면 주문을 생성할 수 있었습니다.여기에서 1가지 같은 2개의 이슈가 발생합니다. [경계선 주변 배달불가능] 첫 번째는 고객이 배달 가능 지역에 가까워도 특정 지점의 행정동코드가 없으면, 배달할 수 없는 문제입니다. 경계선 근처에 거주하는 고객에게 서비스를 제공하지 못한 안타까움이 있습니다.  [움직일 기미가 안 보이는 라이더님] 두 번째는 배달 가능 지역내 일부 영역을 제외할 수 없는 문제입니다. 이 프로젝트가 진행되어야 하는 이유의 많은 지분을 차지하고 있습니다.  공원이나 오토바이가 진입하기 어려운 지역, 오랜 시간을 소요해야 하는 지역(타*팰리스는 보안 때문에 출입시간 소요가 많습니다.)을 피크타임에 유연하게 처리할 수 있도록 해야 합니다.먼저 Geo-fence를 사용하기 위해 네이버 지도 API 문서를 잘 읽었습니다. 그다음 BROS에서 지점별로 접수영역과 차단영역을 그리고 저장할 수 있도록 기능을 개발했습니다.  그리고 행정동코드기반 로직에 접수영역과 차단영역을 추가로 판단하여 배달 가능 여부를 전달하도록 수정하였습니다. [접수영역과 차단영역을 그려봅니다]약간의 문제가 있습니다.기존 시스템에서는 지점들의 배달 가능한 행정동코드를 On/Off로 관리하고 있었습니다. 관리자가 접수영역과 차단영역을 적절하게 그릴 수 있도록 행정동의 정보를 Geo-fence로 같이 볼 수 있어야 했습니다.그래서 통계청 통계지리정보서비스에서 제공하는 행정동 경계 파일을 기반으로 작성된 geojson 파일을 사용하여  행정동 영역을 저장하였습니다. ( github에 공유해주신 개발자님 감사합니다. )하지만, 통계지리정보서비스에서 제공하는 코드는 7자리 행정구역분류코드이고, 저희가 사용하는 코드는 10자리 행정표준코드관리시스템코드이기 때문에 변환이 필요했습니다. ( 아 … 할많하않 ) 통계분류 포털 홈페이지의 행정구역분류 엑셀 데이터를 다운받아 매핑을 할 수 있었습니다. (이 삽질작업은 오픈 프로젝트인 우아한주소에 저장되어 있습니다.) [행정동과 같이 접수영역과 차단영역을 그려봅니다]마지막으로 로직을 수정합니다.기존 로직에 행정동코드 포함 여부에 추가로 고객의 위치가 접수영역 안에 있는지 혹시 차단영역 안에 있는지 판단하는 기능을 추가하였습니다.  이렇게 간단하진 않지만, 대략 이런 느낌입니다.    바쁘신 분들은 뒤로가기를 눌러주세요.Geo-fence에서 생성한 도형 안에 점(Point)이 존재하는 여부를 JTS(평면 기하학을 위한 기능을 제공하는 오픈소스 Java 라이브러리)를 사용했습니다. Point.class와 Polygon.class은 Geometry.class를 상속받아 사용하고 있었으며, 적절해 보이는 within이라는 함수를 사용했습니다.한번 테스트를 해봅니다. [테스트통과는 언제나 기분이 좋아요]궁금증이 하나 생깁니다. 영역의 경계선 위에 점(Point)이 있으면 어떨까요? 제대로 동작할까요? 점(Point)이 영역의 경계선에 있으면, 안에 있다고 판단하지 않습니다. 그렇군요. 문서를 읽어봅시다. (영어라서 문서를 먼저 안 읽…)  문서를 보면 contains, covers, coveredBy, equals … 그럴듯한 함수들이 있습니다. 앞서 사용한 within 함수를 살펴보면 DE-9IM 단어와, [T * F * * F * * * ] 표기가 있습니다. 잘 모르겠습니다. 그래서 검색을 해봤습니다.DE-9IM? [DE-9IM : 두 도형의 관계를 행렬로 표현해 봅시다]DE-9IM은 두 도형의 내부, 경계, 외부의 총 9가지의 관계를 표현하며, 교집합에서 발생하는 도형의 Dimension(차원)을 행렬로 나타냅니다.  그림에서 보면 II(가장 왼쪽 위)는 교집합의 도형이 2차원이기 때문에 2가 나오고, IB는 교집합이 직선이므로 1이란 값이 도출됩니다.A simplified version of dim(x) values are obtained mapping the values {0,1,2} to T (true), so using the boolean domain {T,F}.[Dimension이 0이라고 false가 아닙니다!]그리고 DE-9IM을 boolean으로 변환할 때 점, 선, 면은 모두 true이며 존재하지 않는 도형은 false가 됩니다. 그럼 다시, 앞서 작성한 두 가지의 테스트코드를 다시 살펴봅시다.테스트를 통과하지 못한 이유앞에 두 가지의 경우에 대해 테스트코드를 작성했습니다.문서에 보면 within을 포함한 covers, contains … 함수들의 DE-9IM 규칙을 설명한 내용이 있습니다.  within의 규칙은 [T * F * * F * * *]입니다. 그래서 1번 조건은 만족하지만, 2번 조건을 만족하지 않습니다. 그래서 테스트코드에서 within의 값은 false로 반환됨을 알 수 있습니다.2번 조건을 만족하기 위해선 wihtin 함수가 아니라 coveredBy 함수를 사용해야 합니다.  contains는 within의 도형의 순서가 바뀐 것이며, covers와 coveredBy도 유사한 관계를 알았습니다. 역시 아는 만큼 보입니다!    수포자들은 뒤로가기를 눌러주세요DE-9IM을 사용하여 두 도형의 관계를 표현하는 방식을 알았습니다. 그런데 말입니다. 두 도형의 교집합을 판단하는 건 어디까지나 저의 뇌피셜로 판단을 했는데요,  한 점(Point)이 다른 도형 안에 있다는 것을 어떻게 컴퓨터가 판단하는지 궁금해졌습니다. 그래서 한번 찾아봤습니다.보통 가장 많이 사용하는 방법은 Ray Casting Algorithm입니다. [알고리즘이라서 그런지 0부터 시작(소오름)]알고리즘은 대략 이렇습니다. 그림을 보면 알 수 있듯이, 점을 지나는 임의의 직선을 하나 쭉! 그립니다.  그러면, 그 직선과 도형이 만나는 교점이 생깁니다. 이 교점을 기준으로 7개의 선이 만들어집니다.  그 점이 홀수 번째 선 위에 있으면 도형 안에 포함, 짝수 번째 선 위에 있으면 도형 밖에 있다고 판단하면 됩니다.  ( 이렇게 심플한 방법이! ) 그럼 만만한 문제를 한번 풀어봅시다.수학적 사고를 언어로 작성합니다. [수학문제 같이 생긴 문제를 풀어봅시다]임의의 점(4, 8)이 삼각형 안에 있는지 밖에 있는지 확인하시오. (3점)   문제를 해결하는 순서는 다음과 같습니다.먼저 좌표들을 순회하면서 직선의 방정식을 구합니다.직선의 방정식직선의 방정식은 y = ax + b ( a는 기울기, b는 y절편 ) 입니다. 두 점이 있는 경우 기울기( y증가량 / x증가량 )를 구하고, y절편은 두 점 중 한 점과 기울기를 대입하여 값을 구합니다.3개의 직선 방정식을 구했습니다. 이제 직선들과 점(4, 8)을 지나는 파란 직선(y = 8)과의 교점을 구합니다. y = angle * x + yIntercept 직선에 y = 8을 대입하여 교점(?, 8)들의 x좌표를 구합니다.교점교점을 모두 구하면, 다음과 같이 3개의 교점(빨간색점)의 x값을 찾을 수 있습니다.   [예외인 녀석이 있는 것 같다]그림에서 보면 가장 왼쪽에 있는 교점(빨간색점)은 삼각형의 변 위의 점이 아니기 때문에 예외를 해줘야 합니다. 두 점의 x 값을 범위로 지정하여 교점이 그 사이에 있는지 판단하고, 삼각형과 만나는 교점만을 리스트에 추가합니다.몇 번째 선 위에 있는가?마지막으로, 점(4, 8)이 교점들 사이에 생긴 선 중 몇 번째 속하는지 판단합니다. 감동적인 마무리수고하셨습니다. 드디어 끝났어요! ( 짝짝짝 ) 이렇게 간단(?)하게 작성할 수 있었습니다. 하지만 현실은 그렇게 간단하지 않죠. 알고리즘이 매력적으로 간단하지만, 항상 잘 작동하는 것은 아닙니다.Unfortunately, this method won’t work if the point is on the edge of the polygon. 이런 경우는 임의의 점이 도형 안에 포함되어 있지만, 알고리즘에 의하면 짝수 번째의 선 위에 있어 밖에 있다고 잘못된 값을 반환하게 됩니다. 물론 현실에서 사용하는 도형들은 유한한 점으로 표현하기 때문에 충분히 예외를 처리할 수 있습니다.포스팅을 간단하게 시작했지만, 내용이 산으로 가기도 하고, 기술과 멀어지고, 많이 길어지기도 했습니다.  이런 글도 있어야 다양한 곳에서 인사이트를 얻을 수 있다는 핑계로 작성을 했습니다.  개인적으로, 오래전부터 지도 API를 사용하면서 폴리곤 같은 도형 안에 포함 여부를 판단하는 로직에 궁금증이 있었습니다.  우연한 기회에 잊고 있던 작은 호기심을 깊게 찾아볼 수 있던 좋은 경험이었습니다. 긴 글 읽어주셔서 감사합니다.#문서를잘읽습니다 #영어공부필수 #일을이렇게열심히참조문서",http://woowabros.github.io/experience/2018/03/31/hello-geofence.html,woowabros,,NULL,2018-03-31
신입개발자 교육 후기,"작년 12월 말에 입사한 후 1월부터 9주 동안 진행된 신입 개발자 교육을 마쳤습니다!교육이 어떤 식으로 진행되었는지, 무엇을 배웠는지 짧게나마 공유해드리고자 합니다.크게 위 과정으로 진행되었는데, 모든 과정은 페어 프로그래밍(짝 프로그래밍)으로 진행되었습니다.교육받기 전까지 혼자 결정하고 혼자 코딩하던 저에겐 적응하기 힘든 방식이었지만, 교육 후반쯤 되었을 때는 너무 적응을 한 나머지 혼자 결정하기가 무서워졌었죠..그리고 교육은 대부분 실습으로 진행되었는데, Github으로 코드를 관리하며, 강사님들이 코드 리뷰를 통해 코드가 더 깔끔해질 수 있는 방법들을 말해주는 방식으로 진행되었습니다.먼저 저는 백엔드로 지원을 했습니다. 그 전에도 js(Javascript)를 다뤄봤었지만,  함수만 수십 개 만들어 구조란 찾아볼 수 없는 모습, 잘 돌아가는지 확인하기 위해 새로 고침만 수십번 누르다가 이내 질려버리고 말았었죠. (내가 못 짠 건 생각도 안 하고…)하지만 교육을 받으며, js에도 클래스가 있고, 테스트 코드도 만들 수 있다는 걸 알았습니다. 그러면서 점점 구조가 잡히고, 새로 고침 대신 테스트코드를 돌리며 js의 맛을 조금 알게 되었습니다.뿐만 아니라, Promise를 통한 비동기 처리, Event delegation을 통한 효과적인 이벤트 적용 방법, es5와 es6의 차이 등 백엔드를 공부하면서는 접하기 힘들었던 부분들을 알게 되었습니다.이 시간 덕분에 프론트와 조금이나마 친해질 수 있었고, 프론트 개발하시는 분들을 이해할 수 있게 되었습니다.백엔드 언어는 자바지기님이 지키는 Java로 진행되었습니다.Java를 그래도 좀 안다고 생각했지만, 개발하면서 한 번도 들어본 적이 없는 Optional과 Stream을 만나고… 그건 어디까지나 제 착각이었다는 것을 뼈저리게 느꼈습니다…또, 최대한 TDD를 따르려고 노력하며, HTTP, Spring 프레임워크, JPA 등을 배웠습니다. 테스트를 정말 열심히 만들었지만, 구조가 바뀌면서 망가지는 테스트들을 보며 정말 가슴 아팠습니다.가장 기억에 남는 자바지기님의 한마디는 “비즈니스 로직은 상태 값을 가지는 객체가 하게 해라.” 라는 말인데, 평소 Spring Boot 기반으로 개발을 하면서 습관적으로 Service 계층에서 많은 비즈니스 로직을 처리하던 부분을 모델이 직접 처리하게 만들고 나서 보니 한층 코드가 깔끔해진 것을 느꼈습니다.그리고 개발하면서 구글링을 하다 종종 뵀던 자바지기님이 이렇게 옆집 삼촌 같은 분인지 알게 되었던 귀중한 시간이었습니다.팀 프로젝트를 하면서 배웠던 모든 내용을 바탕으로 Trello 와 비슷한 서비스를 만들었는데, 각자의 직군으로 나눠서 개발하지 않고, 백엔드와 프론트를 모두 같이 만들었습니다.혼자 프로젝트를 진행할 때와는 달리 직접 구현하지 않은 기능들이 생겼는데, 어떻게 만들었는지는 모르지만, 동료들을 믿고 내가 맡은 기능에 충실해야 한다는 것을 깨달았습니다.또, 다른 사람과 의견대립이나 합의가 필요할 때, 빠르고 더 좋은 결과를 내기 위해 투표도 해보고, 팀장을 뽑아서 결정권을 위임하기도 해보았습니다.교육을 받다 보니 다른 사람과 같이 일하는 방법을 배우는 것이 목적처럼 느껴졌는데, 제 생각이 맞다면 이 교육은 꽤나 성공적이었다고 생각합니다. 매일 붙어서 같이 코드를 짜면서 내 의견을 설득도 해보고, 설득당할 때도 있다 보니, 지식도 지식이지만, 서로 존중하면서 대화하는 방법을 더 많이 배울 수 있었습니다.조금 신기했던 부분은, 교육을 받으면서 수많은 커뮤니케이션 과정에서 한 번쯤은 감정이 격해질 만도 한데, 동기들끼리 한 번도 싸우거나 멀어진 적이 없었습니다. 다들 한 인성 하던 분들인 듯… (저 포함)아무튼 아주 만족스럽고 좋은 교육이었습니다. 현업에서도 교육받은 내용을 잘 적용할 수 있도록 노력하겠습니다. 읽어주셔서 감사합니다!ps. 리눅스의 신 honux님, IOS 마스터 JK 님도 감사합니다!",http://woowabros.github.io/woowabros/2018/03/25/newbie-education.html,woowabros,"android,java",NULL,2018-03-25
Hybrid-Cloud 환경에서 보안인증 준비 하기,"지난 2월 오석윤님이 포스팅해주신  [AWS에서 네트워크 공격 자동차단하기]의 Summary에서 내용을 일부 가져오고자 합니다.“Public Cloud 환경에서의 서비스 운영은 Legacy 환경의 IDC 서비스 운영과는 너무도 다르기 때문에 보안이 쉽지 않다.”.  특히나 국내 실정에 맞추어 만들어진 ISMS 인증 표준 또한 Cloud 서비스에 맞추기 위해 변화하고 있지만 아직은 IDC 환경의 서비스에서 준비하기가 조금 더 원활하도록 초점이 맞추어져 있다고 생각이 됩니다.따라서 이번에 ISMS 인증심사를 준비하며 겪었던 몇 가지 이슈사항들과 어떻게 해결하였는지 그 과정을 정리하고자 합니다. 하지만 공개되어 있는 공간이므로 실제 심사 결과의 취약점은 다루지 않고 심사를 준비하며 겪었던 내용을 바탕으로 포스팅해보겠습니다.솔직히 기술적인 부분이 많이 들어가지 않은 글을 기술 블로그에 쓰려고 하니 걱정이 앞섭니다. [기술이 없는 기술블로그를 작성해보자]우선 보안인증에서 첫걸음으로 가장 중요한 부분은 인증 범위의 선정이라고 볼 수 있습니다. ISMS 인증의 경우 관리체계 수립이 자산을 기준으로 진행됩니다. “배달의민족 서비스”에 대한 ISMS 인증을 받고자 한다면 인증 범위에는 배달의민족 서비스를 위한 자산(서버, DB, 네트워크장비, 개발자의 PC 등)들이 모두 포함되게 됩니다. 그리고 인증 범위에 포함된 자산들이 AWS와 IDC에 나누어져 운영되고 있다면 AWS와 IDC 모두가 인증 범위에 포함되어 인증 대상이 되어야 합니다.사무실도 예외로 할 수 없습니다. 개발을 하고 기획을 하는 모든 업무가 배달의민족 서비스에 반영되고, 개발자와 기획자가 업무를 하며 이용하는 백오피스 시스템도 배달의민족 서비스의 한 부분이니까요. 따라서 사무실 보안에 대해서도 보안대책을 세워야 합니다.[CCTV같은 물리적 보안도 포함해서 말이죠]여기까지 인증 범위 선정하기가 정리되었습니다. 하지만 문제는 여기서부터 발생합니다. 일반적으로 많이 사용하는 IDC와 Cloud 서비스를 제공하는 AWS는 다른 부분이 너무 많았습니다. 물리적으로 존재하는 방화벽이 아닌 SecurityGroup… 서버가 하루가 다르게 생겼다 없어졌다 하는 EC2… 등등 AWS의 이런 편리한 기능들은 서비스와 관리를 하기에는 굉장히 유용하지만 자산을 바탕으로 정보보호 관리체계를 수립해야 하는 ISMS 인증 준비단계에서 큰 고민거리가 되었습니다.회사에서 정보보호관리체계를 세우기 위해서는 우선 보호하고자 하는 자산의 식별과 식별된 자산의 위험평가 그리고 위험평가를 위한 취약점 진단이 진행되어야 합니다. 하지만 Cloud 서비스에서는 자산의 식별부터 막히게 됩니다. Auto-Scaling 등과 같은 Cloud 서비스의 특성으로 인해 식별되어야 하는 자산이 하루가 다르게 생겼다 없어졌다를 반복해버립니다. 또한 식별이 되었다 한들.. 이렇게 변화무쌍한 서버들에 대해서 취약점 진단과 위험평가는 어떻게 진행해야 할까요. 이 부분이 중요한 이유 중 하나는 ISMS 인증심사 진행 시 심사비용 수수료 결정에 가장 큰 영향을 미칩니다. 자산 수에 따라 심사일수를 정하게 되고, 정해진 심사일수에 따른 수수료가 결정이 되죠.   두 번째로는 개인 정보를 전송할 때에는 암호화 통신이 되어야 합니다. 하지만 서비스를 AWS와 IDC에서 함께 사용하는 환경인 경우, 정적인 통신 대상과 동적인 통신 대상이 있고 시스템의 환경 설정을 할 수 없도록 되어있는 Public Cloud의 관리형 서비스 환경 등… 이렇게 제한되어 있는 상황에서 어떤 보호대책을 수립해야 효율적인 서비스를 유지하면서 컴플라이언스를 만족할 수 있을까요.[서울에도 Region이 있다. 이건 비밀인데 어디에 있냐면…]세 번째로 AWS은 사용되는 IP 주소 목록이 Public 하게 공개되어 있습니다. 그에 따른 보안 위협은 끊임없이 들어오는 단순 스캔 공격만 봐도 알 수 있습니다. 보안 위협을 방어하기 위한 IPS, 웹방화벽 등과 같은 보안장비의 적용이 필요합니다. 하지만 일반적으로 AWS에서는 IDC 환경처럼 물리적 보안장비를 직접 구축하여 운영할 수가 없습니다. Region이 어디 있는지 모르고, 어디 있는지 알더라도 들어갈 수 없으니까요. 공격자가 전산센터의 위치가 어디 있는지 모르고 들어갈 수 없지만 사용자도 같이 모르고 들어갈 수가 없으니 안전하다니… 대체 어떻게 해야 할까요.[심심하면 들어오는 SSH BruteForce 공격]AWS의 급변하는 인스턴스에 맞춰 자산을 식별하려면 자산 식별의 기준이 필요했습니다. 첫 번째로 자산 목록을 결정할 특정 기준일을 정했습니다. 해당 특정 기준일을 시점으로 최근 한 달간 변화를 보고 최소로 줄어든 인스턴스 개수를 자산목록에 기입하여 식별하였습니다. 예를 들어 하나의 Baemin-server라는 호스트네임을 가진 인스턴스가 Auto-Scaling으로 인해 한 달간 최대로 늘어난 수가 Baemin-server-1~20이고, 최소가 Baemin-server-1~4로 나타났다면 자산 식별 수는 4개로 결정하고, 식별된 자산 목록에는 Baemin-server-1,2,3,4로 4개의 server가 들어갑니다.다음 식별된 자산을 기준으로 취약점 진단을 진행해야 하는데, 동일한 설정을 가진 시스템이라는 전제하에 1대씩 샘플링으로 진행을 합니다. 일반적으로 취약점 진단은 체크리스트를 기반으로 스크립트를 통한 수동 점검을 진행합니다. 하지만 AWS에는 애플리케이션의 취약성 또는 모범 사례와 비교한 차이점을 자동으로 평가하는 Amazon Inspector(이하 Inspector)라는 취약점 자동 점검 툴이 있습니다. 운영 중인 서비스에 직접 툴을 적용할 경우 리소스 과부하가 발생하지 않으리라는 보장이 없기 때문에 운영 인스턴스들을 복사하여 별도의 VPC를 생성한 뒤 툴을 적용한 후 취약점 점검을 진행하였습니다.하지만 Inspector를 통한 점검 결과로 위험평가를 진행하기에는 기존의 위험평가 Concerns List와는 다른 점이 많았습니다. 그래서 기존의 항목을 기반으로 Inspector를 이용하여 점검할 수 있는 항목을 Concerns List에 녹여냈습니다.[서버 취약점 점검 평가 항목][위험평가 Concern List 일부인데 잘 안보이는게 맞습니다. 가렸으니까요.]그 다음은 당연히 발견된 취약점에 대해 위험조치계획을 수립하고 위험관리를 수행하면 됩니다.실제 우아한형제들의 시스템 간 네트워크 구성이 어떻게 되어있는지는 언급하지 못하므로 검토했던 내용 중 2가지에 대해 간략하게 기술해보겠습니다. 우선 AWS-IDC 간 개인정보가 평문으로 전송되지 않도록 하는 것이 핵심이었습니다. 개인정보의 암호화 통신이 키워드이니까요.첫 번째로 AWS에서 제공하는 Direct Connect 서비스가 있습니다. 용어 그대로 IDC환경의 온프레미스 IT 자원과 AWS 클라우드 자원을 전용 회선으로 연결하는 서비스입니다. 전용선을 구축할 경우 암호화통신으로 볼 수 있기 때문에 개인정보 암호화통신 이슈를 해결할 수 있습니다.두 번째로 IDC의 서비스와 분리하여 배달의민족 서비스가 AWS 내부에서만 통신 가능하도록 구성하는 방법이 있습니다. 완전한 Cloud 서비스 환경으로 구성하는 아주아주 간단한(?) 방법입니다. IDC가 아닌 Cloud 내부에서만 통신을 하게 된다면 이슈가 줄어들게 됩니다.여러 가지 방법들 중 회사의 환경과 상황에 맞게 구축 진행하면 해결할 수 있는 문제였습니다.[이러지 않았으면 좋겠습니다.]현재도 그렇고 앞으로도 가장 고민이 많은 부분입니다. 보안장비를 구축함에 있어서 석윤님이 포스팅해주신 “자동화”가 핵심이라고 생각합니다. 공개되어 있는 공간인 만큼 특정 제품을 언급하지는 못하지만, Public Cloud 환경의 특성상 선택폭이 상대적으로 크지가 않습니다.하지만 현재 AWS에 적용이 가능한 보안 제품들이 많이 나오고 있으며, appliance 형태의 보안장비가 아닌 SaaS 형태의 보안장비는 AWS에 인스턴스를 생성하여 구축, 운영할 수 있습니다. 현재 회사에서 꼭 필요한 것이 무엇인지, 또 잘 활용할 수 있는 보안장비가 무엇인지 파악하는 것이 중요하다고 생각합니다.[이번 고비가 지나면 다음 고비가 온다. 정말로. 꼭 옵니다.]현재 많은 기업들이 비용 면에서 효율적인 Public Cloud 서비스를 이용하고 있습니다. 하지만 아직 국내 컴플라이언스가 Public Cloud 환경과 맞지 않는 부분이 많은 것으로 보입니다.(우아한형제들의 공식적인 입장이 아닙니다. 우아한형제들은 국내 보안규정을 준수하고 있습니다.)컴플라이언스를 충족하면서 정보보호관리체계를 구축하고 운영하려면 아직 많은 고민거리들이 존재합니다.등등… 많은 고민들이 생겨나고 해결되고 또 다시 생겨나게 될 겁니다.   물론 위에서 언급했던 방안들이 모두 정답이라고는 할 수 없습니다. 하지만 급변하는 IT 환경 속에서도 우리는 답을 찾을 것입니다. 언제나 늘 그랬듯이",http://woowabros.github.io/security/2018/03/20/isms-certification.html,woowabros,,NULL,2018-03-20
SIL(Swift Intermediate Language)을 통한 Swift debugging,"몇일 전 그렇게 멀지않은 방이동, 경복궁 건물 6층 배민찬 개발팀에서,제너릭을 가지는 구조체에 반환값이 있는 readonly 프로퍼티를 선언한 스위프트 개발자 A는 구조체를 확장하며 지난 선언을 잊고 프로퍼티를 중복해서 선언한 후, Xcode에 숨겨진 무서운 비밀을 만나는데…Xcode 사용자 분들은  An internal error occured. Source editor functionality is limited. Attempting to restore...라는 에러와 함께 코드 autocompletion동작이 동작하지 않거나 코드 하일라이트가 사라지는 등의 문제를 여러번 겪으셨을 겁니다. 이전에는 단순히 Xcode의 버그라고 생각해, 재부팅이나 clean등으로 해당 문제를 해결하려고 했습니다. 하지만 항상 Xcode의 버그만 이런 문제를 발생시키는건 아닌것 같습니다. Xcode는 소스들의 인덱싱 작업을 하며 swift빌드 단계의 특정(AST->SIL) 단계를 이용하여 코드 하일라이트나 autocompletion을 수행하고 있다는 추측을 하고 있습니다. 이 글을 쓰게 된 계기는 바로 SIL코드 생성 단계가 실패하여 발생한 문제였습니다. 이를 파악하는 도중 알게된 SIL에 대한 지식과 사용가능한 몇 가지 툴을 공유하고자 합니다.코드를 작성 중 어떤 특정 변수를 실수로 중복해 선언한 상태로 중복 선언이라는 에러 메시지 없이 xcode의 데몬이 멈추고 build 시 sil 생성중 에러를 반환하는 경우를 만나게 되었습니다.이전에 비슷한 경우를 만났던 경우 의심되는 코드를 완전히 지우고 다시 설계하고 작성해서 넘어갔었는데, 몇 번 비슷한 상황을 겪은 터라 이번에는 확실히 알고 넘어가기로 결심했습니다. 문제를 더 간단한 코드로 재현하여, 명확하게 문제를 파악해서, 제대로된 에러를 반환하고 그럼으로써 문제의 원인을 파악하여 해결책을 찾아보기로 결심했습니다.구조는 좀 더 복잡했지만, 재현과 분석을 원활하게 하기 위해 원 코드를 단순화한 코드로 바꿔 진행해보겠습니다.여기 A와 B, 두 구조체가 있습니다.struct Astruct BA와 B는 각각 Element라는 제너릭을 선언하고 있습니다. 이것은 어떤 값이라도 선언할 수 있도록 아무런 constraint를 선언하고 있지 않습니다.A는 b 함수를 선언하고 반환 값은 B<Element>입니다. A의 Element와 b 함수가 반환하는 B 클래스의 Element는 동일합니다. A.Element == B.Element입니다.그런데 b함수가 인자를 받지 않는 것이 눈에 띕니다. 이것이 거슬렸던 저는 함수를 프로퍼티로 바꾸기로 결심합니다.그러면서 한 가지 실수를 저지르게 되었죠.위의 코드는 제가 범했던 실수를 명확하게 드러내주고 있습니다.A라는 구조체를 확장하고 b함수를 프로퍼티로 변경하는 과정에서 b는 readonly 프로퍼티이니 A의 확장에서 b를 선언하는게 좋겠다고 판단하고는 확장에서 선언을 한 후에 A 구조체 선언부에서 b 프로퍼티 부분을 제거하는 것을 잊어버렸습니다. 그리고 그 순간부터 Xcode는 지속적으로 에러와 복구를 반복해서 수행했고, 저는 Xcode가 또 땡깡을 부리는구나 판단하고는, clean, 재부팅등을 시도했습니다. 변한것은 없었고, 뭔가 문제가 있으니 빌드를 해볼까 싶어 빌드를 시도했습니다. 그런데 에러가 등장하기는 했습니다만, 소스 코드상에 특정 부분을 지적하는 에러가 아닌, 개발할 때 제일 꼴보기 싫은 에러인 Segmentation fault: 11에러를 아래와 같이 만나게 되었습니다.swiftc ./test.swift0  swift                    0x000000010ca7236a PrintStackTraceSignalHandler(void*) + 421  swift                    0x000000010ca717a6 SignalHandler(int) + 6622  libsystem_platform.dylib 0x00007fff50a80f5a _sigtramp + 263  libsystem_platform.dylib 0x0000000000000008 _sigtramp + 29417760724  swift                    0x0000000109cc4c9b swift::Lowering::SILGenFunction::SILGenFunction(swift::Lowering::SILGenModule&, swift::SILFunction&) + 2035  swift                    0x0000000109c36d45 swift::Lowering::SILGenModule::emitFunction(swift::FuncDecl)::$_1::operator()(swift::SILFunction) const + 2616  swift                    0x0000000109c362c9 swift::Lowering::SILGenModule::emitFunction(swift::FuncDecl*) + 7617  swift                    0x0000000109d1f176 swift::Lowering::SILGenModule::visitExtensionDecl(swift::ExtensionDecl*) + 4228  swift                    0x0000000109c3c91b swift::Lowering::SILGenModule::emitSourceFile(swift::SourceFile*, unsigned int) + 11159  swift                    0x0000000109c3e2a9 swift::SILModule::constructSIL(swift::ModuleDecl, swift::SILOptions&, swift::FileUnit, llvm::Optional, bool) + 84110 swift                    0x00000001093ced06 performCompile(swift::CompilerInstance&, swift::CompilerInvocation&, llvm::ArrayRef<char const>, int&, swift::FrontendObserver, swift::UnifiedStatsReporter*) + 1296611 swift                    0x00000001093ca1f4 swift::performFrontend(llvm::ArrayRef<char const>, char const, void, swift::FrontendObserver) + 771612 swift                    0x000000010937ee78 main + 1224813 libdyld.dylib            0x00007fff507ff115 start + 114 libdyld.dylib            0x000000000000000f start + 2944405243Stack dump:보통 이런 에러를 만나면 좌절했겠지만, 요즘 스위프트의 빌드 과정에 대해 공부하고 있던 차 stack dump의 1. While emitting SIL for getter for b at ./test.swift:13:6이 눈에 들어왔습니다. 이건 스위프트 빌드 단계 중 두 번째인  Swift Intermediate Language를 생성하는 단계에서 test.swift 파일의 13번째 라인 6번째 컬럼에 있는 b를 위한 getter SIL을 생성하는 도중 에러가 발생했다는 의미입니다.여기서 잠깐 SIL? AST? 이런 용어를 아마 처음 들으시는 분들도 계시리라 생각합니다. 이것은 스위프트의 빌드 단계를 지칭하는 이름이기도 하고 그 단계에서 생성하는 코드의 형태를 지칭하는 단어이기도 합니다. 본격적인 분석에 들어가기 전에 스위프트의 빌드는 어떻게 이루어지는지 살펴보겠습니다.####1. LLVM여기서는 주제와 좀 떨어져 있으니 LLVM의 빌드 구조만 간략하게 소개합니다. 상세한 내용은 llvm.org의 내용을 참조해주세요.Frontend->LLVM Optimizer->LLVM Backend####2. 스위프트의 빌드 단계스위프트의 코드 작성과 실행 가능한 바이너리가 만들어지기 까지는 아래와 같이 몇 단계를 거치게 됩니다.Swift Code -> Swift AST -> Raw Swift IL -> Canonical Swift IL -> LLVM IR -> Assembly -> Executable참고: swift/SIL.rst다음 챕터부터 SIL의 코드를 보게 될텐데 그 전에 대강 SIL이 이렇구나 하는 정도로 훑어보겠습니다.다음의 간단한 스위프트 파일을 SIL로 빌드해보겠습니다.스위프트 파일에서 SIL 파일을 생성하기 위해서는 스위프트 컴파일러인 swiftc에 -emit-silgen 혹은 -emit-sil 옵션으로 컴파일합니다. 이 옵션들은 AST로부터 SIL을 생성하게 되는데, -emit-silgen은 raw SIL을 -emit-sil은 canonical SIL을 생성하게 됩니다. swift-demangle툴은 생성한 SIL의 알아보기 힘든 이름들을 정리해서 읽기 쉽게 변경해 줍니다.Person의 n변수의 getter부분을 살펴보겠습니다.$0등의 숫자와 주석의. user: %.., id: %..등이 눈에 띕니다. 이것은 SIL에서 사용하는 레지스터를 표현하는 것이기도 하고 해당 레지스터나 선언이 어떤 레지스터와 의존관계를 이루고 있는지 알 수 있게 해주는 레이블로서의 표현이기도 합니다. 아래에서 이 소스 코드에서 사용하고 있는 SIL의 키워드에 대해 설명해보겠습니다.hidden - Person 구조체를 default로 선언했기 때문에 n 프로퍼티는 같은 모듈에서만 사용할 수 있다는 뜻입니다. 스위프트의 코드 스코프를 알려주는 키워드입니다.[transparent] - inline 함수라는 의미입니다.@test.Person.n.getter : Swift.String : $@convention(method)  (@guaranteed Person) -> @owned String// %0                                             // users: %2, %1bb0(%0 : $Person):debug_value %0 : $Person, let, name ""self"", argno 1 // id: %1%2 = struct_extract %0 : $Person, #Person.n // users: %3, %6%3 = struct_extract %2 : $String, #String._core // user: %4%4 = struct_extract %3 : $_StringCore, #_StringCore._owner // user: %5retain_value %4 : $Optional          // id: %5return %2 : $String                             // id: %6} // end sil function ‘test.Person.n.getter : Swift.String’​대충 보면 도저히 읽을 수 없을 것 같은 코드들을 SIL.rst를 참조하며 읽어보았습니다.이렇게 SIL의 극히 일부분을 살펴봤습니다만, 문서를 참조하며 한땀한땀 차분히 읽다보면, 다른 부분을 읽을 때도 의미를 잘 파악하실 수 있으리라 생각합니다.자 드디어 다음 단락부터 문제의 분석에 들어갑니다.우선 분석에 앞서 더 간단한 코드를 통해 invalidate redeclaration 에러를 발생시킬 수 있을지 알아보겠습니다.A의 b를 프로퍼티가 아닌 초반에 만들었던 함수로 만들어 확장 시 해당 함수를 재선언 해보겠습니다.$ swiftc ./test.swift제대로 에러를 발생합니다.흠, 혹시 제너릭 선언과 프로퍼티 선언 간의 복합적인 문제일까요? 그래서 몇 가지 조건을 실험해보기로 했습니다.실험 1 A와 B 둘 다 제너릭이 없고 b가 프로퍼티인 경우실험 2 A와 B 둘 다 제너릭이 없고 b가 함수인 경우실험 3 A만 제너릭을 선언하고 b가 프로퍼티인 경우실험 4 A만 제너릭을 선언하고 b가 함수인 경우실험 5 B만 제너릭을 선언하고 b가 프로퍼티인 경우실험 6 B만 제너릭을 선언하고 b가 함수인 경우실험 7 A와 B 둘 다 제너릭이 있고 b가 프로퍼티인 경우실험 8 A와 B 둘 다 제너릭이 있고, 제너릭의 타입이 동일하며  b가 함수인 경우실험 9 A와 B 둘 다 제너릭이 있고, 제너릭의 타입이 다르며 b가 함수인 경우A.Element != B.Element실험 10 A와 B 둘 다 제너릭이거나 A만 제너릭이며, 확장 시 where 절을 통해 Element의 타입을 명시할 경우결과 빌드가 정상적으로 실행결과를 보면 sil단계에서 에러를 발생하는 경우는 다음과 같습니다.(* 이런 경우를 복잡한 코드에서 만나게 되는 경우 정말 손도 발도 쓰기 힘들다는 게 가장 문제입니다.)결국 b가 어떤 타입이냐는 중요하지 않습니다. A가 제너릭을 가질 것, 제너릭이 Any타입(암묵적이든 명시적이든) 일 것, 확장 시 이미 선언한 프로퍼티를 중복해서 선언할 것으로 문제를 발생시키는 경우를 좁힐 수 있습니다.자 swift의 빌드 구조가 과연 어떻게 되기에 이런 문제가 발생하는지 한 번 알아보겠습니다.먼저 빌드를 성공시킬 수 있는 정도로 코드를 단순화해서 sil 코드를 만들어 보겠습니다. class는 현재 단계에서 볼 필요가 없는 코드를 많이 생성하기 때문에 좀 더 간단한 결과를 볼 수 있는 struct로 바꿨습니다.$ swiftc -emit-silgen test.swift > test.silgen우리가 class, struct 등으로 묶어서 그리고 있는 구조가 sil에서는 해체되고 각 선언들만이 남게 됩니다. 이것을 mangled format이라고 합니다. 다만 네이밍에 AVACyx…등의 알아보기 힘든 형태로 되어있어 툴을 사용해 좀 더 알아보기 쉽게 바꿔보겠습니다.이름들이 이제 알아보기 쉬운 형태로 변환되었습니다. 주석으로 각 선언이 어떤 역할을 수행하는지도 알아보기 쉽게 되어 있습니다.이번에는 다음과 같이 확장의 Element타입을 명시적으로 Int로 선언해보겠습니다.여기까지는 sil 코드가 이전과 별 차이는 없습니다.그렇다면 A.Element == Int 일 경우에만 A의 확장 내용을 사용할 수 있도록 where절로 Element 제너릭을 Int형으로 명시적으로 선언하고 value1 프로퍼티를 추가해보겠습니다.이번에는 SIL 코드에 value1의 getter 선언이 추가되었습니다.code 1where constraint를 빼면 어떨까요?code 2code 1에서는 value1.getter가 A의 확장 함수임을 명시하고 있지만, code 2의 경우에는 해당 부분이 빠져있습니다.문제가 있던 코드 상태로 다시 돌아가 보겠습니다.여기서 sil코드를 출력해서 보고싶지만, 당연하게도 에러가 발생하는 상황으로 인해 더 방법이 없습니다. 그렇다면, 좀 더 자세하게 sil 코드가 생성되는 과정을 디버깅할 수 있는 옵션을 추가해서 출력을 해 보겠습니다.debug constrainted output사실 여기서 뭘 자세히 조사해야 문제를 알 수 있을지 잘 모르겠습니다. 일단 해본 것으로 만족하고 다른 방법을 모색해보겠습니다.그렇다면, 아래와 같이 A.s: String readonly 프로퍼티를 선언하고 A where Element == Int와 같이 확장을 하며 동일한 프로퍼티를 선언하면 어떨까요?에서 생성한 SIL 코드에서 var s 끼리 비교해보면 아래와 같습니다.where Element == Intwhere이 있는 경우 메소드 선언부에서 가 빠지며, `@(extension in test)`가 이 getter는 test에서 A의 확장 함수라는 것을 알려주는 것으로 보입니다. 이 경우 struct A의 s와는 구현은 같지만, 완전히 다른 함수로 선언됨을 알 수 있습니다. 이런 연유로 중복선언처럼 보이지만, 문제 없이 빌드가 됩니다.여기까지 와서 실험할 때 제가 빠트린 경우의 수가 생각이 나서 두 가지를 추가해봤습니다.여기까지는 결국 Element의 타입이 어디에도 명시되지 않았기 때문에, 문제가 발생했다고 볼 수 있습니다. 그런데 이건 처음의 구조와는 좀 다르기 때문에, 새로 알게 된 옵션을 이용하여 아래와 같이 코드를 다시 구성해 결과를 살펴봤습니다.이 경우 아래와 같이 에러를 표시합니다.A 확장에서 var b: B 변수의 getter에 대한 SIL코드를 생성하는 도중 에러가 났다는 사실은 확실합니다.중반부에서 A를 확장하며 Element타입을 명시하면 SIL 코드 생성에서 에러가 발생하지 않는다는 것을 실험에서 알 수가 있었습니다. 이제 같은 상황에 Element타입을 Int로 명시해보겠습니다. 그리고 extension A.b의 getter를 생성하는 부분을 살펴보겠습니다.// A.b.getter에서 제너릭이 A로 선언되어있는데 이 부분은 스위프트코드에서 무슨 이름으로 선언하던지 제너릭 선언 순서대로 A, B, …로 바뀌게 됩니다.제너릭이 두 개인 경우A<Element, Value>로 선언해도 SIL에서는// A<A, B>.b.getter 로 바뀌게 됩니다.getter구문이 생성된 것을 보면 , 이 코드를 SIL코드로 변환하는 부분에서 문제가 생긴다는 추정이 가능합니다.자 여기까지 오느라 힘드셨죠. 고지가 얼마 안남았습니다(물론 저는 남이 이런말을 하면 믿지 않습니다). 그래도 우리 조금만 더 힘내서 하나만 더 테스트해보겠습니다.이번에는 protocol P를 만들고 변수 b에 대한 선언을 명시해서 A가 P를 상속하도록 해보겠습니다. 코드는 sil terminated 되는 그 코드입니다.$ swiftc test.swift어라 좀 다르네요? 첫 번째는 그렇다 치고 두 번째에 타입 B인 b 변수가 하나 이상 있다는 에러를 볼 수 있습니다. 여기까지 SIL문법을 제대로 모르지만, 제 작은 회색 뇌세포를 총동원해서 추론해보면, 구조에 대한 선언 없이 확장을 통해 A 타입에 어떤 프로퍼티를 추가하는 경우, 그리고 A의 제너릭 타입을 명시하지 않는 경우 SIL이 getter 구문을 생성할 때 참고할 만한 어떤 자료가 전혀 없기 때문에, sil 생성시 terminated가 발생하게 된다고 생각할 수 있습니다. 그리고 protocol로 먼저 구조를 만들게 되면 SIL 구문 체크시 참고할 데이터가 있기 때문에, 좀 더 명확한 에러를 반환해주는 것 같습니다. 혹은 확장시 A의 제너릭 타입(Swift에서 제공하거나 혹은 개발자 명확하게 선언한 어떤 타입인 경우)을 명시해 주는 경우에는 참조 가능한 구조가 생성되어 별도의 SIL함수 제공되니 빌드가 정상적으로 이루어진다고 추론해보겠습니다. 하지만 추론은 추론이고 더구나 근거가 매우 미약합니다.저는  명확한 답을 얻어보고자 스위프트 사용자 포럼에 문의를 해놓은 상태입니다. 좋은 답이 오게되면 이 글의 해당 부분을 개선할 수 있을거 같습니다.    추가 답이 달렸습니다. 스위프트의 버그가 틀림없으니 버그 리포트를 하라는군요. ㅎㅎ 신나게 버그 리포트를 달고오겠습니다.지금까지 SIL코드와 툴, 여러가지 변수를 통해 문제를 파악해보려 했습니다.결국은 실수에서 벌어진 일입니다. 스위프트는 Protocol Oriented Programming 추구한다는 것이 힌트가 될 수 있겠죠.객체 혹은 타입을 작성하기 전에 protocol로 구조를 먼저 만들고 해당 protocol을 상속하는  객체 혹은, 타입을 만듭시다. 이것은 여러 장점이 있겠지만, 이 글에서 발생한 문제에 대해서도 에러가 명확해진다는 큰 장점이 있습니다. Xcode도 뭔지 모를 에러를 만들지 않겠지요.초반에 스위프트의 확장을 사용할 때, 저는 단순하게 상속의 오버라이딩과 비슷할 것이라 단정하고 코드를 구현하다 버그를 만들어낸 적이 있습니다. 확장은 객체의 상속과는 사실상 아니 당연하지만 매우 다릅니다.예를 들어 아래와 같은 코드를 보겠습니다. 이 코드에서 저는 A를 확장하며 A.Element == Int인 상황에서는 프로퍼티 s1이 “extension A” 문자열을 반환하리라 기대했습니다.code a하지만 기대를 배신하고A1A2를 출력합니다.A를 확장하며 또 A.Element == Int인 경우 “extension A”를 반환하도록 했음에도 A2를 출력합니다.이번에는 코드를 한 줄 추가해보겠습니다.code bA1extension A의 출력 결과를 볼 수 있습니다.이런 경우를 스위프트 코드만으로는 애매모호한 부분이 있지만, SIL코드를 살펴보게 되면 이유가 명확해집니다. 여기에서는 swift-demangle을 쓰게 되면 실제 좌표가 사라지기 때문에, 이번에는 좀 읽기는 어렵겠지만, 가리키는 곳이 명확하게 드러나게 SIL코드를 생성하겠습니다.$ swiftc -emit-gen test.swiftsil a위의 구조를 찬찬히 보면 확장한 A에서 반환하는 s는 _T04test1AVAASiRszlE1sSSfg가 됩니다만 print부분에서는 사용하고 있지 않습니다. _T04test1AV2s1SSfg주소는 원 선언의 s의 getter 주소입니다.sil b**이번에는 명확하게 a2를 print 할 때, A.s1.getter 선언부인 _T04test1AVAASiRszlE2s1SSfg를 가져오고 있습니다.SIL코드를 보지 않았다면, 이런 문제는 머리속에 계속 물음표로만 남을 수 밖에 없었을 것입니다.이렇듯 스위프트를 다루며 명확하지 않은 에러나 현상을 만날 때, SIL에 어느 정도 익숙해져 있다면, 상당한 도움이 될 수 있습니다.WWDC가면 이런 거 잘 다루는 애플 개발자를 만날 수 있다는 전설이 있습니다. WWDC 2018 가고싶다.여기까지 길고 재미없는 글을 읽어주신 분들에게 감사를 표하며 행복과 행운이 있기를 바랍니다. 앞에서도 이야기했지만, 지적과 지식은 언제나 환영합니다.참조그리고, 가지가지 오타와 문법 오류, 교정을 봐주신 종립님 고맙습니다.",http://woowabros.github.io/swift/2018/03/18/swift-debugging-with-SIL.html,woowabros,,NULL,2018-03-18
"[번역] SIL(Swift Intermediate Language), 일단 시작해보기까지","원문 Swift中間言語の、ひとまず入り口手前まで이 글은 훌륭한 Swift, iOS 개발자이자 교육자인 Tomohiro Kumagai씨가 qiita에 올리신 글을 허가를 얻어 배포합니다.*(주) 내용은 최대한 정확하게 번역하려 했지만, 문장은 초벌 번역에서 겨우 벗어난 수준입니다. 시간 날 때마다 개선할 예정입니다.올해(2016년 글임)의 WWDC를 방문했을 때, Swift Lab에서 Sean Callanan씨가 Swift의 작은 동작을 탐색하는 방법으로 SIL을 활용하고 있는 모습을 보여주었습니다. 뭔가 있을 때 저도 그 흉내를 내어 SIL을 살펴볼 기회가 늘었습니다.SIL은 Swift Intermediate Language의 약칭으로, Swift 중간 언어입니다.그때부터 Swift에서 불가사의한 동작을 맞닥뜨렸을 때마다 SIL을 보고 있는데, 코드를 읽을 수 있다는 것만으로도 큰 도움이 되고 있습니다. 하지만 읽지 못하는 부분도 많아서, 좀 더 잘 읽게 되면 SIL을 통해 여러 가지를 알게 될 수 있을 것 같습니다.그런 생각으로 이번 기사를 쓰게 되었습니다.알듯 말듯한 SIL에 대해, 어느 정도 읽을 수 있는 정도를 목표로 SIL에 대해 조사하기로 했습니다. SIL의 구문과 명령 체계 분석까지 가능했다면 좋았겠지만, 생각보다 깊은 세계였고 저의 기초가 부족한 데다가 시간도 부족하여 깊이 들어가지는 못했습니다.어중간한 내용 같습니다만, SIL에 흥미를 불러일으키는 계기가 되기를 바랍니다.SIL이란 Swift Intermediate Language의 약자로, Swift의 소스 코드를 실행 가능한 바이너리 코드로 바꿀 때, 다른 컴파일러(LLVM)가 취급하기 쉬운 중간표현(Intermediate Representation)으로 변환한 코드를 말합니다. (* LLVM IR과는 다릅니다.)Swift의 컴파일러는 LLVM을 통해서 바이너리 코드를 생성하는데, 바이너리 코드를 생성하는 과정에서 LLVM을 위한 중간표현인 LLVM IR을 생성하게 되고, SIL은 Swift 코드와 LLVM IR과의 중간에 위치합니다.SIL의 목적은 프로그래머가 입력한 Swift 소스 코드와 LLVM IR과의 표현의 차이를 메꾸는 것입니다. 그리고 LLVM IR이 다루기 힘든 Swift 소스 코드 레벨에서의 정적 분석도 범위에 들어갑니다.SIL은 정적 단일 배정 방식(Static single assignment form)에 가까운 언어인듯합니다.상수만을 허용하는 방식으로 보입니다. 그렇다면, Swift의  var를 사용했을 때 let으로 표현이 바뀌는 걸까? 라고 추측했지만, 스위프트와는 별개로 SIL 언어가 그렇게 설계되어 있다고 합니다.SIL이 Swift 소스 코드를 바이너리 코드로 빌드하는 과정 중에 어느 단계인지 알아 두면 파악하기 쉬울 것 같아, Swift 컴파일러의 처리의 흐름에 대해 조사해 보기로 했습니다.Swift 소스 코드로 바이너리 코드를 생성할 때, 컴파일러는 다음의 과정을 따라갑니다.구문분석(AST) → 의미분석 → 모듈 임포트 → SIL 생성 → SIL 정규화 → SIL 최적화 → LLVM IR 생성 → …Swift 소스 코드를 파서로 처리해서, 타입 정보가 없는 추상 구문 트리(Abstract Syntax Tree, AST)를 생성합니다. 소스 코드의 문법(예약어, 타입 체크 등등이 아닌 순수한 구문 분석입니다. 예를 들면 명사 목적어 동사의 순서가 맞는지 같은.)에 맞지 않는 부분이 배제됩니다.덧붙여 파서는 재귀 하향 파서(Recursive Descent Parser)으로 구현되어 있고, 그 코드는  lib/Parse에 있습니다.구문분석으로 생성한 AST는 의미 분석기를 통과하며, 타입 추론 등을 수행해서, 타입 정보를 포함한 완전한 형태의 AST로 변환됩니다. 이 단계에서, 소스 코드에서 의미상 맞지 않는 부분이 배제됩니다.추가로 이 규칙은 ocs/TypeChecker.rst에 언급되어 있으며, 코드는 lib/Sema에 있습니다.AST가 완성되면, 다음으로 Clang Importer에 의해 Clang module이 포함되어, 여기에서 Objective-C나 C api가 Swift의 규칙에 맞는 형태로 사용할 수 있습니다.다만, 앞의 의미분석의 단계에서, 외부 모듈에 규정되어 있는 메소드 등을 토대로 해서 타입 체크를 하는 것으로 보입니다. 그러니 이 단계에서 처음으로 모듈이 관여하는 것도 아닙니다. 이 부분은 잘 이해하지 못하고 있습니다.이 코드는 lib/ClangImporter에 있습니다.여기부터, 이 글의 테마인 SIL을 생성하는 최초의 단계가 될 것 같습니다. SIL 생성기에 의해 AST로부터 Raw SIL이 생성됩니다. SIL에서는 Swift의 var 변수는, 엄격한 정적 단일 배정 방식이 아닌, 변경이 가능한 메모리 영역으로서 표현되는 것 같습니다.덧붙여 구현은 lib/SILGen에 있는 것 같습니다.SIL을 작성했다고 완료된 것은 아니고, 계속해서 정당성의 검증을 행하고, 마지막으로 Canonical SIL이 생성되는 것 같습니다. 이에 의해, 말하자면 “변수에 값을 넣지 않은 채 사용하려고 한다”와 같은 작은 실수를 보정해서, Swift 코드로서 엄격함이 보증되는 것 같습니다.덧붙여 구현은 lib/SILOptimizer/Mandatory에서 수행하는 것 같습니다.그리고, 정규화된 Canonical SIL을 사용해서, SIL 코드를 최적화가 이루어지는 것 같습니다. 구체적으로는 예를 들어 ARC나 가상 메소드의 호출, 제네릭 언저리의 최적화를 도모하는 것 같습니다.덧붙여서, 이 부근의 구현은 lib/SILOptimizer/Analysis, lib/SILOptimizer/ARC, lib/SILOptimizer/LoopTransforms, lib/SILOptimizer/Transforms에서 수행하는것 같습니다.이렇게 해서 조정이 마무리된 Swift 코드가 IR 생성기를 통해서 LLVM IR로 변환되어, LLVM의 세계로의 다리가 놓인 것 같습니다.덧붙여서 구현은 lib/IRGen에서 수행하는 것 같습니다.또한, 이런 처리 과정은 어느 정도 단계별로 살펴볼 수 있어, Swift 컴파일러 swiftc에 다음의 옵션을 넣는 것으로 지정한 단계까지 처리한 결과를 텍스트로 확인할 수 있습니다.그렇다면 시험 삼아 다음의 Swift 코드의 처리 과정을 출력해보겠습니다.code1예를 들어 구문분석한 결과를 보고 싶을 때는, 이 코드를 test.swift라고 하는 이름으로 저장하고 다음과 같이 swiftc 명령어를 실행해서 확인할 수 있습니다.먼저 -dump-parse 옵션을 추가해, 타입 정보가 없는 AST를 출력하면, 다음과 같이 됩니다.모르는 키워드가 잔뜩 나와서 읽기가 상당히 주저됩니다만, 그래도 진득하게 살펴보면 뭔가 본 기억이 있는 단어가 여기저기 보이는 것을 알 수 있습니다. 일단 구조마다 괄호로 둘러 쌓여있고, 자식 요소는 괄호 안에 인덴트를 포함하고 있는 모양입니다.Swift 소스 코드를 문법의 규칙에 따라 의미가 있는 부분만을 잘라 내어, 거기서부터 문법적으로 어떤 역할에 해당하는지를 예를 들어 var_decl 같은 식별자에 태그를 붙여, 그 외의 필요한듯한 정보와 함께 괄호로 묶고 있다고 생각하시면 어느 정도 읽을 수 있게 될 거라 생각합니다.관련해서 이 단계에서는 문법상의 오류만 검출되는 것 같습니다.문법의 오류중에는 예를 들어 private와 public을 동시에 지정했다던가 하는 것도 포함합니다만, 이건 분명 의미를 분석했다기보다는, 무엇의 뒤에 무엇이 와야 하는지에 대한 규칙에 맞지 않는 것이 검출된다는 느낌입니다.이때, 함수를 호출하는 곳에서는 (unresolved_decl_ref_expr type=’' name=arc4random_uniform specialized=no)라고 표기하고 있습니다.세세한 의미까지는 모르겠습니다만, 이 단계에서는 아직 미해결(unresolved)인 상태, 함수명은 있지만, 애초에 존재하는지도 포함하여 “알지 못한다”라는 것을 알 수 있습니다. 실제로 아예 적당한 함수명을 지정해도, 이 단계에서는 에러를 검출하지 않습니다.이 단계에서 출력에 타입 정보가 등장한다고 해도, 어디까지나 기호에 지나지 않는 모양입니다.예를 들어, 변수 선언에서 타입을 지정한 경우는 그 타입 정보가 (type_ident (component id=’UInt32’ bind=none)) 라고 나타납니다만, 이것은 어디까지나 “타입 식별자가 있어야 하는 장소에 UInt32라고 쓰여 있다” 정도에 지나지 않습니다. 게다가, 타입 추론을 돕는 타입 명시라고 한다면, 여기에서는 as NSString 입니다만, 이 단계에서는 불필요한 데다, 애초에 정보로서 포함하지 않는 것 같습니다.계속해서 -dump-ast 옵션을 지정해서, 타입 정보까지 포함해서 완성하는 AST까지 진행해보겠습니다.이 단계에서 갑자기 코드가 많아져서, 저도 모르게 보는 것을 그만두고 싶어집니다만, 구조상으로는 앞의 -dump-parse의 경우와 크게 달라지지는 않았기 때문에, 그렇게 생각하며 기분을 차분하게 한다면 계속 살펴볼 수 있을 것입니다.어째서 여기까지 많아진 이유는, 바로 전의 단계에서 <null type>으로 되어 있던 type의 위치에 구체적인 타입 정보가 포함되었기 때문에, 소스 코드의 해당 지점에 관련한 정보가 추가된 것이 길어진 요인입니다. 이에 의해, 얼핏 봐서는 알아보기 힘들게 되었지만, 반대로 어디가 어떻게 해석되었는지가 확실히 쉬워졌습니다.이 단계에서, 작성하지 않는 타입이 추론되어서, 앞의 단계에서는 <null type>으로 지정되어 있던 type이 모두 타입이 명확하게 정해져 있습니다. 함수나 메소드등에 대해서도, 그것이 어떤 타입의 인수를 받는지 어떤 타입을 반환하는지를 고려해서 타입 정보가 지정되어 있습니다. 아울러서, 그 함수가 어떤 namespace에 속해 있는지에 대해서도 decl에서 확인이 가능합니다함수나 타입의 정보가 조사되기 때문에, 함수가 정의되어 있는지, 대입이나 인수에 넘기는 등에서 제대로 적절한 타입을 사용하고 있는지 등이 체크됩니다. 여기에 부정합이 발생할 때는 에러로 통지됩니다.덧붙여서 이 단계에서는, AST의 어느 부분이, 어느 소스 파일의 어디에 해당하는지나, 함수 등이 어떤 namespace에 정의되어있는지 등의 정보가 location과 range로 나타나고 있습니다.그 정보가 너무 길어서 코드의 양이 지나치게 길어진 것처럼 보이지만, 오히려 파일의 이름과 행 번호로 목적하는 것을 찾을 수 있기 때문에 찾기 쉽게 되어 있습니다. 물론, 코드 양이 많은 만큼, 전체 구조를 파악한다는 것에서는 가독성이 떨어지기 때문에, 구조만 보고 싶다면 -dump-parse를 사용하는 것이 좋을지도 모릅니다.이 단계에서 상수 let에 값을 2회 대입하는 문제도 검출합니다.타입 체크가 거기까지 판단에 관여하는 것도 신기하지만, “값을 넣을 수 있는 상황” 같은 인식하는 방법은 하고 있는 것 같은 느낌이어서, 혹시 그에 관계되어 완전한 AST를 만들 수 없었다고 하는 결론에 도달하지도 모릅니다.다음으로 SIL로의 변환을 살펴보겠습니다. 여기부터 착 하고 인상이 변하는 건, 드디어 Swift Intermediate Language의 세계에 들어갔기 때문에, 지금까지의 Swift 소스 코드와는 다른 관점에서 코드가 만들어집니다. 여기부터, 어쩐지 읽을 수가 없게 되었습니다.코드의 양도 2435줄(역주: -emit-silgen 옵션으로 raw sil을 생성해보니 191줄이 나오니 뭔지 하는 생각이 듭니다.)로 크게 늘어, 여기에 모든 코드를 발췌하는 것은 어렵기 때문에, 중간을 모두 생략해서 기록하고 있습니다.어찌 됐건, 먼저의 구문이 바뀐 느낌입니다만, Swift 언어와 Swift Intermediate Language는 다른 언어이기 때문에, 새로운 언어를 하나 더 기억하는 기분으로 바라보는 편이 대하기 쉬울 것 같습니다. 무엇보다 양측 모두가 Swift의 세계를 이루고 있다는 것에는 변함이 없기에, Swift에 대한 지식이 깊어진다면 조금씩 더 나아질 것 같습니다.다만, 뭔가 (머리가) 잘 돌아가지 않으니 이걸 조금이라도 더 읽을 수 있게 하는 것이 저 자신의 이번 목표입니다.여기서는 단순한 Swift의 타입 정보만이 아닌 그것을 어떤 방식으로 메모리에 배치하는 지나, 메모리 관리의 조작이라던가 하는 세밀한 부분도 코드에 표현하고 있는 인상입니다.또, 이 Swift Intermediate Language의 단계에서도, 원래의 소스 코드의 어느 부분이 작성된 부분인지가 loc에 포함되어 있기 때문에, 원래의 코드의 어느 부분에 대응하고 있는지 알 수 있을 것 같습니다. 다만, 상당히 코드가 자세하게 기재되어 있는 것인지, Swift의 엄밀한 동작을 알고 있지 않으면 소스 코드의 장소가 기록되어 있다고 해도, “어째서 거기에 그 intermediate code가 있을까?” 같은 느낌이 될 거 같습니다.거꾸로 말하면, 자세한 동작을 읽어 해석할 수 없을 때 SIL에 의지하면 보이지 않던 작은 동작을 알 수 있을 것 같습니다.그런데, 생각하지 않았습니다만, 타입 체크를 완료한 AST로부터 Raw SIL을 만드는 단계에서 새로 발생한 에러는 뭐가 있을까요. 확실히 무언가 있었던 기분이 듭니다만, 잊어버렸습니다.구체적으로 어째서 에러가 되었는지 안다면, 무엇을 하고 있는지를 구체적으로 상상하기 쉬울 터이니, 혹시 뭔가 알고 계신 분이 있다면 알려주시기 바랍니다.하나 더, 정규화가 완료된 SIL이 있습니다. 비록 2종류가 있다고 해도 “어느 쪽도 SIL 언어이고, 정규화로 그다지 변하지 않겠지”라고 생각하고 있었습니다만, 자 하고 살펴보면, 코드의 양이 4188줄까지 늘어난 모양입니다.무엇보다 스코프 같은 것이 형성되어 있거나, 가상 테이블 같은 것이 정의되어 있거나, 상상 이상으로 늘어나 있습니다. 무엇보다, 임포트한 기능에 관련된 정보도 포함된 것 같이 보여서, 생각한 것보다 많은 것을 하고 있는 것 같습니다.덧붙여서 이 코드가 Raw SIL인지 Canonical SIL 인지는, 가장 최초의 줄에 있는 sil_stage를 확인하면 알 수 있습니다.이 단계에서 일어나고 있는 일에 대해서는 Guaranteed Optimization and Diagnostic Passes에 있습니다만, 지식이 부족해 무엇을 하고 있는지까지는 이해할 수 없었습니다.어쨌거나, 함수의 인라인화 같은 것도 이 단계에서 일어나는 것 같으니, 원래의 Raw SIL에 나름의 다양한 가공이 일어나고 있는 인상입니다.그 외에도, 이 단계에서 변수 let이나 var를 초기화하지 않은 채로 사용한 경우를 에러로 검출하는 것 같습니다.예를 들어 128을 초과하는 정수 리터럴을 Int8로 캐스팅할 때에 오버 플로우를 검출하는 것도 이 단계로 들어가면서부터 입니다.이것으로 일단 막연하지만 SIL의 입구 부근까지 살펴볼 수 있었기에, 가능하면 이 대로 SIL 문법구조나 명령 셋 같은 것도 살펴보고 싶었지만, 안타깝게도 시간이 부족했습니다.명령 셋도 꽤 수가 많은 것 같아서, 일단 SIL을 정말 알아야 할 필요가 있어야 진행이 수월할 거 같습니다. 그렇게 천천히 알아가보도록 하겠습니다.",http://woowabros.github.io/swift/2018/03/18/translation-SIL-for-the-moment-before-entry.html,woowabros,,NULL,2018-03-18
쿠버네티스를 이용해 테스팅 환경 구현해보기,"실제로 서비스에 도입해보기 전에 쿠버네티스를 유용하게 사용해 볼 수 있는 방법 중에 하나가 아닐까.이 글은 앞으로 우리가 관리하는 서비스(배민찬)의 아키텍처가 컨테이너 기반의 마이크로 서비스를 지향할 것으로 결정한 후 이를 위해 우선 아키텍처를 테스팅 환경으로 구현하여 실제로 서비스에 도입하기 전에 충분한 기간을 가지고 사용경험을 쌓는 것을 목적으로 쿠버네티스로 테스팅 환경을 구축하면서 겪었던 여러 상황들을 정리해본 글이다. 쿠버네티스의 구조와 그 리소스(Pod, Service, Deployment, ETC…)등은 그것만으로도 책 한 권은 가벼운 주제라 생각되니 그에 대한 설명을 할 수는 없지만 전체적인 테스팅 환경의 구조와 작업을 진행하면서 막혔던 부분, 주의해야 했던 부분을 짤막하게 언급하는 식으로 작성하였다.일단 쿠버네티스 리소스를 올리려면 클러스터를 만들어야 한다. AWS에서 클러스터를 구축을 하는 데에는 kops를 사용하였다. 공식 사이트의 가이드에도 AWS에서 클러스터를 올리는 방법 중 하나로 설명이 되어있으며 비교적 손쉽게 클러스터를 생성할 수 있기 때문이다. kops가 요구하는 AWS 권한을 가진 계정으로 awscli를 사용할 수 있는 상황이라면  가이드를 따라서 손쉽게 클러스터를 만들어낼 수 있다. 생성할 클러스터의 구조는 다음과 같다.시작은 작은 규모로 t2.medium 마스터 1대, 미니언 2대로 구성하도록 하였다. 마스터 노드의 수는 Raft 알고리즘의 특성상 홀수로 유지하는 것이 좋은데 두 개의 마스터노드는 한 개만 못한 결과를 초래할 수 있기 때문이다(둘 중 하나만 다운돼도 둘 다 다운되는 효과가 나오는 기적). 마스터, 미니언 노드는 private 서브넷에 생성되며 private 서브넷에 있는 노드(EC2 인스턴스)에 접속하려면 Bastion 노드를 통해야 한다. 위의 구조를 가지는 클러스터를 생성하는 명령어는 다음과 같다. 자세한 파라미터 목록은 kops create cluster 문서를 참조하자.클러스터를 만드는 것은 가이드대로 하면 간단한 일이지만 클러스터를 생성하면 클러스터에 사용되는 VPC 가 생성되는데, 다른 VPC와의 피어링 등의 이슈가 있어 VPC와 서브넷의 CIDR 값을 수동으로 지정해야 한다면 kops update cluster --yes 명령어를 사용하여 최종적으로 클러스터를 생성하기 전에 kops edit cluster 명령어를 사용하면 에디터가 열리고 VPC와 Subnet 의 CIDR을 수정할 수 있다. 이미 클러스터를 생성했는데 이를 변경해야 한다면 차라리 kops delete cluster 명령어로 클러스터 자체를 삭제하고 새로 만드는 게 더 빠르다.수정 내역을 저장한 후 kops update cluster --yes 명령어를 사용하여 클러스터를 생성했다면 이제 Pod(이하 팟)에 사용할 도커 이미지를 준비한다.클러스터 환경이 준비되었다면 Pod에 사용될 도커 이미지를 만들어야 한다.  테스팅 환경을 구성하기 위해선 4개의 컨테이너가 필요했는데, 이 컨테이너들은 다음과 같은 관계를 지닌다.필자는 로컬에서 도커 이미지를 빌드하여 ECR 에 푸쉬한 후 클러스터에서 사용하였다. kops를 통해 AWS상에 클러스터를 만들었다면 동일한 계정의 ECR에 올린 도커 이미지는 별도의 imagePullSecret 이 없어도 가져다 쓸 수 있다.이미지가 준비되었다면 이제 쿠버네티스 리소스를 만든다. 다음과 같은 구조로 구현하였다. 참고로 그림에 있는 팟들은 전부 Deployment 리소스가 관리하고 있다고 생각하면 된다.테스트를 구성하는 팟에는 한 개의 컨테이너만 배포되어있지만 팟에는 여러 개의 컨테이너를 한 번에 배포하여 사용할 수 있다. 나중에 젠킨스를 통한 빌드 작업에서 하나의 팟에 여러 컨테이너를 실행하여 사용하는 것을 볼 수 있을 것이다.필자가 구현할 테스팅 환경은 https 프로토콜을 사용하기 위해 로드밸런서가 생성하는 ELB가 AWS ACM 인증서를 사용하도록 해야 했는데, 이것은 로드밸런서 설정에 다음 어노테이션을 추가하여 해결하였다. 해당 어노테이션을 추가하면 AWS 콘솔에서 ACM이 ELB에 사용되는 것을 확인할 수 있을 것이다.테스팅 환경을 구성할 쿠버네티스 리소스의 yaml 설정 파일들이 파일이 준비되었다면 kubectrl create -f 명령어를 통해 쿠버네티스 리소스들을 클러스터에 모두 생성하고 테스트를 해 본다. 감사하게도 QA 팀 분들이 테스트를 해주셔서 테스팅 환경이 구현되었음을 확인할 수 있었다.이제 쿠버네티스 클러스터에 테스팅 환경이 올라갔다. 이제 이 테스팅 환경에서 테스트를 진행할 수 있을 것 같은데, 현재는 하나의 테스팅 환경을 올렸을 뿐이다. 그리고 현재는 테스팅 환경을 하나 만드는 것만 해도 다음과 같은 절차가 필요하다.만약 이것을 자동화하지 않으면 클러스터에 테스팅 환경을 매번 배포하는 것부터가 큰일이니 젠킨스를 사용하여 자동화를 해야 할 것 같다. 이 과정을 젠킨스에서 처리하면 다음과 같은 절차를 거치게 될 것이다.그런데 막상 배포 자동화를 하려고 하니 문제가 있었다. 여러 명이 각자의 테스팅 환경을 사용할 수 있도록 각 테스팅 환경은 alpha-cluster01~05-www.testdomain.com와 같은 서로 다른 도메인을 사용해야 했는데, 이를 위해서는 쿠버네티스 리소스와 함께 nginx 의 설정 파일, Java의 환경변수, PHP 설정 파일을 변경해야 했고 이를 젠킨스에서 처리하도록 하는 것은 매우 비효율적이었기 때문이다.Helm은 쿠버네티스 패키지 매니저인데, helm 사용하면 클러스터에 Tiller라는 팟이 설치되고, 이 팟을 통해 Helm 패키지(이하 차트) 내부에 정의한 쿠버네티스 리소스들을 클러스터에 올릴 수 있다. 흥미로운 점은 Helm에서 템플릿 기능을 지원한다는 것이다. 이 템플릿 기능을 사용하여 도메인에 따라 설정을 변경해 줘야 하는 작업을 해결할 수 있었다.{{ .Release.Name }}  은 helm을 사용하여 차트를 배포할 때 --name 파라미터로 지정한 값으로 치환되어 들어갈 것이다. (지정하지 않으면 도커 컨테이너처럼 임의의 자동으로 생성된 이름이 할당된다.) 그럼 이제 도메인의 변경이 필요한 파일들을  도커 이미지에 넣지 않고 ConfigMap(이하 컨피그맵)에 넣은 후에, 차트 배포 시 치환된 컨피그맵을 팟의 컨테이너에 파일로 마운트 하거나 환경변수로 설정한다이때 --name 으로 넘기는 파라미터는 생성된 테스팅 환경에 접속할 때 사용할 도메인의 접두사 (ex: alpha-cluster01~05)를 사용하는데 이는 alpha-cluster01-www.testdomain.com와 같은 도메인 설정을 동적으로 하고 차트를 통해 배포된 테스팅 환경에서 생성된 ClusterIP 서비스를 각 테스팅 환경끼리 구분하기 위해서 사용된다.그리고 helm에서는 차트의 의존성을 관리할 수 있는데, 이 기능을 사용하면 테스팅 환경에 필요한 각 서비스별로 차트를 일일이 배포하지 않고, 이들을 포함하는 하나의 임의의 패키지를 만들어 한번에 배포할 수 있다(사실 차트를 동일한 이름으로 중복해서 배포할 수 없으므로 테스팅 환경을 구성하는 서비스들의 차트들이 동일한 도메인을 사용하려면 하나의 차트로써 배포될 필요도 있었다). helm 차트로 구성한 테스팅 환경의 구조는 다음과 같다.이제 helm install 명령어로 alpha 차트를 배포할 때 --name 에 설정한 도메인 접두사가 각 서비스의 컨피그맵에 치환되어 들어갈 것이다.  차트가 준비되었으면 helm install 명령어를 통해 클러스터에 차트를 배포하는 것이 가능하다. helm install 명령어에서는 템플릿에서 사용할 값을 파라미터로 넘겨줄 수도 있는데, 이 기능은  잠시 후에 jenkins 파이프라인 예시에서 helm 차트를 배포할 때 파이프라인을 통해 빌드된 도커 이미지의 태그를 제공하는 용도로 사용하였다.helm 차트를 만듦으로써 테스팅 환경의 배포는 helm install 명령어 하나로 처리할 수 있게 되었고 도메인 변경에 따른 문제도 해결되었다. 그럼 이제 배포 자동화를 위해 젠킨스 파이프 라인을 구성해보도록 하겠다.helm을 이용하면 helm 차트 저장소에 등록되어 있는 차트들을 내려받아 사용할 수 있는데 이중에는 젠킨스 차트도 있으며 이 차트는 이미 쿠버네티스 클러스터 관련 설정이 이미 되어있어 매우 유용하다. (쿠버네티스 젠킨스 플러그인이 이미 설치되어있고 해당 젠킨스 차트가 올라가있는 클러스터에 관한 설정이 이미 되어있는 상태), 그리고 설치되면서 자동으로 PersistentVolume(이하 PV) 리소스를 생성하여 젠킨스 관련 데이터를  영속적으로 저장하기 때문에 노드 자체가 날아가는 상황에서도 별도의 설정 없이 젠킨스의 데이터를 유지할 수 있는 장점이 있다.참고로 본인은 이 패키지의 존재를 모르고 오피셜 젠킨스 이미지를 사용하던 중 노드가 다운되는 일이 벌어졌는데 PV을 사용하지 않아 거의 다 완성한 파이프라인을 날려먹는 참사를 당하게 되었다. 별도로 PV를 마운트 하거나 hostPath를 마운트 한 경로에 데이터를 저장하지 않으면 팟의 삭제와 함께 모든 데이터가 날아가니 팟에서 만들어지는 소중한 데이터는 꼭 영속적인 저장소에 저장하도록 하자.그리고 젠킨스의 쿠버네티스 플러그인은 젠킨스 슬레이브 팟을 클러스터에 배포하여 빌드를 지원하는데, 흥미롭게도 이 슬레이브 팟에는 여러 컨테이너를 추가할 수 있어 이를 빌드 과정에서 사용할 수 있다. 그렇다면 굳이 마스터 젠킨스에 빌드를 위한 기능을 설치하지 않고 빌드 전용 컨테이너를 만들어 빌드 작업 자체의 휴대성을 높일 수도 있을 것이다. 이는 php, composer, npm 등 빌드에 필요한 게 많았던 레거시 웹 서비스 빌드에 특히 유용했다.그리고 젠킨스 슬레이브 팟에서 kubectl, helm 컨테이너를 사용 시에는 별도의 설정 없이 클러스터를 사용할 수 있어 kubectl의 config 파일을 설정할 필요도 없어진다. 이제 이를 사용하는 파이프라인을 작성해보자.빌드를 실행했는데 빌드가 계속 대기 중이고 시작되지 않는다면 젠킨스 설정에서 Executor 설정을 확인하자. 필자의 경우 젠킨스 차트를 통해 설치 했을 때 기본값이 0으로 저장되어 있어 영문도 모르고 한동안 기약 없는 대기를 타야 했다.이것으로 배포 과정이 자동화되었다. 이제 차트가 배포되었을 때 생성된 Router 로드밸런서의 ELB에 Route53을 통해 도메인을 연결해주기만 하면 테스팅 환경을 사용할 수 있게 되었다. 그럼 이제 클러스터가 기존의 5개의 테스팅 환경(기존에 테스팅 환경을 5개까지 사용했으므로)을 감당해낼 수 있는지 확인해보자.안타깝게도 다수의 테스팅 환경을 배포하는 과정에서 미니언 노드 하나가 다운되었는데, 원인을 알아본 결과 팟의 리소스 사용량에 제한을 두지 않아서 이런 문제가 발생한 것으로 보인다. 특히 CPU 보다 메모리 사용량을 제한하지 않을 경우 치명적인데 최악의 경우 OOM(Out of Memory) 이 발생하여 노드가 재시작될 수도 있다. 팟의 리소스 제한을 설정하면 노드에 충분한 리소스가 남아있지 않을 경우 팟이 아예 배포되지 않으므로 노드의 OOM을 방지할 수 있을 것이다. 일단 팟의 리소스 제한을 설정하기 위해 어떤 팟이 얼마나 리소스를 사용하는지 모니터링을 해보자Heapster를 설치하면 kubectl top (node|pod) 명령어를 사용하여 각 노드와 팟의 CPU, 메모리 사용량을 모니터링할 수 있다. Heapster만 설치해서는 명령어를 친 순간의 리소스 사용량만 모니터링할 수 있지만  지금은 이걸로 충분한 것 같다(influxDB, Grafana 플러그인을 사용하면 좀 더 상세한 모니터링이 가능하다). 그럼 명령어를 한번 실행해 보자.kubectl top pod 명령어로 팟의 리소스를 모니터 할 때는 팟이 클러스터에 올라가고 시간이 좀 지나야 한다. 금방 올린 팟의 리소스 사용량이 안 뜬다면 잠시 후에 명령어를 다시 실행해 보자.모니터링 결과 java로 만든 msa1과 Api-gateway 팟의 메모리 사용량이 상당함을 알 수 있었다. t2.medium 타입의 EC2 인스턴스를 두 미니언 노드의 가용 메모리는 8Gi인데 자바를 사용하는 팟 두 개 만으로도 1Gi가 넘는 메모리를 사용하는 셈이다. 배포에 사용되는 젠킨스 팟은 한술 더 뜨는데, 두개의 팟이 거의 2Gi 의 메모리를 사용하고 있는 상황이다. 이런 상황에서 메모리 사용량을 제한하지 않았으니 팟은 약간의 노드에 약간의 리소스만 사용 가능해도 배포되었을 것이며 시간이 지남에 따라 제한 없이 사용 메모리를 계속 늘려감으로써 노드의 OOM을 초래하게 되는 것도 무리가 아니었다. 안정적으로 다수의 테스팅 환경을 위해 팟에 리소스 제한을 설정하자.쿠버네티스에선 팟에서는 사용할 리소스를 제한할 수 있는데, 만약 제한하지 않으면 팟은 메모리를 제한 없이 사용하게 된다. 팟이 사용할 리소스 설정에는 request, limit 두 가지가 있는데 request는 해당 팟이 실행되기 위해 요구하는 리소스 사용량으로 쿠버네티스는 노드에 request 에 설정한 값 이상의 리소스가 남아있을 경우에만 팟을 노드에 배포한다. limit는 팟이 최대로 사용할 수 있는 리소스의 값이다.Deployment에서 관리하는 팟의 리소스 제한을 걸어준다. 리소스 사용량을 모니터링을 하면서 서비스가 유지되는 한도 내에서 최대한 줄여보았다. 다른 팟들의 리소스 사용량도 설정했다면. 이제 배포에 사용되는 젠킨스 슬레이브 팟의 리소스도 제한해야 하는데 마찬가지로 다음과 같이 컨테이너별로 리소스 사용량을 제한할 수 있다.이제 노드가 OOM으로 다운되는 문제가 방지되는지 다시 테스팅 환경을 5개 이상 배포해보니 클러스터가 매우 느려지고 마지막에 배포하려는 테스팅 환경이 배포되지 않는 상황이 발생하긴 하지만 노드 자체가 다운되는 현상은 발생하지 않았다. 이제 나름 안정을 찾게 된 듯하다. 그런데 리소스 사용량을 설정하다 보니 젠킨스 슬레이브 팟의 메모리 사용량 워낙 많음(1Gi 정도를 제공하지 않으면 제대로 동작하지 않았다)을 알게 되었는데, 만약 두 개의 노드에 테스팅 환경을 위한 팟이 골고루 배포된다면 어느 노드에도 젠킨스 슬레이브 팟이 배포되지 않을 가능성이 있지 않을까?사용할 수 있는 총 자원은 충분하지만 팟이 어떻게 배포되느냐에 따라 자원 소모가 큰 팟이 배포가 되지 못할 수 있다. 그렇다면 배포를 할 때 젠킨스 슬레이브 팟의 배포를 위한 자원을 확보하려면 두 개의 노드에 어떤 식으로 팟이 배포될지 제어를 할 필요가 있다.팟에 NodeAffinity를 설정하면 팟이 배포될 때 어떤 노드를 선호할지 노드에 붙은 라벨을 사용하여 설정할 수 있는데, 노드에 라벨을 붙이는 방법은 다음과 같다.kubectl label nodes <node-name> <label-key>=<label-value>이미 붙은 라벨을 수정하려면  –overwrite 옵션을 사용해야 한다.배포를 위한 젠킨스 슬레이브 팟에도 NodeAffinity를 적용하고 싶었으나 안타깝게도 지금은 nodeAffinity 설정을 지원하지 않는 것 같다. 하지만 다행스럽게도 nodeSelector는 지원하는데, nodeSelector 역시 노드에 붙은 라벨을 이용하여 팟의 배포를 제어할 수 있지만 nodeAffinity 처럼 선호하는 노드를 지정하는 것이 아니라 해당 라벨을 가진 노드에만 팟의 배포가 가능하도록 하는 방식이다. 즉 nodeSelector에 지정한 라벨을 가진 노드가 없을 때는 팟이 배포되지 못하니 주의하자.이제 테스팅 환경용 팟은 alpha-pod-affinity=service 라벨이 붙은 노드에 우선적으로 배포된 후 더 이상 배포하기 힘들 때에나 라벨이 alpha-pod-affinity=deploy 인  노드에 팟을 배포할 것이다. 그리고 젠킨스 슬레이브 팟은 alpha-pod-affinity=deploy 라벨이 붙은 노드에만 배포될 것이다.클러스터가 안정되니 이번엔 15분을 넘어가는 배포 속도가 거슬리기 시작했다. 만약 이렇게 느린 배포 과정에서 마지막 도커 이미지 빌드에 사용되는 Git 브랜치 명이라도 잘못 입력하여 빌드가 실패한다면 썩 유쾌하진 않을 것이다. 젠킨스 빌드 로그를 보면 빌드에 걸리는 속도의 주범은 gradle, composer, npm 등을 사용하여 라이브러리 의존성을 처리하는 작업인 것으로 보이는데 이런 작업들은 일반적인 상황이라면 실행 시 캐시가 남아 다음 실행 시의 실행시간이 단축되지만 현재 빌드 환경에서는 언제나 새로운 젠킨스 슬레이브 팟이 배포되기 때문에 캐시가 남지 않는 것이 엄청나게 느린 속도 빌드 속도의 주범이다. 그렇다면 helm의 jenkins 패키지처럼 PV를 마운트 하여 캐시를 영속적으로 저장한다면 빌드 속도를 개선시킬 수 있지 않을까? 일단 AWS 에서 사용할 EBS를 만들고 해당 id를 이용하여 클러스터에서 사용할 PV를 만들도록 하자.PV 와 PVC 리소스를 만들었다면 파이프라인에 persistent volume 을 설정해준다.이미 생성된 EBS의 ID 를 사용할 경우 배포될 팟과 EBS의 availability zone 은 동일해야 한다. 그렇지 않으면 팟이 배포되지 않는다. 빌드에 사용되는 EBS 는 모두 ip-10-yy-yy-yy.ap-northeast-2.compute.internal 노드와 동일한 availability zone 에 생성해두었다.EBS를 마운트 하여 사용하니 자바 서비스의 빌드 속도가 눈에 띄게 개선되었다(MSA #1 서비스의 경우는 8분 → 2분, ApiGateway 5분 → 2분으로 많이 단축되었지만 Front Web은 8분→5분 정도로 살짝 단축됨). 그리고 클러스터 상에 자원이 많을 경우 파이프라인의 parallel 문을 사용하여 java로 된 MSA #1, ApiGateway 서비스와 Front Web 서비스를 빌드하는 각각의 젠킨스 슬레이브 팟을 클러스터에 동시에 배포하여 빌드를 병렬로 진행하는 파이프라인을 추가하여 배포에 걸리는 시간을 더 단축할 수 있었다.이제 마지막으로 수동으로 해줘야 하는 작업이 남아있는데, 그것은 바로 테스팅 환경이 하나 배포될 때마다 생성된 ELB에 Route53 의 도메인을 연결하는 작업이다. 사실 도메인 연결은 귀찮긴 하지만 별것 아니지만 새로 생성된 ELB의 시큐리티 그룹을 설정해주는 것이 더 문제다. 테스팅 환경이 배포될 때마다 새로 생성된 ELB의 시큐리티 그룹을 다시 설정해주지 않으면 테스팅 환경이 외부에 노출될 수도 있을 것이다. 이제 이 문제만 해결한다면 배포는 완전 자동화를 달성할 수 있을 것이다. 이 문제는 Ingress 리소스를 사용하여 ELB를 한 개만 고정으로 사용하고 Ingress 에서 받은 요청을 호스트 값에 따라 알맞는 테스팅 환경으로 각각 포워딩하면 해결할 수 있을 것이다. Ingress 는 apache 의 virtual host 와 같은 역할을 한다고 생각하면 될 것이다. 그런데 Ingress 리소스는 쿠버네티스에서 기본으로 지원되는 것은 아니라서 사용하려면 우선 ingress addon 을 설치해줘야 한다. Ingress를 addon을 설치하면 kube-ingress 네임스페이스에  ingress-nginx 라는 로드밸런서를 만드는데, 이 로드밸런서 역시 AWS ACM인증서를 사용하기 위해서 ACM 설정을 위한 annotation을 추가해준다. (ACM인증서 사용을 위한 annotation은 이 글의 윗부분에서 찾을 수 있다) 이제 ELB는 이 로드밸런서에서만 사용할 것이다.이제 ingress 리소스를 설정하여 클러스터에 추가하자이제 ELB 는 Ingress 에 연결된 1개만 남았고  테스팅 환경을 배포하면 Ingress 를 통해 접속할 수 있어 Route53과 Security Group 을 테스팅 환경을 배포할 때마다 수정할 필요가 없어지게 되었으니 이제 배포가 자동화되었다고 할 수 있을 것 같다.이제 테스팅 환경을 배포하는 것은 자동화 하였는데, 만약 수정한 서비스는 한 개인데 테스팅 환경에 필요한 모든 리소스를 재배포해야 한다면 효율적이지 않을 것이다. 원하는 하나의 서비스만 교체하는 파이프라인을 만들어 보자. 테스트를 구성하는 서비스는 Deployment를 통해 팟을 관리하니 kubectl set image 명령어를 사용하면 지정한 Deployment에서 사용하는 팟의 도커 이미지가 수정할 수 있는데, Deployment 리소스는 사용하는 도커 이미지가 변경될 경우 팟을 변경된 이미지를 사용하도록 재배포하므로 이를 이용하여 원하는 서비스만 갱신하는 파이프라인을 만들 수 있다.이제 원하는 서비스만 빌드하여 배포하는 것이 가능해졌으니 좀 더 효율적으로 테스팅 환경을 사용하는 것이 가능할 것이다.쿠버네티스를 사용하며 경험을 쌓아보자는 생각으로 시작한 작업이었지만 실제로 테스팅 환경을 구축하면서 느낀 점은 테스팅 환경을 구성하는 데에 있어서도 편리하고 유용했다는 점이다. 쿠버네티스의 리소스들은 클러스터가  AWS든 GCE 든 상관없이 클러스터 환경이 구성되어 있다면 얼마든지 올려서 사용할 수 있으며 AWS를 다루는데 익숙하지 않은 본인의 입장에서 도커 이미지를 빌드하고 쿠버네티스 리소스를 생성하는 것으로 손쉽게 다른 서비스들을 테스팅 환경에 추가할 수 있다는 점에서 상당히 매력적이었다. 그리고 정말 잘 구성한다면 테스팅 환경을 유지하는데 드는 예산도 절약할 수 있는 가능성을 보여준다. 사용하는 AWS 인스턴스 수가 줄어드는 건 소소한 덤이라고 볼 수 있겠다.정리를 해놓고 보니 쿠버네티스 자체보다는 배포 자동화에 대한 내용이 더 많아진 것 같다. 필자는 젠킨스의 쿠버네티스 플러그인을 사용하여 파이프라인을 작성하였지만 굳이 이 플러스인 사용 없이도 얼마든지 배포를 자동화시킬 수는 있을 것이다. 하지만 젠킨스 슬레이브 팟을 클러스터에 배포하고 팟에 포함된 컨테이너를 통해 빌드를 하는 것은 나름 신선한 경험이었고 빌드를 위한 컨테이너를 별도로 만들어서 빌드 작업에 사용하는 것도 의외의 편리함을 제공하여 한번 사용해 볼 만한 가치는 있다는 느낌이 들었다.  만약 쿠버네티스에 관심이 있고 사용해보고 싶지만 실제로 적용하는데 부담이 된다면 테스팅 환경과 그 배포 환경을 쿠버네티스를 이용하여 구성해보는 것부터 비교적 가볍게 시작해보는 건 어떨까?",http://woowabros.github.io/experience/2018/03/13/k8s-test.html,woowabros,,NULL,2018-03-13
안정된 의존관계 원칙과 안정된 추상화 원칙에 대하여,"Robert C. Martin의 Agile Software Development - Principles, Patterns, and Practices 에서 SDP, SAP 를 정리해보았습니다.이 글은 기본적으로는 Java와 Spring Framework 기반(혹은 이와 유사한 계층형 방식)으로 개발하시는 개발자분들을 대상으로 합니다.개발을 하면서 어떨 때는 interface를 만들고 어떨때는 안 만드는지 혹시 규칙이 있는 것인 아닌지 궁금할 때가 있습니다.특히 Controller 패키지, Service 패키지, Repository 패키지의 기본 계층으로 개발을 할 때 많이 제기되는 문제이면서 항상 마지막엔 “정답은 취향따라”로 결론지으며 끝나는 논의 중에 “Service는 interface를 뽑아내고 구현해야하는지에 대한 고민”이 있습니다.그러다가 Robert C. Martin 의 Agile Software Development - Principles, Patterns, and Practices 에 “20장 패키지 설계의 원칙”에 나온 내용을 읽다보니 아 이부분을 통해서 interface 사용 여부를 결정하는 것도 가능하겠구나 라는 생각이들어서, 이를 제 나름대로 이해하고 정리하며, 개인 의견을 덧 붙인 것입니다. 책의 내용 요약과 제 개인 의견이 혼재되어 있으니 주의해서 봐주세요.해당 장에서 두가지 부분 Stable Dependencies Principle(안정된 의존관계 원칙)과 Stable Abstraction Principle(안정된 추상화 원칙)에 대한 정리가 이 글의 핵심입니다. Controller-Service-Repository 레이어는 비교 예제일 뿐 이 원칙들이 유일하게 적용되는 대상은 아닙니다.먼저 패키지에서 안정성이 의미하는 바를 알아보고 안정적인 패키지는 어떻게 추상적이어야 하는지 살펴보겠습니다.“20장 패키지 설계의 원칙”을 보면 Stable Depencies Principle은 간단히 “의존은 안정적인 쪽으로 향해야 한다.”라는 것을 뜻합니다.소프트웨어 설계는 정적일 수 없습니다. 유지보수를 하려면 변화는 필연적입니다. 안정된 의존 관계 원칙을 통해 쉽게 변할 수 있는 패키지를 만들 수 있습니다. 이 패키지는 변화할 것을 예상하고 있습니다. 이렇게 쉽게 바뀔 것이라고 예상되는 패키지들은 바뀌기 어려운 패키지의 의존 대상이 되어서는 안됩니다.쉽게 바뀔 수 있는 모듈에 무언가가 의존하기 시작하면 금세 이 모듈은 변경하기 어렵게 됩니다. 클래스 다이어그램을 그릴 때 불안정한 것을 위로 안정적인 것을 아래로 두는 습관을 가지면 그 방향이 바뀌었을 때 문제를 알기 쉽습니다.소프트웨어 패키지를 변경하기 힘들도록 만드는 한 가지 확실한 방법은 바로 다른 많은 소프트웨어 패키지가 그 패키지에 의존하게 만드는 것입니다. 의존해 오는 패키지들이 많은 패키지는 변경한 내용이 의존하는 모두를 만족시키려면 매우 많은 일이 필요하므로 매우 안정적이라고 말합니다.안정성은 패키지에 의존하는 수와 패키지가 의존하는 수를 통해 측정할 수 있습니다.불안정성 = 패키지 외부 클래스에 의존하는 패키지 내부 클래스의 수 / (이 패키지에 의존하는 외부 클래스의 수 + 패키지 외부 클래스에 의존하는 패키지 내부 클래스의 수)불안정성이 1 이면 이 패키지에 의존하는 다른 패키지가 없다는 의미 입니다. 이는 최고로 책임을 지지 않고 의존적이며 불안정합니다. 불안정성이 0 이면 이 패키지는 책임을 지며 독립적이며 안정적입니다. 이 패키지에 의존하는 다른 요소가 많기 때문에 함부로 변경하기 어려우며 다른 것에 의존하지 않으므로 자신의 의존성에 의해 변경될 가능성도 적습니다.안정된 의존관계 원칙에 따르면 어떤 패키지의 불안정성 측정값은 그 패키지가 의존하는 다른 패키지들의 불안정성 값들보다 반드시 커야 합니다(즉, 의존 관계의 방향으로 불안정성 측정값이 줄어들어야 합니다).자 이제 생각해 봅시다.Controller 는 일반적으로 Service와 Repository에 의존합니다. 하지만 일반적으로 Controller 코드를 사용하는 다른 코드는 존재하지 않습니다.Controller가 10개가 있고 이들 모두 Service, Repository에 의존하지만 어느 것도 Controller에 의존하지 않는다고 했을 때Controller의 불안정성 = 10 / (0 + 10) = 1 이 됩니다. 최고로 불안정하게 됩니다.이제 Service를 보면 Repository에 의존하는 Service가 10개가 있고, 이 Service들에 20개의 Controller들이 의존한다고 하면Service의 불안정성 = 10 / (20 + 10) = 0.333 이 됩니다. 약간 안정적입니다.이제 Repository를 보면 Repository 자체는 우리가 직접 만든 다른 계층에 의존하지 않고(0) 이 Repository에 의존하는 Service들과 Controller들이 20개가 있다면Repository의 불안정성 = 0 / (20 + 0) = 0 이 됩니다. 최고로 안정적이게 됩니다.즉, 의존간계의 방향으로 Controller (1) -> Service (0.333) -> Repository (0) 불안정성 값이 줄어들게 됩니다.이것을 보면 안정된 의존 관계원칙으로 봤을 때 Repository는 절대로 Service나 Controller에 의존하면 안 됨을 알 수 있습니다. 마찬가지로 Service도 Controller에 있는 코드를 호출해서는 안됩니다. 그렇다면 이런 안정적인 설계가 필요한 코드는 설계의 유연성이 떨어지게 됩니다. 안정적이면서도 설계의 유연성을 높일 수 있는 방법은 무엇일까요?바로 추상 클래스(abstract class)입니다.패키지는 자신이 안정적인 만큼 추상적이기도 해야 한다.안정된 추상화 원칙은 안정적인 패키지는 그 안정성 때문에 확장이 불가능하지 않도록 추상적이기도 해야하며, 거꾸로 이 원칙에 따르면 불안정한 패키지는 구체적이어야 하는데, 그 불안정성이 그 패키지 안의 구체적인 코드가 쉽게 변경될 수 있도록 허용하기 때문입니다.따라서 어떤 패키지가 안정적이라면 확장할 수 있도록 추상 클래스들로 구성되어야 하며, 확장이 가능한 안정적인 패키지는 유연하며 따라서 설계를 지나치게 제약하지 않아야 합니다.안정된 의존 관계 원칙은 의존관계의 방향이 안정성의 증가 방향과 같아야 한다고 말하고, 안정된 추상화 원칙은 안정성이란 추상성을 내포한다고 말하기 때문에 따라서 의존 관계는 추상성의 방향으로 흘러야 합니다.이를 간단히 말하면추상성 = 패키지 안에 들어있는 추상 클래스 수(하나 이상의 순수한 인터페이스를 가지고 있으며 인스턴스화 할 수 없는 클래스) / 패키지 안에 들어있는 클래스 수추상성은 0부터 1로 나올 수 있으며 0은 패키지에 추상 클래스가 하나도 없다는 뜻이고 1은 패키지에 추상 클래스 밖에 없다는 뜻입니다.추상성과 안정성의 그래프를 위와 같이 그려볼 수 있습니다.모든 클래스가 “(0,1) 안정적, 추상적” 위치나 혹은 “(1,0) 불안정, 구체적” 위치에 올 수는 없습니다. 여기서 가강 좋은 것은 위 그래프에서 “주계열” 부분에 위치하도록 코드를 만드는 것입니다.그에 앞서 “쓸모없는 지역”과 “고통의 지역”은 무조건 배제하는 것이 좋습니다.(0,0) 안정적이고 구체적인 영역에 패키지가 있다고 해보면 추상적이지 않기 때문에 확장하기 어려운데 안정적이라서 변경하기도 함듭니다. 잘 설계된 패키지는 (0, 0) 위치에 오기 어렵습니다. 이 부분을 “고통의 지역”이라고 부릅니다.하지만 고통의 지역에 있을 수 밖에 없는 경우도 있습니다. 데이터 베이스 스키마는 매우 구체적인데 이에 의존하는 코드도 무척이나 많은 안정적인 것입니다. 데이터베이스 스키마 변경이 고통스러운 이유중의 하나입니다.그 외에 String 관련 클래스들이 있습니다. String 관련 클래스들은 매우 안정적으로 다른 수많은 코드가 의존하고 있는데 매우 구체적인 코드입니다. 하지만 문자열 코드는 변경의 가능성이 매우 적기 때문에 별로 해가 되지 않습니다.여기서 봤을 때 정말 어쩔 수 없는 경우와, 변경 가능성이 0에 가까운 문자열, 유틸리티성 코드가 아니면 안정적이면서 구체적으로 만드는 행위는 피해야 함을 알 수 있습니다.(1, 1) 지역은 매우 추상적이면서도 불안정합니다. 불안정하다는 것은 이에 의존하는 다른 코드가 없음을 나타냅니다. 그런데 추상적이라는 것은 인터페이스를 만들고 구현했다고 보면 됩니다.바로 Controller를 만들 때 인터페이스를 만들고 이를 구현하면 바로 이 부분 (1,1) 지역에 들어가게 됩니다. 이름 그대로 불안정한 Controller를 추상적으로 만드는 것은 매우 “쓸모 없는 행위”임을 알 수 있습니다.이와 비슷한 것으로 Spring Batch의 Tasklet 같은 것이 있겠습니다. Tasklet 인터페이스 그 자체는 Sprig Framework가 Tasklet을 인식하기 위한 인터페이스이지 Tasklet 코드를 위한 인터페이스는 아닙니다. Tasklet은 Spring에 의해서만 호출되지 개발자가 직접 호출하지 않습니다. 즉 매우 불안정한 것인데, Tasklet에 별도의 인터페이스를 또 만들어서 구현하게 하는 것은 쓸모 없는 행위 임을 알 수 있습니다.여기서 봤을 때 우리가 직접 사용하는 코드가 아닌 프레임워크에 의해 호출되는 코드는 프레임워크 규약을 따르기 위한 인터페이스를 제외하고는 별도의 인터페이스를 따로 빼서 구현할 필요가 없음을 알 수 있습니다.우리는 고통의 지역과 쓸모 없는 지역은 항상 피하려고 노력해야 합니다. 물론 절대로 피할 수 없는 경우도 있습니다.가장 바람직한 패키지는 주계열의 양끝 (0, 1) 안정적이고 추상적인 위치와 (1, 0)불안정하고 구체적인 위치이지만 대부분의 코드는 그 외 어딘가에 존재합니다. 그 중에서도 주계열이라고 표시된 지역에 있는 패키지는 “안정성에 비해 너무 추상적”이지도 않고, “추상성에 비해 너무 불안정적”이지도 않습니다. 즉, 쓸모 없지도 않고 특별히 고통스럽지도 않습니다. 자신이 추상적인 정도만큼 의존의 대상이 되며, 자신이 구체적인 정도만큼 다른 패키지에 의존합니다. 패키지를 주계열쪽에 위치하게 설계하는 것이 좋습니다.주계열로 부터의 거리는 다음과 같이 측정합니다.거리 = |추상성  + 불안정성 - 1|이 결과는 절대값이므로 항상 0~1사이만 나오며, 거리가 0인 패키지는 주계열 바로 위에 있음을 의미합니다. 1은 가장 멀리 떨어져 있음을 뜻합니다.이 주계열로 부터의 거리를 측정함으로써 예외적인 패키지들을 판변해 내고 이들을 조사해 보는 것이 좋습니다.여기부터는 순전히 제 개인 의견만 기술합니다.위에서 말한 Controller를 계산해보면 위에서 Controller의 불안정성을 1(불안정적)이라고 했고, Controller에 대해 전혀 인터페이스를 만들지 않을 것이므로 추상성은 0이 됩니다. 따라서,Controller의 주계열로부터의 거리 = |Controller의 추상성 0 + Controller의 불안정성 1 - 1| = 00은 주계열 바로 위를 뜻하므로 좋습니다.다시 위에서 말한 Repository를 계산해보면 위에서 Repository의 불안정성을 0(안정적)이라 했고, Repository는 항상 인터페이스를 구현하도록 했으므로 추상성은 1이 됩니다. 따라서,Repository의 주계열로부터의 거리 = |Repository의 추상성 1 + Repository의 불안정성 0 - 1| = 0마찬가지로 0은 주계열 바로 위를 뜻하므로 좋습니다.그렇다면 Service는 어떨까요? 바로 상황에 따라 조사를 해봐야 한다는 의미가 됩니다.해당 서비스의 안정성과 추상성을 측정해보면서 주계열에 가까운지를 지속적으로 살펴보면 됩니다. 하지만 몇가지 예를 살펴보도록 하겠습니다.대체로 우리가 웹서비스를 만들 때 Email 발송은 매우 많이 하게 됩니다. 최초의 시작은 SMTP 서버에 의존하겠지만 나중에는 DB에 메일 내용을 넣고 배치작업으로 메일을 보내거나 아니면 MQ를 통해 메일 내용을 전달하고 다른 프로그램에서 실제 메일 발송을 하게 하는 경우도 있는등 변동성이 매우 큰 것이 Email 발송입니다.EmailService의 불안정성 = 패키지 외부 클래스에 의존하는 패키지 내부 클래스의 수(SMTP 의존 1) / (이 패키지에 의존하는 외부 클래스의 수 100여개의 이메일 호출 + 패키지 외부 클래스에 의존하는 패키지 내부 클래스의 수 SMTP 의존 1) = 1 / (100 + 1) = 0.009불안정성 0.009라는 것은 정말 매우 안정적임을 의미합니다.매우 안정적인데 추상성이 0이라면주계열로부터의 거리 = |추상성 0 + 불안정성 0.009 - 1| = |-0.991| = 0.991주계열로부터의 거리 0.991는 거의 1에 가깝다는 뜻으로 매우 멉니다. 문제가 있지요.따라서 추상성을 1로 높이는 것이 좋습니다. 즉, 인터페이스를 구현해야 합니다.EmailService를 인터페이스로 구현했다면 추상성이 1이 되어|1 + 0.009 - 1| = 0.009주계열로부터의 거리 0.009는 주계열에 매우 가깝다는 의미이므로 매우 좋습니다.Repository 5개를 호출해 그 결과를 조합해서 다른 결과를 도출하고, Controller 한 개에서만 사용되는 Service가 있다고 할 때 이를 일단 BusinessService라고 해보지요.BusinessService의 불안정성 = 패키지 외부 클래스에 의존하는 패키지 내부 클래스의 수 Repository 의존 5 / (이 패키지에 의존하는 외부 클래스의 수 1개의 컨트롤러가 호출 + 패키지 외부 클래스에 의존하는 패키지 내부 클래스의 수 Repository 의존 5) = 5 / (1 + 5) = 0.83불안정성 0.83은 매우 불안정함을 뜻합니다.이 매우 불안정한 클래스를 추상적으로 만드는 것은 계산해보지 않아도 크게 의미가 없어 보입니다.하지만 상황은 변하게 마련입니다. 시간이 지남에 따라 안정성이 변하고 그에 따라 필요한 추상성도 변할 수 있습니다.그리고 원칙적으로 이 계산은 클래스 단위 보다는 패키지 단위입니다.어떤 패키지 군에 속하느냐에 따라 어떤 Service는 추상적이어야 할 수도 있고 구체적이어야 할 수도 있습니다.이 책에서는 추상 클래스란 하나 이상의 순수한 인터페이스를 인스턴스화 할 수 없는 가진 클래스라고 합니다.하지만 저는 여기에 또다른 한가지 규칙이 더 내포돼 있다고 생각합니다.“인터페이스의 메소드 시그너쳐에 구현에 대한 정보가 없어야 한다” 라는 규칙입니다.다시 EmailService로 돌아가서 아무리 EmailService 인터페이스를 만들고 그 구현을 EmailSerivceSmtpImpl 클래스로 만들었다해도 메소드 시그너쳐가 다음과 같다면 무의미합니다.위 코드를 보면 인터페이스 메소드 시그너처에 String smtpHost, String username, String password가 포함돼 있습니다. 이 파라미터들은 Email 발송을 SMTP로 구현한다고 가정할 때만 의미 있는 값들입니다.인터페이스에서 그 구현이 SMTP 서버를 통해서 이메일을 발송해야 한다고 제약하고 있는 것입니다.실제 이메일을 보내는 측에서는 그 구현이 SMTP이건 MQ로 다른 EMail 전송 서버에 쏴주건 DB에 메일 발송 관련 정보를 저장하건 상관이 없습니다. 호출자측에서 중요한 것은 그 뒤에 있는 발송자 이메일, 수신자 이메일, 제목, 내용 이것 뿐입니다.따라서 Email을 발송하는게 목적인 인터페이스의 메소드 시그너쳐는 아래와 같이 구현의 상세에 대한 정보를 가지고 있어서는 안 됩니다.일단 두가지로 구분해 볼 수 있어보입니다.Email 발송, Push, SMS 발송, Logging 등등 인프라성 코드는 거의 불안정성이 0에 가깝습니다(안정적). 호출자는 매우 많은데 그 자신이 의존하는 것은 별로 많지 않은 경우가 많습니다. 그러면서도 그 구현체는 시스템의 성장에 따라 바뀌기 쉽습니다(Email의 경우 SMTP → DB → MQ). 안정성이 높으면 변경 대응을 위해 추상적이어야 합니다.따라서 인프라성 Service는 거의 무조건 interface를 구현해야 하며, 위에서 제가 말한 추상성의 의미 - 인터페이스의 메소드 시그너처에 구현에 구현의 상세를 포함하지 말 것 -을 지켜야 합니다.Repository Layer도 마찬가지 입니다. 저는 과거에 “세상에 DB를 바꿀일이 뭐가 있다고 Repository를 인터페이스로 만들어?”라고 생각했었습니다. 하지만 지속적으로 성장하는 서비스를 맡아하면서 여러번 DB를 다른 DB 시스템 혹은 NoSQL 등으로 변경합니다. 그 뿐만 아니라 Persistence Framework도 바뀔 수 있습니다. 저는 얼마전까지 iBatis를 사용하던 프로젝트들을 JPA, QueryDSL, jOOQ 기반으로 변경하는 작업을 하기도 하였습니다. 이렇게 안정성이 높으면서 그 변경도 잦을 수 있는 Repository는 철저하게 추상적으로 만들기를 권합니다.비즈니스 로직 서비스는 상황을 지켜봐야 할 것으로 생각됩니다. 처음부터 무작정 인터페이스를 만들면 복잡도만 높고 개발 효율은 떨어질 수 있습니다(쓸모없는 지역).비즈니스의 성장에 따라 고통스러운 순간이 오거나 혹은 측정에 의해 인터페이스로 분리하는 작업을 해도 될 것 같습니다.밥 아저씨(Robert C. Martin)는 다음과 같이 이 장을 마무리하십니다.“측정값은 신이 아니다. 그것은 단지 임의로 만든 어떤 기준에 따라 측정해본 값일 뿐이다. 이 장에서 선택한 기준이 특정한 애플리케이션에만 적합하고, 다른 것에는 적합하지 않은 일도 분명히 일어날 수 있다.”또한 이 글은 간략화를 위해 Controller, Service, Repository 계층을 빗대어 예로 들었지만, 코드 계층에 이 세가지만 있는 것은 결코 아닙니다. 기본적으로는 interface를 만드느냐 안마드느냐는  Controller/Service/Repository 계층화 개발과는 별개의 문제입니다.또한 interface 구현의 필요성을 여기 나온 수식으로만 판단해서는 안 됩니다. 의존성 역전 원칙 등에 따라서 다각도로 고민이 필요합니다.그리고 이 책의 내용은 기본적으로 패키지를 기준으로 하지만 저는 클래스 단위와 패키지 단위를 혼재해서 사용하였습니다. 책의 내용 전체를 정리한 것이 아닙니다. 빠진 부분도 있으니 책을 읽어주세요.긴 글 읽어주셔서 감사합니다.",http://woowabros.github.io/study/2018/03/05/sdp-sap.html,woowabros,,NULL,2018-03-05
Spock으로 테스트코드를 짜보자,"Spock으로 테스트코드를 작성한 경험을 공유합니다.안녕하세요! 우아한형제들 배달의민족/배민라이더스 주문시스템 팀 정용준입니다.여러분은 어떻게 테스트 코드를 작성하고 계신가요? 일정 지키기도 힘든데 무슨 테스트코드냐 하시는 분들도 계신가요? 저도 아직 테스트코드를 작성하는 것이 습관화되어 있지 않고 익숙하지 않습니다. TDD는 먼 나라 이야기이고 무엇을 어떻게 테스트해야 하는지를 정하기조차 어렵기도 하지만 조금씩 빈도를 늘려가고 있습니다.저는 JUnit 기반의 테스트코드를 작성해왔습니다. 그러던 중 사내에서 Spock의 사용빈도가 높아지면서 좋은 점을 어필해주시는 주변 동료들 덕분에 Spock을 알게 되었는데요. 그동안 테스트코드를 작성하기도 쉽지 않을뿐더러 새로운 배움에 대한 부담감에 (일정도 빡빡하고 하다 보니) Spock에 도전해 볼 마음이 들지 않았습니다. 그런데 막상 테스트를 작성하다 보니 생각보다 간단했고 아직 Spock을 잘 모르시는 분과 함께 경험을 나누면 좋겠다고 생각이 들었습니다.저도 이제 막 시작하는 단계이다 보니 부족한 점이 많습니다. 틀린 부분은 가감 없이 지적해주시고, 빈약한 내용은 열심히 공부해서 꼭 다음에 풍성히 채워오겠습니다.먼저 Spock을 사용하기 위해서 아래 두 의존성을 추가해야 합니다. (Gradle 기준)이제, Spock으로 테스트를 작성할 수가 있습니다. Spock은 Groovy를 사용합니다. 사실 Groovy를 잘 알지 못한 점도 하나의 허들이었습니다. 이번 기회에 Groovy도 같이 공부할 수 있으니 좋네요 :)(초록막대가 나오길 두근두근..)  딸랑, 3줄 작성한 건데. (좀 당황스러웠습니다. ㅎㅎ) 저는 JUnit 테스트를 작성할 때 //given //when //then을 잊지 않기 위해 테스트 템플릿을 만들어 사용하고 있습니다. 이번에도 습관적으로 주석으로 명시하고 테스트를 돌려봤습니다. (나름 잘했다고 생각하고 있었는데..) 코드 블록을 선언하지 않은 것이 테스트가 깨지는 원인이었습니다.Spock에서는 given, when, then과 같은 코드 블록을 block이라 부릅니다. block은 테스트 메소드 (feature method) 내 최소한 하나는 있어야 하고요! JUnit에서는 있어도 그만 없어도 그만이었는데 Spock에서는 필수입니다. (개인적으로는 더 좋네요!) [원본 출처] https://code.google.com/archive/p/spock/wikis/SpockBasics코드블록을 선언하고 나니 잘 수행이 되네요 :)사실, where block을 처음 보고나서 Spock을 써봐야겠다고 생각했습니다. 테스트를 하다보면 다양한 케이스를 검증해야 할 때가 많으시죠?where block을 사용하면 간단하게 해결할 수 있습니다. 처음 보는 생소한 기능이지만 코드를 따로 설명해 드리지 않아도 이해하는데 조금도 어려움이 없으실 거에요.만약, JUnit 기반의 테스트코드를 작성했다면 어땠을까요?   의미없는 중복된 코드가 여기저기 널부러져 있었을 것 같습니다.  여러분은 이런 경우 어떻게 테스트코드를 작성하시나요?그리고 테스트가 실패되는 경우 JUnit은 제일 처음 실패한 케이스만 알 수 있다면, Spock은 실패한 모든 테스트 케이스와 그 내용을 더 상세히 알려줍니다. 0보다 작은 음수가 들어왔을 때 ‘예외’가 발생하는지를 테스트 해보겠습니다.Spock에서 예외는 thrown() 메서드로 검증할 수 있습니다. thrown() 메서드는 발생한 예외를 확인할 수 있을 뿐만 아니라 객체를 반환하기 때문에 예외에 따른 메시지도 검증을 할 수 있습니다. 그리고 테스트코드를 작성한 흐름에 따라 예외를 확인할 수 있으니, 처음 코드를 본 사람이 더 쉽게 이해할 수 있을 것 같습니다 :)Spock에서 Mock 테스트도 어렵지 않습니다. 가짜 객체의 반환 값은 ‘»‘으로 설정할 수 있고 예외를 발생시키고 싶다면 아래와 같이 하시면 됩니다.Spock으로 테스트코드를 작성하는 것 생각보다 어렵지 않은 것 같습니다. 아직은 작은 단위의 기능을 검증하는 정도로 적용하고 있는데요, 기존에 JUnit으로 작성한 테스트코드를 Spock으로 구현해봐야겠습니다. 다음번에는 좀 더 깊이 있는 내용으로 찾아뵙겠습니다.",http://woowabros.github.io/study/2018/03/01/spock-test.html,woowabros,,NULL,2018-03-01
MySQL에서 'a' = 'a '가 true로 평가된다?,"DB 알못의 어떤 리서치안녕하세요 기계인간 이종립입니다. FC플랫폼개발팀에서 배민찬 백엔드를 개발하고 있습니다.DB알못인 저는 업무 중에 우연히 MySQL에서 'a' = 'a '의 결과가 1로 나오는 이상한 현상을 발견하게 되었습니다.특수한 조건에서만 발생하는 버그일까요?또는 버그가 아닌데 내가 잘못 생각하고 있는 것인지, 다른 DB에서도 같은 일이 일어나는지 궁금해졌습니다.그래서 다른 DB도 조사해보기로 했습니다.차이점을 발견할 수 있다면 알아둘 만한 정보가 될 거라는 생각도 들었고요.종합해보니 다음과 같은 결과를 얻을 수 있었습니다.제가 조사한 결과 중에서는 PostgreSQL 과 SQLite 만 'a'와 'a '를 다른 값으로 평가하는군요.여러 DB를 확인했더니 그렇게 돌아가더라 하고 끝나면 안 되겠죠?레퍼런스 문서를 찾아보기로 했습니다.MySQL 5.6 Reference Manual을 확인해보니 버그가 아닙니다.이럴 수가……. DB알못은 그저 혼란스러울 뿐입니다.혼란스럽던 차에 마침 개발실 서가에 가보니 “SQL 전문가 가이드”라는 책이 꽂혀 있습니다.표지에 “국가공인 2013 Edition” 이라 인쇄되어 있으니 일단 국가를 믿고 참고해 보도록 합니다.한참 책을 뒤지다 보니 159쪽에서 CHAR를 비교하는 일에 대한 내용을 발견할 수 있었습니다.CHAR에서는 문자열을 비교할 때 공백(BLANK)을 채워서 비교하는 방법을 사용한다. 공백 채우기 비교에서는 우선 짧은 쪽의 끝에 공백을 추가하여 2개의 데이터가 같은 길이가 되도록 한다. 그리고 앞에서부터 한 문자씩 비교한다. 그렇기 때문에 끝의 공백만 다른 문자열은 같다고 판단된다. 그에 반해 VARCHAR 유형에서는 맨 처음부터 한 문자씩 비교하고 공백도 하나의 문자로 취급하므로 끝의 공백이 다르면 다른 문자로 판단한다.오호 드디어 알겠습니다.비교하려는 두 문자열의 길이가 다른 경우, 짧은 쪽에 공백을 이어붙여 길이를 똑같이 만든 다음 비교하기 때문에 발생하는 일이었습니다.이런 식이라면 'a'와 'a  '를 비교해도 'a '와 'a '를 비교하는 것과 똑같을 수밖에 없겠네요.그런데 왜 이렇게 하는 것일까요? 그냥 길이가 다르면 FALSE 라고 하면 안 되는 이유라도 있는 것일까요?MySQL 때문에 시작한 일이었으니 일단 MySQL 레퍼런스 문서를 좀 더 찾아봤습니다.다음 문장이 눈에 띄는군요.When CHAR values are stored, they are right-padded with spaces to the specified length. When CHAR values are retrieved, trailing spaces are removed unless the PAD_CHAR_TO_FULL_LENGTH SQL mode is enabled.그리고 여기에서도 같은 문제를 언급하는 예제가 있습니다.다음과 같은 테이블도 있네요.CHAR(4) 컬럼에 'ab'를 저장하면 'ab__'처럼 된다는 말이군요. (이제부터는 가독성을 위해 공백 대신 _ 를 쓰겠습니다.)CHAR는 VARCHAR 처럼 가변 길이가 아니기 때문에, 길이를 맞추기 위해 컬럼 정의에 따라 우측에 공백이 추가되어 보관됩니다.그렇다면 CHAR(4)에 저장한 'ab'와 CHAR(6)에 저장한 'ab'를 정확히 비교하려면 두 가지 방법이 있을 것입니다.만약 이런 방법을 사용하지 않는다면 'ab__'와 'ab____'를 비교하는 셈이 됩니다.즉, 저장하기 전엔 'ab'로 똑같았던 값을 저장된 값을 가져와 비교하면 무조건 FALSE가 나오는 황당한 일이 벌어집니다.좀 이상하게 느껴지긴 해도 짧은 쪽에 PAD를 추가해 'ab____'로 바꾼 다음 비교하는 것이 납득이 갑니다.이렇게 하지 않으면 길이가 다른 모든 타입의 컬럼에 저장된 문자열을 비교하는 것이 불가능할 것입니다.FALSE만 나오게 되겠죠.짧은 쪽에 맞추기 위해 긴 쪽의 문자를 지우면 알고리즘이 지저분할 테니, 공백 PAD를 붙이는 심플한 방법 쪽을 선택했을 거라는 생각도 듭니다.CHAR 문자열을 저장하는 방식 때문에 PAD를 사용한 비교가 도입된 것이라는 추측이 드는군요.그러나 멋대로 결론 내리기 전에 먼저 문자열 저장과 비교에 대한 표준을 찾아보는 것이 순서일 것 같습니다.SQL 표준을 명시하는 SQL-92에서 space로 검색해서 하나하나 찾다 보니 234쪽에서 다음과 같은 문단을 찾을 수 있었습니다.데이터를 저장할 때의 일반 규칙 중 하나입니다.이게 한 문장이라니……. 침착하게 읽고 정리해보니 다음과 같은 내용이었습니다.만약 문자열이 정의된 길이보다 짧을 경우 오른쪽을 space로 채운다는 말이로군요. 이 방식이 표준이 맞네요.그렇다면 이번에는 비교에 대한 표준을 찾아볼 차례인 것 같습니다.위에서 조사했을 때에는 Oracle, MySQL, SQL Server 와 PostgreSQL, SQLite의 결과가 모두 같지는 않았습니다.문자열 비교에 대해 표준을 지키지 않는 DB가 있다는 말일까요?역시 SQL-92에서 comparison으로 일일이 찾아보니 208쪽에서 찾아냈습니다.찬찬히 읽어보니 다음과 같은 정보를 알 수 있었습니다.아하. 국가공인 책에 나왔던 'a' = 'a '를 'a ' = 'a '로 만들어 비교하는 방식이 표준이 맞는군요.그리고 effectively라는 표현은 아마도 비교 알고리즘의 효율성이 아니라 각기 길이가 다른 여러 타입을 비교하는 관점에서의 효율을 말하는 것 같습니다. 만약 알고리즘상의 효율이라면 PADDING을 하지 않고 그냥 왼쪽 글자부터 비교했을 테니까요.그렇다면 이제 PostgreSQL 과 SQLite 에서 'a' = 'a ' 가 FALSE로 평가되도록 구현한 이유가 궁금해지는군요.그리고 PostgreSQL이 CHAR를 저장하는 방식도 뭔가 표준과 다를 수 있다는 생각이 듭니다.그런데 아무래도 저 혼자서만 궁금증을 느낀 것은 아닌 모양입니다.운이 좋았는지 Albe Laurenz라는 분이 2013년 01월 17일에 PostgreSQL 개발자들에게 보낸 이메일을 발견할 수 있었습니다.편지의 내용을 요약하자면 다음과 같습니다. (이메일도 편지니까 편지라고 하고 싶습니다.)오 제 궁금증과 일치하는 질문이네요.그렇다면 이 편지에 대한 PostgreSQL 측의 답장도 읽어봐야 할 것 같습니다.답장을 한 사람은 컴퓨터 과학자이자 PostgreSQL 개발팀의 멤버인 Tom Lane입니다.Tom Lane의 편지의 내용을 요약하자면 다음과 같습니다.영어 실력이 딸려서 더 어렵게 느껴집니다. 그러나 적어도 표준이나 아니냐의 이분법적인 관점으로 접근하는 것이 곤란하다는 생각이 드네요.그리고 시스템의 측면에서 문자를 바라보는 시각도 제시해주는군요.아마도 이런 생각이 PostgreSQL의 비교 방식에도 영향을 준 모양입니다.그런데 아직 저장 방식과 PAD / NO PAD의 관계에 대해 아직 뚜렷하게 이해하지 못한 것 같은 느낌이 듭니다.그래서 일단 다음과 같이 간단한 테이블을 MySQL과 PostgreSQL에 하나씩 만들고 레코드 하나를 입력했습니다.참고로 vc2와 c2는 'test__'로 같은 입력값이며, 오른쪽 공백이 두 개입니다.그리고 다음과 같이 테스트를 수행해 보았습니다.테스트 1.1의 결과를 보면 MySQL과 PostgreSQL의 결과가 다릅니다.또한, 테스트1.2의 결과를 보면한편 테스트 1.3의 결과를 보면 VARCHAR는 입력값을 그대로 저장하고 있습니다.VARCHAR와 CHAR를 비교해보면 의미 있는 결과를 얻을 수 있을 것 같네요.이 테스트 결과를 보니 Tom Lane의 말이 좀 더 와닿는군요.물론 PostgreSQL은 저장할 때 오른쪽 공백을 없애고, MySQL은 저장할 때 오른쪽 공백을 추가했겠지만, 결과는 똑같습니다.다음 테스트는 VARCHAR와 타입이 정의되지 않은 CHAR의 비교입니다. 테스트 3.2를 보면테스트 3.1과 3.3은 위에서 수행했던 테스트를 다시 한 것입니다.테스트 3.2와 3.4가 공백을 이어붙이는 경우인데, MySQL에서도 이어 붙이는 경우에 대해서는 PADDING을 하지 않는군요.어쩌다보니 MySQL과 PostgreSQL의 비교로 끝이 났습니다.그러나 어느쪽이 더 표준을 잘 지키고 어느 쪽이 더 바람직하다는 결론은 아닙니다.다만, 개인적으로는 PostgreSQL이 문자열 비교에 대해 제가 갖고 있던 상식과 일치하는 느낌이라 종전보다 강한 호감을 갖게 되었습니다.개념의 혼동을 최소화할 수 있는 선택을 선호하기 때문입니다.사실 이 글은 제가 2016년 6월에 우아한형제들 사내 위키에 쓰다 만 글을 토대로 새로 작성한 것입니다.원본은 각 DB 비교하는 부분까지 있었으니 분량이 3배 이상 늘었네요.모든 테스트는 2018년 2월 25일에 다시 수행하였으며, 2016년의 DB2 테스트 결과는 삭제하였습니다.예전에 DB2를 테스트했던 웹 사이트에서 DB2를 선택하는 옵션이 사라졌기 때문입니다.대신, 2016년에 “다음에 알아보기로” 했었던 PostgreSQL의 이야기를 조사할 수 있어서 매우 기쁘고 재미있었습니다.긴 글 읽어주셔서 감사합니다.의견과 격려를 주신 최광훈님, 최윤석님, 김정환님께도 감사를 드립니다.그리고 마지막으로, 이렇게 어려운 DB를 관리해주시는 세상의 모든 DBA님들께 존경과 감사를 드립니다.EOB",http://woowabros.github.io/study/2018/02/26/mysql-char-comparison.html,woowabros,"mysql,java,php,spring",NULL,2018-02-26
AWS에서 네트워크 공격 자동차단 하기,"최근 Public cloud 시장이 활성화 되면서 많은 기업들이 Cloud 도입을 시작하고 있으며, 한국의 경우 대표적으로 Amazon Web Service(AWS)를 사용하고 있다. 그리고 한국의 Seoul region(ap-northeast2)은 2017년 12월 기준으로 AWS Global 매출 TOP 5에 포함된 만큼 폭팔적으로 사용량이 늘어나고 있다. 그러나 Legacy환경의 IDC과 너무도 다른 환경에서의 보안은 쉽지 않기때문에 본 글에서는 우아한형제들의 AWS에서 기술적인 보안 방법을 공유 하는것을 목적으로 하고, 시리즈로 연재 하고자 한다.AWS에서 네트워크 보안은 몇가지 어려움이 있는데, 그 중에서 SecurityGroup은 White-list 기반 정책만 가능하기때문에 특정 EC2로 네트워크 공격이 들어오는 경우 Black-list로 차단 할 수가 없다. 차단 하려면 윈도우 방화벽이나, iptables를 이용해야 하는데 그렇게 하려면 scale-in, out이 빈번하게 일어나는 환경에서 매번 ec2 한대씩 터미널로 접속을 해야하는 엄청난 수고를 해야한다.그래서 VPC의 subnet에 있는 NACL을 이용을 권장하며, NACL은 subnet 단위로 L4 기반 차단을 할 수가 있다.그.러.나 GuardDuty에서 탐지되는 수백개의 이벤트를 하나씩 확인해서, 공격 대상이 되고 있는 ec2들이 사용하는 subnet을 확인하고, NACL을 입력해주는것은 수백마리의 벌레들을 한마리씩 잡는것과 같다. 그정도로 많은 이벤트가 발생할까? 라는 생각을 할 수도 있는데, AWS는 AWS에서 사용되는 IP주소 목록을 Public하게 공개 해뒀고, 그 목록 안에서 사용자들에게 할당/회수를 반복적으로 하기때문에 IP주소 목록을 기반으로 많은 공격들이 들어온다.   (그나마 몇개 잡으면 다른 것들이 벌때처럼 밀려들어온다..) 나는 고민끝에 GuardDuty에서 탐지되는 네트워크 공격들의 대상 정보를 자동으로 Pasring 하고, 대상 정보를 바탕으로 NACL에 차단 Rule을 자동으로 추가 및 차단 로그를 남기고, 지정된 시간이 경과하면 자동으로 차단 해제하는 자동화된 초동 대응용 모델을 AWS API들을 이용하여 디자인하였다.    GuardDuty에서 탐지 이벤트 발생을 CloudWatch Event의 trigger 조건으로 설정해서, 이벤트가 발생하면 탐지 데이터를 특정 Lambda로 넘겨주고 Parsing 과정을 거친 다음 NACL에 차단 Rule을 추가하는 순서로 진행된다. 때문에 탐지된 데이터를 적절히 Parsing 해야, NACL에 차단 Rule을 추가/삭제를 용이 하게 할 수 있기때문에 아래와 같이, 먼저 샘플용 탐지 데이터들을 생성하여 참고하는것이 좋다.탐지 이벤트 발생과 동시에, CloudWatch Event에서 Lambda를 호출하게 되는데 Parsing 및 NACL 차단 Rule 추가시 주의해야할 사항은 아래와 같다.GuardDuty에서 탐지 이벤트가 발생되면, Lambda를 실행 하도록 trigger 설정을 CloudWatch Event에서 해줘야 하며, 모든 공격에 반응하기 보다는 serverity가 5이상의 수준에만 반응 하도록 설정 해주는것이 워크로드 증가를 줄일수 있기 때문에 권장한다.  차단된 로그들은 s3에 저장하고, 저장된 로그들을 위의 그림처럼 ElasticSearch로 가져와서 차단 추이 분석이나, 다른 AWS Account별로 공유하여 IP Black-list를 생성 할 수 있다. 나는 ElasticSearch를 이용하여 차단 로그들을 관리하고 NACL을 조절함으로써 자동차단 도입전 대비 공격 시도를 약 80% 줄였다.Public cloud는 flexibility and scalability가 최고의 장점이다. 그런데, 보안하는 입장에서는 신경 써야할것이 엄청나게 많다. 예전에는 IDC환경에서 장비들 박아놓고 관리만 하면 되었지만, 지금은 늘어났다 줄어났다도 부족해서 여기갔다 저기갔다 하는 IT자산들에 맞춰서 움직이고, 구성을 변경하고, 보안 범위를 늘였다 줄였다 해야한다.이런 환경에서 사람이 수동으로 작업 한다는것은 미친짓이다. 때문에 이런 환경에 빠르게 대응 하려면 자동화는 필수이다. Public cloud로 이전을 고려하고 있는 회사의 보안 관리자라면 이러한 Security orchestration and automation를 반드시 고민해야 할것이다.",http://woowabros.github.io/security/2018/02/23/aws-auto-security1.html,woowabros,"ruby,django,mongodb",NULL,2018-02-23
내 안의 가짜를 부수고 진짜 사용자를 만나는 방법,"9월 11일, 공식적으로 배민프레시는 배민찬으로 브랜드명을 바꿨습니다. 신선 커머스에서 반찬 플랫폼으로 변화를 시작합니다...그리고 서비스를 만드는 사람으로서 많은 고민이 시작됐습니다.다른 동료들과 배민찬, 서비스에 대해 깊은 이야기를 나누고 싶었습니다.그러나 업무 중 남는 시간을 활용해 깊이 있는 이야기를 해야 하니 아쉬움이 많았습니다. 그리고 다른 분들도 같은 고민을 하고 있다는 확신이 들었습니다. 차라리 정기적으로 서비스에 대해 얘기를 하는 시간을 가졌으면 좋겠다는 생각에 주변 기획자, 개발자, 디자이너를 모아 수다 모임을 시작하게 됐습니다.모임 시작 후, 서비스에 대해 많은 얘기를 하면서 느낀 부분은 다음과 같았습니다.모임 내에서도 저를 포함해 배민찬 서비스를 맡게 되면서 배민찬을 알게 된 분들이 많았기 때문에 배민찬을 사용하는 것에 대해 막연히 좋을 것 같다는 느낌은 있지만 반대로 공감하기 어려운 부분도 있었습니다. 서비스로 시작한 수다는 자연스럽게 사용자로 흘러갔고, 진짜 배민찬 사용자를 이해하기 위해 무엇을 할 수 있을지에 대한 토론을 하게 됐습니다. 그 결과 사용자에 대해 어떻게 더 깊게 알 수 있는지를 먼저 알아야 된다는 공감대가 만들어졌습니다.그렇게 UX 스터디를 시작하게 됐습니다.제목이 끌려 (사용자를) 생각하게 하지 마!1 란 책을 보게 됐습니다. 얇고 내용도 실용적인 거 같아서 스터디 할 책으로 선정했습니다. 수다 모임은 챕터를 하나 읽고 매주 한 번씩 점심시간에 모여 토론하는 스터디로 방향을 바꿨고 그래서 ‘수다 모임’에 ‘UX 스터디’를 붙여 UX 스터디 같은 수다 모임이 됐습니다.줄여서 ‘사생하’라고 불렀습니다사실 아직도 UX가 뭔지에 대해 정의해보라면 막연합니다. 하지만 스터디 전에 UI가 안 좋아 보이거나 사용하기 불편한 걸 UX가 좋지 않다고 말하던 것보다는 좀 더 깊은 이해가 생겨났다고 생각합니다.제가 이해한 UX란, 이해관계자 입장에서 사용자에게 가치를 전달하는 과정과 사용자 입장에서 서비스를 사용하면서 느끼는 것이 복합된 형태라고 생각합니다.UX = 사용자에게 가치를 전달하는 과정 + 사용자가 사용하면서 느끼는 것그래서 대부분의 UX 방법론은 서비스에 대해 구체화하는 방법과 서비스를 사용하는 사용자에 대해 알아가는 방법 그리고 그렇게 만들어진 서비스를 평가 및 개선하는 방법을 모두 아우르고 있습니다. UX는 서비스 전체를 포괄하는 면도 있어서 한마디로 정의하기가 어렵다고 생각합니다.따라서 UX가 좋다는 말은 “사용자를 깊게 이해하고 다른 서비스와 차별되는 특별한 가치를 잘 전달하는 것”이라 이야기할 수 있지 않을까 생각해봅니다.처음에는 이게 정말 책에서 소개하는 것처럼 꼭 필요한 것일까 하는 의문을 가졌습니다. 하지만 스터디를 해오면서 공감 가는 부분이 정말 많았으므로 사용성 평가 데모 영상을 같이 감상해봤습니다. 24분짜리 사용성 평가 데모 영상2이고, 내용은 사용자를 한 분 초대해 렌터카 웹사이트를 사용해보게끔 하는 겁니다. 이 영상을 보면서 느낀 점은 한마디로 답답하다였습니다. 웹사이트는 왜 저렇게 불편하게 만들었으며, 사용자는 왜 저렇게 잘 사용 못 하는지 답답했습니다. 만드는 사람과 사용하는 사람의 관점 차이를 생각할 수 있는 기회가 되었습니다.책에서 사용성 평가에 대해 계속 강조하는 부분은 쉽고, 누구나 할 수 있고, 심지어 셀프 평가도 가능하다는 점이었습니다.슬슬 스터디 하면서 알게 된 것을 기반으로 뭔가를 해보고 싶었기 때문에 한번 실습해보자는 의견이 모였고 책에 나온 가이드를 따라 준비를 시작했습니다.사용성 평가를 시작하기 전에 서비스에서 어떤 걸 평가하고 싶은지 먼저 정해야 합니다. 책에서 나온 가이드는 이렇습니다:서비스에서 가장 중요한 기능을 몇 가지 추린 후에, 그 기능이 포함된 시나리오를 만들고, 이를 사용성 평가할 때 사용성 평가 참가자에게 과제로 내드리는 겁니다.10분 정도 시간을 내서 배민찬에서 가장 중요한 기능에 대해 각자 다섯 가지씩 적어보기로 했습니다. 그리고 전부 취합해서 세 가지를 뽑아보니 이렇게 나왔습니다:아무래도 커머스 서비스이다 보니 어느 정도는 예상된 결과였다고 생각되지만, 한편으로는 이렇게 합을 차근차근 맞춰본 게 계속 스터디를 진행하는 동기 부여도 되지 않았을까 생각합니다.아무래도 주문하는 과정을 가장 중요하다고 생각했기 때문에 모든 시나리오에 주문하는 과정까지 포함시켰습니다. 그리고 상품 탐색 및 추천 기능에 대해서는 사용자가 마주할 만한 실제 상황을 가정해 시나리오를 작성 했습니다. 만들었던 시나리오는 다음과 같습니다:지금 생각해보면 시나리오에 아쉬운 부분이 있지만 일단 해보는 데 의의를 두자는 생각으로 두려움을 쫓으면서 계속 진행을 했습니다. 시나리오에서 가장 중요한 부분은 사용성 평가에 참여한 참가자 입장에서 공감이 되는가 같습니다. 그래서 처음에는 시나리오를 지정해드렸지만, 나중에는 시나리오 중 하나를 선택해달라고 부탁드렸습니다.사용성 평가에 대해 경험이 있던 분이 없었기 때문에 일단 1번 시나리오를 실제로 돌려보자는 생각으로 사내에 새로 오신 QA 담당자에게 사용성 평가 참여를 부탁드렸습니다. 진행 및 관찰을 하면서 느꼈던 건 “이거 조금 이상한데?” 였습니다. 당시 제가 이상하다고 느꼈던 부분을 몇 가지 꼽아보자면..첫 사용성 평가가 끝난 후, 평가를 진행하셨던 분들과 얘기를 나눠봤습니다. 다들 저와 같이 의아해하는 부분들이 많았고 이거 제대로 해봐야겠다는 생각이 들어 본격적으로 사용성 평가 진행을 원활하게 하기 위한 준비를 시작했습니다.이 부분 또한 책에 자세한 가이드가 나와 있습니다. 가이드를 참고해 사용성 평가라는 게 뭐고, 어떻게 진행되고, 참가자가 아니라 배민찬 서비스에 대해 평가하려고 한다는 것에 대해 친절하게 설명하는 대본을 작성했습니다. 첫 사용성 평가 후 받은 피드백 중에 참가자 정면에 앉아서 쳐다보면 불편하다는 얘기가 있어 정면은 제외하고 자리 선정을 했고, 책에서는 혼자서 진행할 것을 권장하지만 실제로 해보니 혼자서 진행하면서 기록을 동시에 하기가 쉽지 않아 2인 1조로 구성했습니다.책에서 대본을 작성해서 그대로 읽으라고 가이드가 나와 있습니다. 실제로 해보면 아무래도 처음 보는 분에게 사용성 평가에 대해 설명을 해야 하기 때문에 꽤 긴장됩니다. 실제로 기록자일 때 진행하시는 분을 보고 있으면 긴장해서 대사를 빠뜨리기도 합니다. 하지만 경험이 쌓이며 이런 실수는 하지 않게 되었습니다.2인 1조로 구성해 한 명은 사용성 평가 진행, 다른 한 명은 기록을 맡았습니다.두 번째 사용성 평가 이후, 가입을 위한 새로운 시나리오를 만들었습니다. 결제를 위해 새로 가입을 하는 경우를 위한 것이었습니다. 그리고 시나리오별로 어떤 부분을 주로 관찰하고 기록할지에 대해 기록자용 템플릿도 만들었습니다.참가자는 따로 연령층이나 타겟을 고려하지 않았지만, 결과적으로 다양한 연령과 환경을 가진 분들이 참여해 주셨습니다. 11월 초부터 12월 중순까지 1달 조금 넘는 기간 동안 사용성 평가에 총 12명 참가해 주셨고, 이중 회사 내부 7명, 외부 5명이었습니다.사용성 평가를 진행하면서 참가자의 음성을 녹음하고 앱 사용 화면을 녹화했습니다. 앱 화면 녹화를 위해 Appsee3를 사용했는데 트라이얼 기간이 만료돼 나중엔 음성만 녹음했습니다.영상이 남지 않는다고 해서 특별히 아쉽지는 않았습니다. 그 이유는 사용성 평가는 1년 또는 큰 업데이트가 있을 때만 한 번씩 하는 게 아니라 한 달에 한 번 정도 짧은 주기를 가지고 사용성 문제를 찾고, 찾은 부분을 고치고, 다시 사용성 평가를 진행하면서 다른 문제를 찾는 흐름을 가져야 한다고 생각하기 때문입니다.서비스는 수시로 변하기 때문에 어떻게 녹화해서 오랫동안 보관할까가 아니라 어떻게 주기적으로 할 수 있을지에 대해 고민하는 게 맞을 것 같습니다. 그리고 다른 분들과는 단순히 녹화자료를 공유하는 것으로 끝나지 않고, 직접 사용성 평가에 같이 참여할 수 있는 방안에 대해 고민해 보면 좋겠다는 생각을 가지고 있습니다.사용성 평가 후에는 시간을 내주신 것과 사용성 평가에 참여해주신 것에 대해 감사하는 의미로 운영비를 모아 커피 쿠폰을 하나씩 드렸습니다.사용성 평가를 한 분 진행하고 나면 A4 1~2장 분량의 정리 결과와 약 40분 정도 녹음한 음성 파일이 남게 됩니다. 이렇게 12명 진행을 한 결과에 대해서 스터디 시간(점심시간을 이용한 1시간)에만 취합을 하기에는 너무 오래 걸릴 것 같았습니다. 머릿속에 사용성 평가를 했던 느낌이 강하게 남아있을 때 하는 게 좋을 것 같아서 한 주만 예외적으로 매일 스터디를 진행했습니다. 그리고 어떤 툴로 정리를 하느냐도 고민이 많이 됐었는데 처음엔 마인드 맵 프로그램이나 개인 일정 관리를 위해 쓰고 있는 트렐로 그리고 팀원이 추천한 PostgreSQL(…)로 정리를 하려고 시도했지만, 아무래도 스터디 구성원이 다 같이 하기에는 어렵다는 생각이 들어 디자이너의 의견을 받아 보드에 포스트잇으로 정리를 시작했습니다.최종적으로 선택한 정리 방법은 포스트잇과 펜입니다.사용성 평가 기록 정리는 화면 위주로 했습니다. 주로 특정 화면에서 참가자의 이야기와 행동을 듣고 관찰해 기록했기 때문입니다. 이렇게 정리를 하고 보니 보드 세 개로 정리할 수 있었습니다. 정리된 보드의 크기가 꽤 크고 점심시간마다 스터디를 진행하다보니 자연스럽게 다른 팀원들도 관심을 가져 주셨습니다. 그래서 종종 물어보시면 이것도 전파할 수 있는 기회라고 생각해 왜 이걸 하게 됐는지, 어떤 결과가 나왔는지에 대해서 공유를 했습니다.이렇게 보드로 정리한 후에는 팀원뿐만 아니라 배민찬 부문 내의 다른 직군에서 일하시는 분들도 초대해 같이 얘기를 해보는 시간도 가져봤습니다. 그 전에는 얼굴만 알고 가벼운 인사만 하는 분들이었지만 실제로 배민찬을 사용하면서 나온 피드백을 가지고 얘기를 진행해보니, 서로 서비스에 대해 많은 이야기를 어렵지 않게 할 수 있었습니다. 이를 통해 서로 업무 요청을 하는 사람, 요청을 받아 개발을 하는 사람이 아니라 배민찬 서비스에 대해 같이 고민하고 더 나은 방안을 찾아가는 사람으로 서로 인식할 수 있게 된 좋은 계기가 됐다고 생각합니다.스터디 구성원 외에 팀에 공유할 때는 원래 보드를 놓고 둘러앉아 얘기하는 식으로 진행을 하려고 했습니다. 하지만 사용성 평가 자체가 생소한 분들도 많았기 때문에 사용성 평가가 뭔지부터 차근차근 밟아 가는 게 좋겠다고 생각했습니다. 그래서 사용성 평가 개념부터 결과까지 정리해 공유 준비를 시작했습니다. 장표에 사용성 평가 참가자의 의견들을 다 담을 수는 없었기 때문에 어떻게 장표를 만드는가도 도전적인 과제였습니다. 원래 12월 말에 공유하려고 했지만 결국 한 달 뒤인 1월 말에 공유할 수 있었습니다.배민찬 개발/기획팀 대상으로 공유했습니다. 그리고 위/아래 다른 체크무늬 남방입니다.솔직히 말해보자면, 개발자가 이런 걸 하는 게 맞는지 동료 개발자가 어떻게 봐줄지에 대해서도 고민이 됐던 게 사실입니다. 그래서 공유할 때도 걱정이 많이 됐었는데 다행히 현장 분위기는 매우 좋았습니다. 그리고 질문도 많이 해주셔서 더 좋은 시간이었다고 생각합니다.사용자와의 접점에 있는 개발자로서, 자주 사용자 입장에서라는 말을 하게 됩니다. 내가 말하는 사용자가 진짜 우리 서비스를 사용하는 사용자가 되려면 우리가 기술을 공부하듯이 사용자에 대해서도 많이 알려고 노력하고 공부를 해야 하지 않을까요? 내 안에 있는 어쩌면 개인의 취향이나 욕망이 반영된 가짜 사용자를 부수고, 우리 서비스를 사용하고 있는 진짜 사용자에 대해서 알아갈 수 있는 방법으로 사용성 평가는 분명히 좋은 시작점이 될 수 있을 것입니다.이 글을 작성하는 데 많은 도움을 주신 UX 스터디 같은 수다 모임의 구성원, 참여해주신 모든 참가자, 교정 및 편집을 도와주신 동료 종립님, 도연님 그리고 영감을 준 우에다 마리에, 젤다의 전설에 소소한 감사를 전합니다.이 책은 UX라는 단어가 보편적으로 사용되기 전에 나온 책입니다. 다른 UX 책과는 다르게 UX에 대한 개념이나 설명을 장황하게 풀어놓지 않고, 저자의 많은 경험을 토대로 진짜 사용자가 하는 행동을 바탕으로 보편적으로 개선해야 하는 점들을 담고 있습니다. 웹사이트 기반으로 작성된 책이지만 사용성을 개선하기 위한 많은 인사이트를 얻을 수 있었습니다. 참고로 개정판엔 모바일 앱 챕터도 추가됐습니다. ↩https://www.youtube.com/watch?v=QckIzHC99Xc ↩https://www.appsee.com/ ↩",http://woowabros.github.io/experience/2018/02/22/usability-testing-in-baeminchan.html,woowabros,,NULL,2018-02-22
Presto 쿼리 실행계획 겉핥기,"우리는 여러 가지 이유로, 여러 가지 용도에 사용하기 위해 데이터를 조회합니다. 많은 경우 SQL기반의 데이터 처리 엔진에 SQL 을 사용해서 데이터를 조회하게 됩니다. 이 때, 기본적으로 문법에 맞춰서 데이터를 조회하면 데이터가 잘못 나올 일은 극히 드뭅니다. 하지만 간혹 생각과 다른 데이터가 나온다거나, 잘 돌아가는 지를 확인하고 싶은데 쿼리가 무거울 것 같아서 무조건 돌려보기 애매하다거나, 별 것 아닌 쿼리라고 생각했는데 데이터 조회가 오래 걸리거나 하는 일이 발생합니다. 정말 어쩔 수 없는 경우도 있지만, 상당수의 경우는 쿼리를 좀 더 예쁘게 짜면 전반적인 쿼리 성능을 높일 수 있습니다. 이를 위한 작업을 흔히 ‘쿼리 튜닝’이라고 합니다.이런 쿼리 튜닝을 위해 우선적으로 선행되어야 할 작업은 쿼리가 어떻게 실행되는 지를 아는 것입니다. 대부분의 SQL처리 엔진에서는 SQL 문장을 받으면 이를 어떤 식으로 수행할 지에 대한 계획을 세우는데, 이를 ‘쿼리 실행 계획(Query Plan)’ 이라고 합니다. 그리고 대부분의 SQL처리 엔진에서는 이런 쿼리 실행 계획을 확인할 수 있습니다. 이를 확인할 때는 일반적으로 원하는 쿼리 문 앞에 EXPLAIN을 사용해서 다음과 같은 방식으로 나타냅니다.EXPLAIN query_statement그리고 이 EXPLAIN을 사용하는 방식은 Presto(프레스토)에서도 동일하게 사용 가능합니다. 하지만 프레스토의 경우 다양한 데이터 소스 위에서 동작하는 분산 처리 SQL엔진이므로 다른 데이터베이스에서의 실행 계획과 다소 다릅니다.사내에서 데이터에 접근할 때는 대부분 제플린에서 프레스토에 연결해서 사용하므로, 프레스토의 쿼리 실행 계획을 이해할 줄 알면 데이터를 조회하는 데에 큰 도움이 됩니다.하지만 GUI가 잘 되어 있는 SQL 클라이언트에 익숙해진 사람들이 보기에는 그다지 보기 좋지 않습니다(…). 또한 예전에 CLI로 SQL을 사용하던 사람들에게는 용어가 그다지 익숙하지 않아서 역시나 그다지 보기 좋지 않습니다.(예는 사내에서 사용하는 제플린+프레스토 에서의 실제 실행 결과로, 테이블 이름은 숨겼습니다.)하지만 최소한 계단 형태라도 나오는 게 어디인가 싶습니다(…). 그리고 천천히 뜯어보면 그다지 어렵지 않습니다. 특히,  프레스토의 최소한의 실행 구조와 용어를 알고 뜯어보면 DB 실행 계획 만큼 쉽습니다.프레스토의 쿼리 실행 형태는 기본적으로 다음과 같습니다.위의 내용을 기억해 두고, 앞서 예시로 든 쿼리를 살펴 보겠습니다. 위의 쿼리는 간단한 SELECT-FROM-WHERE절로 일부만 보기 위해 LIMIT 10을 사용했습니다.참 쉽죠(!!).그러면 조금 더 복잡한, 간단한 JOIN과 집계 기능 사용한 쿼리문의 실행 계획을 살펴 보도록 하겠습니다.갑자기 길어진 것 같아서 조금 현기증이 나지만 역시나 찬찬히 뜯어보면 별 차이 없습니다.역시나 하단부터 살펴봅니다.정말 별 것 없습니다.여기에 더불어, 수행 시간이나 대략 사용하는 데이터의 크기를 보고 싶으면 EXPLAIN ANALYZE  구문을 사용할 수 있습니다.여기서는 각 부분에서 사용하는 리소스(CPU, 사용 추정 행 수 등)가 표시됩니다. 데이터의 수는 추정치지만 평균 및 표준 편차도 같이 표시해 주므로 대략적인 양을 산정할 수 있습니다. 더불어 각 부분 옆에 SINGLE, SOURCE, HASH 등 앞서 설명한 각 부분에서 처리하는 방식이 같이 나와있어서 보다 상세히 작동 방식을 이해할 수 있습니다.이를 통해 얼마나 많은 데이터가 필요하고, 리소스는 얼마나 필요한 지를 어림짐작할 수 있습니다. 특히 프레스토는 데이터 소스에서 데이터를 가지고 와서 최종적으로는 메모리에 올려서 연산 처리를 하다 보니 데이터의 양을 어느 정도 추정할 수 있게 되면 메모리에 과부하가 가서 쿼리 결과가 안 나오는 사태가 발생한다든가 하는 일을 미연에 방지할 수 있습니다. 다만 이는 추정치고, 프레스토에서는 타 소스에서 데이터를 가지고 와서 자체 연산을 하는 식이다보니 정확도가 DB의 쿼리 실행계획보다는 다소 낮다는 사실을 인지하고 있어야 합니다 (특히 쿼리 실행 계획을 확인한 때와 실제 쿼리를 실행하는 때가 다르다 보면 사용 가능한 CPU 나 메모리가 다르고, 이에 따라 예상 속도가 다르고, 어떤 경우에는 실행 계획 자체가 일부 바뀌기도 합니다).기획부터 개발까지, 다양한 분야에서 점차 많은 분야에서 데이터를 활용하게 되고, 이를 위해서는 데이터를 당연히 조회하게 됩니다. 그러면서 데이터 조회에 대한 이야기도 많이 하게 되는데, 이 때 가장 많이 하는 이야기는 ‘원하는 것을 정확히 생각하고, 그 것이 어떤 데이터로 만들어져야 하는지, 그 데이터가 어떻게 구해지는 지 계속 생각하는 것’입니다.  데이터는 예민하고, 각도에 따라 모습이 너무 달라지기 때문에, 생각하지 않고 기계적으로 하다 보면 무언가를 놓치게 됩니다. 이를 위해서, 본인이 어떤 코드를 만들었고, 그 것이 어떤 형태로 데이터를 만들어서 본인에게 오게 되는지를 생각하는 것이 필요합니다. 쿼리 실행 계획을 확인하는 것은 이런 데에 정말 많은 도움이 됩니다. 특히 프레스토의 경우에는 동작 구조와 일부 형태만 알면 실행 계획은 매우 단순하므로 쉽게 이해할 수 있고, 한 번 이해하면 이후에 정말 여러 모로 유용하게 사용할 수 있을 것이라고 생각합니다.Presto 0.190 Documentation",http://woowabros.github.io/tools/2017/12/13/prestoquery.html,woowabros,"mysql,php,python,java",NULL,2017-12-13
학습에 실패한 이야기,"프로그래머에게 지속적인 학습은 기본적으로 갖춰야 할 덕목 중 하나라고 생각합니다. 문제를 해결하는 방법들은 계속 발전하고 변해가며 하나를 배우면 오히려 배울 것이 늘어나는 경험을 항상 합니다. 당장 우아한형제들의 구성원을 봐도 직급이나 연차와 상관없이 아침, 점심시간을 아껴 공부하는 모습이 낯설지 않습니다.하지만 익혀야 할 것은 무수히 많고 시간은 한정되어 있습니다. 따라서 어떤 것을 먼저 할지 우선순위를 정하고, 선택하고, 집중해야 합니다. 그것도 아주 효과적인 방법으로요.사실 저는 지난 몇 달간 비효과적인 방법으로 시간을 낭비했습니다. 이 글에서 제가 학습하고, 학습에 실패한 경험을 공유합니다.올해 초, 업으로서 프로그래밍을 시작한 지 1년쯤 될 때입니다. 개인적인 할 일, 공부할 것, 읽어보고 싶은 책들은 큐Queue에 쌓아 두고 관리 합니다.그 당시에도 여러 주제가 쌓여 있었고 큐의 전방front에는 객체지향 프로그래밍이 있었습니다. 그래서 그 능력을 향상하겠다는 목표로 본격적인 학습을 시작했습니다.너무 막연하고 두리뭉실하며 학습의 성과를 측정하기 힘든 목표였습니다.평소 책을 통한 지식 습득을 선호합니다. 주제를 정하면 그것과 관련된 여러 책을 연속해서 찾아봅니다. 역시 하던 방식대로 학습을 시작했습니다. 객체지향 프로그래밍에 관련된 책들을 찾아서 읽어 보고 책의 예제를 따라 했습니다. 유튜브 같은 곳에서 관련 강의를 찾아보기도 했습니다. 지금 생각해보면 단순히 읽고 반복하는 편안한 방식의 학습이었습니다.그렇게 한 달, 두 달, 석 달… 문득 이런 생각이 들었습니다.내가 제대로 하고 있는 건가?하지만 어떤 입력에 대해 출력이 있는 것처럼 명확한 답이 있는 주제가 아니었기에 현재 상태를 측정하기 힘들었습니다.진척도를 측정하기 힘든 학습 목표, 끝이 정해져 있지 않은 학습 과정.시간이 좀 더 흘러서는 자신도 뭘 하고 있는지 몰랐고 지루해지기 시작했습니다. 그러면서도 아직 부족 하다는 생각에 시간만 질질 끌기 시작했습니다.꽤 많은 시간을 어영부영 흘려보내다 문득 이런 생각이 들었습니다. 그러자 더 학습을 진행하는 것은 힘들었습니다. 읽던 책, 학습하던 것 모두 중단한 후 며칠을 온전히 놀았쉬었고 그 후, 효과적인 학습 방법을 찾기 시작했습니다. 그때, 의식적인 연습이 떠올랐습니다. 주변의 괜찮은 프로그래머라고 생각한 분들이 한 번씩 언급했지만, 이전에는 관심 두지 않던 키워드입니다.책 ‘1만 시간의 법칙’에 의식적인 연습이라는 표현이 등장합니다. 재능보다 노력이 중요한데 이 노력과 성실함에도 전략이 필요하다고 합니다.이를 설명하기 위해 많이 인용하는, 걷기로 역시 예를 들자면 우리는 태어나서 부모님의 도움과 많은 연습을 통해서 걸을 수 있게 됩니다. 이렇게 스스로 직립 보행을 할 수 있게 된 후 마냥 30년을 더 걷는다면 걷기 1년 차 보다 발의 피로를 줄이는 효과적인 발 디딤과 효율적인 호흡을 하며 걸을 수 있을까요? 만약 팔자걸음이 습관에 베였다면 마냥 많이 걸어서 걸음걸이가 저절로 교정 될까요?이는 걷기, 테니스 그 외의 무엇에도 적용됩니다. 만족하고 기계적으로 할만한 수준에 도달하게 되면 더 발전을 멈춥니다. 즉, 단순히 행위를 반복하는 것은 연습이 되지 않으며 실력이 늘지 않습니다. 노하우가 쌓일 뿐이죠. 자신의 약점을 고치려고 의식적으로 노력해야 합니다. 김창준 애자일 코치님의 ‘프로그래밍 어떻게 공부할 것인가’ 강의에서 업무와 놀이는 연습이 아니라고 말합니다.Work != Deliberate Practice != Play집중하고 고치고 반복하라 이 세 가지가 의식적인 연습의 핵심 키워드입니다. 의식적인 연습은 다음과 같은 특징을 가집니다.기존에 했던 방법을 돌아보면 구체적이지 못한 목표를 세우고 단순 반복적으로 읽는 학습 방식을 취했으며 성과를 측정할 방법이 마땅치 않았습니다.단순히 많은 시간을 들여 꾸준히 한다면 실력이 늘 것으로 생각했지만 의식적인 연습 방법들은 이제까지 해왔던 방법들과 조금 달랐습니다. 따라서 앞으로 의식적으로 교정하려는 것은 다음과 같습니다.결심에는 두 가지 종류가 있다고 합니다. 목표 의도Goal Intention와 실행 의도Implementation Intention입니다. 목표 의도는 “살을 빼겠다”와 같은 결심이고 실행 의도는 “매일 달리기를 해서 두 달 안에 5kg 빼겠다”와 같이 구체적인 실행방법을 포함한 결심입니다.객체지향 프로그래밍을 학습하기로 했다면 이 목표는 다시 (1) 만들고자 하는 주제를 정한 후, 그 안에서 객체들을 추출해본다. 그리고 각 객체에 책임을 할당하고 서로 협력하도록 프로그램을 작성해본다  (2) 회사 코드에 객체지향 생활체조 규칙을 적용해본다 (3) 한 달 전에 작성한 코드를 객체지향적으로 리팩토링해본다 와 같이 구체적인 실행 계획과 기간을 포함한 세부 목표로 나눠 실천할 수 있을 것입니다.책의 예제를 쉽게 따라 하기 위해 화면의 반은 코드 작성 도구, 나머지 반은 전자책을 띄워놓는 경우가 많았습니다. 하지만 이런 식의 학습법은 단순히 받아 적기, 옮겨 적기밖에 안 된다고 생각됩니다. 인출연습Retrieval Practice을 해야 합니다. 단순히 반복해서 하거나 읽는 것은 장기 기억에 비효율적입니다. 공부한 내용을 일정한 주기로 인출 혹은 회상하는 것이 기억을 강화하고 망각을 막아준다고 합니다. 따라서 책을 통해 학습한다면 한번 전체적으로 살펴본 후, 코드를 작성하는 일은 최대한 스스로 하려 합니다.한 달 또는 일정 주기로 이전에 학습했던 내용을 다시 학습해 보는 것은 장기 기억에 도움이 된다고 합니다. 이전에 풀었던 알고리즘 문제를 다시 풀어보거나 작성했던 코드를 개선해보려 합니다.많은 사람이 프로그래밍을 효과적으로 학습하기 위해서 개인 프로젝트를 많이 하라고 했습니다. 하지만 항상 주제 선정의 어려움을 겪어 선호하지 않는 방법이었습니다. 주제를 정한다 하더라도 너무 목표만 높이 잡아 계획만 세우다 끝나는 일이 다반사였습니다. 효과적인 학습 방법을 조사하며 왜 많은 사람이 이 방법을 권했는지 조금 이해하게 됐습니다.하나의 프로그램을 만드는 과정은 많은 실행 오류들을 겪게 되고 자신의 노력을 끌어내게 됩니다. 이를 바람직한 어려움Desirable Difficulties이라고 하는데 적절한 학습의 난이도는 더욱 탄탄한 학습으로 이어집니다. 또한, 이렇게 작성된 프로그램은 다른 용도로 또다시 활용될 수 있습니다. 이런 프로그램들은 언제든 바꾸고 부술 수 있는 장난감이기 때문에 새 기능을 마음대로 추가하고 다양한 방식으로 리팩토링해 볼 수 있는 놀이터play ground로 활용할 수 있습니다.앞으로 주제는 너무 거창하게 정하지 않으려 합니다. 연습을 위해 하는 프로젝트에서 너무 멋진 프로그램을 만들려고 하기보다 당장 내가 필요한 작은 프로그램으로 시작해 보는 것이 좋겠습니다.프로그래밍 학습의 피드백은 작성한 프로그램을 실행해 동작을 살펴보는 방식을 취할 수 있습니다. 하지만 이는 프로그램이 어느 정도 완성이 되어야 가능하기에 피드백이 너무 늦어질 수 있습니다. 학습에 TDDTest-Driven Development 방식을 취한다면 좀 더 작은 단위로, 좀 더 빠르게 피드백을 받을 방법이라고 생각합니다.객체지향설계나 좋은 코드에 대한 피드백은 어떻게 받을 수 있을까요? 일단 가장 쉽고 낮은 수준의 피드백은 정적분석 도구를 활용하는 것입니다. 학습을 위해 작성한 코드에도 정적 분석 도구를 적용함으로써 아주 기본적인 피드백을 받을 수 있습니다. 또 한 가지 방법은, 많이 알려진 주제를 선택하는 것입니다. 예를 들어 TDD를 연습한다면 볼링게임이나 계산기 만들기를 주제로 정하는 것입니다. 이런 주제들은 잘 알려져 다른 사람의 코드를 많이 찾을 수 있습니다. 스스로 코드를 작성해본 후, 다른 코드와 비교해보는 방법을 취할 수 있습니다.사실 가장 좋은 방법은 다른 개발자의 리뷰를 받는 것으로 생각합니다. 상대에게 너무 부담을 주지 않는 선에서 이런 부탁을 한다면 리뷰를 통해 또 다른 토론을 이끌어낼 수 있고 이런 토론들이 생각을 더 확장 시켜줄 것입니다. 스터디 모임에 참여하는 것도 좋은 방법일 수 있겠네요.글의 서두에서 지속적인 학습은 프로그래머의 기본 덕목이라고 적었습니다. 그리고 효과적인 학습을 위한 방법들을 정리해보았는데요. 한가지 놓친 것이 있었습니다. 우리는 왜 공부해야 하나요?최종 목적지가 확실해야 가끔 딴 길로 새더라도 결국 그 방향을 향해 갈 수 있을 것 같습니다. 더 나은 커리어 패스를 위해서? 돈을 많이 벌기 위해서? 배움 그 자체의 즐거움으로? 개개인의 목표는 다를 수 있고 각 목표는 존중받아야 합니다.저는 돌이켜보니 어느 순간 학습을 위한 학습을 하고 있었습니다. 뛰어난 동료들, 그럼에도 꾸준한 자기계발. 그런 분위기 속에서 어떤 목표를 위한 학습이 아니라 단지 ‘학습해야 한다!’라고 자신을 압박만 했습니다.  처음 프로그래밍을 접한 후 프로그램을 동작시키기 위해 공부해야 했습니다. 그 목표를 어느 정도 스스로 이룰 수 있게 된 후 항상 머릿속에 담고 있던 것은 ‘잘 작동하는 깔끔한 코드 (Clean code that works) ‘이고 그것을 실천하기 위해 노력하는 과정이 즐거웠습니다. 참 간결한 문장이지만 서비스는 계속해서 성장하고 있고 그만큼 늘어나는 트래픽과 트랜잭션을 처리할 수 있어야 합니다. 또, 더 높은 사업적 목표를 달성하기 위해서 소프트웨어는 계속 함께 자라나야 합니다. 그 과정에서 좋은 품질도 유지하는 일은 절대 만만치 않은 일입니다.정리하자면 저는 결국 프로그램은 잘 동작하고 코드는 사람이 이해하기 쉽도록 작성하기 위해 학습한다고 정리했고, 이 목표는 학습의 우선순위 등을 정할 때 가장 먼저 고려 될 부분이 될 것입니다.노력과 학습이 뇌를 변화시키고 지적 능력이 자신의 통제에 크게 의존한다는 점을 이해하도록 도움을 받은 사람들은 어려운 도전에 착수하고 꾸준히 버틸 가능성이 더 높다. 이들은 실패를 무능력의 표시이자 막다른 길이라고 생각하는 대신 노력의 표시이자 전환점으로 여긴다. (중략) 실패는 숙달된 상태로 가는 데 필수적인 경험이 된다.-어떻게 공부할 것인가, 헨리 뢰디거, 마크 맥대니얼, 피터 브라운 저, 김아영 역, 와이즈베리 2014학습에 실패한 이야기라는 제목으로 시작했지만 사실 스스로 실패라 생각하지는 않습니다. 이전에는 단순히 많은 시간을 들여 많이 읽는, 어쩌면 너무 편안한 학습 방법을 취해왔습니다. 지금이라도 이렇게 학습 방법에 대해 돌아보고 교정할 수 있는 시간을 가져 다행입니다.  위에 나열한 방법들은 절대적인 방법들이 아닙니다. 학습하고자 하는 주제, 개인의 성향에 따라 방법은 무궁무진할 수 있습니다. 다만 기존에 하던 방법보다 더 효율적인 방법은 없는지 고민하며 학습 전략을 나에게 맞도록 조정해 가는 것은 분명히 필요한 일이라는 생각합니다. 저와 같은 고민을 하는 분들에게 조금의 도움이라도 되길 바랍니다.",http://woowabros.github.io/experience/2017/12/11/how-to-study.html,woowabros,,NULL,2017-12-11
신선함으로 다가온 ES6 경험,"이번에 FC플랫폼개발팀에서 진행하는 프로젝트에서 ES6를 이용하면서 기존에 혼재되어있는 자바스크립트 파일들을 모듈별로 나누게 되었습니다. 처음 ES6 를 접했을 때 기존에 써왔던 자바스크립트와는 조금 다른 형식에 당황하기도 했지만 (앗 이게 뭐지? 신선한데…?) 신기하기도 했습니다. import export const…… 유용해 보이면서도 재밌어 보이는데…!처음 하면서는 모르는 부분들이 많아 꽤 어렵다고 느껴졌었는데 조금 익숙해지고 나니 이전의 코드들보다 이해하기가 쉬워진 것 같습니다.   ES6를 사용하기 위해 공식 문서들과 많은 블로그 글들을 참고하였고 (글 중간중간에 링크 달았습니다.)   이번 글에서는 ES6의 많은 feature 들 중에서 몇 가지를 설명해드리려고 합니다. 그 이전에 간단히 ECMAScript 설명을 하겠습니다.ECMAScript is a standard script language 자바스크립트 언어의 표준입니다.넷스케이프에서 자바스크립트를 지원하면서 자바스크립트가 성공하자 마이크로소프트가 J스크립트를 개발했습니다. 넷스케이프는 표준화를 위해 자바스크립트 기술 규격을 ECMA 인터내셔널에 제출하였고 ECMA-262라는 표준이 생겨났습니다. 넷스케이프의 Brendan Eich가 JavaScript를 개발하였으며 Javascript는 처음에는 Mocha 라는 이름으로 후에는 LiveScript 최종적으로 Javascript라는 이름이 됐습니다.ECMAScript 라는 이름이 이상하다고 생각할 수 있는데 그렇게 생각하는 게 전혀 이상한 일이 아닙니다. Brendan Eich도 그 이름에 대해서 언급했었습니다.“ECMAScript was always an unwanted trade name that sounds like a skin disease.” 피부병 이름 같이 들리다니..ECMA스크립트 위키ECMAScript 2015 Language SpecificationECMAScript 6 는 2015년 6월에 업데이트 되었습니다 ! ECMAScript의 6번째 에디션입니다.Class 문법을 제공합니다. constructor 메소드도 사용할 수 있고 extends를 통해서 클래스 상속도 가능합니다.const let함수는 간결해지고 코드는 짧아졌습니다.Arrow Function 은 자신만의 this를 생성하지 않습니다. 예를 들어서 예전의 방식을 보겠습니다.화살표 함수는 자신의 this가 바인드 되지 않기 때문에 함수의 스코프에서의 this 가 적용됩니다.화살표 함수 definitionsExport, Import 를 이용해 function이나 variables 들을 다른 곳에서 사용할 수 있습니다.비동기 프로세싱을 위해 사용됩니다. (Asynchronously) 가독성이 좋으며 중첩된 콜백의 단점을 완화합니다. (Callback Hell이라는 Callback 함수가 다시 Callback을 호출하고 또다시 Callback을 호출하는 코드를 읽기도 관리하기도 힘들어지는 것은 완화할 수 있습니다.)Promise의 세가지 상태그 외에도 많은 ES6 feature들이 있고 아래의 링크에서 확인하실 수 있습니다.  더 많은 ES6 featuresES6 경험기의 글에 맞게 경험을 조금 적으려 합니다.   프로젝트를 진행하며 있었던 사례 몇 가지를 예를 들어보겠습니다.기존에 체크박스에 관련된 함수의 대략적인 코드는 아래와 같았습니다. ES6를 이용해서 새롭게 바꾼 코드는 다음과 같습니다.기존의 코드보다 짧고 괄호가 많지 않아 깔끔하게 느껴지며 가독성이 좋아졌습니다. String Interpolation을 이용해서 섬세하고 깔끔하게 표현을 할 수 있게 되었습니다.기존에는 변수가 값이 변하는 것인지 변하지 않는 것인지를 알기가 어려웠습니다.새롭게 바꾼 코드에서는 변수만 봐도 나중에 바뀔 값인지 아닌지 구분하기 쉬워졌습니다.이전에 있던 또 다른 코드의 예시를 들어보겠습니다.같은 동작을 하지만 좀 더 짧은 표기법을 이용해 엄청나게 많은 변화는 아니지만 조금 더 sweet한 코드가 되었습니다.이전에의 대략적인 코드는 아래와 같았습니다. 코드를 따라가기가 쉽지 않았습니다.현재는 아래와 같은 형태로 바꿨습니다.깔끔한 코드를 보며 한결 마음이 가벼워짐을 느껴보세요 ! :)프로젝트에서 처음 써보았을 때는 기존 자바스크립트 코드의 분석과 ES6에 익숙해지기까지의 시간이 조금 걸리긴 했습니다.   하지만 프로젝트를 진행하면서 ES6에 익숙해지고 자바스크립트 파일을 모듈별로 나누게 된 이후에는 깔끔해진 코드와 그 코드들의 관리가 쉬워진 점에 대해 만족하고 있습니다. 이번에 신선함으로 저에게 다가온 ES6를 경험하며  기존의 가독성이 안 좋거나 중복되거나 불필요했던 코드들 정리도 동시에 진행하게 된 점이 좋았습니다 :) !",http://woowabros.github.io/experience/2017/12/01/es6-experience.html,woowabros,,NULL,2017-12-01
우린 Git-flow를 사용하고 있어요,"안녕하세요. 우아한형제들 배민프론트개발팀에서 안드로이드 앱 개발을 하고 있는 나동호입니다. 오늘은 저희 안드로이드 파트에서 사용하고 있는 Git 브랜치 전략을 소개하려고 합니다. ‘배달의민족 안드로이드 모바일 파트에서 이렇게 브랜치를 관리하고 있구나’ 정도로 봐주시면 좋을 것 같습니다. 2016년 1월, Github로 소스코드를 이전하면서 Github-flow를 사용하기 시작했습니다. 그러다 2017년 6월부터 Git-flow로 브랜치 전략을 바꾸게 되었습니다. 오늘 할 이야기는 저희가 브랜치 전략을 왜 바꾸게 되었는지 그리고 어떻게 브랜치를 관리하고 있는지 이야기를 하려고 합니다. 기존의 배달의민족 앱의 개발 프로세스는 ‘기획-디자인-개발-QA-출시’ 순서의 흐름으로 차근차근 흘러갔고 3주 주기마다 앱을 출시했습니다. 그 일을 하는 안드로이드 앱 개발자 인원은 보통 2~3명이였습니다.회사에서는 지속적으로 개발자를 채용했고 어느새 배달의민족 안드로이드 앱 개발자가 5명으로 늘어났습니다. 기획, 디자인, 서버 등 많은 사람들과 흐름을 맞춰야하기 때문에 이 5명이 모두 이번 버전에 포함될 기능을 개발하는 것은 비효율적이였습니다. (무엇보다 iOS 개발자가 부족합니다..) 작업에 따라 개발 기간이 3주 이상이 필요한 작업들이 많아지기 시작한 이유도 있었습니다. 그래서 기존의 개발 프로세스에서 약간의 변화가 생겼습니다.새롭게 바뀐 개발 프로세스는 이렇습니다. 5명은 우선순위에 따라 나열된 작업 중 우선순위가 높은 작업부터 하나씩 선택하여 작업을 나눠 갖습니다. 그리고 이번 버전에 포함될 필수 작업과 함께 다음에 언젠가는 배포될 작업들을 병렬로 진행합니다. 병렬로 처리하던 작업들이 완료가 되면 가까운 배포 주기에 포함시켜 출시합니다. 저희는 이렇게 바뀐 개발 프로세스를 가장 잘 반영할 수 있는 모델이 Git-flow라고 생각했고 안드로이드 개발자들 역시 Git을 사용하는 데 어려움이 없어 브랜치 전략을 바꿔도 큰 걸림돌은 없을 것으로 판단했습니다. 먼저 현재 Git Repository 구성부터 살펴보겠습니다. Repository는 Upstream Remote Repository(이하 Upstream Repository), Origin Remote Repository(이하 Origin Repository), Local Repository 이렇게 3부분으로 구성됩니다. Upstream Repository는 개발자들이 공유하는 저장소로 최신 소스코드가 저장되어 있는 원격 저장소입니다. Origin Repository는 Upstream Repository를 Fork한 원격 개인 저장소입니다. Local Repository는 내 컴퓨터에 저장되어 있는 개인 저장소입니다.위 그림은 Git Repository 구성과 워크플로우를 설명하고 있습니다. Local Repository에서 작업을 완료한 한 후 작업 브랜치을 Origin Repository에 push합니다. 그리고 Github에서 Origin Repository에 push한 브랜치를 Upstream Repository로 merge하는 Pull Request를 생성하고 코드리뷰를 거친 후 merge 합니다. 다시 새로운 작업을 할 때 Local Repository에서 Upstream Repository를 pull 합니다.이런 워크플로우를 두는 데에는 한 가지 이유가 있었습니다. 그 이유는 개발자들의 실험정신(?)을 펼치기 위해서였습니다. 모두가 공유하고 있는 Repository에서 실험하기에는 위험이 있다고 생각했고, Forked한 Repository를 두면 부담 없이 원하는 실험들을 해볼 수 있다고 생각했습니다. 무엇보다 이런 구조로 가져갔을 때 개발자가 해야 할 작업들이 중앙집중식 워크플로우보다 일이 늘거나 크게 복잡해지지도 않았습니다. 저희는 작업을 할 때 지켜야 할 몇 가지 약속이 있습니다.Git-flow를 사용했을 때 작업을 어떻게 하는지 살펴보기 전에 먼저 Git-flow에 대해서 간단히 살펴보겠습니다.  Git-flow에는 5가지 종류의 브랜치가 존재합니다. 항상 유지되는 메인 브랜치들(master, develop)과 일정 기간 동안만 유지되는 보조 브랜치들(feature, release, hotfix)이 있습니다.  Git-flow를 설명하는 그림 중 이만한 그림은 없는 것 같습니다.    위 그림을 일반적인 개발 흐름으로 살펴보겠습니다. 처음에는 master와 develop 브랜치가 존재합니다. 물론 develop 브랜치는 master에서부터 시작된 브랜치입니다. develop 브랜치에서는 상시로 버그를 수정한 커밋들이 추가됩니다. 새로운 기능 추가 작업이 있는 경우 develop 브랜치에서 feature 브랜치를 생성합니다. feature 브랜치는 언제나 develop 브랜치에서부터 시작하게 됩니다. 기능 추가 작업이 완료되었다면 feature 브랜치는 develop 브랜치로 merge 됩니다. develop에 이번 버전에 포함되는 모든 기능이 merge 되었다면 QA를 하기 위해 develop 브랜치에서부터 release 브랜치를 생성합니다. QA를 진행하면서 발생한 버그들은 release 브랜치에 수정됩니다. QA를 무사히 통과했다면 release 브랜치를 master와 develop 브랜치로 merge 합니다. 마지막으로 출시된 master 브랜치에서 버전 태그를 추가합니다.좀 더 자세한 설명을 보시려면 ‘A successful Git branching model’로 가시면 보실 수 있습니다.이제는 저희가 실제로 어떻게 작업하는지 알아보겠습니다.아래의 Repository와 Branch는 앞으로 설명을 할 때 나오기 때문에 알아 두시고 가면 한결 수월하게 보실 수 있을 거라고 생각합니다.Github-flow에서 Git-flow로 변경됐지만 하나의 티켓을 처리하는 방법은 이전과 비슷합니다. 다만 티켓을 처리하는 개발자는 Github-flow를 하고 있을 때와는 다르게 관리되는 브랜치들이 늘어남에 따라 어느 브랜치에서 작업을 해야 하는지 항상 주의해야 합니다.앞서 ‘작업을 할 때 지켜야 할 서로 간의 약속’에서 ‘하나의 티켓은 되도록 하나의 커밋으로 한다’라고 했습니다. 그래서 기능을 구현하기 전에 여러 개의 티켓으로 작업을 먼저 나누게 됩니다. 나눠진 작업 티켓 중 ‘로그인 레이아웃 생성’이라는 티켓이 있고 이 티켓을 처리한다고 가정하고 살펴보겠습니다.(feature-user)]$ git fetch upstream  (feature-user)]$ git checkout -b bfm-100_login_layout --track upstream/feature-user(bfm-100_login_layout)]$ git commit -m “BFM-100 로그인 화면 레이아웃 생성”(bfm-100_login_layout)]$ git rebase -i HEAD~2(bfm-100_login_layout)]$ git pull --rebase upstream feature-user(bfm-100_login_layout)]$ git push origin bfm-100_login_layout위의 절차에서 4, 5번의 작업을 수행하는 이유는 커밋 그래프를 단순하게 가져가고 의미 있는 커밋들로 관리하기 위해서입니다.4번 작업을 예로 들면, ‘BFM-100 로그인 화면 레이아웃 생성’ 작업을 할 때 로그인 화면의 레이아웃을 생성한 커밋 하나와, view의 약간의 간격을 조정한 커밋 하나, 그리고 view의 id를 변경한 커밋 하나, 이렇게 3개의 커밋으로 분리된 상태입니다. 이 3개의 커밋이 그 의미를 나눌 필요가 없거나 코드리뷰를 도와주지도 못한다면 커밋을 분리하는 것은 불필요하다고 판단하고 하나의 커밋으로 합치게 됩니다. 물론 항상 하나의 커밋으로 합쳐야만하는 것은 아닙니다. 하나의 티켓에 대한 작업이라도 커밋이 분리되어 있는 게 낫다고 생각이 든다면 2개 이상의 커밋으로 나눌 수도 있습니다. 그러나 대부분은 티켓을 더 작게 나누지 못한 경우일 가능성이 높습니다.5번 작업도 예를 들어보면, 동료와 같이 같은 기능을 개발하면 하나의 feature 브랜치에 커밋을 하게 됩니다. 서로 같은 커밋에서 시작했다가 feature 브랜치에 하나씩 merge 되기도 하고 얽히고설켜서 merge 되기도 합니다. 그러면 커밋 그래프가 복잡해지고 이력 확인을 할 때도 어렵게 됩니다. 그래서 커밋을 순차적으로 만들기 위해서 작업한 커밋이 feature의 최신 상태에서 시작하도록 rebase를 수행합니다.아래 그래프를 보시면 rebase를 했을 때 그래프가 얼마나 단순해지는지 볼 수 있습니다.작업을 할 때 브랜치의 수명은 되도록 짧게 가져가는 게 좋지만, feature 브랜치에서 기능을 완료하는데 해야 할 작업들이 많아서 오래 걸리는 경우 들이 있습니다. 그러다 보면 develop에 추가된 기능들이 필요한 경우가 종종 생기게 됩니다. 그럴 때는 feature 브랜치에 develop의 변경사항들을 가져와야 합니다.(feature-user)]$ git fetch upstream  (feature-user)]$ git merge --no-ff upstream/develop(feature-user)]$ git push upstream feature-user드디어 feature-user 브랜치에서 작업하던 기능이 완료되었습니다. 이젠 feature 브랜치를 이번 출시 버전에 포함시키기 위해서 develop에 merge 해야 합니다.(develop)]$ git fetch upstream  (develop)]$ git merge --no-ff upstream/feature-user(develop)]$ git push upstream develop이번 버전에 포함되어야 할 기능들이 모두 완료되었습니다. 이제부터 출시 담당자가 해야 할 일이 많습니다. 출시 담당자는 QA를 시작하기 위해 먼저 release 브랜치를 생성하고 upstream에 push하여 release 브랜치를 공유합니다.(develop)]$ git fetch upstream  (develop)]$ git checkout -b release-1.0.0 --track upstream/develop(release-1.0.0)]$ git push upstream release-1.0.0개발을 완료한 후 QA 중 버그가 발생하지 않으면 좋겠지만 항상 생각지 못한 예외 상황들이 발생하게 됩니다. 예외 상황이 발생할 때마다 버그 티켓이 하나씩 생성되는데 이 티켓들을 모두 해결해야만 앱을 출시할 수 있습니다.  버그 티켓들도 티켓이기 때문에 ‘1. 티켓 처리하기’와 같은 방법으로 처리합니다.(release-1.0.0)]$ git checkout -b bfm-101_bug_login_id_max_length(bfm-101_bug_login_id_max_length)]$ git commit -m “BFM-101 로그인 아이디 길이 제한 버그 수정”(bfm-101_bug_login_id_max_length)]$ git push origin bfm-101_bug_login_id_max_length발생하는 버그들을 모두 수정했다면 이젠 출시를 준비할 때입니다. release 브랜치를 master 브랜치와 develop 브랜치에 merge하고 마지막으로 master 브랜치에서 버전 태그를 달아줍니다.(release-1.0.0)]$ git pull upstream release-1.0.0(release-1.0.0)]$ git checkout develop  (develop)]$ git pull upstream develop  (develop)]$ git merge --no-ff release-1.0.0(develop)]$ git push upstream develop(develop)]$ git checkout master  (master)]$ git pull upstream master  (master)]$ git merge --no-ff release-1.0.0(master)]$ git tag 1.0.0(master)]$ git push upstream master 1.0.0 이것으로 출시 담당자의 브랜치 관리는 끝이 나고, 앱을 스토어에 출시합니다. (hotfix는 없는걸로..)Github-flow일 때보다 늘어난 브랜치들을 관리 해야 하는 부담은 늘었지만 전보다 일관되게 여러 상황들을 대처할 수 있는 것 같습니다. 물론 Git-flow 가이드대로 항상 흘러가지만은 않았습니다. release 브랜치를 시작했는데 기능이 추가돼야 하는 경우도 있고, 때로는 feature들이 많아서 완료된 feature들만 먼저 release에 포함해서 QA를 우선 시작하는 경우도 있었습니다. 현재는 Git-flow를 그대로 따라 하고 있지만 이런 시행착오를 겪으면서 우리에게 맞는 브랜치 전략으로 발전할 거라고 믿고 있습니다. 읽어주신 분 모두 자신의 상황에 맞는 브랜치 전략을 선택하실 수 있기를 바라겠습니다. 감사합니다.",http://woowabros.github.io/experience/2017/10/30/baemin-mobile-git-branch-strategy.html,woowabros,,NULL,2017-10-30
코딩테스트 연기 건 사과 드립니다.,"10월 21일 오후 2시에 진행 예정이었던, 신입공채 1차 코딩테스트가 원활하게 진행되지 못하고 연기하게 된 점 사과 드립니다.우아한형제들은 코딩테스트를 위하여 Codility라는 서비스를 이용하고 있습니다. 이번 신입공채에 굉장히 많은 분들이 지원하셨는데, 이 분들이 동시에 테스트를 진행하게 되면서 Codility 서비스가 그 부하를 감당하지 못하는 일이 발생하였습니다. Codility 쪽에 저희 쪽의 지원자 수를 알리고, 이번 테스트를 위해 별도의 얘기를 진행하였으나, 그 부분에 대한 대비가 충분히 안 되었던 것으로 보입니다.Codility 서비스에 부하가 생기면서, 어떤 분들은 테스트를 위한 링크는 받았으나 60분을 기다리라는 메시지를 보신 분도 있고, 어떤 분들은 Codility 자체가 원활하게 동작하지 않으면서 테스트 메일을 못 받으신 분들도 발생하였습니다.상황을 지켜 보고 Codility 와 연락을 취하여도 단시간 내에 해결하기는 어렵다는 판단에, 2시 15분에 오늘 코딩 테스트를 중단하기로 결정하였습니다. 그리고 2시 28분에 문자메시지를 통해서 금일 코딩 테스트 연기 사실을 발송하였고, 2시 40분부터 수신자 그룹 별로 좀 더 상세한 메일 안내를 발송하였습니다.이 과정에서, 많은 분들이 테스트 링크를 받지 못한 불안한 마음에 메일로 문의 주셨는데요. 오늘 상황이 몇 분의 문제가 아니라 응시한 대부분의 분들이 겪은 상황이다보니 보내 주신 메일에 각각 회신을 드리지 못하고 전체적인 공지를 준비하고 발송하느라, 지원자 분들 입장에서는 빠르게 회신을 받지 못하여 불안하고 답답하셨을 것 같아 더욱 죄송스럽습니다.토요일 오후에 코딩 테스트를 준비하느라 미리 시간도 비우고 이런 저런 준비도 많이 하셨을텐데, 코딩테스트가 원활하게 진행되지 않아서 몇 십 분의 시간 동안 안타깝고 마음 졸이는 상황이 만들어지게 된 점, 정말 죄송합니다.이미 공지 드린 바와 같이, 이번 코딩테스트는 차주 토요일로 예정되어 있던 2차 테스트 기간에 시행하도록 하겠습니다. 그리고, 차주에 진행되는 테스트는 오늘과 같은 일이 일어나지 않도록 코딩테스트를 제공하는 서비스 자체에 대한 검토와 더불어, 미리 철저한 부하 테스트를 통해서 이런 일이 발생하지 않도록 철저하게 대비하도록 하겠습니다.우아한형제들 신입공채에 관심 갖고 지원해 주셔서 정말 감사 드리고요. 감사한 만큼이나 오늘의 불미스러운 상황에 대해 아쉽고 죄송한 마음이 무척 큽니다.저희가 좀 더 철저하게 준비하고, 지원하시는 분들이 채용 전형 과정에서 어려움을 겪지 않도록 해 드렸어야 했는데, 저희가 많이 부족했습니다. 빠르게 개선하여, 다시 이런 불편함을 겪지 않도록 노력하겠습니다.죄송하고, 또 감사합니다.우아한형제들 CTO 김범준 드림",http://woowabros.github.io/woowabros/2017/10/21/apologize.html,woowabros,,NULL,2017-10-21
"자바 직렬화, 그것이 알고싶다. 실무편","자바의 직렬화 기술에 대한 대한 두 번째 이야기입니다. 실제 자바 직렬화를 실무에 적용해보면서 주의해야 할 부분에 대해 이야기해보려고합니다.자바 직렬화는 자바 개발자 입장에서는 상당히 쉽고 빠르게 사용할 수 있도록 만든 기술입니다.JSON 또는 CSV 등 형태의 포맷을 이용하면 직렬화 또는 역직렬화시에 특정 라이브러리를 도입해야 쉽게 개발이 가능하며, 구조가 복잡하면 직접 매핑시켜줘야 하는 작업도 포함하게 됩니다.  그것에 비해 자바 직렬화는 비교적 복잡한 객체도 큰 작업 없이 (java.io.Serializable 인터페이스만 구현해주면)  기본 자바 라이브러리만 사용해도 직렬화와 역직렬화를 할 수 있습니다.하지만 등가교환이라는 말이 있듯이 쉽게 이용할 수 있는 만큼 실제 업무에서 사용할 때에는 신경 써야 하는 부분이 있습니다.  제 경험에 빗대어서 신경 써야 할 부분에 대해 몇 가지 이야기해보겠습니다.앞서서 예시를 들은 woowahan.blog.exam1.Member (이하 Member) 클래스를 기준으로 이야기해보겠습니다.예제에서 Member 클래스가 있습니다. 이 클래스의 객체를 직렬화 시켜보겠습니다.  아래에의 문자열은 직렬화된 Member 클래스의 객체 문자열입니다. 테스트에 용의 하도록 Base64로 인코딩하였습니다.이 문자열을 바로 역직렬화 시키면 바로 Member 객체로 변환합니다. (테스트할 때에는 반드시 패키지도 동일해야 합니다.) Member 클래스의 구조 변경에 대한 문제를 확인해보겠습니다.우리가 보통 원하는 것은 phone 멤버 변수가 추가되어도 기존 멤버 변수의 기존 멤버 변수는 채워지길 원합니다. phone은 null 되어 있더라도 말이죠.  이전에 자바 직렬화된 데이터를 역직렬화 시켜 보겠습니다.이렇게 클래스의 멤버 변수 하나만 추가되어도 java.io.InvalidClassException 예외가 발생합니다.  예외 메시지를 읽어보면 serialVersionUID의 정보가 일치하지 않기 때문에 발생한 것을 알 수 있습니다.  우리는 Member 클래스에서는 serialVersionUID 의 값을 -8896802588094338594 정보로 설정해준 적도 없으며,  7127171927132876450으로 변경한 적도 없습니다. 어떻게 된 일일까요? 그래서 자바 직렬화 스펙을 확인해보았습니다. (링크)간단히 정리해보겠습니다.serialVersionUID 를 직접 기술하지 않아도 내부 적으로 serialVersionUID 정보가 추가되며,  내부 값도 자바 직렬화 스펙 그대로 자동으로 생성된 클래스의 해쉬 값을 이라는 것을 확인할 수 있었습니다. (링크 를 보면 알 수 있지만 해쉬값은 클래스 구조 정보를 이용해서 생성하는 것을 알 수 있습니다.) 즉 serialVersionUID 정보를 기술하지 않는다고 해서 사용하지 않는 것이 아니 다라는 것이 확인되었습니다.그럼 어떤 형태가 좋을까요?“조금이라도 역직렬화 대상 클래스 구조가 바뀌면 에러 발생해야 된다.” 정도의 민감한 시스템이 아닌 이상은 클래스를 변경할 때에 직접 serialVersionUID 값을 관리해주어야 클래스 변경 시 혼란을 줄일 수 있습니다.물론 그렇게 해도 모든 것이 해결되는 것은 아닙니다. serialVersionUID 값이 동일할 때에도 신경 써야 할 부분이 생깁니다.  serialVersionUID 값이 동일할 때에도 어떠한 문제가 생길 수 있는지 몇 가지 살펴보겠습니다.기존 자바 직렬화된 데이터는 String 타입이었지만 StringBuilder클래스 타입으로 바꿔 봤습니다.혹시 primitive 타입인 int 을 long으로 바꾸는 것은 괜찮지 않을까요?역시나 타입 예외가 발생했습니다.  자바 직렬화는 상당히 타입의 엄격하다는 것을 알 수 있습니다. 에러는 발생하지 않습니다. 값 자체만 없어졌습니다.  그럼 멤버 변수를 추가해보겠습니다.이번에도 에러가 발생하지 않습니다. 원하는 형태로 값이 채워졌네요.자바 직렬화를 사용할 때 클래스 구조 변경 시 어떤 부분을 확인해야 할지 정리해보겠습니다.특별한 문제없으면 자바 직렬화 버전 serialVersionUID의 값은 개발 시 직접 관리해야 합니다.serialVersionUID의 값이 동일하면 멤버 변수 및 메서드 추가는 크게 문제가 없습니다.    그리고 멤버 변수 제거 및 이름 변경은 오류는 발생하지 않지만 데이터는 누락됩니다.역직렬화 대상의 클래스의 멤버 변수 타입 변경을 지양해야 합니다. 자바 역직렬화시에 타입에 엄격합니다.             나중에라도 타입 변경이 되면 직렬화된 데이터가 존재하는 상태라면 발생할 예외를 경우의 수를 다 신경 써야 합니다.외부(DB, 캐시 서버, NoSQL 서버 등)에 장기간 저장될 정보는 자바 직렬화 사용을 지양해야 합니다.   역직렬화 대상의 클래스가 언제 변경이 일어날지 모르는 환경에서 긴 시간 동안 외부에 존재했던 직렬화된 데이터는 쓰레기(Garbage)가 될 가능성이 높습니다.  언제 예외가 발생할지 모르는 지뢰 시스템이 될 수도 있습니다.생각 지도 못한 오류가 거품처럼 나기 시작할 것입니다. 이 부분은 사실 알아채기가 힘듭니다. 발생하기 위한 사전 조건도 많기 때문입니다.   차라리 이 글을 읽으신 분은 위와 같은 문제 사전에 차단하실 것을 추천합니다.    위와 관련된 예시는 스프링 시큐리티의 SecurityContextImpl클래스가 있습니다.  SecurityContext 를 구현한 클래스 클래스로 링크 를 보면 확인할 수 있습니다.    serialVersionUID 값이 스프링 시큐리티의 버전 값이기 때문에 버전이 변경될 때마다 신경 쓰입니다.자바 직렬화시에 기본적으로 타입에 대한 정보 등 클래스의 메타 정보도 가지고 있기 때문에 상대적으로 다른 포맷에 비해서 용량이 큰 문제가 있습니다.  특히 클래스의 구조가 거대해지게 되면 용량 차이가 커지게 됩니다. 예를 들면 클래스 안에 클래스 또 리스트 등 이런 형태의 객체를 직렬화 하게 되면 내부에 참조하고 있는 모든 클래스에 대한 메타정보를 가지고 있기 때문에 용량이 비대해지게 됩니다.  그래서 JSON 같은 최소의 메타정보만 가지고 있으면 테스트로 된 포맷보다 같은 데이터에서 최소 2배 최대 10배 이상의 크기를 가질 수 있습니다. 결과간단한 데이터이지만 위와 같이 용량 크기 두배 이상 차이가 납니다. 용량 문제는 생각보다 많은 곳에서 나타나는 문제입니다. 특히 직렬화된 데이터를 메모리 서버(Redis, Memcached)에 저장하는 형태를 가진 시스템에서 두드러집니다.  메모리 서버 특성상 메모리 용량이 크지 않기 때문에 핵심만 요약해서 기록하는 형태가 효율적입니다. 적은 데이터만 입력하는 시스템 구조라면 큰 문제는 발생하지 않습니다. 하지만 트래픽에 따라 데이터 기록이 급증하는 시스템은 유의해야 합니다. 그리고 이 부분을 강조하는 이유는 자바 웹 시스템에서 가장 많이 사용되는 스프링 프레임워크에서 기본적으로 지원하는 캐시 모듈 중  외부 시스템에 저장하는 형태에서 기본적으로 자바 직렬화 형태로 제공되기 때문입니다. (Spring Data Redis, Spring Session …) 기본적으로 프레임워크에서 자바 직렬화로 제공하는 이유는 앞서 말한 자바 직렬화 장점과 일맥상통합니다. 개발자가 신경 안 쓰고 빠르게 개발할 수 있기 때문입니다.  자바 직렬화 사용하는 시스템은 규모가 커지는 시점에서 반드시 다시 점검하여 보시길 바랍니다.일반 사용자를 대상으로 하는 B2C와 같은 시스템에서 자바 직렬화 정보를 외부 캐시 서버에 저장할 때에는  비효율적인 문제를 가지고 있습니다. (용량 크기에 따른 네트워크 비용과 캐시 서버 비용) 새롭게 스타트하는 서비스 같은 경우에는 생산성을 위해서 자바 직렬화를 그대로 이용한다고 해도  트랙픽이 지속적으로 증가할 때에는 JSON 형태 또는 다른 형태의 직렬화로 바꿔주는 것 고려해보시길 바랍니다. 이 부분은 기술적 오류 문제는 아닙니다. 단지 자바 직렬화를 이용해서 개발하면서 불편했던 부분을 이야기하려고 합니다.  자바 직렬화를 이용해서 외부 데이터를 저장하게 되면 제일 큰 아쉬움이 바로 자바에서만 사용할 수 있으면 읽을 수 있는 문제였습니다.   다른 언어를 이용해서 스크립트를 이용해서 여러 가지 처리를 하고 싶어도 불가능에 가깝습니다.  (파이썬에 자바 직렬화 분석하는 라이브러리가 있는 것은 확인해봤지만 사용은 못해봤습니다.) 만약 JSON으로 저장되어 있다면 MYSQL이나 REDIS 등 추가 라이브러리를 통해 조회도 가능하면 다른 언어를 통해서도 탐색 및 조작이 가능합니다 그리고 제가 이야기하고 싶은 것은 “긴 시간 동안 외부에 저장하는 의미 있는 데이터들은 자바 직렬화를 사용하지 말자.“입니다.자바 직렬화는 장점이 많은 기술입니다만 단점도 많습니다.  문제는 이 기술의 단점은 보완하기 힘든 형태로 되어 있기 때문에 사용 시 제약이 많습니다. 그래서 이 글을 적는 저는 직렬화를 사용할 때에는 아래와 같은 규칙을 지키려고 합니다.이전 포스팅으로 이동하기",http://woowabros.github.io/experience/2017/10/17/java-serialize2.html,woowabros,,NULL,2017-10-17
"자바 직렬화, 그것이 알고싶다. 훑어보기편","자바의 직렬화 기술에 대한 대한 이야기입니다.  간단한 질문과 답변 형태로 자바 직렬화에 대한 간단한 설명과 직접 프로젝트를 진행하면서 겪은 경험에 대해 이야기해보려 합니다.자바 기본(primitive) 타입과 java.io.Serializable 인터페이스를 상속받은 객체는 직렬화 할 수 있는 기본 조건을 가집니다.자바 직렬화는 방법은 java.io.ObjectOutputStream 객체를 이용합니다.위 예제에서 객체를 직렬 화하여 바이트 배열(byte []) 형태로 변환하였습니다.자바 직렬화를 아시는 분은 위에서 기술한 예제에서 사용되는 자바 직렬화 대상의 Member 클래스가 serialVersionUID 상수가 없어서 의아하신 분도 계실 겁니다.  사실 반드시 기술해야 되는 필수는 아니기 때문에 빼둔 것입니다. 하지만 상당히 중요한 부분이라서 따로 설명하려고 합니다. 이곳에서는 넘어가도록 하겠습니다.먼저 자바 직렬화를 설명하기 전에 다른 데이터 직렬화 종류를 살펴보겠습니다. 직접 데이터를 문자열 형태로 확인 가능한 직렬화 방법입니다. 범용적인 API나 데이터를 변환하여 추출할 때 많이 사용됩니다. 표형태의 다량의 데이터를 직렬화시 CSV가 많이 쓰이고 구조적인 데이터는 이전에는 XML을 많이 사용했으며 최근에는 JSON형태를 많이 사용하고 되고 있습니다.  여기서는 CSV와 JSON만 살펴보겠습니다.예제에서는 문자열로 단순히 변경했습니다.   자바에서는 Apache Commons CSV, opencsv 등의 라이브러리 등을 이용할 수 있습니다.JSON도 물론 이렇게 직접 문자열을 만들일은 거의 없습니다.   자바에서는 Jackson, GSON 등의 라이브러리를 이용해서 변환할 수 있습니다.위에 언급한 CSV, JSON 형태의 직렬화는 익숙한 사람이 많을 것입니다.  CSV 같은 경우 표 형태의 데이터에서 많이 사용되며, JSON 같은 경우는 구조적인 데이터를 전달하는 API 시스템 등에서 많이 사용하고 있기 때문입니다. 데이터 변환 및 전송 속도에 최적화하여 별도의 직렬화 방법을 제시하는 구조입니다.  직렬화뿐만 아니라 전송 방법에 대한 부분도 이야기하고 있지만 여기서는 직렬화 부분만 이야기하겠습니다. 종류로는 Protocol Buffer(이하 프로토콜버퍼) Apache Avro 등이 있습니다. 기타  지면 관계상 프로토콜 버퍼만 한번 살펴보겠습니다. (살펴보면 알겠지만 직렬화하기 위한 패턴은 비슷합니다.)프로토콜 버퍼는 구글에서 제안한 플랫폼 독립적인 데이터 직렬화 플랫폼입니다.자바에서 사용방법   프로토콜 버퍼는 특정 언어 또는 플랫폼에 종속되지 않는 방법을 구현하기 위해 직렬화 하기 위한 데이터를 표현하기 위한 문서가 따로 있습니다.이렇게 기술된 member.proto 문서를 프로토콜 버퍼 컴파일러를 이용해서 개발하기 원하는 언어(여기서는 자바)로 변환해야 합니다.    (프로토콜 버퍼 컴파일러는 별도로 설치하거나 Gradle, Maven등 의 빌드 도구를 이용하면 됩니다.)    자바로 변환하게 되면 프로토콜 버퍼 형태의 Member 클래스가 생성됩니다.자바 직렬화와 다른 점은 데이터 스펙을 표현하기 위한 문서가 존재하는 부분입니다. 그 이외에는 대부분 동일합니다.그 외 여러가지 직렬화 방법이 있는 있지만 여기서 다 다루지는 못하지만 직렬화 관련 좋은 포스팅이 있어서 추천드립니다. 링크그럼 다시 왜 자바 직렬화를 사용하는지 이야기해보겠습니다. CSV, JSON, 프로토콜 버퍼 등은 시스템의 고유 특성과 상관없는 대부분의 시스템에서의 데이터 교환 시 많이 사용됩니다.  하지만 “자바 직렬화 형태의 데이터 교환은 자바 시스템 간의 데이터 교환을 위해서 존재한다.”고 생각하시면 됩니다.JVM의 메모리에서만 상주되어있는 객체 데이터를 그대로 영속화(Persistence)가 필요할 때 사용됩니다. 시스템이 종료되더라도 없어지지 않는 장점을 가지며 영속화된 데이터이기 때문에 네트워크로 전송도 가능합니다.  그리고 필요할 때 직렬화된 객체 데이터를 가져와서 역직렬 화하여 객체를 바로 사용할 수 있게 됩니다.  그런 특성을 살린 자바 직렬화는 많은 곳에서 이용됩니다. 많이 사용하는 부분 몇 개만 이야기해보겠습니다.서블릿 세션 (Servlet Session)   서블릿 기반의 WAS(톰캣, 웹로직 등)들은 대부분 세션의 자바 직렬화를 지원하고 있습니다.    물론 단순히 세션을 서블릿 메모리 위에서 운용한다면 직렬화를 필요로 하지 않지만,    파일로 저장하거나 세션 클러스터링, DB를 저장하는 옵션 등을 선택하게 되면 세션 자체가 직렬화가 되어 저장되어 전달됩니다.    (그래서 세션에 필요한 객체는 java.io.Serializable 인터페이스를 구현(implements) 해두는 것을 추천합니다.)    참고로 위 내용은 서블릿 스펙에서는 직접 기술한 내용이 아니기 때문에 구현한 WAS 마다 동작은 달라질 수 있습니다.캐시 (Cache)   자바 시스템에서 퍼포먼스를 위해 캐시(Ehcache, Redis, Memcached, …)    라이브러리를 시스템을 많이 이용하게 됩니다.   자바 시스템을 개발하다 보면 상당수의 클래스가 만들어지게 됩니다.    예를 들면 DB를 조회한 후 가져온 데이터 객체 같은 경우 실시간 형태로 요구하는 데이터가 아니라면    메모리, 외부 저장소, 파일 등을 저장소를 이용해서 데이터 객체를 저장한 후 동일한 요청이 오면 DB를 다시 요청하는 것이 아니라 저장된 객체를 찾아서 응답하게 하는 형태를 보통 캐시를 사용한다고 합니다.   캐시를 이용하면 DB에 대한 리소스를 절약할 수 있기 때문에 많은 시스템에서 자주 활용됩니다. (사실 이렇게 간단하진 않습니다만 간단하게 설명했습니다.)     이렇게 캐시 할 부분을 자바 직렬화된 데이터를 저장해서 사용됩니다. 물론 자바 직렬 화만 이용해서만 캐시를 저장하지 않지만 가장 간편하기 때문에 많이 사용됩니다.자바 RMI(Remote Method Invocation)   최근에는 많이 사용되지 않지만 자바 직렬화를 설명할 때는 빠지지 않고 이야기되는 기술이기 때문에 언급만 하고 넘어가려고 합니다.    자바 RMI를 간단하게 이야기하자면 원격 시스템 간의 메시지 교환을 위해서 사용하는 자바에서 지원하는 기술입니다.    보통은 원격의 시스템과의 통신을 위해서 IP와 포트를 이용해서 소켓통신을 해야 하지만 RMI는 그 부분을 추상화하여 원격에 있는 시스템의 메서드를 로컬 시스템의 메서드인 것처럼 호출할 수 있습니다.    원격의 시스템의 메서드를 호출 시에 전달하는 메시지(보통 객체)를 자동으로 직렬화 시켜 사용됩니다.     그리고 전달받은 원격 시스템에서는 메시지를 역직렬화를 통해 변환하여 사용됩니다.    자세한 내용은 작은 책 한 권 정도의 양이 되기 때문에 따로 한번 찾아보시는 것을 추천드립니다.다음 포스팅으로 이어집니다.",http://woowabros.github.io/experience/2017/10/17/java-serialize.html,woowabros,java,NULL,2017-10-17
배민 '앱 친구'의 스프린트 이야기,"배달의민족 앱 개발자들은 주로 다음 과제와 관련된 메일을 받고 다음 앱 업데이트 준비를 시작합니다.여러분의 한 단위 앱 업데이트를 위한 과정은 어떻게 시작되시나요?  이터레이션이라고 부르기도 하고, 스프린트라고도 칭하는 용어들을 사용하고 계신가요 :-)배달의민족을 개발하는 팀에서는 스프린트라는 용어를 주로 사용하고 있습니다.(스크럼을 응용해서 개발 프로세스를 진행하고 있다는 의미도 내포되어 있어요-) 주된 스프린트의 목표는 역시 고객님께 배포되는 앱을 릴리즈 하는것이랍니다. 우리 팀은 성공적인 앱 배포를 위해 흥미롭게 짜여진 스크럼 진행 과정을 따르고 있는데요. 오늘 여러분께 그 과정을 소개해드리고자 합니다.우리 팀은 앱 개발자와 서버 개발자가 반반정도의 비율로 함께 일하고 있고, 서로를 앱 친구들 & 서버 친구들이라고 부르곤 한답니다. 한 ‘앱 친구’(앱 개발자)의 페르소나를 투영해서 릴리즈 준비를 시작하는 시점부터, 최종 릴리즈까지 거치게 되는 흐름들을 함께 흘러가고자 합니다.이제부터 마치 과제를 담당하게 되는 개발자처럼 생각해보세요. Shell We? ;-)“우리 언제 모일까요~?”글 초반에 보여드렸던 다음 릴리즈 과제 담당자 지정에 대한 메일이 오면, 우리는 메신저에서 과제 담당자 관련된 논의를 위해 모일 시간을 정하자고 이야기 해봅니다.그리고, Confluence Wiki(기획자분들은 기획문서를 모두 wiki에 올려주십니다. 꽤나 미리 전부터요~) 에서 과제를 검색해 그 과제의 스펙들은 어떤 것인지 미리 살펴봅니다. 여러 과제들이 어떤 목표와 기획을 가지고 있는지, 특별한 개발 기술들을 필요로 하는지 고민하는 시간을 가지곤 합니다.동료들과 모여서 다음 과제 이야기를 나눌 때는 마치 모여서 잡담을 하는 것 처럼 편안합니다.  자유롭게 과제에 대해 이야기 하는 분위기는 전매특허 수준이예요~각 과제가 어떤 난이도가 있는지, 이번엔 이런 결과를 위해서 어떤 기술을 사용하겠다 등등 과제 관련해서 할 수 있는 이야기는 이 때 가장 많이 나누는 편입니다. 그리고 우리는 각자의 모든 것을 고려해서(선호도, 개발 실력, 개인 휴가… 개인의 현재 상태까지!)과제 담당자들을 지정합니다. 이 과정에서 잡음이 있었던 적은 전혀 없습니다. 아마도, 우리 팀이 일과 관련되서는 서로에 대해 잘 알고있다라고 할 만큼 투명하게 지내는 분위기를 가지고 있기 때문 인 것 같아요. (정말 좋은 팀이죠~? :-D)다음은 플래닝포커를 통한 일정산출입니다!포커카드 없이 점수표를 보면서 각 과제의 난이도나 사용하는 기술을 고려해 얼마의 공수가 필요할 지 머릿속으로 미리 시뮬레이션 해봅니다. 점수를 말하면서 각자의 생각을 공유하고, 내가 생각하지 못한 부분도 듣게 되면서 과제수행에 대한 현실감 게이지가 슬슬 달아오르게 됩니다.그러면서 점수가 이정도니 일정은 얼마나 걸리겠다까지 연장선으로 함께 논의하게 됩니다. 릴리즈 목표일이 확정은 아니지만 어느정도 정해져서 공유가 되는데요. 개발자들은 그 릴리즈 목표일을 생각하며 그 일정 안에 Design QA(품질개선팀에서 수행하는 QA전에, 디자이너와 함께 디자인이 잘 반영되었는지 확인하는 과정을 Design QA라고 지칭)와 QA까지 모두 고려하며 개발 일정은 얼마나 나오는지 역산해 봅니다.이 과정을 통해서 개발팀 내부에선 목표일을 지킬 수 있다, 시간이 더 필요하다, 더 단축시킬 수 있다라는 의견을 정해서 프로젝트 리더에게 공유합니다. 대게 개발자들이 의견이 잘 반영되어 릴리즈 목표일이 확정되곤 합니다.우아한형제들 개발실의 또 다른 플래닝포커를 보고싶다면… 클릭해보세요!본격적인 개발을 위해 아래와 같은 작업을 시작합니다.…을 하고 있으면 노티피케이션이 옵니다!기획 리뷰회의가 잡혀서 5분전 알림이 울렸네요 ㅎㅎ이제 각개전투 시작입니다!  각 과제 앱 담당자들과 서버 담당자들, 기획자와 QA분들이 모여서 함께 회의하고 기획과 관련된 부분을 논의합니다. 같이 모인 메신저방도 생기고 이렇게 회의도 같이하니 궁금하거나 문제가 되는 부분은 바로바로 이야기 할 수 있고, 그로 인해 전달하는 형식의 커뮤니케이션 코스트도 줄어들고 분위기는 훈훈해지는 효과를 얻습니다! ㅎㅎ과제에 따라 매일 스탠딩 회의를 진행하는 경우도 있고, 메신저를 통해 리모트로 작업 진행 과정을 공유하기도 한답니다.본격 코딩을 시작합니다~! 때로는 페어로 개발할 때도 있지만, 속해있는 팀원이 홀수라면 페어없이 혼자 한 과제를 도맡아 할 때도 있습니다. 그런데, 혼자 개발한다는 느낌이 1도 들지 않습니다. 왜일까요? 나의 코드를 지켜보는 동료들이 있기 때문입니다.  안드로이드 개발자들의 치밀한 코드리뷰는 우리 팀의 자랑거리 입니다 :-) 동료들이 서로 리뷰해준 리뷰 내용들, 세세한 실수부터 리팩토링 할 수 있는 것들을 댓글로 달아주는 덕에 결국에 머지되는 코드는 프로페셔널 향기가 날 수 있답니다. 그 과정에서 서로 많이 배우는 것은 굳이 말하지 않아도 될 정도이구요. 이렇게 서로의 코드를 리뷰하며 과제 개발의 마무리를 향해 달려갑니다.  그러다 보면 또 다른 노티피케이션이 도착합니다.바로 품질개선팀이 작성하신 QA TC를 함께 리뷰하는 회의를 위한 소집인데요. 우리팀에서 개발완료라고 부르는 시점은 개발자가 기획된 모든 기능을 개발하고, 디자이너와 Design QA를 진행하고, 품질개선팀이 작성해주신 TC까지 스스로 테스트 해보는 과정을 모두 마쳤을 때 입니다. 이 이후에 본격적인 QA가 진행된답니다.TC를 리뷰하면서, 개발자는 테스트가 필요한 내용들을 품질개선팀에 추가로 전달할 수 있고, 앱의 스펙과 테스트 기대결과들을 최종적으로 점검합니다. 그리고 돌아와서 개발자는 TC를 하나하나 수행하며 체크합니다. 스스로 만든 💩 을 자발적으로 치우며 아름다운 반성의 시간도 가지게 됩니다. 마치 개발 후, 명상의 시간을 갖는 것 같습니다 ㅎㅎㅎ그리고 나면…본격적인 QA기간이 시작되고, QA 이슈 티켓이 작업자에게 할당됩니다. 개발이슈 티켓을 쳐내기에 열중했다면, 이제는 QA이슈 티켓을 완료시키기 위해 집중합니다. 이 과정에서 기획단에서 다시 고민이 필요한 부분들도 나오는데요. 이런 이슈들은 모두가 모여있는 메신저에서 자유롭게 이야기하며 빠른 기대결과 적립 및 수정을 진행하게 됩니다.릴리즈 목표일이 다가오면 프로젝트 리더분에 의해 앱 릴리즈 목표일 즈음에 남아있는 QA이슈들이나 빠진 작업이 없는지 확인되고, 일정이 추가적으로 필요한지 검토해서 목표일 수정이 유연하게 이뤄지는 편입니다.그렇게 빠진 부분이 없는지 잘 챙기다 보면… 어느새 앱 출시 완료! 릴리즈 후에는 과제의 특성에 따라 회고가 이뤄지기도 하고, 생각치 못한 오류들로 인해 패치를 준비하기도 합니다.그렇게 한 번의 릴리즈를 마무리 하고 나면… 어느새 다음 과제 대상자 관련 메일이 또 도착📬하게 되겠죠? 다음엔 어떤 과제를 하게 될 지 궁금해지네요~배달의민족 앱 친구의 스프린트 수행과정 어떠셨나요? 저희 잘 하고 있는 것 같나요~? :-)혹시나 이 글을 읽고, 함께 스프린트를 수행하고 싶은 마음이 불끈 생기셨다면…지체 마시고 클릭해보세요Happy Sprint!",http://woowabros.github.io/woowabros/2017/10/17/baemin-mobile-sprint.html,woowabros,,NULL,2017-10-17
데일리 미팅! 플래닝 포커! 회고!,"안녕하세요. 저는 우아한형제들 FC플랫폼개발팀에서 서버개발을 하고 있는 이경원입니다. 오늘은 글로 배운 애자일 방법론을 도입하고 진행했던 경험담을 기록하고자 합니다. 사실 저는 애자일 방법론에 대해서 잘 알지 못하고, 제가 도입을 시도한 것도 아닙니다. 단지 스크럼 이라는 책만 한번 봤을 뿐입니다. 글로 배운 것이죠.한때 애자일 방법론에 대한 환상이 있었는데, 직접 경험해보지 못했기 때문에 애자일이 무엇인지 감이 잘 오지 않았습니다. 하지만 이번 프로젝트에 애자일 방법론을 경험하며 느낀 점은 애자일 방법론을 도입한다고 해서 거창하게 생각할 필요는 없다는 것입니다. 복잡한 도메인이 어떻게 변할지 정확히 예상할 수 없듯이, 방법론도 마찬가지라고 생각합니다.하지만 여전히 애자일이 무엇인지는…아마 데일리 미팅은 대부분 경험해봤거나, 하고 있다고 생각합니다. 데일리 미팅은 간단합니다. 팀원들이 정해진 시간에 모여 어제는 무엇을 했고, 오늘은 무엇을 할 것이며, 어떤 문제(이슈)가 있는지 공유하고 잡담 자리입니다.주의할 점은 시간이 너무 길어지지 않게 하는 것인데요. 시간이 너무 길어진다면…데일리 미팅에서 길어질 것 같은 주제는 따로 미팅을 잡는 게 좋다는 생각입니다.하지만 이렇게 간단하고 귀찮은 미팅을 왜 매일매일 하는 걸까요? 단순히 자기 일정을 공유하는 자리를 만들기보단 문서나 메신저로 공유하면 안 될까요?데일리 미팅을 시작한 후 마침 김창준 님의 애자일 키워드라는 팟방을 듣게 됐는데요. 데일리 미팅을 하는 가장 큰 이유는 일정 공유보다는 팀원 개개인의 감정을 학습하는 것이라고 합니다. 얼굴을 맞대고 데일리 미팅을 하며 팀원들 서로의 감정을 읽고 학습하는 시간인 것이죠. 쉽게 말하면 팀워크를 다지기 위함이 아닐까요?데일리 미팅뿐 아니라 플래닝 포커, 회고 등을 통해서 가장 좋았던 점은 팀원과 자주 소통하고 다양한 의견을 들어보는 것이였는데요. 그래서 그런지 팀원 간 사이도 더 가까워지는 기분이에요!저는 사실 애자일 방법론에서 가장 해보고 싶었던 것 중 하나가 플래닝 포커였습니다. 플래닝 포커는 일정을 세우기 위한 전략인데, 이 전략은 요구사항을 분석해서 문서를 만들며 정확한 일정을 도출하기보단, 재밌는 방식으로 일정을 세우는 전략입니다. 물론 스토리라고 말하는 어느 정도 정해진 요구사항은 있습니다.저희는 플래닝 포커를 하기 위해 Scrum Time 앱을 이용했습니다.플래닝 포커를 하면 정확한 일정이 나올까요? 저는 처음부터 당연히 나오지 않을 거라고 생각했습니다. 스토리 포인트가 정해지더라도 그 스토리를 해결하는 과정에도 요구사항은 변하고 일정도 변한다고 생각했습니다. 그렇다면 플래닝 포커를 왜 할까요?여기서 스토리는 요구사항 또는 하나의 기능이라고 생각하셔도 됩니다.플래닝 포커를 통해 스토리를 작은 단위로 나누게 됩니다. 저희는 1/2(일), 1(일), 3(일), 5(일)를 기준으로 스토리 포인트를 정했는데요. 5포인트 이상의 스토리가 나오게 되면 2개 이상의 스토리로 쪼개는 것이죠. 한 스토리를 최대한 단순하게 만들어 되도록 스프린트 내에 일정을 맞출 수 있게 하는 것입니다.맞아요. 우리 쪼개는 중이에요.진지합니다!!!저는 스스로도 회고를 많이 하는 편입니다. 회고하며 기록하는 것은 많은 장점이 있습니다.저희도 회고를 통해 위와 같은 장점을 얻었습니다. 무엇보다 스프린트 기간 동안 무엇을 잘했고, 무엇이 문제였는지 확인하고 문제를 해결하는 방법은 무엇일까 고민하는 자리입니다. 무겁게 이야기 하기보단 커피도 한 잔씩 마시며 즐겁게 서로의 감정이 상하지 않도록 이야기하는 자리입니다. 물론 모든 내용은 기록합니다.용서와 칭찬의 시간저기 환하게 웃고 있는 사람이 저입니다. 칭찬을 받았나 봐요. (아니네요. 플래닝 포커 중이네요.)쓰고 보니 이 글도 회고라는 생각이 들었습니다. 사실 애자일 방법론을 경험한 지 한 달 조금 넘었기 때문에 애자일이란 무엇이고 이렇게 해야 돼!라고 말하지는 못합니다. 그리고 앞으로도 못할 거라고 생각합니다. 그 이유는 애자일이기 때문입니다. 애자일 방법론은 정해진 규칙과 방법은 있지만, 정확한 프로세스가 주어지진 않습니다. 우리 상황과 이해관계에 맞게 변화하고 학습하며 적응하면서 우리만의 애자일 방법론을 만들어가는 게 애자일이지 않을까 생각합니다.명주 님은 생각보다 재밌다. 그걸 알게 돼서 좋았다.회고 중 나온 내용인데요. 이 사진을 찍으신 분이 바로 명주 님입니다. 제가 회고 시간에 재밌다고 했더니, 페북에 이렇게 올리셨어요.이 글에도 올려달라고 하셨어요. 좋으셨나 봐요. 올려달라고 말씀하시는 것도 재밌네요. ㅋㅋㅋ코드 리뷰도 합니다.끗.",http://woowabros.github.io/woowabros/2017/09/14/scrum.html,woowabros,java,NULL,2017-09-14
실시간 서비스 경험기(배달운영시스템),"들어가기 앞서 이 글은 신기술 사용기 또는 소개가 아닌 실시간 서비스 즉 배민라이더스 BROS 1.0 을 개발 하면서 겪어왔던 다소 특별한 개발 및 운영 경험기 입니다. BROS 2.0이 나온 상황에서 1.0을 이야기 하는 것이 다소 순서가 맞지 않지만 그 때 당시 경험기를 남겨놓지 못 한 것을 이번 기회에 남겨 보고자 합니다.BROS는 배민라이더스의 주문을 접수(콜센터접수)를 시작으로 배달건을 라이더가 고객에게 신속하고 안전하게 배달하기 위한 통합 운영 관제 시스템입니다.여기서 realtime 또는 실시간서비스란 websocket으로 통신하는 서버를 이용하여 웹페이지 및 모바일 앱에서 실시간으로 데이터를 주고 받고 갱신하는 시스템을 말합니다.angularjs의 양방향 바인딩을 뜻 하며 뷰의 데이터가 변하면 모델이 자동으로 변경되고 반대로 모델이 변하면 뷰도 자동으로 변경되는 특징을 말합니다.angularJS에서 모델 변화를 감지하는 역할을 하여 양방향 데이터 바인딩을 적용하는 역할을 합니다. angularjs1.0의 성능적인 면에서 단점으로 작용하기도 하지만 개별 모델의 one-time bind 설정을 통하여 양방향 바인딩이 필요없는 모델을 제외 할 수 있습니다.웹브라우저는 http 프로토콜로 요청/응답으로 동작하는데 TCP/IP socket 처럼 connection이 유지되어 서로 실시간으로 통신을 할수 없습니다. 그래서 등장한것이 wswebsocket 프로토콜입니다.  websocket을 사용하면 웹브라우저에서도 socket 통신처럼 실시간으로 데이터를 주고 받을 수 있습니다. 최근에는 대부분의 브라우저가 websocket 프로토콜을 지원하지만 IE 같은 경우는 version 10 부터 지원을 하고 있습니다.nodejs 기반으로 실시간 이벤트 서버를 개발 할 수 있는 오픈소스 라이브러리 입니다. 특징으로는 멀티 디바이스(web, android, ios, windows)를  지원하며 websocket을 지원하지 않는 browser도 지원합니다.배민라이더스의 음식 주문은 평균 1시간 내외로 주문의 접수, 처리 및 배송이 완료 되어야 합니다. 즉 주문이 발생한 경우 콜센터직원은 바로 주문의 발생을 알아야 하며, 주문접수가 처리 되면 라이더는 즉시 배달건의 존재를 알아야 합니다. 또한 배달의 상태(대기 - 배차 - 픽업 - 전달)와 라이더의 실시간 위치가 업데이트 되어야 관제자와 라이더들은 원할한 관제 및 배달업무를 수행 할 수 있습니다. 또한 기존 polling 방식의 배민 콜센터 주문접수(현재는 fade out)는 주문건이 증가함에 따라 DB Select가 급증하여 서비스가 위험했던 적이 있었기  때문에 BROS개발 당시 실시간성을 유지하면서 db select를 줄이기 위해서 필수로 실시간 이벤트 서버 도입을 해야 했습니다.그림 1. 주문 처리 activity 다이어그램주문과 배달의 생성 상태변경이 있을 때 마다 socket.io 실시간 이벤트를 전송하고 수신 시 api를 호출하여 배달리스트를 갱신하는 방식은 데이터의 변경이 있는 경우만 database를 select하지만 피크시간대에는 이벤트가 증가하므로 database select가 급증하게 됩니다. angularjs model 변경은 angularjs가 알아서 뷰에 반영하기 때문에 실시간 이벤트를 송수신 할 때 마다 배달리스트를 호출 하지 않고 배달데이터를 생성 삭제 수정 한 후 실시간 이벤트 메시지로 angularjs model에 반영 하도록 하면 뷰는 자동으로 실시간 반영 됩니다. 또한 개발자는 뷰를 업데이트하는 비즈니스로직을 신경쓸 필요가 없고 데이터를 뷰에 나타나는 로직만 구성해 놓으면 됩니다.그림 2. AngularJs 모델 데이터 반영코드 1. 이벤트 수신 Controller코드 2. 수신이벤트 처리 Service코드 3. 수신받은 데이터 모델에 반영데이터의 생성, 업데이트, 삭제를 database에 반영하고 곧바로 socket.io 서버의 실시간 이벤트 메시지로 데이터를 전송 angularjs model에  반영, 뷰는 모델의 변경에 자동 갱신 되기 때문에 client수에 관계없이 사실상 database를 주기적으로 select하는 행위는 거의 일어나지 않으며  배달데이터는 실시간으로 관제 및 라이더에게 반영된다. 그림 3. BROS 실시간 배달현황 화면 그림 3. BROS 실시간 라이더 배차 화면angularjs와 socket.io 서버를 이용하여 database select를 최소화 하고 주문, 배달 및 라이더 위치를 실시간으로 관제하고 배차업무를 할 수 있도록 시스템을 구성하고 실시간으로 눈앞에 데이터들이 화면 갱신 없이 변경이 되고 있었지만 가만히 화면만 바라보고 있을 때는 큰 문제가 없는 듯 하였습니다.“그러나 browser는 열일 하고 있는 중……”실시간으로 화면이 렌더링 되는 것은 사실 아무런 문제가 없었습니다. 하지만 피크시간인 저녁시간에 배달 건수가 급격히 늘어나기 시작하면서 배차를 위해 라이더리스트 다이얼로그를 클릭한다던지 했을 때 0.5초 정도 움찔하는 delay가 발생하였습니다. 사용자 입장에서는 꽤나 신경이 거슬리는 이슈였습니다.요구사항으로 배달완료된 배달건도 리스트에 남기고 당일 모든 배달건(많을 때는 1000건)을 현황에 리스팅 해달라는 요구가 있었습니다. 물론 타협으로 최근 4시간 배달건만 리스팅 하기로 하였지만 피크시간대에는 수백건의 배달을 페이징없이(실시간리스트라 페이징은…) 리스팅 되고 있었습니다.일반적인 초기 화면 진입 이후 뷰의 렌더링이 거의 없는 정적인 페이지와 달리 BROS의 배달/라이더 현황 페이지들 javascript가 실시간으로 이벤트를 수신받고 모델에 반영하고 뷰를 렌더링하고…… 쉴 새 없이 일을 하고 있었습니다.  그래서 성능최적화 작업에 들어갔습니다.forEach, angular.foreach등으로 된 loop를 제거하고 순수 javascript의  역행 루프reversed loop로 변경하였습니다. 배열의 개수가 적을 때는 크게 상관 없지만 수백 수천개가 되면 그 때는 이야기가 다릅니다.코드 4. 역행 루프javascript는 단일 쓰레드로 동작하며. 먼저 수행된 작업이 끝날 때 까지 다음작업은 대기하게 됩니다. 무거운 작업이 있다면 당연히 사용자는 delay를 느끼게 되고. 이러한 점을 해결 하기 위해 setTimeout을 이용하여 작업을 실행하면 javascript engine에서 UI 작업 큐로 작업은 넘겨 지게 되고 event loop가 큐의 쌓여 있는 task들을 처리 하게 됨으로써 blocking이 감소하여 좀더 성능향상을 시킬 수 있습니다.  JAVASCRIPT Event Loop 링크코드 5. setTimeout 사용ng-repeat은 콜렉션을 looping하여 뷰에 리스팅 하는 angularjs의 커스텀 attribute(directive)입니다. 리스팅된 데이터는 digest loop가 양방양 데이터 바인딩을 위하여 관리하는 모델 데이터 들이며 데이터 개수가 많을 수록 digest loop의 성능이 떨어지게 됩니다. 그래서 리스트의 각 항목 업소명, 배달상태, 배달주소.. 등등의 데이터는 onetime binding으로 digest loop를 가볍게 하고 배달번호+수정일시가 조합된 index key의  변경 감지만으로 뷰를 자동 갱신하게 됩니다.코드 6. 조합 index key나머지 모델 데이터는 onetime binding 처리v-repeat이라는 angularjs용 오픈소스 모듈을 사용하여 scroll up & down 할때 화면에 나타나는 tr을 렌더링하고 사라지는 tr은 제거 되도록 처리 하여 리스트가 개수가 수백 수천이 되더라도  화면에 보이는 데이터 모델만 존재 하게 되어 실질적으로 digest loop가 관리하는 모델의 개수가 현저하게 줄어드는 효과를 낼 수 있었고 실제로 성능 향상에 제일 큰도움이 되었습니다.javascript 실행을 메인쓰레드가 아닌 백그라운드쓰레드에서 처리하게 할 수 있게 하여 무거운 작업의 경우 백그라운드 쓰레드가 처리함으로써 기존 단일쓰레드에 비해서 성능향상을 이점을 얻을 수 있습니다.angularjs의 digest loop를  web worker가 처리 하도록 하고 싶었으나 digest loop를 건드리는 일은 angularjs framework core를 건드리는 일이 되어 버리므로 결국 적용을 포기하였습니다 (가장 아쉬운 부분이기도 합니다.)사용료를 지불하고 바로 사용할 수 있는 유료 서비스들이 존재합니다. 대표적으로 pubnub, pusher 같은 서비스가 대표적이며 websocket서버를 직접 개발할 필요없이  사용 할 수 있는 장점이 있습니다. 반면에 장애나 이슈 발생시 즉각적인 처리가 어렵다는 단점도 분명 존재합니다. 실제로 BROS 2.0도 유료 서비스를 사용하다. 장애나 오류 발생시 즉각적인 대응이 어려워 결국은 websocket 서버를 개발하여 사용하고 있습니다.“유료서비스를 사용할 것인가 직접 만들것 인가의 선택은 여건과 상황에 따라 달라 질 수 있습니다.”websocket server는 client와 서버 간에 http protocol로  커넥션을 초기에 맺고 wswebsocketprotocol로 upgrade한 후 서로에게 heartbeat를 주기적으로 발생시켜 커넥션이 유지되고 있는지 체크하며 네트워크를 유지합니다.socket.io를 사용하여 websocket 서버를 개발 했지만 비즈니스로직 문제가 아닌 다양한  network 상황 때문에 이벤트 유실이 발생 했습니다.라이더분들이 반지하로 음식배달을 가면 LTE가 잘 안 터지는 문제도 발생했다. Mobile network 환경은 24시간 시 분 초  connected 상황은 아닐 수도 있다.업무용 폰은 테더링을 사용하는 라이더들도 있었기 때문에…..발생하는 건수는 매우 적은 수준이였지만 BROS 서비스의 특성상 1건이라도 누락이 발생하면 배달업무에 차질이 생기기 때문에  필수적으로  이벤트 유실에 대한 보완이 필요했습니다 . (유료 서비스도 마찬가지로 발생하는 이슈)이벤트 유실을 보완하기 위해 RabbitMq같은 메시지 큐를 사용하여 이벤트를 발송하는 것도 고려 하였으나 BROS 서비스의 특성상 시간이 지난 이벤트를 수신 받게 되거나 한참이 지난후 한꺼번에 미수신된 이벤트를 수신받게 되면 잘못된 데이터가 반영될 수도 있는 문제가 발생하게 되고 그 문제해결을 위해 복잡한 로직을 추가하게 되면 오히려 파생되는 문제가 더 생길 것으로 판단하였고 되도록이면 근본적인 해결책을 찾기로 하였습니다.cron job을 사용하여 2분에 1번씩 batch proccess 한곳에서 만 배달 데이터를 select 하여 database  부하를 줄이면서socket.io 실시간 이벤트로 브로드캐스팅을 하도록 하고 client는 수신받은 데이터로 유실이 발생한 배달 리스트를 fetch 하는 것으로 이벤트 누락에 대한 데이터 미변경을 보완 하였고 적용 이후에는 데이터 미변경에 대한 문제가 보고 되지 않았습니다.(더 좋은 방법도 분명 있을 겁니다.)그림 4. 이벤트 유실을 보완하기 위한 Broadcasting어느 순간이나 서버가 다운되면 안되지만 만약에 다운이 된다면 심각한 장애를 초래하게 됩니다. 실시간 서비스를 개발한다면 항상 염두해 두어야 하는 이슈 입니다. BROS1.0은 socket.io server로의 연결이 disconnect가 되면 바로 api 직접 호출로 변경이 되고 설정해둔 주기만큼 reconnection을 시도 하도록 되어 있으며 reconnection이 성공하면 api 직접호출은 중단키시고 실시간 이벤트수신으로  swiching 되도록 개발 되어 있습니다. 더 좋은 방법은 메소드들을 추상화 하고 2개이상의 실시간 이벤트 서버를 switching 할 수 있으면 더욱 안정적인 시스템이 될 수 있을 것이란 생각도 해봅니다.이제 실시간 서비스를 위해 필수 적으로 필요한 websocket서버에 대한 이야기를 해보고자 합니다. 앞서 잠시 언급 하였지만 서버자체를 구축할 필요없이 유료로 이용할 수 있는 서비스들이 많이 존재합니다. 유료서비스의 장점은 개발과 운영에 대한 리소스가 들지않고  사용할 수 있다는 장점이 있습니다. 하지만 이슈 발생시 빠른 대처가 어렵다는 단점도 분명 존재합니다. 직접 서버를 개발하거나 유료 서비스를 이용하거나 하는 선택은 여러가지 상황에 따라 판단해야 할 듯 싶습니다. 그리고 서버를 직접 개발 하고 안정적인 상태로 유지하기 까지 생각보다 기술 적인  learning curve  높은 편이며 서버가 안정적인 상태까지 올라오기 위해서는 실제로 운영을 해봐야 한다는 어려움도 존재합니다. socket.io 서버를 개발 하면서 겪었던 여러가지 경험에 대해서 이야기 하려고 합니다. 이야기할 내용은 socket.io 서버에만 국한된 이야기라기 보다 websocket 서버를 개발한다면 아마도 동일하게 겪어야 될 경험이라고 생각됩니다.socket.io에서 트래픽을 격리하여 구분하는 단위로 사용됩니다 event는 명칭 그대로 송/수신하는 이벤트의 이름입니다. 트래픽격리 구분없이 이벤트를 송/수신하면 이벤트 리스너를 등록하여 이벤트를 처리하는 코드가 존재하지 않더라도 접속한 모든 client에 전송 및 수신을 하게 됩니다. 불필요한 트래픽이 발생하게 되고 서버 자체의 성능도 저하되기 때문에 적절한 설계로 구분해아합니다.표 1. Socket.io 트래픽 격리 구분다른 서비스에서는 room이란 용어 대신 channel이라는 용어를 많이 사용한다.socket.io에서 이벤트를 송/수신하는 방식을 말합니다.표 2. Socket.io 이벤트 송수신 방식nodejs는 기본적으로 싱글 프로세스로 동작하며 서버 CPU Core 수 만큼 proccess 생성하여 multi proccess로 구동하기 위해서는 cluster를 이용하여 proccess를 생성하게 됩니다.multi thread는 thread간 데이터를 공유되지만 multi processing은 데이터공유가 되지 않는 특징이 있다.그래서 특별한 처리들을 구현해야 한다.nodejs cluster 를 이용하여 proccess를 생성하면 실제 일을 수행하는 proccess를 worker 라고 하며 worker들을 제어하는 역할을 하는 proccess를 master라고 부릅니다.socket.io는 앞서 말한것 처럼 websocket을 지원하지 않는 브라우저도 지원합니다. websocket을 지원하지 않는 브라우저에서는  flashsocket, htmlfile, xhr-polling, jsonp-polling등의 적절한 방식으로 전환되어 통신합니다. (최근에는 버전업이 되면서 websocket, polling만 지원하는 것으로 변경 되었습니다.)flashsocket같은 경우는 브라우저에 flash가 설지되어 있지않으면 작동을 하지 않는 문제가 있었고 안정성이 떨어지는 방식은 지원에서 제외 되었습니다.그리고 nodejs 특징인 Single Thread 기반의 Non-Blocking I/O으로 성능적인 이점이 있습니다. (callback 지옥이라는 단점도 있지만..)“socket.io 홈페이지에 문서를 보니 아래 처럼 간단한 것 같은 ….. 금방 만들수 있겠다…”socket.io document는 detail함이 좀 부족한 느낌이다. 그리고 버전업이 되면서 deprecated 메소드나 설정 값들이 많아 혼란 스러워 socket.io object들을 실제로 console.log로 찍어서 객체를 확인 하면서 개발 해야 했다 휴……코드 7.  Server측 코드코드 7.   Client측 코드원래 호수에 있는 오리를 보면 편하게 둥둥 떠있는 것 처럼 보인다. 하지만 물속은 난리다…..물론 기본 설정이나 여러가지를 구현해야 하지만 큰 로직은 수신/송신이라 할 것이 많이 없을 줄 알았습니다.(websocket 서버를 쌩으로 구현하는 예제들도 기본 예제들이긴 하지만..) 하지만 실제로 실무 서비스에 사용하려고 하니 여러가지 고려 대상이 생각보다 많았었고. 지금부터는 실제로 개발 하면서 겪었던 과정을 설명 하려고 합니다.그래서 실무에서 사용할 서버라면 namespace/room/event 트래픽 격리 구분과  public/private/broadcasting 이벤트 전송 방식을 필수로 구현해야 합니다.여기서 부터 멘붕이 왔습니다. 일반 웹서버처럼 세션관리만 신경쓰면 server를 스케일아웃 하더라도 사람이 신경쓸 것이 별로 없는 상황이 아니였습니다. nodejs는 싱글 프로세스라  멀티프로세스를 생성하고 서로 완벽한 clustering이 되어야 했고. 추후 서버 자체의 scale out이 되었을 경우에도 대비해야 하므로 clustering을 구성하는 것은 꼭 필요했습니다. 단순히 세션에 대한 문제 뿐만 아니라 1번 서버 > 1번 프로세스에 접속된 client가 이벤트를 전송하면 나머지 서버 > 나머지 프로세스들에 접속된 client로 이벤트를 전송하기 위해서 프로세스 끼리는 서로 연결되어 데이터가 전/수송이되어야 했습니다.nodejs는 싱글 프로세스라 node cluster로 core 수만큼 프로세스를 생성해야 했고, 멀티 쓰레드 방식이 아닌 멀티 프로세스방식이라 데이터 공유가 되지 않는 특징 때문에  데이터 공유에 대한 처리가 필요했습니다.코드 8. nodejs cluster위 코드 8 처럼 인위적으로 cpu 수만큼 woker를 생성 하고 woker들 끼리 통신 하기 위해서는  master에게 메시지를 보내고 다시 나머지 worker에게  데이터를 전송합니다. (“아.. 뭔가 framework이 알아서 해주는게 아니라 사람이 코드로 저렇게 해줘야 하다니… 사람은 언제나 실수를….”)worker 끼리 이벤트를 전/송수신 하는 매개체로 redis pub/sub 를 이용했습니다. worker 1에 접속된 client가 이벤트를 전송하면 나머지 worker들에게  redis pub/sub을 통해 이벤트를 전송하고 나머지 worker들은 이벤트를 수신받아 자신에게 접속된 client들에게 최종적으로 이벤트 메시지를 전송합니다.그림 5. 클러스터링 구성도스케일 아웃 된 서버에 client가 접속할 때 마다 서버를 달리하여 접속하게 되면 세션문제를 마주하게 됩니다. 그래서 일관성있게 지정된 서버에만 접속 되도록 sticky session을 보통 L4같은 로드밸런서 장비가 해주게 되는데. 물리적인 서버는 로드밸런서가 처리해 준다고 하지만 문제는 node cluster로 생성한 worker들 입니다. 1대의 물리 서버에 worker들이 멀티프로세스로 동작하는 것은 사실 서버가 여러대 돌아가는 것이나 마찬가지 상황! 그래서 worker들의 sticky session 처리는 오픈소스 모듈을 사용에 처리해 주었습니다.(nodeJs 같은 특별한 경우가 아니면 필요 없을 수도….)client는 server와 websocket으로 connection을 유지하고 서로 통신하지만 http로 이벤트를 전송할 수 있는 기능도 필수로  필요합니다.  client가 websocket으로 연결되어 있을 필요는 없고 event 발송만 하면 되는 경우도 필요하고 수신은 websocket으로 송신은 restful api 처리 끝단에 http로 이벤트를 전송하는 방식으로 시스템을 구성 할 수도 있기 때문에 http 이벤트 전송 api도 구현 해야할 필요가 있습니다. 실제로 BROS 에서 콜센터 주문접수처리 하기 위해서 주문의 상세 화면을 보고 있는 경우 고객이 배민앱에서 주문 취소를 하게 되면 주문취소 api 끝단에 http로 주문 취소 이벤트를 송신했고 콜센터 주문접수 화면에서는 바로 고객주문 취소 안내를 표시 했습니다.코드 9. 이벤트 송신 http api서버를 만들어서 띄어 놓긴 했지만 서버에 대한 관리가 필요했습니다.(이런 부분때문에 유료 서비스를 사용하는 것이….) 일단 서버에 접속된 namespace/room별 접속한 client 현황이 필요 했고. 서버의 cpu/memory 등의 정보등이 필요했습니다. 그리고 서버에서 **오류가 발생했거나 멈췄을 경우 즉각적인 notification기능도 필요했습니다.앞서 말한 것 처럼 접속한 client의 수와 이름 과 room 리스트 데이터들은 각각의 worker 프로세스에서 공유 되지 못하고 따로 관리가 되기 때문에 이런 관리 데이터들은 1곳에 저장하고 조회 할 필요성이 생겼고  채팅 기능에서 서로 간 대화 메시지들이 보관되어야 할 저장소도 필요했습니다. clustering 구성시에 redis를 사용하고 있었기 때문에 redis를 활용하여 데이터들을 저장하고 사용했고 client들이 접속 및 room에 join/out 하거 할때 redis에 정보를 update했고 실시간 이벤트로 모니터링 페이지에 전송했습니다.그림 6. 소켓 서버 현황 페이지사실 이부분은 유료 APM 서비스를 사용한다면 바로 해결될 부분이지만 (개발 당시는 사용하지 않았다.. 역쉬 돈이 쵝오!) 그렇지 않는 경우 필수로 오류상황에 대한 피드팩을 즉각적으로 받아야 할 필요가 있습니다. socket.io server를 개발 할 당시에는 winston 모듈을 사용하여 error 레벨의 로그가 남겨지거나 exception이 발생 했을 경우 설정 해놓은 이메일로 바로 전송 되도록 했습니다.개발하면서 다양한 문제들을 접했는데 접속한 client 개수가 낮은 데도 cpu 100%로 서버마비를 겪은 적도 있고 redis는 메모리 저장소이지만 메모리데이터를 파일에 백업을 하는데 백업옵션에 문제가 생겨오류가 발생 했던 일, IE 브라우저에서 접속한 client가 창이 닫혔을 경우 disconnected를 서버가 인지하지 못한 경우등등을 이야기 하고자 합니다.client 수가 많지 않은 상황이였는데 서버접속이 되지 않았습니다. 서버가 죽은 것은 아니였지만 이상하게 CPU 100% 상태였고 원인은 바로 nodeJs 특징인 Single Thread 기반의 Non-Blocking I/O 에서 비동기 이벤트 loop의 가장 적인 sync한 로직 처리 때문에 발생했습니다. 로직을 sync 하게 처리하게 되면 로직이 완료 될 때가지 block이 발생하게 되고 다음 처리 로직은 대기하게 되는데(비동기 처리의 자세한 내용은 링크클릭) 비동기 처리를 한 이유는 redis에서 namespace/room/clientaccount 등의 정보를 저장해놓고 가져올 때 처리한 로직 때문이였습니다.(아뿔싸!) nodejs 비동기 이기 때문에 for loop가 일반적인 동작순서로 수행되지 않습니다 . 아래 예제를 한번 보시죠~코드 10. nodejs loop 동작이러한 특징을 해결하기 위해 async 모듈을 사용하여 for loop를 sync 하게 처리 하도록 했지만 결국 문제를 일으키고 말았습니다.코드 11. 중첩 loop sync 하게 처리하기 위해 async라는 모듈 사용redis에 저장된 서버 현황 데이터를 가져와서 적절하게 조합하기 위해 for loop 가 여러번 사용 되었는데 async라는 모듈의 waterfall 메소드를 사용하면  loop가 수행된 후 결과를 순차적으로 전달함으로 써 sync 하게 처리 할 수 있었지만 사용률이 증가하면서 성능문제가 발생했습니다. 문제의 해결은 !redis는 string, list, set, hash 등의 key/value 구조의 데이터 타입을 지원하므로 RDB 스타일의 복잡한 계층구조로 데이터를 저장하게 되면 데이터를 가져와 조합하기 위해서 복잡한 처리를 하게 되므로 처음 부터 제공되는 데이터 타입에 잘 맞추어 데이터를 설계하고 저장하면 불필요한 for loop문을 줄일 수 있다.socket 서버의 namespace/room/account/socketid 관리 데이터들은 서버의 현황 데이터기 때문에 사실상 file로 백업 될 필요가 없지만 chatting시 채팅방에 입장 후 재입장 시 대화 내용을 다시 보여 줘야 했기 때문에 redis가 재부팅 되거 나 하는 경우에도 영구적으로 기록 되어 있어야할 필요성이 있었습니다.그림 7. 채팅기능redis에서 파일 저장 시  여러가지 옵션들이 있는데 stop-writes-on-bgsave-error 옵션이 yes로 되어 있는경우 파일로 저장하다가 오류가 발생하면 redis의 메모리에 데이터 저장 자체가 안되게 되서 오류를 발생 시킨다 no 변경하게 되면 메모리에 저장하는 행위는 파일 저장 오류과 관계없이 계속 수행하게 된다.이처럼 redis의 옵션에 따른 예상치 못한 오류때문에 socket server에 오류가 발생 하였고 옵션변경으로 문제를 해결했지만 redis 서버자체의 옵션에 대한 정보도 알아놓을 필요가 있습니다.IE에서 Browser 창을 닫는 경우 서버에서 client가 disconnect된 것을 인식 하지 못해 서버측에서 해당 client의 disconnect 처리를 하지 못 하였고 서버 측 disconnect 이벤트에 구현 되어 있던 데이터 처리가 제대로 되지 않아 서버 현황데이터에서 client가 살아 있는 것으로 표시 되는 문제가 발생 하였습니다. client sdk에서 옵션을 추가하면 해결되는 문제 였지만 여기서 꼭 짚고 넘어가야 할 부분이 있습니다. 유료 서비스 또는 오픈소스 라이브러리들은 기본적으로 client sdk를 제공하는데 물론 오픈소스 라이브러리는 서버를 개발 해야 하지만 기본적으로 둘다 안정적으로 connection 관리를 해주고  서버주소, 옵션값 connection, reconnection, connection interval, error 핸들링, 이벤트 전송/수신 등등의 메소드를 제공합니다. 개발자는 제공하는 메소드들만 잘 사용하면 됩니다.javascript WebSocket 객체가 onopen, onclose, onerror, onmessage 등의 기본 메소드들을 제공하지만  WebSocket 객체로 client를 쌩으로 개발 하게 된다면 connection 관리가 불안하거나 장애를 경험하면서  안정적이 되어 가는 과정을 겪을 수 있을 수도 있습니다. 선택은 각자의 몫이지만 실시간 이벤트 서버를 사용해야 한다면 최대한 안정성이 높은 유료서비스를 선택 하고 차선은 오픈소스라이브러리를 사용하여 개발 “쌩”으로 개발 하는 것은 다시한번 고려 해보아야 됩니다…실시간 서비스를 개발 하게 된다면 중요하게 고려해야될 부분은 Browser의 성능입니다. 일반적인 웹페이지에서는 그렇게 와닫는 문제는 아니지만 실시간 서비스는 반드시  Browser의 성능과 마주하게 됩니다. 그리고 실시간 이벤트 서버를 직접 개발 할 것인가 유료서비스를 사용할 것 인가를 결정하는 것인데  서로 장단점을 충분히 고려 해서 최대한 안정적인 방향으로 결정해야 합니다 그렇지 않으면 “배달건이 안보여요~”라는 피드백을 자주 들을 것입니다. ㅠBROS 1.0을 개발 하면서 처음 마주하는 framework와 기술들을 사용하면서 어려움도 있었지만 무척 흥분된 상태로 일했었습니다. 퇴근 하면 거의 매일 코딩했고 주말에도 거의 대부분 코딩으로 보냈습니다. (출근해서 어서 코딩하고 싶다는 생각이 들었습니다  신기하게도 말이죠) 회사를 다니면서 실무를 하면 현실적으로 이런 경험을 하기는 쉽지 않지만 몇가지 상황이 충족이 되었기 때문이였던 것 같습니다.  일단 오프라인(라이더센터와 사업적인)이슈들에 더 집중 되면서 다음 개발 이슈들에 대한 기간적인 여유가 약간 있었고, 처음 접해보는 신기술?(그때 당시에는)로 개발 하면서 흥미가 높았습니다.(와~~ 웹페이지가 새로고침 없이 막 움직인다 움직여~). 또한 개발에 집중 할 수 있도록 챙김이님의 배려의 가 있었기 때문이 아니였나 생각이 듭니다. (늦게 나마 다시한번 회사와 동료들에게 감사 드립니닷~~) 끗!",http://woowabros.github.io/woowabros/2017/09/12/realtime-service.html,woowabros,"mysql,php",NULL,2017-09-12
우아한테크캠프: 좋은 개발자가 되고 싶다면,"안녕하세요, 지난 8월 31일을 끝으로 우아한테크캠프 - iOS 개발 인턴 과정을 마친 김다인입니다. 두 달동안 진행되었던 인턴십 프로그램을 통해 제가 무엇을 배웠고 경험할 수 있었는지를 공유해드리고자 합니다.우아한테크캠프는 좋은 개발자가 되기 위해서 필요한 실제적인 것들을 집중적으로 배우고 경험해 볼 수 있었던, 개발자 지망생들과 주니어 개발자들에게 있어서 매우 유익한 시간이었습니다.저는 개발자로서 실무에 필요한 능력들을 키우고 싶어 기업의 인턴십 프로그램들을 찾아보고 있었고, 그렇게 우아한테크캠프에 참여하게 되었습니다. 그리고 기대한 것 이상으로 많은 것들을 얻게 되었는데요, 두 달동안 캠프를 진행하면서 이곳에서 제가 배운 것들이 단순한 인턴 과정을 통해서는 쉽게 배울 수 있는 것들이 아니라는 것을 점차 알게 되었습니다.무엇이 어떻게 얻어야할지 잘 알지 못하는 상태에서 최고의 선택을 한 것에 대해 정말 감사함을 느꼈습니다.저를 포함해 우아한테크캠프에 참여한 인턴 24명은 회사 개발 조직과는 별개의 공간에서 코드스쿼드 마스터분들의 지도아래 함께 교육을 받았습니다. 흔히들 생각하는 인턴과는 다르게 정말 교육 중심으로서, 진행되는 실무 중 일부를 단순히 경험해보는 것이 아니라 개발자로서 필요한 능력들을 하나부터 열까지 차근차근 배워나갔습니다. 웹/모바일 개발을 기초부터 심화까지 공부하고, 실습과 코드리뷰를 통해 어떤 코드가 좋은 코드인지를 알게 되었습니다. 또한 웹/모바일 공동 프로젝트를 4명이 한 팀이 되어 진행하면서 협업 과정을 실제적으로 경험하고, 설계부터 배포까지 함께 서비스를 만들어 나가는 과정이 어떤 것인지를 배울 수 있었습니다.동시에 피플팀분들의 여러 이벤트, 이사님들의 귀한 강연, 그리고 개발자 런치 및 멘토님들과의 교류 등을 통해 우아한형제들이 어떤 조직인지, 어떤 비전과 가치관들을 가지고 있는지, 어떻게 그것들을 성취해나가고 있는지를 자세히 엿볼 수 있었습니다.앞으로 우리 회사가 계속 성장하고 싶고, 좋은 신입/주니어 개발자를 채용하여 그 성장을 지속하고 싶다면, 회사가 지금까지 받았던 도움을 이 업계에 다시 환원하고, 그를 통해서 다시 도움을 받는 것이 필요한 것 같습니다. - 우아한 테크캠프 참가자를 모집합니다. 중에서모든 일정이 정말 유익한 시간이었습니다. 이런 귀한 시간들을 마련해 준 우아한형제들의 훌륭한 의식 수준에 감탄하면서 세상이 아직 살만한 곳이구나 또 깨닫게 되었습니다.첫 주차에는 이후 프로젝트를 같이 해 나가게 될 팀원들과 함께 팀 홈페이지 만들기를 진행했습니다. 이 과정에서 html/css 기본과 AWS기반 리눅스 서버로 웹페이지를 서비스하는 법을 배웠고, 이와 더불어 있었던 여러 미션들을 수행하면서 팀 빌딩의 시간을 가졌습니다. 2~4주차에는 모바일과 웹 각각 12명씩 두 트랙으로 나뉘어 따로 교육이 진행되었습니다. 제가 있었던 모바일 트랙에서는 Swift 기초와 개발환경 구축부터 시작해 MVC패턴과 Delegate, 나아가 동시성 해결, 소프트웨어개발 방법론, 앱 사용성 분석까지 iOS 개발에 있어서 기본부터 심화까지의 내용들을 여러 실습과 함께 익힐 수 있었습니다. [이 많은 것들을 한 달동안 배웠다니!]수업 중간마다 실습과 함께 자신의 코드를 사람들에게 공개하며 발표하는 시간을 가졌습니다. 자주 해볼 수 없는 경험이었고, 특히 마스터분들로부터 자신의 코드에 대해서 직접적인 코칭을 받은 것들은 좀 더 나은 코드를 만드는 개발자가 되어갈 수 있는 큰 양분이 되었습니다.  또한 페어프로그래밍 경험들을 통해 동료가 작성한 코드를 이해하는 연습을 해볼 수 있었고, 동시에 다른 이가 이해할 수 있도록 코드를 작성할 수 있어야 한다는 것을 알게 되었습니다. 이 시간들은 결국 동료들과 함께 성장하는 것에 있어서 익숙한 태도와 분위기를 갖게 해주었다고 느낍니다. [코드리뷰 중 신박했던 노티키: 노티야 일하자!]5~9주차 동안 이루어졌던 프로젝트의 모든 과정들은 배움의 연장선에서 진행되었습니다. 팀규칙 만들기부터 기획, 백로그 작성 및 설계, 매주 반복된 플래닝, 스크럼, 개발, 데모 및 회고까지 어떤 결과를 내는 것에 집중하기 이전에 이 모든 각각의 과정들을 조금씩이라도 배우고 알아갈 수 있도록 섬세하게 지도해주셨습니다. 사용자들의 입장에서 어떤 기능이 필요한지를 고민하고, 단순한 기능 구현 발표가 아닌 사용자가 무엇을 할 수 있는지의 관점으로 데모를 하는 모든 시간들은 코드를 작성하고 서비스를 만드는 그 자체보다 그것이 사용자들에게 어떤 가치를 가져다주는지를 더 중요하게 여기는 태도를 가지게 해주었습니다. 또한 한 주간의 일정과 그 주의 마지막 날 데모 과정을 통해 서비스를 배포하는 과정들을 간접적으로 경험해볼 수 있었습니다. 회사 구성원들을 대상으로 한 마지막 날의 시연회는 서비스가 왜 필요한지, 어떤 가치를 가져다주는 지에 대해서 다른 이들에게 설득력 있게 어필하는 법을 연습할 수 있었고 동시에 현직 개발자 분들의 자세한 피드백들을 통해 넓은 시야와 다양한 관점들을 경험할 수 있었습니다. [설계부터 배포까지]어떻게 보면 이것을 위해서 두 달간의 일정이 이루어졌다고 여길 수 있을 만큼 협업에 대한 것들은 테크캠프를 통해 배울 수 있었던 것들 중 가장 귀한 것이었습니다. 협력을 통해서만이 더 큰 혁신을 이룰 수 있다고 믿는 우아한형제들의 가치관과 마찬가지로 협력과정을 강조하는 코드스쿼드의 협업 중심의 교육이 시너지 효과를 이루어 테크캠프의 전체적인 일정 동안 다른 이들과 함께하는 법은 물론 효과적인 협력이 이루어졌을 때 더 나은 결과를 얻을 수 있다는 마인드를 실제적인 경험들을 통해 직접 배울 수 있었습니다. 커뮤니케이션과 갈등 관리, 페어프로그래밍 등을 통해 왜 많은 개발조직에서 단순 프로그래밍 능력보다 먼저 협업할 수 있는 주니어 개발자들을 원하는 지를 깊이 공감할 수 있었습니다.[협력이 더 나은 가치를 만든다]인동소(인턴 동기를 소개합니다), 사내 투어, 따따따워크샵 등 피플팀이 준비해 준 여러 이벤트를 통해서 우아한형제들이라는 공동체가 가진 색깔과 분위기를 인턴들도 함께 느낄 수 있었습니다. 덕분에 독립적인 일정과 공간에서 생활하고 있었음에도 불구하고 우아한형제들이라는 공동체에 대한 소속감과 자부심을 깊이 느낄 수 있었습니다. 여러 이사님들은 강연을 통해서 하나같이 정체성과 관련된 본질적인 이야기들을 해주셨고, 우아한형제들이 어떠한 정체성과 비전을 가진 회사인지 깊이 알 수 있어서 즐거웠습니다. 개발자런치 및 멘토님들과의 만남 등을 통해서는 실제 구성원들이 어떤 분들이고 어떤 생활을 하고 계신지 알 수 있었고, 여러 격려와 조언들을 통해 힘을 얻을 수 있었습니다. [답은… 1번이 확실합니다]우아한테크캠프를 통해 함께하는 즐거움을 배웠습니다. 동료들과 많은 추억과 즐거움을 나누었고, 서로 도움을 주며 함께 성장하였습니다. 앞으로도 분명 다시 마주치게 될 것이라고 믿고 다음을 기약합니다. [함께하는 즐거움]귀한 시간이었던 만큼 정말 많은 분들의 수고와 노력이 있었을 것이라는 생각이 듭니다. 정말 감사합니다. 우아한형제들, 코드스쿼드, 그리고 techHR 분들께, 앞으로도 우아한테크캠프가 더 나은 모습으로 계속되어서 이를 통해 이루고자 하셨던 귀한 비전이 성취되기를 소원합니다. 부족한 글을 끝까지 읽어 주셔서 감사합니다.",http://woowabros.github.io/woowabros/2017/09/06/dain-techcamp.html,woowabros,,NULL,2017-09-06
"넌 강해졌다, 돌격해!","안녕하세요. 우아한 테크캠프 iOS 개발 인턴이었던 김준영입니다. 지난 8월 31일에 우아한 테크캠프를 마쳤습니다. 좋은 책을 다 읽은 것처럼 아쉬움과 기분좋은 여운이 남아있네요.테크캠프에서 배운 점이 학부에서의 몇년보다 많아서 꼽기 어렵습니다만, 그래도 그 중 몇 꼭지를 꼽아 우아한 테크캠프에서 무얼 경험했고 배웠는지를 공유하고자 합니다.배달의 민족을 필두로 세상을 바꾸고 있는 우아한 형제들과 코딩교육으로 가치를 만드는 코드스쿼드의 역대급 콜라보 교육과정입니다. 개발 인턴과 흡사하지만, 일반 인턴과정과는 달리 코드스쿼드의 마스터님들이 직접 가르치실 정도로 교육에 방점이 찍힌 프로그램이었습니다. 또한 개발뿐 아니라 함께, 스스로 라는 가치에 중점을 두고 협업을 위한 방법을 익힙니다. 지원자들 입장에서는 교육 + 인턴 + 실습 + 프로젝트를 모두 잡을 수 있는 기회였죠.iOS 는 코드스쿼드 김정 마스터님께, 웹 프론트엔드는 코드스쿼드 윤지수 마스터님께 3주간 가르침을 받았습니다.  그 과정에는 swift 와 javascript에 대한 지식도 있었고, 코딩을 어떻게 하는 지에 대한 내용도 있었습니다. 그 중, 정말 도움이 되었던 건 어떻게 협업할 수 있는 코드 를 짤 수 있을 지에 대한 조언이었습니다.저와 같은 주니어 개발자(지망생)들은 대부분 혼자 개발을 시작하게 됩니다. 자연스레 기능만 돌아가면 되지! 라고 생각하고 개발을 하는 게 보통입니다. 다른 사람이 제 코드를 읽을 거라고 가정하지 않지요. 하지만 테크캠프는 시작부터 다음과 같은 얘기를 하면서 시작했습니다.코딩은 글쓰기와 비슷합니다. 늘 다른 사람이 내 코드를 읽을 거라 생각하고 작성하세요.이런 가정하에, 다음과 같은 이야기들을 들을 수 있었습니다.이런 이야기를 프로젝트 내내 바로바로 들을 수 있었고, 이는 코드의 방향성을 잡는 데 무척 도움이 되었습니다. 자연스레 기능 구현만이 아니라  같이 일하고 싶은 코드 를 짜는데 방점이 찍히기도 했구요.테크캠프의 프로젝트는 한 서비스를 웹과 iOS 두 방향으로 만드는 것이 목표였습니다. 이에 따라 팀도 웹 FE 두명, iOS 두명으로 구성되었습니다. 여태까지 경험한 프로젝트는 같은 분야의 개발자와만 일하는 데에서 그치는데 반해, 테크캠프에서는 색다른 경험을 할 수 있었습니다.저희 팀은 Google Firebase 로 백엔드를 구축하고 관리했는데요, 같은 데이터베이스를 쓰기 위해서 끊임없이 소통해야했습니다. 웹이 사용자 데이터를 날리면 모바일이 갑자기 뻗어버리는 현상이 있지 않나, 모바일에서 올린 리뷰가 바로 웹에서 뜨게 하도록 해야하고.. 당연히, 한 플랫폼만 개발하는 데에 비해서 고려해야할 변수가 많았습니다. 데이터 구조에 대해서 합의해야 했고, 데이터를 업데이트하는 방식도 이야기를 꾸준히 나눠야했습니다. 데이터의 메이저 변경점이 있으면 즉각적으로 모두가 알아야했구요. 이를 위해 어떻게 변경점을 알릴 것인지 합의 했고, 협업도구를 통해 모두가 변경사항을 알 수 있도록 했습니다.[데이터 구조 설계]같은 서비스라는 느낌을 주는데도 애로 사항이 있었습니다. 같은 스펙을 구현해야 했구요, UI에서도 사용자에게 동일 서비스를 사용하는 느낌을 주기 위해서 끊임없이 얘기해야했습니다. 때문에 서로의 서비스를 사용해보면서 중간 지점을 찾고 타협하는 과정을 거쳤습니다.이렇게 협업을 해보니, 한 서비스를 만들어내는 개발자분들 (특히 우아한 형제들)이 너무 대단하게 느껴졌습니다. 일의 절반은 커뮤니케이션 비용이라는 말도 절감했구요. 다른 사람들과 같이 일하기 위해서는 꼼꼼한 설계 후 개발도 꼭 필요하다는 점을 느꼈습니다.저희 프로젝트는  유난히 뷰가 많은 편이었습니다. 직접 뷰를 짜본 경험이 적어 헤매던 중,  마스터님께서 Cocoa Controls  를  소개해주셨습니다. Cocoa Controls에는 다양한 iOS UI 컴포넌트 오픈 소스들이 올라와있는 사이트입니다. 마침  기본 검색 뷰는  앱의 테마 방향과 어울리지 않아, 이 검색뷰를 참고해서 사용하게 되었습니다.그런데 막상 소스를 받고 보니 저희 앱에 맞게 고쳐야할 점들이 있었습니다. 일단 영어로 된 항목을 한글로 고쳐야했습니다. 그리고 검색 결과를 누르면 원하는 화면으로 가도록 해야했고, 텍스트가 하나하나 입력 될 때마다 검색하는 방식이 아니어야했습니다. 고치고 나서 원하는 대로 동작 하는지 확인해야 하니, 오픈 소스가 어떻게 작동하는 지 알아야했습니다. 이 과정에서 데모를 돌리고 파일을 하나하나 뜯어 보았습니다.원하는 대로 고치고 나니, 또 하나의 고민이 생겼습니다. 이렇게 고친 소스를 팀원과 공유해야하는 문제였습니다. swift의 의존성 관리 도구는 Cocoa pod를 사용했는데, podfile에 원하는 pod을 등록해놓고 pod install 커맨드로 설치하는 방식입니다. 이때 설치되는 건 물론 제가 고친 소스가 아니라..  원본 소스가 되겠죠. 마스터님께  여쭤보니, 이런 경우  pod으로 관리하는 게 아니라 프로젝트 파일 하위에 포함해서 사용해야한다고 하셨습니다.소스를 고치면서, 오탈자를 발견했었습니다. 침착하게 배운대로 저장소를 fork 한 뒤, 변경점을 커밋해서 pull request를 날렸습니다. 그랬더니 짜잔![이삭줍기는 즐거워]저의 첫 오픈소스 기여 기록이 생겼습니다!오픈 소스를 써보기 위해서는 자잘한 지식이 기반이 되어있어야 했습니다. 의존성을 관리하는 법, 프로젝트 구조, git과 github에 대한 이해도 필요했구요. 이런 부분이 막힐 때마다 여쭤볼 마스터님들이 계셔서 빠르게 적용할 수 있었습니다.위에서 잠깐 말씀드렸지만 저희 팀은 Google Firebase로 백엔드를 구축했습니다. 우아한 테크캠프에서 백엔드를 다루지 않는 만큼, 빠르게 프로젝트를 만들기 위한 선택이었습니다. 하지만 프로젝트가 진행될수록 속도에 대한 답답함이 생겼습니다.다른 팀들처럼 api 서버를 만들 수는 없을까?테크캠프에서는 AWS에 express를 올리는 실습을 간단하게 다뤘었습니다. 그래서 인지, 배워서 해볼 만 할 거라는 자신감이 생겼습니다. 다른 팀들 중에는 rails로 백엔드를 구축한 팀이 있어, django도 되지 않을까? 하는 생각이 들었구요. 결국 django를 AWS  EC2에 올려서 돌리면 되는 거 아냐? 하는 생각에 도달했습니다. 바로 정호영 마스터님께 질문했습니다.[호눅스님은 구글 그 자체이신게 틀림없다]바로 그 주 주말, 추천해주신 튜토리얼을 기반으로 django rest framework 를 공부하기 시작했습니다. djangorestframework 와 django-rest-swagger 를 적용하는 내용의 튜토리얼을 따라간 결과, 하루 정도 만에 원하는 대로 구현하는 데 성공했습니다. [이렇게 쉽게 API가 만들어지다니]교육동안 swift에서 json을 받아오는 걸 배웠으니, 앱에 연동하는 건 쉬운 일이 되었습니다.아쉽게도 결국 프로젝트에는 drf를 적용하지 못했습니다. 다만 배운 건, 지식이 하나씩 늘 수록 할 수 있는 건 몇 배로 불어난다는 점이었습니다. 이전에는 aws도, git, api 도 잘 몰랐기 때문에 조금만 더 배우면 api 서버 구현을  할 수 있다는 사실 자체를  몰랐습니다. 또한 그때 그때 잡아 주시는 마스터님 덕분에 시간 낭비하지 않고 용감하게 배워볼 수 있었죠. 그래서인지 팀원들도 파이썬으로 크롤링을 배워 바로  프로젝트에 적용하는 등 다른 공부에도 도전한 모습이 기억납니다.우아한 형제들에는 매주 목요일마다 CTO실 전체가 랜덤하게 점심을 함께하는 ‘개발자 런치’ 문화가 있습니다. 감사하게도 테크캠프 인턴들이 교육기간 동안 이 런치에 참여할 수 있었습니다. 또한 강연과 대담 시간에도 개발자 분들이 조언을 아끼지 않으셨죠. 그래서 저희는 우아한 형제들의 개발자 분들의 이야기를 들을 기회가 다양하게 있었습니다.그 중 인상깊게 남았던 것 중 하나가 개발자로서의 재능에 대한 얘기였습니다.개발자 지망생들의 고민 중 하나는 분명 내가 재능은 있는거야? 입니다.웹FE 개발자분들과의 대담 중 이 질문에 대한 대답을 들어, 여기에 일부를 옮깁니다.사실 개발에 지치고, 개발이 배우기 어렵고 하는 건 항상 있는 일이에요. 재미가 없을 수도 있어요. 그럴 때마다  ‘내 적성은 이게 아닌가? ‘ 하는 분들을 봅니다. … 지금 개발이 좋다고 하면, 스스로의 모티베이션을 만들어가는 노력을 해보세요. 다른 사람이 ‘이래야한다’ ‘이렇게 하자’ 라고 어떤 근사한 동기부여를 해도 그건 자기 것이 아니거든요. 스스로 나아갈 줄 아는 게 재능이에요.테크캠프 인턴 친구들에게도 많이 배웠습니다. 이 친구들은 참 이상합니다. 분명히 6개 팀으로 나뉘어서 서로의 프로젝트를 발표해야하는 데 경쟁심이 없습니다. 다른 팀이 막히는 부분을 소스코드를 같이 보면서 고쳐보고, 모르면 찾아서라도 알려줍니다. 좋은 소스가 있으면 공유하고, 데모가 잘 안되면 진심으로 안타까워합니다. 서로의 서비스를 적극적으로 사용하면서 개선점을 말해주고 갑니다. 이런 태도와 분위기 덕분에 누구나 모르는 걸 부끄러워하지 않고 적극적으로 배울 수 있었습니다.꿈같던 테크캠프가 끝나고 이제 현실로 돌아갈 때가 되었네요. 이런 기회를 제공해주신 우아한 형제들, 코드스쿼드, techHR 팀분들께 너무 감사합니다. 만약 후에 테크캠프 지원을 망설이시는 분이 있다면, 더 강한 개발자가 되기위해서 꼭 지원하세요. 이보다 더 행복하게 성장할 기회는 많이 없으니까요. 부족한 글 읽어주셔서 감사합니다. [넌 강해졌다, 돌격해!]",http://woowabros.github.io/woowabros/2017/09/05/juneyoung-techcamp.html,woowabros,,NULL,2017-09-05
우아한테크캠프 - 8월의 일기,"유난히도 더웠던 8월. 7월에 배운 교육 과정을 바탕으로 참가자 분들이 스스로 프로젝트를 기획하고 개발하는 실습 과정을 가졌습니다. 이번 프로젝트는 나 혼자 개발이 아닌 함께 하는 개발의 의미를 찾는 과정으로 그 동안 경험하지 못했던 협업을 통해 서로 부딪히고, 조율하고, 부족한 부분을 채워가는 시간이었습니다.기획서 작성을 시작으로 8월 프로젝트의 첫 단추를 끼웠습니다! 의견들이 다양하여 조율하는데 어려움을 겪었지만 프로젝트의 첫 시작이니 만큼 다들 설레고, 적극적인 모습을 보여주었습니다. 또한 개발 시작 전 git & github 기반 협업과정을 통해 서로 공유하고 관리하는 법을 이해하며, 프로젝트에서 가장 중요한 협업을 재차 강조 하였습니다.평소라면 늦잠 자고 가족, 친구들과 여행 다니며 즐겁게 보낼 수 있는 여름방학이지만, 힘들다는 투정 없이 늘 밝은 모습으로 참여해 준 참가자 분들을 위해, 저희 캠프 운영진들은 고마움과 8월 프로젝트를 응원하는 마음을 담아 잠시 쉬어 가는 시간을 마련 하였습니다. 7월의 교육 과정을 잘 마친 서로를 격려하며  본격적으로 프로젝트 개발 전 사기 충전과 팀워크를 다지는 시간이 아니었을까 생각합니다.  프로젝트의 완성도를 높이기 위한 배민 디자이너들과의 협업이 있었습니다. 어색하고 설레는 첫 만남 후, 프로젝트를 시작하자 마자 쏟아지는 참가자 분들의 열정에 디자이너 분들도 내심 긴장하며 서로에게 자극이 되는 시간이었습니다. 실무로 바쁜 와중에도 참가자 분들의 프로젝트를 위해 디자인 작업 및 피드백을 아끼지 않는 모습을 보며 우아한테크캠프에 대한 디자이너 분들의 많은 관심을 엿볼 수 있었습니다.  우아한테크캠프는 모바일과 웹 두 트랙으로 진행한 교육형 인턴 프로그램입니다.  교육에 참여하고, 프로젝트를 진행하면서 가장 궁금했던 배민의 iOS와 웹 FE란 무엇인지, 어떻게 진행되고 있는지 실무자의 목소리로 생생하게 들을 수 있는 만남의 장을 마련 하였습니다. 그 외에도 개발자 선후배의 입장으로 iOS 개발자, 웹 개발자로서 진로나 개발자로서 겪는 일들에 대한 생각을 공유하는 의미있는 만남이였습니다.  캠프 운영진과 강사진이 이틀 동안 24명의 캠프 참가자 분들을 한 명 한 명을  만나  이야기를 나누는 근황Talk를 진행 하였습니다. “요즘 어떻게 지내는지? 캠프를 진행하는 동안 가장 좋았던 점이나, 힘든 점은 없었는지? 팀 프로젝트를 하면서 힘들지는 않는지? 이번 캠프를 통해 개발자로서 한 층 더 성장한 것 같은지?”  등의 질문과 답변을 통해 서로 피드백을 주고 받는 시간이었습니다. 24명 모두 캠프에 대한 만족도가 매우 높았고, 시간이 금방 가는 것에 대한 아쉬움을 함께 나누었습니다. 참가자 한 명 한 명 만난 이 시간을 통해 인턴 분들도 그 동안 캠프나 회사에 대해 궁금했던 점이나 개발자로서의 성장에 대한 고민을 나누는 기회가 되었고, 한층 더 가까워진 계기가 되었습니다.캠프가 끝나 갈 무렵, 플래닝 - 스크럼 - 개발 Iteration - Demo와 회고의 반복으로 조금은 지친 참가자 분들을 위해 다같이 웃고 떠들며 힐링 할 수 있는 WWW워크숍을 준비 하였습니다. 서로가 얼마나 잘 알고 있는지를 확인하는 OX퀴즈와 배달의민족 장안의 화제인 비욘드치킨(일명, 치믈리에)를 진행 하였습니다. 팀 프로젝트를 하느냐 평소 다른 팀과의 교류가 적었던 분들의 아쉬움을 달래고, 프로젝트로 지친 몸과 머리를 재충전 하는 즐거운 시간 이었는데요. 인턴 분들의 끊이지 않는 웃음소리와 미소 가득한 얼굴을 보며 진행하는 피플팀도, 준비한 운영진도 뿌듯함을 느꼈습니다.  8월 31일. 우아한테크캠프가 드디어 두 달 간의 여정이 끝났습니다. 팀 별 프로젝트 Demo와 전체 회고를 통해 지난 두 달을 돌아보는 시간을 가지며 서로의 결과물을 공유하고 격려하였습니다. 또한 7월 교육과 8월 프로젝트의 결실을 맺는 시연회를 가졌는데요. 평소 우아한테크캠프에 관심이 많았던 우아한형제들 개발자 분들이 줄을 서서 대기 할 정도로 많이 참여해 주셨습니다. 단순히 결과물을 살펴 보는 것에 그치지 않고, 질문과 피드백을 통해 애정 어린 관심을 표현하였습니다. 캠프 운영진과 강사진 모두 상기된 얼굴과 들뜬 목소리로 결과물을 시연하는 참가자 분들의 모습에 흐뭇하지 않을 수 없었습니다. 근 한 달 동안 개발한 결과물임에도 불구하고, 기대 이상의 전문성이 돋보인 이번 프로젝트 결과물은 많은 분들의 호평으로 마무리 되었습니다. 서동욱 참가자 - 모바일 개발매일 아침 커피를 사고 회사의 내 자리에 앉고, 팀원들이 다 도착하면 커피 한 모금 마시면서 오늘 각자 어떤 일을 할지 말하고, 하루를 열심히 일하다가 퇴근 전에 모여서 오늘 어떤 일을 했는지 정리하는 시간을 갖고…. 이런 하루들이 모여 내가 아닌 우리가 만든 프로젝트의 결과물을 보고 있으면 놀랍습니다.  혼자서는 쉽게 포기했을 것 같은 프로젝트가 이제는 실제로 써볼 수 있는 제품으로 만들어졌다는 게 말이죠. 협업의 힘을 느낄 수 있었던 캠프였습니다.첫 한 달은 IOS app를 만들기 위한 지식을 배우는 시간 이었다면 남은 한 달은 그 지식을 협업의 장에서 사용해 보면서 지식이 아닌 본인의 지혜로 만드는 시간이었습니다. 개발을 업으로 삼고 싶은 사람이라면 꼭 참여해야 하는 캠프가 바로 이 우아한테크캠프라고 자신 있게 말할 수 있습니다. 기획부터 개발 그리고 유지보수까지 개발자가 하는 일들의 일련의 과정을 직접 해볼 수 있었습니다.진로를 개발 쪽으로 바꾸고 있는 시기였는데, 저에게 이번 우아한테크캠프는 정말 인생의 전환점이었습니다. 이 기회를 제공해준 우아한형제들, 그리고 모든 과정에서 항상 가르침을 주셨던 코드스쿼드 마스터분들께 감사합니다.박진수 참가자 - 웹프론트엔드 개발프로그래밍은 필요에 의해서 만들어나가는 과정입니다. 지금까지는 재미로 해왔지만 이제는 팀의 일원으로서 해야만 하게 되었습니다. 프로젝트를 하면서 정말 친한 친구보다 더 많이 얘기를 나눈 사이가 된 우리들. 이견과 의견이 난무하는 회의 속에서 마침내 기획을 확정하고 모든 팀원이 생각하는 방향을 하나로 모았을때 안도감. 막상 처음부터 끝까지 페어프로그래밍으로 웹페이지를 만들자고 했을땐 걱정했지만 고생하고 노력한 만큼 좋은 결과물이 나와 느끼는 이 뿌듯함. 마음먹은 대로 잘 되지 않아 고생도 많이 했지만 테크캠프에서 보고 듣고 느끼며 경험한 것들이 피와 살이 되어가고 있다는 것을 느끼고 있습니다.서로 다른 사람들을 만나 이야기하면서 때로는 자극을 많이 받기도 하고, 때로는 누군가에게 자극을 주기도 하면서 생활해 왔다는 점이 놀랍습니다. 제게 테크캠프는 성장과 함께 물음표를 가져다 주었습니다. 테크캠프가 끝나더라도 개발자가 되기 위한 개발과 공부를 게을리 하지 않을 것입니다. 개발을 생각해보거나 지망하고 있는 사람들에게  우아한테크캠프는 정말 큰 기회이자 터닝 포인트가 될 수 있다고 생각합니다.어디서도 쉽게 배우기 힘든 프론트엔드를 즐겁게 가르쳐주신 코드스쿼드 마스터님들과 즐거운 인턴 생활을 위해 물심양면으로 도와주시고 궁금한 점이 있을때마다 아낌없이 말씀해주신 우아한형제들 분들에게 깊이 감사드립니다. 2017년의 뜨거운 여름. 짧기도 길기도 했던 우아한테크캠프가 끝났습니다.  부족한 부분도, 아쉬운 부분도 많았지만 열정 넘치는 24명의 참가자 분들과 진정성과 전문성을 겸비한 최상의 교육을 제공해주신 코드스쿼드 마스터 님들, 그리고 우아한테크캠프에 많은 관심을 가지고 지원해주신 우아한형제들 구성원들 덕분에 무사히 잘 마칠 수 있었습니다.  개발자로서 멋있게 성장할 우아한테크캠프 참가자 분들을 응원하며 다시 만날 때 까지 뜨거운 안녕 ! : D",http://woowabros.github.io/woowabros/2017/09/04/woowa-techcamp2.html,woowabros,"vue,angular,jquery,css,android,react",NULL,2017-09-04
Mqtt Stress Test,아래의 링크의 글을 읽고 오시면 이 글을 읽는데 도움이 됩니다.(아마도?) MQTT 적용을 통한 중계시스템 개선 조만간 Mqtt를 사용하는 새로운 업주용 솔루션이 늦어도 올해안에는 출시될 예정입니다.  그동안 RESTFul API 기반의 주문정보 조회시스템은 안정적으로 잘 동작했으나 Multi Agent기반으로 확장하기에는 태생적인 한계로 몇가지 문제점을 안고 있었는데요. RESTFul API는 Connection이 유지된 상태가 아니므로 서버에서 즉시 클라이언트로 정보를 전달할 수 없고 (이것이 가장 큰 문제)  Multi Client기반으로 데이터를 전달하기 위해서는 등록되어 있는 클라이언트에 대칭되는 데이터를 서버에 준비해야 합니다.  또한 이 데이터를 클라이언트가 중복되거나 누락되는 일 없이 전달되도록 치밀하게 처리해야 합니다. 예를 들면 클라이언트가 접속하기 전 생성된 데이터를 받을 수 있도록 서버 정보를 갱신해야 할지 라던가  클라이언트가 받아가지 않고 종료된 데이터를 어떻게 삭제해야 할 지를 고민해야 하죠.  (물론 이런 문제는 Mqtt를 사용하더라도 Plan B로 처리해야 합니다.) Mqtt를 사용하기로 결정이 나고 서버를 올렸으나 이것은 적어도 우아한형제들에서는 한번도 적용해 본 적이 없는 새로운 시스템.  아무도 얼마나 성능이 나올지 얼마나 안정적으로 돌릴 수 있을지 감이 없습니다.  하여 간단히(?) 테스트 프로그램을 작성해서 스트레스 테스트를 해보기로 했습니다. 테스트를 위해서는 아래와 같은 기능이 필요했습니다.대충 Controller를 하나 만들고 그 프로그램이 Mqtt Client를 생성하는 프로그램을 실행하게 하자. PC당 대충 2000개쯤 만들면 되겠지 라고 생각하고 테스트 코드 작성. 느려!!!돌아가는 모양새를 보니 프로세스를 생성하는 부분이 부하가 있거나 Windows Form생성부분에서 부하가 있는것으로 보입니다.  나중에 생각해보니 메모리를 프로세스당 1M만 써도 2000대면 2G가 되더군요.(이래서 수학을 열심히 해야 합니다.) 1000대 정도는 어떻게 되는 것 같은데 2000대는 도저히 테스트 할 수 있는 상태가 아닙니다.  PC당 1000 Connection을 처리하면 예상 테스트 수치 30000대를 처리하려면 PC가 30대가 있어야 합니다.  프로세스당 1개의 Connection을 처리하던 Mqtt Client를 Client당 10개의 Connection을 생성하도록 변경합니다. 적당히 200개 정도 생성하도록 하여 PC당 2000 Connection을 테스트 할 수 있게 되었습니다.  테스트를 수행하다 보니 접속과 종료를 빈번하게 테스트 해야 하는데 이걸 일일이 사람이 처리해야 하는게 너무 귀찮습니다. 테스트를 용이하게 하기 위해 Controller에도 Mqtt를 붙여봅니다. 이제 프로그램만 띄워 놓으면 일괄적으로 테스트를 수행할 수 있게 되었습니다.  테스트를 하다보니 문제점이 발생합니다. Mqtt서버가 다운되니 Controller에 붙어있는 Mqtt까지 같이 다운되어 통제불능 상태가 됩니다.  서로 서버를 분리해야 할 필요가 있습니다. Controller에 서버정보를 고정으로 심고 Stress Test에 사용할 서버정보는 테스트 실행 메세지에 전송하도록 합니다. 테스트 하고 나면 Mqtt Client당 하나씩의 로그를 저장하도록 했습니다.  이 로그를 정리해서 봐야 할 필요가 생겼습니다. 일일이 부탁해서 로그를 취합해도 되지만 이미 PC접수 로그수집을 위해 사용하는 채널을 이미 AWS S3에 운영하고 있으니 이곳에 모아보기로 합니다. 하여 개략적인 전체 구성도는 아래와 같습니다. 결론 아직 계속 튜닝을 진행하고 있는 단계여서 결론을 내리기엔 성급하지만 Mqtt는 ‘가벼운 클라이언트’를 위해 서버는 많은 일을 하고 있는 것으로 보입니다.  몇만대 수준의 Connection을 이루기 위해서는 서버의 튜닝과 더불어 클라이언트의 subscribe와 ping과 같은 부분도 세심하게 조절해야 할 것 같습니다. 테스트 일정이 뒤로 밀리면서 테스트가 끝나지 않았는데 글을 발행하게 되었습니다. 다음에 기회가 되면 After Service로 찾아뵙도록 하겠습니다.,http://woowabros.github.io/experience/2017/08/28/mqtt_stress_test.html,woowabros,,NULL,2017-08-28
Hystrix! API Gateway를 도와줘!,"안녕하세요. 배민FRESH 서비스를 개발하고 있는 조건희입니다.오늘은 API Gateway를 사용하면서 겪은 뼈아픈(?) 장애 사례와 해결 과정을 간단히 공유하고자 합니다. 너무 자세하게 쓰지는 않았습니다. 관련된 링크를 충분히 공유하오니 양해 부탁드립니다.어느 날 저녁 평소보다 많은 트래픽이 갑자기 유입됩니다. 보통 마케팅이나 모바일 앱 푸시 일정이 공유되지만, 이날은 예고 없이 찾아왔습니다.그림 1. 요청 수 추이그런데 이 중에서 꽤 많은 비율로 502 Bad Gateway 응답이 발생합니다. (어흑)그림 2. 요청 수와 502 응답 수 추이어디서 502를 응답한 걸까요? 확인해 보니 저희가 사용하고 있던 API Gateway에서 발생했네요. 더는 문제가 지속되지는 않았지만, 원인 분석과 추가 조치가 필요해 보였습니다. 마침 그날은 앞으로 API Gateway를 담당하게 될 거라고 전달받은 날이었습니다. 잘됐다 싶었죠. 확인해 보겠다고 했습니다.API Gateway는 왜 502를 응답했을까요? 문제를 좀 더 이해하고 싶었고요. 그래서 502 원인을 추적하기 시작했습니다. 가장 먼저, 502를 응답한 URL들을 통계 내어 살펴봤습니다. 별다른 특이사항이 보이지 않네요. 다음으로는 서버 로그를 살폈습니다. Root Cause Exception에 다음과 같은 메시지가 보입니다.처음 보는 메시지입니다. 일단, 예외가 발생한 지점의 코드를 열어 봤습니다. 코드는 많이 단순화시켰으니 주의하세요!executionSemaphore.tryAcquire()가 거짓을 반환해서 발생한 거군요. 참고로, 저희는 API Gateway의 한 구성요소로  Hystrix를 사용하고 있습니다. 위 코드는 Hystrix의 AbstractCommand 부분이고요. getExecutionSemaphore 부분의 코드도 잠깐 살펴봤습니다.아직 뭔지는 잘 모르겠지만 어쨌든 SEMAPHORE 여부를 판단하고 있습니다. 그리고 좀 더 코드를 따라가 보면, 발생한 예외가 ZuulFilter의 구현체인 RibbonRoutingFilter에서 잡히고요. 바로 여기서 502 응답을 만들어 반환합니다.그렇습니다. 저는 평범한 개발자입니다. 이 코드만을 보고 해결책을 찾아낼 리가 없죠. 하지만 적어도 502는 Hystrix가 만든 것이고, RibbonRoutingFilter에서 HystrixRuntimeException을 처리한 결과임은 알 수 있었습니다.현재 저희 API Gateway는 3가지 라이브러리를 사용하고 있습니다.그중에서도 Hystrix가 예외를 발생시켰고요. 따라서, 이 녀석에 대해 좀 더 살펴보기로 했습니다. 다음은 Hystrix에 대한 간단한 설명입니다.In a distributed environment, inevitably some of the many service dependencies will fail. Hystrix is a library that helps you control the interactions between these distributed services by adding latency tolerance and fault tolerance logic. Hystrix does this by isolating points of access between the services, stopping cascading failures across them, … (중략)- 출처: Hystrix Wiki, What is Hystrix?요약하면 이렇습니다.“장애 내성fault tolerance과 지연 내성latency tolerance을 가진, 분산된 서비스들 간의 통신을 돕는 라이브러리”Spring Getting Strated, Circuit Breaker에서는 Hystrix를 Circuit Breaker 구현체라고 소개하기도 합니다. 그리고 Hystrix, How it Works 문서는 Hystrix의 내부 동작을 잘 설명하고 있는데요. 여기서 아래의 순서도를 만날 수 있습니다.그림 3. Hystrix Command 동작 순서도 (크게 보기)어? 그런데 이 그림에서 4번, 5번이 유독 눈에 들어오네요. 저는 반가웠습니다. 왜냐구요? 위에서 살펴봤던 코드를 그대로 표현하고 있기 때문이었죠. 저만 반가운 건 함정.이번에는 application.yml 파일을 살펴봤습니다. 저희가 Hystrix를 어떻게 설정하고 있나 궁금했기 때문입니다.어라, 또 한 번 반갑지 않으신가요? 이것도 위에서 살펴봤던 코드와 관련 있고요. 그림 3의 5번 부분이기도 합니다. 아무래도 격리 전략Isolation Strategy을 살펴봐야겠다고 느꼈습니다. 이 때, Hystrix, How it Works를 주로 참고했고요. 한 문장으로 정리하면 다음과 같습니다.“일종의 Bulkhead 패턴이며, 각 서비스에 대한 의존성을 격리하고 동시 접근을 제한한다.”그림 4. Hystrix Isolation위 그림은 Hystrix가 어떻게 의존 서비스들을 격리하는지 보여줍니다. 빨간색으로 표기된 네모 상자는 특정 서비스의 호출이 지연되고 있다는 뜻인데요. 나머지 서비스에는 영향을 주지 않고 있습니다. 또한, 동시 접근 제한을 서비스별로 다르게 설정하고 있습니다.격리의 방법으로는 2가지가 존재합니다.Thread 방식에서는 서비스 호출이 별도의 스레드에서 수행됩니다. 예컨대, Tomcat의 스레드 풀과 서비스에 대한 호출 스레드가 격리되는 거죠. 이렇게 하면 네트워크상의 타임아웃 위에 스레드 타임아웃을 둘 수 있습니다. 하지만 별도의 스레드를 사용하는 만큼 비용이 수반됩니다. 여기서는 이를 가리켜 연산 오버헤드computational overhead라고 표현하네요.한편, Semaphore 방식에서는 서비스 호출을 위해 별도의 스레드를 만들지 않습니다. 단지 각 서비스에 대한 동시 호출 수를 제한할 뿐입니다. 위에서 살펴봤던 코드 덕분에, 내용을 좀 더 쉽게 이해할 수 있었습니다. 아래 그림은 Thread와 Semaphore의 차이를 보여줍니다.그림 5. Thread와 Semaphore의 격리 방식 (크게 보기)위에서 살펴봤던 코드 중에 executionSemaphore.tryAcquire() 부분이 있습니다. 여기 코드를 좀 더 살펴보면, HystrixPropertiesManager.EXECUTION_ISOLATION_SEMAPHORE_MAX_CONCURRENT_REQUESTS를 만나게 되는데요. 이는 execution.isolation.semaphore.maxConcurrentRequests 프로퍼티에 대응하는 상수입니다. 처음에는 이 수치를 좀 더 늘리려고 했습니다. 왜냐면 기존에 저희가 SEMAPHORE를 격리 전략으로 사용하고 있었고요. 여기서 Semaphore 구간에 진입할 수 있는 요청의 수만 늘려주면, API Gateway의 동시 처리량이 늘어날 테고, 그러면 502 발생 가능성이 감소할 거로 생각했기 때문입니다. 프로퍼티에 대한 설명은 여기를 참고하세요. (폴백fallback을 설정한 경우도 가용한 Semaphore 개수의 제한을 받습니다.)하지만 Hystirx Configuration 문서를 좀 더 살펴보면, 아래와 같은 내용이 있습니다.The default, and the recommended setting, is to run HystrixCommands using thread isolation (중략)Commands executed in threads have an extra layer of protection against latencies beyond what network timeouts can offer.Generally the only time you should use semaphore isolation for HystrixCommands is when the call is so high volume (hundreds per second, per instance) that the overhead of separate threads is too high; this typically only applies to non-network calls.HystrixCommand를 사용할 때는 Thread 격리를 권장한다는 내용입니다. (서비스 호출의) 지연으로부터 보호되는 별도의 계층을 가질 수 있으니까요. 그리고 Semaphore를 써야 하는 경우는 유일하다고 합니다. 꽤 강력한 어조네요. 의구심이 생길 만큼요. 바로 “호출량이 너무 많아서 분리된 스레드의 사용이 주는 오버헤드가 큰 경우”이고요. 네트워크 요청이 발생하지 않는 경우non-network call가 보통 여기에 해당한다고 합니다. 좀 더 찾아보니, Netflix API도 아주 일부만 Semaphore를 사용하는 군요. 인메모리 캐시에서 메타 데이터를 가져오거나, Thread 방식에 대한 퍼사드facade에 한해서요.저희가 기존에 Semaphore를 선택한 이유는 성능 테스트 결과가 더 좋았기 때문이라고 합니다. 확인을 위해 다시 한번 테스트해 보았는데요. 여전히 더 나은 속도를 보이네요. 하지만 유의미하게 느껴지는 차이는 아니었습니다. 또 항상 그런 것도 아니었고요. 확증 편향이 시작된 건가! 만약, 설정(재시도, 타임아웃 등)을 안정적으로 관리할 수 있고, 의존 서비스들을 충분히 신뢰할 수 있다면 Semaphore를 선택할지도 모르겠습니다. 연산의 오버헤드 비용이 격리가 주는 이득을 넘어선 시점인 거죠. 하지만 지금은 아니라고 판단했고요. 그래서 Thread로 결정했습니다.지금까지 Hystrix는 무엇이고, 그중에서도 격리가 무엇인지 살펴보았습니다. 그리고 격리 전략은 Thread를 선택하기로 했고요. 이제는 부하 당시 만났던 502를 줄여나갈 차례입니다. 작업 순서를 요약하면 다음과 같습니다.*기본적으로 API Gateway의 동시 처리량과 TPS를 높이는 것이 목표입니다. 이것만으로 부족하다면, 스케일 아웃을 얼마나 해야 하는지 판단 근거를 마련하고자 했습니다.우선 프로덕션 환경과 유사한 테스트 환경을 마련했습니다. 서버 인스턴스는 물론, URL도 부하 당시의 것들을 사용했습니다. 부하가 특정 임계치에 다다르니 API Gateway가 502를 응답하기 시작하네요. 서버 로그에도 “could not acquire a semaphore for execution” 메시지가 찍힙니다. 처음에 만났던 메시지군요.여기서부터는 조금씩 Hystrix 설정을 바꿔가며 부하 임계치를 늘려나갔습니다. 처음에는 API Gateway가 병목이었는데요. 점차 의존 서비스들이 부하를 못 견디는 상황으로 바뀌었습니다. 이대로 만족할 수 없어서, 의존 서비스들의 인스턴스들을 추가 투입해가며, API Gateway의 성능을 개선해 나갔습니다.결과적으로 변경한 설정값은 아래 표의 5가지입니다. 참고로,  zuul.ribbonIsolationStrategy  설정값을 THREAD로 바꾸면, 기본적으로 모든 라우팅에 Hystrix의 스레드 풀이 사용됩니다. 관련 내용은 Spring Cloud Netflix, How to Configure Hystrix thread pools을 참고하세요.표 1. 성능 개선을 위해 변경한 설정과 간단한 설명그 외에도 아래 그림을 참고하여 커넥션 관련 설정을 조정해 주었습니다.그림 6. Hystrix ThreadPool 설정 예시. 출처: Hystrix Configuration, ThreadPool Properties (크게 보기)어느 정도 개선이 되었다고 판단했습니다. 그리고 기존과 달라진 점을 확인했는데요. 먼저 단순 TPS 수치를 비교했습니다. 기존 대비 약 4배가량 성능이 개선되었네요. 동시 처리량도 늘어났고요. 이제 이 수치를 부하 당시에 대입해 보았습니다. 기존 처리량으로는 확실히 (수치상으로도) 부하를 견디지 못하겠네요. 하지만 개선 후에는 더 적은 수의 인스턴스로 더 많은 요청을 처리할 수 있습니다. 정말 다행입니다. 서비스가 열심히 홍보돼서 사용자들이 유입됐는데, API Gateway가 이를 막아버리는 꼴이었으니까요. 요구사항을 만족시키지 못하는 기술이 무슨 의미가 있나요. 관리의 부담만 늘어나는걸요.개선된 내용은 팀에 공유하고 배포했습니다. 현재까지 아무런 문제 없이 잘 사용하고 있습니다 :)지금까지 서비스가 장애를 만난 상황, 부하를 일으킨 지점의 코드, Hystrix와 격리 전략, 개선 내용과 결과를 간략하게 살펴보았습니다. 사실 문서와 코드를 살펴보면서, 궁금한 부분들이 줄어들기는커녕 늘어나기만 했습니다. 해야 할 일도 굉장히 많아 보였고요. 앞으로 꾸준히 문서와 코드를 뒤적거리며 공부해야겠다고 느꼈습니다. 더 중요한 것은 API Gateway를 통해 우리가 해결하려는 문제입니다. 공부를 하다 보면 목적을 자주 잊어버리곤 하는데요. 우리가 왜 이 기술을 쓰는지, 정말 필요한 것인지, 다른 대안은 없는지 꾸준히 고민해야 하겠습니다.부족한 글 읽어주셔서 감사합니다. 끗.",http://woowabros.github.io/experience/2017/08/21/hystrix-tunning.html,woowabros,,NULL,2017-08-21
개발환경을 한 방에! 쉘 스크립트의 힘,"안녕하세요. 우아한형제들 서비스개발실 주문시스템개발팀의 라태웅입니다.어느 개발 조직이건 새로운 사람이 들어오면 그 사람의 PC에 새롭게 개발 환경을 셋팅해야 합니다.이 때, 저는 세 가지 경우를 경험했는데요.1번의 문제는 문서가 노후화되고 사람이 이해하기 쉽게, 따라하기 쉽게 작성하기가 어렵다는 단점이 있습니다.2번의 문제는 전달자가 헷갈리거나 오래되어 잊어버린 경우 굉장한 혼선이 온다는 것, 거기에 신규 입사자 입장에선 이 조직이 과연 이대로 괜찮은가 하는 생각이 들 수도 있겠죠.하지만 3번처럼 쉘 스크립트 한 방으로 셋팅이 된다면?!신규 입사자의 감탄사가 들리시나요!? (와아아아아아아아아아!!!!!!!!!!)들리..십니까? 제 목!쏘리가! 하!늘에!이 글에서는 두 가지 쉘 스크립트를 작성할건데요.첫 번째,보너스로 PHP Codeigniter를 AWS ElasticBeanstalk에 Deploy 해보기.두 번째,이 말인즉슨, 신규 입사자는 첫 번째 쉘 스크립트로 기본적인 AWS 기반의 개발 환경이 갖춰지고, 두 번째 쉘 스크립트로 로컬 환경에서 개발이 바로 가능해진다는 것이죠!하지만 이 글에서는 쉘 스크립트의 문법에 대해서는 다루지 않습니다! 이곳을 참고해주세요! 이 글에서는 쉘 스크립트로 꽤 많은 것을 편하게 할 수 있다는 것을 알려드리는데에 초점이 맞춰져 있습니다.먼저 프로젝트 폴더를 생성하고, 내부에 디렉토리 구조를 만들어봅니다.만들어진 폴더 구조는 아래와 같습니다.이제 쉘 스크립트를 작성해봅니다.이제 이 쉘 스크립트를 실행 가능한 상태로 만들어줍니다.ls -al 명령어로 확인하면 실행 권한이 추가된 것을 확인할 수 있습니다.이제 만든 쉘 스크립트를 실행해 볼까요?패스워드를 입력하면..이것저것 설치를 합니다!AWS Access Key를 넣어주면..이렇게 자동으로 Credential 까지 생기게 되죠!잠깐! 혹시 AWS Access Key가 없으신가요?AWS에 로그인 후 IAM 서비스로 이동합니다.Groups > Create New Group을 눌러 새로운 그룹을 생성합니다.Group Name을 적은 후 Next Step을 누릅니다.테스트용으로 쓸거기 때문에 AdministratorAccess를 체크하고 Next Step을 누른 다음, Create Group을 눌러 그룹 생성을 마칩니다.이제 유저를 생성할 차례입니다. Add User를 눌러주세요.사진과 같이 적은 후 Next: Permissions를 누릅니다.방금 만들었던 SSPJ 그룹에 유저를 추가하고 Next: Review를 누른 뒤, Create User를 눌러 유저 생성을 마칩니다.SYSTEM : 독자이(가) Access Key을(를) 획득했다!이제 다시 돌아와서…먼저, webserver.zip 파일을 다운로드 받고, ~/sspj/webserver 폴더에 압축을 풉니다.AWS ElasticBeanstalk에 관한 설명은 Elastic Beanstalk Configuration files(.ebextensions)에서도 보실 수 있습니다. 나는 쉘 스크립트만 궁금하다 하시는 분은 이 파트를 건너뛰셔도 됩니다!PHP Codeigniter 기반으로 작성된 뼈대 웹서버 인데요. 이를 AWS ElasticBeanstalk CLI로 간편하게 배포해보겠습니다.위의 eb는 AWS ElasticBeanstalk CLI 인데요. 아까 첫 번째 쉘 스크립트가 자동으로 설치해준 녀석입니다. init 명령어를 통해 최초 설정을 해줍니다.서울을 선택해줍니다.새로운 어플리케이션을 만듭니다.어플리케이션 이름은 sspj로 해줍니다.네. 우리의 웹서버는 PHP가 맞습니다.저는 항상 최신 버전으로 개발하려고 노력합니다.이 글에선 안 쓰지만 아쉬우니 SSH Key도 만들어 봅니다.새로운 키페어를 생성합니다.키페어 이름은 sspj-keypair로 하겠습니다.패스워드는 자유롭게 설정합니다.ElasticBeanstalk Application이 만들어졌습니다. 이제 Environment를 만듭니다.Environment 이름과 도메인 Prefix를 설정합니다.로드밸런서는 클래식으로 해봅니다.로그가 찍히더니 성공했다고 나옵니다!웹 콘솔로 접근해보니 잘 배포되었군요!접속도 잘 되구요!이제 다음 배포부터는 정말 간단합니다.정말 쉽죠?그런데 개발할 때 테스트를 위해서 기능을 수정할 때마다 deploy를 하고 수정하고 하는 식은 너무 불편하겠죠. 그래서 이를 Docker로 로컬 환경에서 실행해보겠습니다.두 번째 쉘 스크립트에 작성하기 전에, webserver.zip 파일을 다운로드 받고, ~/sspj/webserver 폴더에 압축을 풉니다. 이미 앞선 파트에서 받으셨다면 받지않으셔도 됩니다.저희는 Docker를 통해 개발 환경을 설정할 것이기 때문에 먼저 Docker를 설치해야 합니다. (이곳(Docker for Mac)에서 설치할 수 있습니다.)먼저 Dockerfile을 만듭니다.Dockerfile에 대한 자세한 설명은 진행하지 않습니다! 이런식으로 쉘 스크립트를 사용할 수 있다고만 봐주세요!Docker에서 바라볼 config 파일을 생성합니다.이제 이 Docker를 자동으로 빌드하고 실행하는 스크립트를 작성합니다.쉘 스크립트 자체는 정말 짧지요?실행해보겠습니다. (일단 실행 권한을 먼저 줘야겠죠?)뭔가 열심히 설치를다 했더니!로컬에서 바로 접속이 됩니다!이번 글에서는 쉘 스크립트를 한 번 만들어두면 개발 환경을 쉽게 구성할 수 있습니다! 라는 것을 전달드리고 싶었는데요… 다 적고보니 뭔가 뒤죽박죽이 된 것 같습니다 -0-…결론은! 이렇게 누군가가 셋업을 해두면, 다음 사람들은 Docker를 설치하기만 하면이 명령어로 바로 개발이 가능하다는 것이죠.여러분의 개발 환경에도 적용해보시는 것은 어떨까요?감사합니다!",http://woowabros.github.io/tools/2017/08/17/ost_bash.html,woowabros,"mysql,php,bootstrap,ruby",NULL,2017-08-17
MQTT 적용을 통한 중계시스템 개선,"주문중계채널은 개별 디바이스들이 중계서버에 일정시간에 한번씩 API polling을 하는 구조로 운영되고 있습니다.  신규주문 뿐만 아니라 주문의 취소나 상태변경과 같은 정보를 전달 받기 위해 API polling을 수행합니다.  바로결제 이용 업소와 바로결제 주문건의 증가에 따라 채널별 디바이스에서 polling이 가파르게 증가하고 있습니다. 이러한 polling 횟수 증가는 대응 API에 부하를 가져와 auto-scale에 의한 instance 수 증가와 이에 따른 운영비용 상승의 원인이 됩니다. 또한 각 채널의 개별 디바이스들의 live 상태를 API 서버를 통해 update 해야 하는데 이전에는 polling API를 live signal로 판단했습니다.  하지만 운영을 진행하면서 개별 디바이스의 live도 명시적 live message를 통해 update 해야 할 필요가 발생했습니다. 이러한 이유로 구조적으로 polling API를 통한 pull 구조가 아닌 서비스 서버에 의한 push 구조로 변경함으로써 해법을 찾으려 했습니다. MQTT Broker를 적용하고 Topic 구조에 Message 발행(publication) & 구독(subscription)을 이용한 EDA(Event Driven Architecture)로의 전환을 계획하게 되었습니다.MQTT(Message Queue for Telemetry Transport)는 M2M 또는 IoT 기기와 G/W의 연동을 위해 정의된 프로토콜입니다. Facebook messenger가 MQTT를 사용했다고 알려져 있습니다(지금도 쓰고 있는지 정확히 어떤 용도인지는 모릅니다). 경량 프로토콜로 저전력 장비에서도 운용 가능하며 network bandwidth가 작은 곳에서도 충분히 운용 가능하도록 설계된 프로토콜입니다. 주요한 특장점은 아래와 같습니다. Connection Oriented * MQTT broker와 연결을 요청하는 client는 TCP/IP socket 연결을 한 후 명시적으로 종료하거나 network 사정에 의해 연결이 끊어질 때까지 연결 상태를 유지합니다. * Topic에 발행된 message와 연결상태 확인을 위한 live(heart-beat)를 항상 유지된 연결을 통해 전달하게 됩니다. * 연결 상태를 유지하는 것은 물론이고 연결이 끊어진 경우 재접속 등의 지원을 위한 자체 기능을 보유하고 있습니다.  Topic 그리고 발행(publication) / 구독(subscription) * 개설된 Topic에 message를 발행하면 해당 Topic을 구독하는 client 들에게 message를 전송합니다. * 따라서 one to multi 또는 one to one message 전송을 모두 지원할 수 있습니다.  QoS(Quality of Service)는 0, 1, 2 세단계를 지원 * 0 : 최대 1회 전송. Topic을 통해 message를 전송할 뿐 꼭 받으리라는 보장은 안해줍니다. * 1 : 최소 1회 전송. 혹시 구독하는 client가 message를 받았는지 불확실하면 정해진 횟수만큼 재전송합니다. (계속 주는 건 좋은데 중복의 위험이 ;;;) * 2 : 등록된 client는 요구된 message를 정확히 한 번 수신할 수 있도록 보장합니다.  다양한 개발언어의 다양한 클라이언트가 지원 * C는 물론이며 JAVA, Node.js, Python 등등 여러 종류의 개발언어로 Broker/Client Library가 존재합니다. * 대부분 유료의 경우 QoS-2까지 지원하고 보통은 QoS-1까지 지원합니다.  각각의 Action에 따른 Notification * Client의 연결, 연결해제, 구독, 발행 등등의 event에 대해서 MQTT broker가 대응할 수 있도록 해줍니다. AWS ElasticBeanstalk + Node.js Module : mosca (Node.js용 module인 mosca를 사용했습니다.) 구조가 단순하지만 필요한 기능의 지원은 모두 가능하고 사용 환경에 따라 customizing 하기도 용이합니다. 필요에 따라 REDIS나 MongoDB를 활용한 storage option도 지원합니다. MQTT broker를 적용해 구성한 멀티채널 중계시스템의 모습입니다.  앞서 발생한 주문 data의 변동내용(신규,최소,상태변경)에 따라 API 서버에서 MQTT broker로 Message 발행하고 MQTT broker를 구독하고 있던 하위 MQTT Broker#1,2에 message 중계합니다.  각 채널에 소속된 개별 디바이스는 어느 MQTT broker를 구독하고 있던 message를 전달 받게 됩니다. 거꾸로 개별 디바이스는 구독하는 MQTT broker#1,2에 live 상태보고를 하고 MQTT broker#1,2는 API 서버를 통해 live 상태를 저장합니다. MQTT를 중계시스템에 적용한 이후 기대하는 효과는 이렇습니다.당초 단말기를 제외한 모든 채널을 MQTT로 통합하고 client에서의 API polling을 보조적 수단으로 지원하는 것을 목표로 했습니다. 그러나 … 주문접수앱 * 추진과정에서 스마트폰의 최근 OS에서 battery와 memory의 효과적 관리를 위한 보호모드로 인해 MQTT 접속이 지속될 수 없음을 확인하게 됩니다. * 이러한 문제를 해결하고자 여러 방안을 시도해 보았지만 현재로서는 실패 ㅠㅠ * 따라서 이 부분은 기약 없이 연기한 상태입니다.  배민 단말기 * 현재 사용하고 있는 단말기가 가진 구조적 한계가 있습니다. 이로인해 단말기도 현재로서는 MQTT를 적용할 수 없습니다. * 차기 모델은 이 부분을 극복해 단말기도 MQTT 연동이 가능하도록 개선할 예정입니다. mqtt.org mosca github joinc mqtt",http://woowabros.github.io/experience/2017/08/11/ost_mqtt_broker.html,woowabros,,NULL,2017-08-11
Elastic Beanstalk Configuration files(.ebextensions),"사내 서버 인프라가 거의 대부분 AWS 환경으로 넘어가면서 신규로 구축되는 많은 시스템들이 배포 및 확장, 관리등의 용이성 때문에 Elastic Beanstalk 으로 구축되고 있습니다. 제 경우에도 AWS 환경에서 신규로 구촉했던 BROS 2.0/신배라/주문지면개편 세 프로젝트 모두 Elastic Beanstalk 을 이용하여 환경을 구축했습니다. 하지만, Elastic Beanstalk이 무조건 장점만 있는 건 아닙니다. 특히나, Elastic Beanstalk 의 경우 사용할 수 있는 platform 이 한정적이며 또한 주어진 platform 에서 서비스에서 사용되는 특정한 라이브러리를 추가하거나 시스템 설정을 변경해야할 경우가 발생하면 쉽게 적용하기 힘든 단점도 분명 존재합니다. 그래서, 이런 단점을 해소하기 위해서 AWS 에서 Elastic Beanstalk 환경을 약간이나마 커스터마이징 할 수 있도록 제공해주는 기능이 .ebextensions 입니다.배포할 서비스에 Elastic Beanstalk 설정을 위한 파일을 추가하고 싶다면 우선 배포될 소스 bundle의 root 디렉토리 아래 .ebextensions 폴더를 추가하고 해당 폴더 아래 설정 파일들을 추가하면 됩니다. 이 때, 설정 파일 뿐만 아니라 설정파일에서 사용되는 기타 다른 파일들도 해당 디렉토리에 포함시키면 설정파일에서 사용할 수 있습니다. 그리고, 설정 파일들은 보통 ###.config 와 같이 작성되는데 확장자는 사실 큰 의미는 없지만, 설정을 위한 파일을 구분하기 위해서 보통 .config를 사용합니다. 설정파일의 적용 순서는 파일명 alphabetical order 순서 이므로, 적용 순서가 중요한 경우 순서대로 ‘00-xxx.config’, ‘01-xxx.config’ 이런 식으로 이름을 주면 됩니다. 여기서 한가지 주의 할 것은 spring-boot 으로 만들어진 application의 경우에 platform 을 tomcat 하거나 혹은 embedded tomcat을 사용하는 경우 platform을 java로 하는 경우가 있는데 두 경우 약간의 차이가 있습니다. 보통 tomcat에 application을 올리는 경우는 war 로 패키징을 하는데 이 경우에는 gralde을 사용해서 빌드하는 경우라면 build.gradle 에서 간단하게war {            from(‘config 파일이 포함되어 있는 소스 경로’) {               into(‘.ebextensions’)             }     }추가해서 빌드만 하면 문제가 없습니다. 하지만, embedded tomcat 을 사용하면서 .jar로 배포하는 경우에는 jar에 저렇게 .ebextenions 폴더를 포함시킬 수 없기 때문에 따로 배포전에 jar 파일과 함께 .ebextenions 폴더를 하나의 zip 파일로 묶어서 배포해야 제대로 설정파일이 적용됩니다.zip -r application.zip application.jar .ebextensions저는 앞선 BROS 2.0/신배라 프로젝트는 tomcat platform을 통해서 war 파일 형태로 배포했었는데, 프로젝트 막바지단계 합류했던 주문지편 개편의 경우에는 java platform 에 jar 형태로 배포되고 있었는데 둘의 차이를 제대로 인지하지 못해서 하루정도 beanstalk 설정이 안되서 헤맸던 아픔(?) 경험이 있습니다. 그리고, 뒤에 다시 언급하겠지만 tomcat/java platform 에 따른 배포는 더 중요한 차이가 있습니다..ebextenions을 통한 설정에서 가장 중요한 것은 당연히 confiuration 파일 통해서 설정할 수 있는 사항들에 관한 것일 겁니다. 이런한 설정 항목을 AWS에서는 key라고 하는데 많이 사용되는 key 항목에는 다음과 같은 것들이 있습니다.Packages - 서비스 구동에 필요한 추가적인 패키지들을 다운로드 받아서 시스템에 install 할 수 있습니다. 기본 문법은 다음과 같습니다.packages:   name of package manager:       package name: versionex) 현재 우아한형제들 사내 시스템의 경우 서버 모니터링 툴로 newrelic을 사용하고 있는데 newrelic 서버 모니터링 패지지의 경우 다음과 같이 추가하면 elastic beanstalk 서비스 배포나 autoscaling시 자동으로 패키지가 설치됩니다.packages:     yum:         newrelic-sysmond: []     rpm:         newrelic: http://yum.newrelic.com/pub/newrelic/el5/x86_64/newrelic-repo-5-3.noarch.rpmSources - 시스템에 필요한 파일들은 압축 파일 형태로 만들어 public url 형태로 다운로드 할 수 있게 만들어 둔 경우 해당 파일은 지정된 위치로 다운로드 받아서 압축까지 풀어줍니다. 기본 문법은 다음과 같습니다.sources:   target directory: location of archive fileex) newrelic APM을 agent 형태로 구동할 때, 필요한 라이브러리를 s3에 올려두고 다음과같이 원하는 위치에 다운로드 받아서 사용할 수 있습니다.sources: /usr/share/newrelic-java: https://s3.ap-northeast-2.amazonaws.com/{bucket-name}/newrelic.zipsource를 사용해서 필요한 파일을 받을 때, 한가지 주의 할 것은 target diectory와 압축이 풀린 파일들의 owner가 기본적으로 ‘root’ 입니다. 따라서, 파일이 사용되는 용도에 따라서 권한 문제가 발생할 수 있으니 필요한 경우 Owner나 mode를 수정해야 합니다.Files - 파일을 만들거나 혹은 다운로드 받을 수 있습니다. 기본 문법은 다음과 같습니다.files: “target file location on disk”:      mode: “six-digit octal value”      owner: name of owning user for file      group: name of owning group for file      source: URL      authentication: authentication name:   “target file location on disk”:      mode: “six-digit octal value”      owner: name of owning user for file      group: name of owning group for file      content: |       this is my content      encoding: encoding format      authentication: authentication name:이때, content 와 source 옵션을 동시에 사용될 수 없습니다.Commands - ec2 인스턴스에서 구동되는 실행 명령을 기술 할 수 있습니다. 뒤에 나오는 Container Commands 와 비슷하지만 둘은 큰 차이가 있습니다. commnads는 container commands 보다 먼저 실행되는데 application과 web server 가 아직 설정되기 전, application version 파일이 적용되기 전에 실행되며 container commands는 application과 web server가 모두 준비되고 application version이 deploy 되기 직전인 상태에서 실행되는 차이가 있습니다. 둘 모두 여러개의 명령어를 한꺼번에 기술할 수 있는데, 이 때 실행 순서는 commnad name의 alphabetical order 순입니다. 기본 문법은 다음과 같습니다.commands:   command name:       command: command to run       cwd: working directory       env:           variable name: variable value       test: conditions for command       ignoreErrors: trueex) Elastic beanstalk에서 신규로 만들어지는 ec2 인스턴스의 시간은 기본적으로 모두 UTC라 다음과 같이 commnads 설정으로 로컬타임으로 변경할 수 있습니다.commands:   01remove_local:       command: “rm -rf /etc/localtime”   02link_seoul_zone:       command: “ln -s /usr/share/zoneinfo/Asia/Seoul /etc/localtime”Container Commnds - 앞서 설명한 commands와 거의 비슷하지만 실행시점에 차이가 있으면, “leader_only” 라는 아주 유용한 옵션을 가지고 있습니다. “leader_only” 옵션의 경우 true로 설정하게 되면 여러 대의 인스턴스로 구성된 서비스에서 오직 한대의 인스턴스에서만 해당 명령이 실행됩니다. 하지만, 실제적 운영했을 때 몇가지 이슈를 발견했는데 뒤에 다시 한번 언급하도록 하겠습니다. 기본 문법은 다음과 같습니다.container_commands:   name of container_command:         command: “command to run”         leader_only: true     name of container_command:         command: “command to run”앞서 tomcat/java platform 에서 war/jar 배포시 배포 파일 생성시 차이점을 언급했었는데. 이 둘은 java 실행 옵션을 설정하는데도 큰 차이가 있습니다.기본적으로 Java plafrom + jar 배포인 경우에는 콘솔에 어떤 항목을 수정하더라도 실제 application 실행 후 ec2 인스턴스에 들어가서 실행된 application 을 확인해 보면 “java -jar application.jar” 로 실행옵션이 적용되지 않는 것을 확인할 수 있을 것입니다. 이는 Elastic beanstalk에 구현되어 있는 java platform deploy process로 인한 것인데, 이 JVM command line 옵션등과 같이 실행 옵션을 변경하기 위해서는 “Profile” 이 필요합니다.Procfile 파일은 앞서 설명한 것 처럼 Elastic beanstalk Java platform에서 JVM 옵션을 설정하거나 혹은 여러개의 jar 파일이 들어있는 서비스를 구동할 때 사용되는 파일인데, 기본적으로 다음과 같이 기술됩니다.web: java -jar server.jar -Xmms:256m cache: java -jar mycache.jar web_foo: java -jar other.jar여기서 cache나 web_foo 라인은 없어도 되지만 web 항목은 필수이며 여기에 메인 application 실행 명령을 줄 수 있습니다. 적용할 Procfile은 패키징시 jar/.ebextensions 디렉토리와 같이 root에 함께 패키징되어야 합니다.zip -r application.zip Procfile application.jar .ebextensions실제 주문지면 개편시 API 서버를 구축하는데 서버 모니터링 APM으로 newrelic 을 사용하기 위해서 “-javaagent:/usr/share/newrelic-java/newrelic.jar -Dnewrelic.environment=dev “ 이 몇줄을 commnad line 옵션으로 주기 위해서 하루 종일 삽질(?)을 한 아픈 기억이 있습니다T_T. 앞서 말했듯이 기존에 구현했던 프로젝트들은 Tomcat + War 여서 AWS 콘솔에 써주면 그만 이었는데 이 녀석은 그게 안되서 반나절쯤 하다가 아직 상용 오픈 안한 서비스여서 그냥 싹 다 Tomcat에 war로 배포할까 진진하게 고민했었던….타이틀이 좀 이상하긴 하지만, Java platform 에서 한대의 서버만 commnad line 옵션을 다르게 줘야하는 경우가 생길 수도 있습니다. 지면개편 프로젝트에서 주문 API의 경우 전사적으로 pinpoint를 사용할 수 있게 되면서, 기존 newrelic 상용계정 한대 + 나머지 서버는 모두 pinpoint 로 모니터링 하게 서버를 구축하고 싶었습니다. 그런데, newrelic/pinpoint 모두 javaagent방식으로 데이터를 수집하다보니 두개의 옵션을 모두 적용하면 둘중 한쪽 or 양쪽 모두 데이터 수집에 문제가 생기는 경우가 발생했습니다. 그래서, 상용 서버는 newrelic agent옵션을 나머지 서버들은 pinpoint agent 옵션을 주려고 했는데 Java platform 에서는 Profile 에서만 해당 옵션을 줄수 있고 이 Profile은 Container Commnads leaer_only 옵션으로 수정하는 시점에는 이미 Profile이 적용된 시점 이후여서 적용해도 제대로 동작하지 않았습니다. 그래서, 구글링으로 방법을 찾아보다가 Profile web 항목에 shell script를 쓸 수 있는 걸 확인해서 다음과 같이 구현했습니다.Profile web : ./run.shConatiner Commnads     006_default_run_sh:         command: cp ./.ebextensions/run.sh run.sh; chmod a+x run.sh         ignoreErrors: true     007_replace_run_sh:         command: cp ./.ebextensions/run_leader.sh run.sh; chmod a+x run.sh         ignoreErrors: true         leader_only: true그렇습니다. Profile 은 container commands 적용 시점에 이미 변경해도 의미가 없지만, Profile 이 web 에서 실행되는 shell script의 경우에는 실제 서비스가 deploy 될때 해당 script를 찾아서 실행될 것이므로 이 shell script를 cotainer commnds leader_only 옵션으로 구분해서 수정했고 실제로 잘 동작됩니다! 한가지 주의할 점은 shell script로 java를 실행할 경우 shell script가 실행권한이 있어야 되므로 위의 command 옵션 마지막 항목에서 처럼 chmod 를 통해서 실행권한을 주는 것을 잊지 말아야합니다.앞서 container commands 설명에서 leader_only 옵션을 잠깐 설명드렸습니다. 여러 개의 인스턴스로 구성된 서비스에서 한 서버만 구동되는 명령어라고 할 수 있는데, 실제 제가 진행했던 프로젝트들에서는 회사의 라이센스 규정상 newrelic APM 상용계정은 서비스당 한대에만 적용가능해서 이 옵션을 통해서 유용하게 설정했던 기억이 있습니다. 하지만, 실제로 운영중에 약간의 이슈를 발견했습니다. 주문 지편 개편 프로젝트의 지편 게이트웨이 서버의 경우 기본 2대의 인스턴스로 운영되지만 주문이 많이 몰리는 피크 타임에는 스케쥴링 걸어놓고 미리 1대 인스턴스를 더 준비해서 총 3대의 인스턴스로 운영하다가 피크타임이 지나면 다시 2대로 운영하고 있습니다. 이 서비스의 경우에는 newrelic APM은 leader_only 옵션을 사용하여 한대의 인스턴스만 상용계정이고 나머지 2대의 인스턴스는 일반 계정으로 APM 을 설정했습니다. 해당 설정으로 1주일정도 운영하면서 newrelic 에서의 모니터링도 큰 문제가 없었는데 어느날 부터인가 상용계정에서 해당 서비스가 모니터링 되지 않더니 엉뚱하게 개발 일반 계정에서 기본 2대/피크시 3대의 서버가 잡히기 시작한 것입니다. 이걸 인지하고 콘솔에서 health 항목을 통해 확인해보니 보통의 경우에는 처음 설정된 2대의 인스턴스는 계속 운영되고 1대의 서버만 스케쥴링 시간에 맞춰서 붙었다 떨어졌다를 해서 기본 2대의 서버의 running day가 동일했는데 이 항목이 10일이상 차이가 난 것을 발견했습니다. 추측컨데, 타임스케쥴링 되어서 인스턴스가 증가되서 줄어들때 무슨 이유에서인지 leader_only 설정이 되어 있던 인스턴스가 빠졌고, 그 이후에는 leader_only 무용지물이 된 것입니다. 아마도, autoscaling 시에는 leader_only 옵션이 없는 인스턴스 상태를 그대로 가져와서 새로운 인스턴스를 구성하는 것 같은데 서버를 다시 배포하지 않는 이상 영원이 leader_only : true 인 서버는 올라오지 않습니다! 5월말에 운영시작해서 2달 조금 넘게 운영하고 있는데 이와 같은 상황이 2번이나 발생했습니다.T_T 그래서, 정말 운영상에서 중요한 옵션을 leader_only 옵션으로 적용하는건 개인적인 경험에서는 자제하는게 좋은 것 같습니다. (혹시 이런 현상의 정확한 이유나 막는 방법 아시는 분은 댓글로 제보 부탁드립니다.^^)",http://woowabros.github.io/woowabros/2017/08/07/ebextension.html,woowabros,"kotlin,php,android,java",NULL,2017-08-07
인(人)턴(Turn) - 당신 인생의 전환점,"흔히 인턴이라고 하면 단기간 회사에서 정식 구성원이 되기 위해 실습 훈련을 밟는 일원을 말합니다. 말이 실습 훈련이지 막상 회사에 가면 짧게는 2개월, 길게는 6개월, 1년 동안 제대로 된 실습 훈련을 받지는 못합니다. 개발자라면 이는 더 더욱 힘듭니다. 개발자에게 2 개월의 하계 인턴이라는 제도는 이도저도 할 수 없는 어중간한 기간일 수 밖에 없습니다. 이런 2 개월의 시간을 의미있게 만들어보자는 취지하에 우리는 새로운 인턴 제도를 그려 보았습니다. 2개월동안 하계 인턴을 지원한 이들에게 제대로 된 실습 개발 교육을 제공하기로 했습니다. 학교에서 배우는 따분한 코딩 수업이 아니라 체계적인 실무 교육과 실습 위주의 강의, 실제 회사에서 프로젝트를 수행할 수 있는 역량을 키울 수 있는 교육, 우리는 인생의 전환점이 되어줄, 우아한 테크 캠프를 열었습니다.우아한 테크 캠프는 내부 개발자들이 교육을 지원했던 과거의 배민 학당에서 벗어나 프로그래밍 교육 기관 출신 강사분들이 세운 코드스쿼드라는 교육 기관에서 2 개월 풀 타임으로 소프트웨어 교육을 지원하기로 하고 김정 대표님, 윤지수 마스터님, 정호영 마스터님과 함께 채용 심사 과정부터 함께 했다. 500 명이 넘는 지원자, 200 명이 넘는 서류 통과자, 코딩 테스트 및 면접 진행자 70 명을 거쳐 최종 24 명의 인원이 선발됐습니다. 채용 선발 과정에서는 내부 개발자 분들의 아낌없는 지원으로 원활히 진행될 수 있었습니다.채용을 진행하면서 빠듯한 일정에 힘들기도 했지만 우리는 젊은 지원자 분들의 열정과 열의를 보며 옛 생각에 잠기기도 했고 면접관들끼리 후기를 공유하며 요즘 젊은분들의 지식과 경험에 놀라기도 하며 나름의 의미있는 시간을 가졌습니다. 면접은 면접관에게 자신을 알리는 대화라고 합니다. 대화의 과정을 통해 면접자 뿐만 아니라 면접관 또한 새로운 간접 경험을  체득하는 값진 시간이 아니었을까 생각합니다. 2017년 7월 3일 월요일, 우아한 테크 캠프가 시작되었습니다. 경쟁하지 않는 구도 안에서 많이 배울 수 있는 장을 열어주고 싶은 취지에서 만든 이 교육 과정은 웹과 모바일의 두 개의 트랙으로 나뉘어 진행되었습니다. 짧은 시간안에 인턴분들이 많은 걸 얻어갈 수 있는 강의로 채우려고 노력했고 강의 내용은 주차별로 아래와 같습니다. 기초부터 응용까지 스스로 실습하고 코드리뷰하며 서로 회고하는 시간을 통해 개개인이 더 발전할 수 있는 교육을 지원하려 했습니다. 4 주 동안 개발 교육만 진행이 된게 아니라 중간 중간 우아한 형제들의 철학을 엿볼 수 있는 강연과 피플팀과의 워크샵을 통해 우형의 문화 또한 체험할 수 있는 기회를 전했습니다.    지난 1달, 4주는 캠프 운영진만이 아닌 강사진에게도 의미있는 시간이었습니다. 3월 20일 코드스쿼드의 김정 대표님과 처음 만나 교육형 인턴 프로그램을 기획하면 어떻겠냐라며 시작된 첫 만남이 빠르게 진행돼 여기까지 왔습니다. 이 교육이 인턴분들에게 긍정적인 피드백을 받을 수 있는 건 무엇보다 강사님들의 노력의 힘이라고 생각합니다. 강사님들은 체계적인 강의안과 인턴분들이 성장할 수 있는 환경을 조성해 주셨으며 스스로 생각하며 문제를 해결해 나가도록 유도하며 지식 전달이 아닌 방법을 찾게 교육해 주셨습니다. 우형에서 색다른 인턴 프로그램을 진행하며 나름의 재미를 찾으며 강의를 진행해 주신 두 마스터님은 지난 1달간의 교육을 아래와 같이 회고합니다.김정 대표님 - 모바일 마스터님모바일 개발자가 되고 싶었던 인턴도 있고, 웹과 모바일을 다 해야만 한다고 생각하기도 했습니다. 모바일 개발자가 고민해야하는 기술 분야나 도메인 지식을 포괄해서 생각하는 방법을 경험하고 있습니다. 새로운 업무 환경에서, 새로운 개발 환경에서, 새로운 언어를 배우며 서로의 코드를 읽고, 서로의 생각을 배우고, 서로의 부족함을 채워갑니다.앱을 만들기 위해서 기획하고, 프로토타입을 만들고, 다시 설계를 하고, 짝프로그래밍으로 구현을 해봅니다. 각자 배웠던 언어도 다르고 경험도 다양해서 코딩 스타일도 달랐지만, 테스트를 작성하며 과정속에서 협업을 경험합니다. 다 같이 리뷰하며 다른 생각을 두려워하지 않습니다. 스스로 몰입하고, 성장하고, 또 다른 사람의 성장에 도움을 주는 경험은 다음주에 시작할 프로젝트 활동의 긍정적인 에너지 원천이 될 것입니다.캠프를 기획하면서 “함께 경험하며 다같이 배우는 과정“을 만들어보고 싶었습니다.  4주가 지난 지금 시점에서, 그 목표에 딱 절반쯤 다가간 것 같습니다. 윤지수 마스터님 - 웹 마스터님좋은 환경에서 열정이 넘치는 주니어 개발자들과 함께 하고 있습니다. 과정에서 중요하게 여기는 부분은, 설계(design), 협력, 그리고 성장 입니다. 좋은 코드를 만들기 위해 우리는 ‘first design’을 중요하게 여기며 ‘code and fix’에서 벗어나가려 노력중입니다. 더 많은 사고 과정을 거치며 소프트웨어 개발의 참 맛을 느끼고 있습니다.협력은 더 빠른 결과를 만들어낸다고 합니다. 페어프로그래밍을 하고 어려운 문제를 함께 해결할 때 더 팀이 단단해지고 더 빠른 해결방법이라는 것을 깨닫게 되는거 같네요. 우리는 매일 일어나는 코드리뷰, 페이프로그래밍을 통해서 서로서로 끊임없이 배우는 중입니다. 많은 것을 내려놓고(?) 서로의 코드를 리뷰하고 개선해 나가는 중입니다. 불필요한 경쟁은 없으며, 서로를 신뢰하고 도우며 발전하고 있습니다.   7월 한달간의 교육 과정에 대한 만족도를 조사한 결과 교육 프로그램에 대한 만족도는 매우 높았습니다. 단순 지식 전달이 아닌 생각하는 프로그래밍을 강조하는 교수님들의 강의와 직접 코딩하며 만들어보는 과정이 많은 도움이 된다고 합니다. 8월에는 7월에 배운 교육 과정을 통해 인턴 분들이 스스로 프로젝트를 만드는 실습 시간을 갖게 됩니다. 알찬 교육의 결과물을 직접 기획, 개발하며 수업 내용을 활용하는 시간이 될 겁니다.이번 교육은 운영하는 사람의 입장에서도 즐거운 시간이었습니다. 젊은 분들의 패기와 열정에 흥분됐고 이분들에게 제공된 기회와 환경이 때론 부러웠습니다. 우리에게 또한 좋은 추억을 만들어준 24명의 멋진 인턴 분들에 감사하며 이분들에게도 잊지 못할 2 달이 되었으면 합니다.",http://woowabros.github.io/woowabros/2017/08/02/woowa-techcamp.html,woowabros,,NULL,2017-08-02
Swift가 진화하는 법,"안녕하세요. FC 서비스 개발팀에서 육아(샤워 전문)와 iOS 앱(배민프레시) 개발을 담당하고 있는 최광훈입니다.배민프레시 2.0.0 iOS버전을 무사히 올리고, 아기 샤워를 마치고, 밥을 먹이고, 잠을 재우고(그러나 새벽에 다시 깨었지. 30분을 울었지.), 사랑하는 부인과 함께 이유식을 만든 후, 고요함이 찾아온 금요일 저녁이었습니다. 그 동안 뒤쳐진 사회성을 끌어올리기 위해 facebook을 정주행중이었는데, 타임라인에서 김범준 이사님의 포스팅 하나를 보게 되었습니다.stackoverflow의 글에 대한 포스팅이었는데 해당 내용인즉외부 변수 i를 for in문의 index i로 사용해서 외부 변수를 변경하는 것이 불가능하지요? 라는 질문이었습니다. Swift의 문법에서는 스코프 바깥의 변수 혹은 상수명과 동일한 명칭을 스코프 안에서 사용한 경우 별개의 선언으로 취급하며, 동일한 명칭에 대한 shadowning 경고도 없기 때문에, 위와 같은 질문이 나오게 된 거죠.포스팅에 몇가지 유사한 경우를 댓글로 달다 애초에 for item in collection { … }의 형태가 사용자에게 오해를 줄 여지가 있다면, 그리고 경고보다 좀 더 확실한 표현으로 제한이 가능하다면 어떨까 하는 생각이 들게 되었습니다.Swift는 open source로 전환을 시작한 후부터 여러 형태로 사용자들이 기여할 수 있도록 하고 있습니다.개발자들의 토론의 장도 필요하겠죠? swift.org에서는 다음과 같은 메일링 리스트를 통해 커뮤니티를 구성하고 있습니다.제가 제안 할 내용은 다음과 같습니다.를로 제안하려고 합니다.swift-evolution링크로 이동하겠습니다.바로전의 깔끔한 화면과는 달리 좀 단촐해보이는 페이지가 등장합니다. 오픈 소스 커뮤니티의 메일링 리스트는 GNU 메일링 리스트 관리툴인 Mailman을 사용하는 경우가 많아 같은 형태의 레이아웃을 자주 볼 수 있습니다.구성이제 메일을 보내면 archives에 바로 등록됩니다.[swift-evolution] Change ‘for in’ expression to for [] { (item) in … } 의 내용으로 메일을 보냈습니다. 엉터리 영어로 쓴지라 두근두근했지만, 그냥 send를 눌렀습니다. (지금 다시 보니 제가 stackoverflow의 원글을 잘못 이해했다는 것도 알 수가 있네요.)별 기대는 안하고 다른 일을 하고 있는데, 12분 지나고 첫 메시지가 도착했습니다. (내용은 요약한 버전입니다.)Alex Blewitt : forEach 쓰시면 됩니다.그리고 몇 개의 메시지가 추가로 도착했습니다.Jacob Williams : 기존 문법을 대치하는 것은 너무 많은 양의 수정사항을 발생시키며, forEach 쓰면 됩니다.Robert Bennett : forEach와 똑같은데요?이대로 수긍하기에는 제 설명이 너무 부족했던지라 저도 부연설명을 추가했습니다.저 : 0..<10과 같은 Range타입인 경우 forEach를 쓰려면 (0..<10).forEach { … }와 같은 괄호로 감쌀 필요가 있어요. 불편하니까 그냥 for in바꾸진 말구 새로 추가하면 어때요? 물론 이미 기존의 for문 하나 없에서 좀 더 깔끔한 코드를 만들게 해줬지만 말이에요. (Swift 2까지는 for in문 외에도, 일반적인 for문이 존재했었습니다.)Robert Bennett : 이미 대체할 방법이 있는데다, 언어의 발전은 기본 문법의 결함을 감추는 것 이상이다.Haravikk : 의도에는 동감하나 잘못된 해결 방법인거 같습니다. 그보다 shadowning이 발생하는 상황을 제거하거나 경고를 추가하는 것이 어떨까요. 개인적으로는 변수명을 좀 더 고민하는게 좋겠습니다.Taylor Swift : 사실 for문에서 외부 변수를 사용하는 것은 C가 심하게 비판받는 부분입니다. 이 변화는 더 심한 혼란을 야기할 것입니다.이 시점에서 저는 모두의 견해에 고마음을 표하는 답변을 보냈습니다. 그리고 다음날 아침 즈음에 하나의 답변이 추가로 도착했습니다.Daryle Walker : nested function을 없애고, 모든 지역 변수는 동일한 이름을 가져선 안되는 것이 좋을 거 같습니다. 이런 언어에 대해 읽은 적이 있네요.Swift의 철학은 안전, 신속, 표현성으로 대표됩니다. 그리고 그를 위해서 Apple의 Swift 코어 개발자 뿐만 아니라 Swift를 사용하는 수많은 개발자들이 제안을 하고 토론을 하며 그 중에서 Swift 명세에 추가가 정해지며, 다시 검토를 통해 탈락 하기도 합니다. 또한 어마어마한 개발자들의 신적인 토론의 장이 아니라 저 같은 보통개발자들도 참여할 수 있는 열린 교류의 장이기도 합니다.제가 제 부족한 제안에 대해 글을 쓴 것은 여러분도 겁내지 말고 Swift의 발전에 대해 재밌게 참여 할 수 있기를 바라기 때문입니다.*마지막으로세상에서 제일 짧은 제안이 얼마나 긴 thread가 되고 결국 Swift 3에 포함되었는지 보면 재미납니다. (나만 그런가…)nulTerminatedUTF8의 nul이 오타라고 생각했던 세상에서 제일 짧은 제안이 Swift 3의 명세가 됩니다.And Thanks Google Translate.",http://woowabros.github.io/experience/2017/07/31/evolution-with-swift-evolution.html,woowabros,,NULL,2017-07-31
로그 데이터로 유저 이해하기,"우아한형제들 데이터서비스팀 송훈화입니다. 제 업무는 로그를 설계/정의하고 데이터를 분석하는 것입니다. 궁극적으로, 유저가 남긴 로그로부터 유저의 경험을 추정하고 니즈를 파악해 서비스 개선에 필요한 인사이트를 제공하는 것입니다. 이를 위해 로그 설계/수집/분석에 이르는 전반적 과정에 직/간접적으로 관여하고 있으며, 입사후 4개월간 경험한 내용과 생각을 공유하고자 합니다.입사 직후 진행한 업무는 클라이언트 로그를 설계하는 것이었습니다. 앱의 모든 화면과 이벤트(클릭, 배너 노출)를 상세히 파악하고, 시나리오와 서비스의 흐름을 이해하는 것부터 시작했습니다. 마치 실제 유저가 앱을 쓰듯이 모든 기능과 화면을 하나씩 파악하면서 로깅 항목을 정리했습니다. 다소 노가다 업무였지만, 이 작업을 하면서 앱에 대한 이해가 한 단계 더 깊어지는 경험을 하게 되었습니다. 또, 이 과정에서 (제가 느끼기에) 편리한 기능도 있었고 이상한(?) 기능도 있었는데, 향후 분석을 위한 방향과 프레임을 잡는 데 유용한 정보를 얻었습니다.로그 설계/정의 업무가 마무리되고 엔지니어 및 개발자와 협업하면서 로그 수집을 진행하였습니다. 데이터는 JSON 형태로 저장소에 차곡히 쌓이기 시작했고, 엔지니어의 도움으로 언제든 저장소에 접근해 데이터를 추출/분석할 수 있는 환경이 마련되었습니다. 실제 수집된 로그는 아래와 같았습니다.(아래 이미지 참고) 유저가 우리 서비스에 접속해 특정 화면을 보거나 액션을 할때마다, 설계된 스키마 대로 데이터가 쌓였고 샘플을 추출하여 데이터 탐색 준비를 마무리 하였습니다.로그 데이터 예시(일부 항목 숨김처리)이번과 같이 로그 수집 프로세스가 처음 진행된 경우, 본격적인 데이터 분석을 진행하기 앞서 데이터 품질을 확보하는 것이 중요하다고 판단했습니다. 기존에 정의한 대로 각 필드 및 파라메터에 적절한 로그가 쌓이고 있는지, 누락되거나 이상한 데이터가 없는지 확인하고 만약 수정/보완이 필요한 경우 데이터 품질을 확보하는 작업을 진행하였습니다. 예를 들어, 아래 예시와 같이 수집이 잘못된 경우 유관자와 원인을 파악하고 문제 해결 과정을 통해 데이터 품질 확보에 많은 노력과 시간을 투입하였습니다.데이터 수집 오류의 예시또 다른 중요한 과정은 분석 프레임을 설정하는 것이었습니다. 일반적으로 로그 데이터의 경우 단기간에 몇 십만, 몇 백만 건의 데이터가 순식간에 쌓이고 로그 정의 항목은 수백 건에 달합니다. 무작정 데이터 탐색 분석으로 뛰어들 경우 망망대해에서 길을 잃고 허우적거리는 경험을 할 것 같았습니다. 따라서 목적을 명확히 설정하고 적절한 질문을 사전에 작성하는 것이 효과적일 것으로 판단했고, 로그 설계시 경험을 바탕으로 대략적인 프레임을 구축하여, 데이터 분석 및 인사이트 도출 과정에 유용한 나침반으로 활용하였습니다. 분석 프레임 설정의 예시는 아래와 같습니다.여담이지만, 현재 팀에는 분석가를 위해 전용 서버, Spark, Zeppelin 등 최적화된 분석 환경이 마련되어 있습니다. 쾌적한 환경 구축을 위해 애쓰신 엔지니어분들께 감사를 전하고 싶습니다. 또 로그 수집과 데이터 품질 개선을 위해 노력해주신 개발자분들께 감사를 전하고 싶습니다.로그 데이터를 추출해보면 난해한 결과가 나오는 경우가 있습니다. 경험상 주로 다음과 같은 이유로 발생하는 것 같습니다.위 4번에 해당하는 예시위 항목 중 1,2,3 번의 경우 인적요인으로 인해 발생한 것이며, 실무자와 협의를 통해 해결 가능한 부분입니다. 4번의 경우는 기계적으로 수집되는 과정에서 자연스럽게 발생할 수 있는 부분입니다. 이 역시 협업을 통해 해결할 수 있으나, (엔지니어분과 개발자분들은 항상 바쁘므로) 4번 같은 경우 분석 과정에서 자체적으로 해결하는 것이 효과적일 것으로 판단했습니다.즉 위 테이블을 그대로 읽으면, ‘UserNo가 천사(1004)인 유저가 MyPage 화면을 3초동안 5번 보았다’로 해석되는데, (유저는 기계가 아닌 인간이기에) 어떤 유저도 이런 식으로 앱을 이용하지 않을 것 같았습니다. 차라리 초(Second) 단위의 정보를 무시하고(중복 수집으로 판단), ‘2017년 5월 1일 10시 10분에 천사 유저가 MyPage를 1번 보았다’로 해석하는 것이 더 적절할 것으로 판단했습니다.때로는 ‘이러한 방식이 세밀한 정보를 놓치는 것이 아닌가?’ 혹은 ‘너무 자의적인 해석이 아닌가?’ 라고 스스로 반문하기도 하였으나, (비록 정보 손실이 있더라도) 효율을 추구하는 동시에, 인간의 행동을 효과적으로 설명할 수 있는 해석이 타당해보였습니다. 결과적으로 기존 5개 행의 데이터를 중복으로 처리해 하나의 행으로 축약시켰으며, 유사한 데이터가 있을 경우 ‘무엇을 기준으로 중복 값을 제거하는 것이 적절한가?’에 대한 물음을 자문하며 분석을 진행했습니다. 이 과정에서 유용했던 것은 초반에 설정한 목적과 의미, 그리고 논리성과 인간을 기반으로 한 접근 방식이었던 것 같습니다.로그 데이터를 설계/수집하고 분석하는 일련의 과정은 이 업무의 절반에 해당한다고 생각합니다. 나머지는 분석 결과를 유관자에게 전달하고, 설득을 통해 실제적인 변화와 성과를 이끌도록 지원하는 것이라고 생각합니다. 이를 위해 분석 결과를 명확하고 간결하며, 이해하기 쉽게 전달하는 것은 매우 중요한 과정인 것 같습니다.주니어 분석가 시절에는 시각화와 리포트 작성에 많은 노력을 투입했고, 단순하고 쉬운 방법론 보다 고급 방법론이 항상 좋은 것이라고 착각했었습니다. 하지만 아무리 고수준의 방법론이라도, 결과를 공유받는 상대로부터 실제적인 변화를 이끌어내지 못한다면 큰 의미가 없다는 것을 깨닫고, 아래 원칙을 토대로 커뮤니케이션하기 위해 노력하고 있습니다.단순하고 이해하기 쉬운 그래프보기에 멋지지만 이해하는 데 시간이 오래걸리고 만들기도 어려운 시각화일반적으로 로그 데이터를 수집/처리/분석하기 위해 많은 담당자분들이 노력과 시간을 투입합니다. 이러한 인적자원뿐 아니라, 서버 및 분석도구 등 시스템적 비용 역시 발생하기 때문에 데이터 활용도를 높이는 것이 중요하다고 생각합니다.일차적으로 생각해볼 수 있는 각 영역/부문별 데이터 활용 방안은 아래와 같습니다.개인적으로 데이터가 비로소 그 가치를 발휘하는 순간은 분석 결과가 실제 비즈니스에 적용되어 가시적인 성과를 일으키는 것이라고 생각합니다. 다만 첫술에 배부를 수 없듯이, (작은 규모라도) 반복적인 프로세스로 운영하고 개선이 필요할 경우 기민하게 진행하는 것이 필요하다고 생각합니다. 이를 위해 부서간 기밀한 협업과 업무 프로세스에 대한 공감대 형성이 필요하며, 또 데이터에 대한 적극적이고 열린 태도로 업무를 진행하려는 노력이 필요할 것 같습니다.더불어, 이를 지원할 수 있는 데이터 전문 인력과 변화에 열려있고 효율성을 추구하는 조직 문화, 유저 친화적인 시스템 등의 기반 역시 필요할 것 같습니다. 비록 데이터나 수치가 모든 비즈니스 문제의 해답을 말해주지 않지만, 문제 해결을 위한 실마리를 제공할 수도 있으니 부담 없이 한번 시도해보는 것은 어떨까요??",http://woowabros.github.io/woowabros/2017/07/30/logdata.html,woowabros,,NULL,2017-07-30
QR코드 속 보물찾기,"안녕하세요 배라개발팀 박민철 입니다. 배민7주년 행사 중 QR코드를 활용한 보물찾기 이벤트를 진행했던 경험을 이야기를 해보려 합니다.지난 6월 배민7주년 행사가 있었습니다.  배민7주년 행사 컨셉은 미래와 경쟁하자 였고, 미래기술에 대한 브레인스토밍 중 QR코드를 활용하자는 의견을 토대로 보물찾기 이벤트를 제작하게 되었습니다. 행사장소 곳곳에 붙여진 QR코드를 촬영하면 (상품 || 꽝) 이미지가 나오는데, 상품이미지를 저(노예)에게 보여주면 해당 상품을 받을 수 있는 방식으로 진행하였습니다. QR코드는 Quick Response의 약어로, 1994년 일본의 덴소웨이브란 회사에서 처음으로 개발하였습니다.QR코드를 제작하는 서비스를 해본 경험이 있어서, 어렵지 않게 구현 할 수 있었습니다.(JQuery 플러그인을 사용하면 쉽게 QR코드를 만들 수 있어요!)사용자 화면에 이미지URL이 어떤 방식으로든 노출이 가능하기 때문에 사실 가장 많이 걱정을 했습니다. 이부분은 상품번호를 md5로 암호화하여 모바일에서 직접입력하기 어렵게 했습니다. (실제로 URL의 코드 일부를 수정해서 호출하거나, 직접 md5코드를 제작하여 호출하신분도 있었어요!)상품이 많지 않아, 인식률이 떨어지길 기대했지만, goo.gl 서비스를 이용하여 단축URL을 생성하고, 보다 간단한 QR코드가 만들어지도록 했습니다.이부분은 오픈전날(D-1) 갑자기 불현듯 스쳐 지나가며 생각이 났습니다. AWS Micro EC2 딱 하나 띄어놓고 있었는데, 점점 불안해지며 잠이 달아나기 시작했습니다.   jmeter라는 성능테스트도구를 사용하여 500명 동시접속의 시나리오를 작성하여 그 결과를 볼 수 있었습니다. 원활하게 처리됨을 확인 하고 그제서야 맘편히 잠들 수 있었습니다. [500명 x 2회 = 1000번 수행]보물찾기의 요구사항(제가 해석한)은 다음과 같습니다.이미 같은 상품을 발견한 사용자에게 꽝을 보여주려고 했으나, 혹시 모를 상황에 대비해 상품이미지를 노출했습니다.하지만, 현장에서는 사용자에게 같은 상품에 다시 당첨이 되었다고 오해를 일으켰습니다. 차라리 위의 경우 이미 발견한 상품이라는 안내가 더 좋았을 것 같습니다.상품의 수량이 없어지면서 계속 꽝이 노출이 되었습니다. 마치 누군가는 모든게 꽝인것 처럼 보이게 되었고, 불친절한 경험을 제공할 수 있다는 생각을 하게 되었습니다. 상품이미지와 함께 아쉽게 놓쳤다는 안내라도 보여줬으면 하는 아쉬움이 남았습니다. [사진을 찾다보니 꽝인 경우밖에 없었어요]13:00부터 모든 데이터를 초기화하고 서비스를 오픈하여 15:00까지 큰 이슈 없이 이벤트가 자연스럽게 종료가 되었습니다. 보물찾기 이벤트를 진행 하면서 크게 2번의 위기가 있었는데요.첫번째는 100여장 정도의 QR코드 프린트물을 행사장소 곳곳에 붙이는 일이었습니다. 다른 노예분들께서 도와주셨지만 정말 힘들었어요. (상품들이 생각보다 너무 빨리 발견되어서 좀 더 변태같이 어렵게 숨기지 못한 아쉬움이 있었습니다.)두번째는 상품수령에 대한 구글스프레드시트 작성과 상품지급을 동시에 처리하는 일이 쉽지가 않았습니다. 보물찾기 이벤트에 적극적으로 참여해주셔서 그런지 금방 보물이 바닥을 보였는데요, 수령자를 기록하는 일과 상품을 지급하는 일을 혼자서 맡아서 진행하다보니 정신이 없었습니다. 중간에 같은 상품을 중복해서 수령한 경우가 있었는데, 구글스프레드시트 덕분에 정상적으로 회수하고 정합성을 유지할 수 있었습니다. (Google Apps Script를 활용하면 자동화를 할 수 있는데, 마저 구현하지 못해서 아쉬움이 있었습니다. 이렇게 바쁠줄 몰랐어요.)13:00부터 15:00까지 데이터를 정리하여 보았습니다.보물찾기 프로젝트를 진행하면서, 서비스 구현 보다는 크고 작은 문제를 어떻게 해결하면 좋을지를 많이 고민 했던 것 같습니다. 그런 부분에서 더 흥미와 재미를 느낄 수 있었고, 고민을 하면 할 수록 더 나은 대안이 도출 되었지만 불안정한 내용들을 완벽히 채우지 못해 정말 아쉬움이 많이 남습니다. 다음에 기회가 된다면 더 나은 서비스로 찾아뵙도록 하겠습니다. :-)  읽어주셔서 감사합니다.",http://woowabros.github.io/experience/2017/07/28/qrcode.html,woowabros,,NULL,2017-07-28
QA != 통합테스트,"안녕하세요. 우아한형제들 품질개선팀에서 근무하고 있는 임선진입니다. 저희 팀에서는 우아한형제들 서비스와 제품에 대한 QA, QC, Testing 업무를 주로하고 있습니다. 이 글은 어찌보면 모두가 알고 있는 QA(Quality Assurance Assistant)에 대한 이야기 입니다.이 글을 팀장님도 아닌 제가 써도 되나… 많이 망설였습니다. 너무나 거국적인 주제인데다, 이미 충분히 잘 알고 있어서 이해해주시는 분도 있는데, 굳이 쓸 필요가 있을까 싶은 생각도 들었습니다. 또한 다른 곳에서 같은 QA업무를 수행하며 현재는 고통받고 계시지만, 개선의 의지를 가진 분들이 … “배민도 별거 없네.” 라고 생각하고 희망을 접어버리지 않을까 걱정도 했습니다. 그리고 괜한 오해가 생길 수도 있단 생각을 했지요.하지만 불과 몇일 전 까지도 잘못된 이해로 많은 일들을 겪으면서 꼭 이 주제에 대해 써야 될 것 같다고 생각했습니다.저는 몇몇 분들이 QA를 통합테스트로 이해하고, QA의 일을 이해하지 못하는 상황을 접합니다. 프로젝트를 진행하거나 유관부서 분들을 만나 얘기를 할 때, 제 입장에서는 황당한 일들을 많이 겪습니다. 몇 가지 예를 들어보겠습니다.상황1. (한 달도 넘게 진행된 프로젝트 내용을 미리 공유받지 못한 상황에서) “다음주 오픈 예정인데 일주일만 QA해주세요.”“일주일 기능 테스트만이라도 해주세요.” 라고 하면 조금 덜 당황할 수 있습니다. QA는 프로젝트 시작과 끝 전반에 걸쳐 품질을 저해할 수 있는 요소를 찾아내고 알리고 해결을 돕는 활동들을 의미합니다. QA라고 말하는 것도 이상할 뿐 더러, 기능 테스트만 하더라도 몇일은 테스트 대상과 범위를 분석하는데 거의 모든 시간을 소모하게 됩니다.(상황1 +) 상황2. “QA했는데 왜 운영 이슈가 계속 나와요? (QA한 거 맞나요?)”1번에서 말한 상황이 황당하긴 하지만, 단 몇일 이라도 기능 테스트를 해서 사용자에게 더 나은 가치를 제공할 수 있다면 어쩔 수 없이 테스트를 시작합니다. 이 경우 버튼을 누르자마자 기능 동작을 하지 않는 등 엉망진창인 상태에서 올 때가 가끔 있습니다. 이 때, 저희는 의사결정을 할 수 있는 분께 프로젝트 일정을 더 늘려야한다, 개발 완료가 되지 않았다고 알립니다. 하지만 프로젝트를 처음부터 참여하지 않은 탓일까요? 얼마 만큼의 일정이 더 필요하고 얼마 만큼 구현이 덜 되었는지 근거가 부족할 때가 많습니다. 다행히도 무사히 프로젝트가 잘 진행되어 왔다면 그나마 안도하지만, 짧은 기간 안에 파악한 내용으로는 정말 어떻게 동작하는게 맞는 방향인지 알기 어려울 때가 많습니다. 국지적으로 확인만 하는 체커(checker)에 지나지 않을 수 밖에 없습니다. (물론 처음부터 프로젝트를 같이 진행했더라도 이슈는 많을 수도 있습니다. 하지만 훨씬 가능성이 낮아질 겁니다 !) [이게 어떻게 만들어지는게 맞는 거야? 일단 의자가 앞뒤로 움직이면 맞는건가?]상황3. QA담당자가 프로젝트 킥오프 회의와 회고 회의들에서 누락되는 상황.앞서 말했지만, QA는 테스트만 하는 활동이 아닙니다. 프로젝트의 목적과 목표에 어긋나지 않으면서도 소프트웨어와 기술을 바탕으로 사용자에게 최고의 품질(가치)을 제공하기 위해 노력하는 활동입니다. 그런 활동들 중 테스트라는 것이 있고, 그 동안은 테스트를 하는 활동에 집중 됐을 뿐입니다. 킥오프 회의에서 프로젝트의 목적과 목표를 듣지 못했다면, 적절한 활동을 하지 못할 것입니다. 회고 회의에서 이번 프로젝트가 어땠는지에 대해 듣지 못한다면, 다음 어떤 활동을 할지 발전이 없을 것입니다.이것 외에도 … 크고 작은 황당한 일들은 시도때도 없이 힘을 빼놓습니다. [잠깐만 숨 한 번 고르고요]이런 일들을 이해는 합니다.소프트웨어의 역사만큼이나 소프트웨어 품질의 역사는 길지 않다.소프트웨어의 품질은 처음 제조업에서 말하는 품질관리에서 시작되어, 제조업의 품질관리를 소프트웨어에서 동일하게 적용하면 안 된다는 것을 알게 된지 얼마 되지 않았습니다. 아직도 이렇게 하는 게 맞는지 저렇게 하는게 맞는지, 고민하고 방향을 찾아가는 과정에 있다고 생각합니다. 심지어 업무를 진행하고 있는 사람들 조차도 본인의 일이 QA인지 테스트인지 인지하지 못하는 분들도 더러 있을 것입니다.QA 업무를 하는 사람과 일해본 사람은 드물다.지금의 조직에서도 프로그래머와 기획자의 수에 비해 QA로 일을 하는 분들은 정말 소수 입니다. 그리고 그 소수의 인원은 한정된 다른 부서의 분들과 함께 일을 합니다.  어느 정도 큰 조직이 아니면 별도의 QA조직을 두고 운영하기 힘들어서, 경력이 꽤 있더라도 함께 일해 본적이 없다고 합니다. (혹은 테스터 분들 하고만 일을 해봤다고 합니다.)QA의 일은 계속해서 변화합니다.소프트웨어의 플랫폼과 언어가 변화하듯 비지니스 구조가 변하듯, 우리는 더 많은 파라미터를 가지고 움직여야 합니다. 어떤 제품을 맡게 되느냐에 따라 계속해서 플랫폼과 로직에 대한 학습이 필요하고, 무언가를 시도하고 적용하는데 더 많은 노력이 듭니다. 또한, 현재는 주로 테스트를 직접 수행함으로써 고객에게 가치를 제공하지만 다른 형태가 될 수도 있습니다. 다른 조직에서는 또 다른 방법으로 QA 활동을 하는 분들도 있고, QA가 하는 활동을 명확히 정의하기 어렵기 때문에 잘 모를 수도 있다고 생각합니다.다시 한 번 더 말씀드리지만, QA는 통합테스트와 대치할 수 없는 단어입니다. QA는 통합테스트만 하는 일을 의미하지 않습니다. [출처 : https://www.slideshare.net/interfaceULG-innovationManagement/130528jodogneprofessionalsoftwaredevelopment-140113090851phpapp01]품질(Quality) 관점에서 테스트는 극히 일부 밖으로 보이는 영역일 뿐, 우리는 더 많은 일들을 해야합니다. 사용자에게 어떻게 하면 극대의 가치를 전달할 수 있도록 잘 만들어질 수 있나 사용자의 입장에서, 기술 관점에서 모두 신경써야 합니다.사실 저도 어떻게 하면 잘하는 것인지, 어떻게 하면 좋은 방법인지 잘 모르겠습니다. 하지만 계속해서 더 나은 방향을 생각해내고 최선을 다해 행동하는 것을 멈추면 안 되겠지요. [현실과 부딪혀가며…]계속해서 황당한 상황이 반복되고 앞으로 나갈 수 없는 많은 이유중 하나는 단어의 정의부터 잘못 인식하고 있기 때문이라는 생각이 들었고, 이렇게 기술블로그에 글을 쓰게 되었습니다.여러분들이 생각하는 QA는 어떤 것이었나요?덧1. 심심하면 나무위키 페이지. 보러가기덧2. 품질개선팀의 채용은 열려있습니다. 우리 함께 일하며 성장해요. 입사지원서",http://woowabros.github.io/woowabros/2017/07/23/QA-not-integrationTest.html,woowabros,,NULL,2017-07-23
좋은 동료와 함께 성장하는 기쁨,"작년 10월 즈음 시작했던 토비님의 ‘토비의 스프링’ 책 스터디를 드!디!어! 끝! 마쳤습니다.   약 9개월의 시간이 걸렸으니 짧지 않은 시간이었네요. [함께해준 동료들 덕분에 스터디 끗!]아시다시피 토비의 스프링 책은 매우 두껍습니다.  그러한 책이 2권이나 되니 첫인상으로만 보자면 혼자 완독을 하기란 쉽지 않아 보이죠.  (아마 혼자 시작했다면, 중간에 포기했을 것 같습니다.)Technology is constantly evolving and going through changes.  Because of this, programmers are required to keep up with these changes and trends in order to stay relevant in their field.얼마 전 사내에 공유된 링크 5 ESSENTIAL QUALITIES OF A GOOD PROGRAMMER 인 데요,  좋은 개발자가 갖춰야 할 자질을 소개하고 있고, 그 첫 번째로 ‘개발자의 학습’과 관련한 언급이 있었습니다. (각자 생각하는 바가 다를 수 있으니 가볍게 읽어보는 것도 좋을 것 같습니다.)   다만, 좋은 개발자가 되기 위해서 끊임없이 학습해야 한다는 것만큼은 부정할 수 없는 것 같습니다.  저 역시 머리를 쥐어짜며 블로그에 글을 올리는 지금도 이 기회에 마크다운 문법에 대해 알게 되었으니 조금은 성장한 것이 맞겠죠?기술적 변화뿐만 아니라 (업무적)환경 변화에 적응하는 것 또한 중요한 부분일 텐데요, 제가 스터디에 참여하게 된 계기이기도 했습니다.  아시다시피 (모르실 수도 있겠지만^^;;) 우아한형제들 기술조직은 개발언어를 전환(PHP -> Java)하고 있습니다.  그리고 그 첫 단추가 제가 속했었던 팀의 프로젝트이기도 했습니다.  배달의민족의 바로결제(온라인결제)를 처리하는 빌링시스템을 새롭게 만드는 것이었으니 꽤나 중요했죠 (Java로 처음 개발해보는 것이어서, 스터디도 좀 하고 여유가 있을 줄 알았는데… 바로 전쟁터에 나가야했던 기억이… 나네요)  고생은 많았고 (토닥토닥) 큰 이슈 없이 프로젝트를 마무리했지만, 냉정하게 좋은 품질의 코드는 아니었습니다.  그리고 ‘저 코드가.. 정말 괜찮은 것일까?’ 하는 두려운 마음 때문에 잠을 설치는 날도 많았습니다. (아무래도 돈이 관련되다 보니..)모르고 만든 버그도 버그니까요.스터디에 참여하게 된 계기는 좋은 개발자가 되고 싶은 마음도 한 몫 했지만  솔직히는 작성한 코드를 스스로 이해하지 못하는 데서 오는 자괴감 때문이었습니다. (내가 이러려고 Java로 개발한다고 했는지… 자괴감 들고..) 때마침 동료들이 토비의 스프링 스터디를 시작한다는 얘기를 들었고, 주변으로부터 이 책은 꼭 봐야 한다는 말을 수도 없이 들어왔던지라 참여하게 되었던 것 같습니다. (그래도 무언가 얻어가는 것이 있겠지 하고 말입니다.) [됐어! 성공했어!]스터디는 매주 이틀씩 오전 8시부터 1시간 동안 진행했습니다. 정해진 분량을 읽어오고 이해한 내용을 나누는 방식으로 진행하였고 모르는 부분은 같이 찾아보기도 했습니다.  Java 언어로 개발한 경험이 없어서 몰랐던 과거 선배님들의 고충을 들을 수도 있었습니다. (으악! 세상 참 편해졌! )   (한편으로는 그런 경험도 조금은 부럽다는 배부른 생각을..?)  그리고 올해 초 자바지기 박재성 님의 사내 강의가 있었는데요, 때마침 강의와 스터디 진도가 겹치는 부분이 있어 예습/복습도 할 수 있어서 좋았습니다.개인적인 소감을 조금 언급해보자면,  스터디 자체를 마친 것이 정말 기뻤고요!  스프링의 원리에 대해서 조금은 이해할 수 있어서 좋았습니다.  그리고 생각보다 책의 내용이 막. 어렵고 그렇진 않더라고요! (AOP는 넘나 헬..) 정말 설명이 넘나 자세했습니다.  첫인상에 지레 겁을 먹으신 분들이 계신다면 가능할진 모르겠으나 차분한 마음으로 한장 한장 넘겨보시는 것을 추천해 드립니다.함께한 동료들의 소감도 담아보았습니다. :)“세상 친절한 책이다. 겁내지 말고 도전했으면 좋겠다.”- 손현태 우아한형제들 배민B2B개발팀 , 2017년 상반기 우수사원“토비의 스프링이 왜 스프링 최고의 교재인지 느낄 수 있었던 스터디 였다. 좋은 사람들과 함께해서 끝까지 할 수 있었다. 이제 실전이다!!”- 민경수 우아한형제들 배민B2B개발팀“좀 오래 걸리긴 했지만 함께 해서 끝을 볼 수 있었다.  이제는 실제로 적용하면서 내 것으로 만들어야겠다!”- 김승영 우아한형제들 배민B2B개발팀이 글의 제목을 정하기가 쉽지 않았는데요, “좋은 동료와 함께 성장하는 기쁨”이라고 결정한 것은   약 1년 동안 포기하지 않고 스터디를 끝마쳤다는 기쁨도 있었지만   이 시간을 지내오면서 함께한 동료들의 성장에 대한 열정을 피부로 느낄 수 있었던 것이 가장 큰 이유였던 것 같습니다. 정말 많은 동기부여가 되기도 했고요.  경쟁을 통한 성장도 중요하겠지만, 같은 목표를 향해 달려갈 수 있는 동료들이 있다는 것은 정말 소중하고 값진 것 같습니다. 진짜 결론은! 우아한형제들에서 함께 성장하고 싶으신 분들은 주저하지 마시고 입사지원서를… 성장 욕구가 충만한 주니어 개발자들도 겁나 많습니다! 어서 오세요!부족한 글 읽어주셔서 감사하고, 다음에 좀 더 나은 컨텐츠를 들고 또 찾아뵙겠습니다.",http://woowabros.github.io/experience/2017/07/19/finish_toby_study.html,woowabros,,NULL,2017-07-19
"똑똑, 프로젝트에 코틀린을 도입하려고 합니다.","이 글은 2017년 4월, 배민프레시에 코틀린 도입하는 과정에서 작성된 글을 바탕으로 재구성되었습니다.2017년 4월, 모바일 플랫폼에서 사용자 경험 극대화를 위한 여정의 첫발로 메인 개편 프로젝트를 시작했습니다. 이 프로젝트의 목표는 다음과 같습니다.기존 배민프레시의 앱은 웹뷰 기반에 하이브리드 구조로 만들어져 있었습니다. 이를 네이티브 앱으로 전환하며 UX 개선과 성능 향상을 꾀했습니다.FC서비스개발팀은 새로운 안드로이드 앱을 만들 도구로 코틀린을 도입하고, iOS 앱은 스위프트를 도입하는 것으로 결정했습니다. 이 글은 안드로이드 앱을 개발할 때 접하는 아쉬운(또는 불편한) 점과 그 대안을 생각해보고, 왜 코틀린을 도입했는지에 대한 고민을 담았습니다.안드로이드 개발을 하면서 크래시 수집된 결과를 보면 정말 많은 부분이 NullPointerException(이하 NPE) 입니다. 이유에 대해 고민해 보니 세 가지 정도로 요약할 수 있었습니다:NPE에 대처하는 가장 일반적인 방법은 그 부분에 not null 체크를 추가하는 것입니다:다른 방법도 있습니다:이렇게 처리를 해두면 당분간은 좋습니다. 그러나 유지보수를 하다 보면 결국 코드의 대부분이 if / try 문에 둘러싸이게 됩니다. 또한, 새로운 코드를 작성할 때 null이 아닐 수 있지만 그래도 null 처리를 해두는 게 안전하지 않을까 하는 마음에 불필요한 처리를 하게 되고 이것을 본, 팀의 다른 개발자분도 별다른 고민 없이 비슷한 코드를 만들 게 됩니다. 왜냐하면, 크래시가 발생해서 앱이 죽는 것보단 낫기 때문입니다. 자바 8에서는 보다 안전한 null 처리를 위해 Optional이 추가됐지만 아쉽게도 자바 8 지원이 포함된 안드로이드 스튜디오 2.4 프리뷰 4 에서도 Optional에 대한 언급은 없었습니다.안드로이드 프레임워크는 성능을 매우 중요하게 생각하는 프레임워크인 만큼 대부분 추상화보단 저수준의 API를 제공합니다. 따라서 관련된 보일러 플레이트 코드가 많을 수밖에 없는데 자바의 다소 부족한 표현력이 더해져 실제 실행시키고 싶은 코드보다 보일러 플레이트 코드가 더 많은 경우가 자주 나타납니다.물론, 자바도 표현력 개선을 위한 여러 가지 시도들이 있었습니다.안드로이드 스튜디오 2.4 프리뷰 4 버전에서 공식적으로 자바 8 지원을 하게 됨으로써 더이상 Retrolambda를 사용하지 않고 위의 표현이 가능합니다.안드로이드에서 현재 자바 현황다만, 이렇게 보일러 플레이트 코드를 제거해 표현력을 높일 수 있는 부분은 많지 않으며 람다와 메소드 레퍼런스만으로는 전반적인 안드로이드 보일러 플레이트에 대응하기엔 무리가 있어 보입니다.대표적인 안드로이드의 보일러 플레이트 코드의 예로는 다음과 같이 XML 레이아웃 파일에 정의한 뷰 레퍼런스를 가지고 오는 부분이나 SQLite 트랜잭션을 처리하는 부분이 있습니다.이 부분에 유틸리티 클래스나 패턴을 활용해 반복되는 부분을 추출할 수도 있을 겁니다. 다만, 이런 보일러 플레이트가 안드로이드 API 전반에 걸쳐 있기 때문에 파일 처리, 비트맵 처리, 뷰 초기화, UI 관련, DB 등 추가하다 보면 유틸리티 클래스가 비대해질 수밖에 없으며 유지보수 하는 데 어려움이 따르게 됩니다.이외에도 대부분의 앱이 리스트를 사용하는 만큼 리스트 아이템을 반복하며 처리하는 일이 상당히 많은데 자바 8의 스트림 API를 사용하지 못하는 건 아주 아쉽습니다. 반복문과 조건문을 사용하다 보면 모든 케이스에 대한 테스트가 어려워 실제 라이브 환경에서 예외 상황을 겪는 경우가 많았습니다.보일러 플레이트 코드 제거 APT 쪽은 크게 전반적인 보일러 플레이트를 없앨 수 있는 AndroidAnnotations와 그외 라이브러리로 나눌 수 있습니다. APT 라이브러리는 안드로이드 보일러 플레이트 코드를 하나의 애너테이션으로 대체 할 수 있는 큰 장점을 가집니다. APT마다 사용하는 방법이 다를 수 있습니다만 일반적으로 원래 클래스를 상속해 코드를 자동 생성해주는 방법을 쓰기 때문에 자동 생성된 클래스를 사용하지 않으면 APT 기능을 사용할 수 없으며 빌드를 해봐야 에러를 발견할 수 있고 에러가 발생했을 경우 정확한 원인이 명시되지 않는 경우도 많아 디버깅에 어려움을 가집니다.스트림 대안 streamsupport, Lightweight-Stream-API는 리스트 처리의 아쉬운 점을 보완할 수 있는 라이브러리로 리스트 처리를 반복문과 조건문보다 스트림을 사용하면 상당히 견고한 코드가 됩니다. 두 라이브러리가 자바 8 API의 대안을 제공하는 부분에는 차이가 있지만 공통적으로 스트림과 Optional을 제공하며, 안드로이드 지원을 명시해 두고 있습니다.RxJava 또한 자바 8 스트림의 훌륭한 대안이며 이미 안드로이드 커뮤니티에서 널리 쓰이고 있는 라이브러리입니다. 안드로이드에서 많이 사용되면서 메인 스레드에서 구독한 코드가 실행되게 하거나 특정 라이프사이클에서 구독을 중지시키는 등의 보다 안드로이드 플랫폼에 특화된 기능을 제공하고 있습니다. 스트림의 대안을 넘어서 비동기, 이벤트 기반 개발을 위해서 꼭 필요한 라이브러리입니다.편해지는 것 같긴 한데…저 뿐만 아니라 대부분의 안드로이드 개발 환경이 위의 대안책에 네트워크 라이브러리, 이미지 로더 등을 추가해 프로젝트를 꾸렸을 거라고 생각합니다. 그런데 언제부터인가 편해지기 위해 의존성을 추가하는 게 부담으로 다가오기 시작했습니다. 오픈소스 라이브러리는 작성자가 모두 다르기 때문에 같은 APT 기반의 라이브러리를 사용하더라도 풀어내는 방법이 달라 각각의 라이브러리를 학습해야 하는 부담이 있고 의존성이 늘어갈수록 관리 부담(새 버전 확인, 등록된 이슈 및 회피 방법)이 커지는 부분도 있었습니다. 또한, 어떤 라이브러리를 사용하더라도 NPE에서 자유로울 순 없었습니다.라이브러리들의 의존을 줄이면서 보다 일관적인 해결책을 가진 방법, 보다 안전하게 사용할 수 있는 방법이 필요하다고 느꼈습니다.코틀린이 언어 수준에서 제공하는 Null Safety는 null을 처리하는 데 있어 안전한 방법을 제공합니다. 코틀린으로 코드를 작성하면서 느꼈던 좋은 점 중 하나는 변수를 선언하는 시점부터, 그 변수의 특성을 고민하게 만들었다는 것입니다. 변수를 선언할 때 읽기만 가능한지 또는 쓰기도 가능한지, null 값을 가질 수 있는지 없는지, 그리고 초깃값으로 뭘 가지는지 정해야 합니다.프로퍼티가 어떤 값을 가져야 하는지 그리고 값이 바뀔 수 있는지 아닌지에 대해 먼저 고민하고 코드를 작성하게 해 NPE를 막는 데 많은 도움을 줍니다. 그리고 null을 안전하게 다룰 수 있는 문법을 지원해주기도 하며, 만약 null을 가질 수 있는 변수를 올바르게 처리하지 않으면 컴파일러 수준에서 에러를 발생시킵니다.또한 메소드 시그니처에서도 해당 파라미터가 null일 수 있는지 아닌지를 지정할 수 있습니다.이렇게 변수(또는 인자, 매개변수 등)의 선언부터 사용까지 null 상태를 고려하도록 언어가 강제하기 때문에 보다 안전한 코드를 작성할 수 있습니다.Higher-Order Functions and Lambdas, Function References 람다와 메소드 레퍼런스를 지원하고, 자바 6 버전 이상 호환되기 때문에 안드로이드 SDK에 제한적이지 않습니다.Collections (lists, sets, maps, etc) 코틀린의 컬렉션은 filter, map, foreach와 같은 다양한 고차함수 API를 제공하고, 변경 가능한 컬렉션과 불가능한 컬렉션을 엄격히 구분합니다.서버에서 수신받은 데이터를 컬렉션으로 다룰 일이 많기 때문에 이런 컬렉션 기능은 코드를 보다 간결하고, 안전하게 만드는 데 도움이 됩니다.Extension Functions 확장 함수(Extension Functions)는 이미 존재하는 클래스에 새로운 메소드를 추가할 수 있는 강력한 기능입니다.앞에서 나왔던 SQLite 트랜잭션 코드를 코틀린 확장 함수를 사용해 재구성해보면 다음과 같이 표현해볼 수 있습니다.코틀린은 고차 함수를 지원하기 때문에 함수를 파라미터로 넘기는 게 가능합니다. 위 코드는 트랜잭션 처리가 되어 있고, 파라미터로 람다를 받는 inTransaction 함수를 SQLiteDatabase에 추가하였습니다. 그리고 전달받은 람다를 트랜잭션 템플릿 안에서 실행해 트랜잭션 관련 보일러 플레이트 코드를 없앨 수 있습니다.View Injection 제트브레인에서 제공하는 Kotlin Android Extensions 그래들 플러그인을 추가하면 뷰 인젝션을 사용할 수 있습니다.지정한 id명으로 프로퍼티가 생성되며 Button 타입이 됩니다. 액티비티뿐만 아니라 프래그먼트, RecyclerView.Adapter에서 인플레이트한 뷰도 사용 가능합니다.코틀린과 자바의 호환성은 정말 탁월합니다. 공식 사이트에서도 100% interoperable with Java and Android 라고 소개하고 있고, 언어 사양에서도 자바와의 연계가 중요한 설계 원칙 중 하나로 세워져 있습니다.코틀린에서 기존 자바 코드를 사용하는 데 있어 중간에 뭔가를 통하거나 할 필요가 전혀 없고 일반 자바 코드를 작성하듯 사용할 수 있기 때문에 기존 안드로이드 라이브러리를 제약 없이 사용할 수 있습니다. APT 역시 지원하기 때문에 코틀린을 사용함으로써 기존에 잘 사용하던 것을 포기할 필요는 없습니다. (하지만 많은 부분이 코틀린을 사용한 코드로 대체될 겁니다)서비스 프로덕트에 새로운 언어를 도입한다는 것은 도전적인 과제입니다.현재 팀 내 개발자를 포함해 앞으로 팀에 합류할 개발자들 모두가 새로운 언어를 학습해야 하고, 프레임워크 또는 라이브러리를 선별하는 등 새로운 언어에 맞춰 팀 내 개발환경에 변화가 필요합니다. 개발을 진행하는 동안 기술적 이슈가 발생했을 때 대응시간이 상대적으로 오래 걸릴 수도 있고, 수개월에 개발 후 끝나는 것이 아니라 이후 수년에 걸쳐 지속해서 운영하며 개선 및 유지관리 업무도 수행해야 합니다.코틀린이 내세우는 장점 중에는 언어에 대한 학습 곡선이 매우 낮고, 자바를 다룰 줄 아는 안드로이드 개발자가 더욱 효율적으로 코드를 작성하게 도와준다는 것입니다. 학습에 필요한 내용은 코틀린 레퍼런스 문서에 명료하게 잘 작성되어 있고, 문서 양도 많지 않아 며칠이면 읽고 코틀린 코드를 다룰 수 있습니다. 고급 기능과 함께 능숙하게 언어를 사용하려면 다소 시간이 걸릴 수 있지만, 전반적으로 간결한 언어입니다. 팀 내 코틀린 도입에 대한 의견을 제안한 후 코틀린을 모르던 안드로이드 개발자가 약 일주일간 학습을 시도했습니다. 그 결과 코드를 읽고, 작성하는 데 무리가 없었습니다. 자바와의 호환성이 높고, 상호 운용이 가능하기에 언어의 특징만 잘 숙지하면 언어를 다루는 데 있어 어렵지 않다고 판단해주셨습니다.또 다른 장점으로 안드로이드/자바 플랫폼과 100% 양방향 호환성을 내세우고 있습니다. 따라서 안드로이드 SDK를 포함해 안드로이드 플랫폼(또는 자바 플랫폼)에서 동작하는 프레임워크와 라이브러리를 그대로 사용할 수 있으며, 그레이들이나 메이븐과 같은 빌드 도구도 사용할 수 있으므로 추가적인 개발비용이 들지 않습니다. 더 나아가 코틀린 생태계에 Kotlin Android Extensions, Anko 등을 통해 생산성 향상을 꾀할 수도 있습니다. 기존 앱에 코틀린 코드를 섞어 테스트를 해보았으며 기능적으로 문제없이 동작한다는 것을 확인했습니다. 또한, 코틀린 개발을 주도하고 있는 곳은 제트브레인입니다. 자바 외에도 스칼라, 스위프트, 파이썬 등 다양한 언어들의 IDE를 개발하고 있습니다. 거기에 인텔리제이를 안드로이드 개발을 위해 특화한 형태인 안드로이드 스튜디오로 안드로이드 앱을 개발하는 것이 업계에 자리 잡은 지 오래입니다. 프로그래밍 언어에 대한 이해도나 관련된 기술력이 코틀린에 대한 신뢰성을 높이 보게 되었습니다.하지만 코틀린 기반으로 안드로이드 앱을 개발하는 데 있어 공개된 모범 사례들이 많지 않기 때문에 개발함에 있어 시행착오가 있을 수 있습니다.좋은 소식은 2016년 이후 코틀린 커뮤니티가 가파르게 성장하고 있다는 것입니다. 공식 블로그의 통계에 따르면 16만 명의 사용자와 공식 커뮤니티도 4배 이상 성장, GitHub에 8132개의 저장소가 생성되어 있고, 10만 라인 이상의 코드도 쌓였습니다. 그리고 관련 도서도 출간되고 있으며, 나라별 로컬 커뮤니티도 조금씩 자리 잡고 있습니다. 다양한 안드로이드 오픈 소스로 많이 알려진 Square를 포함해 Pinterest, Basecamp 등의 회사에서 코틀린을 사용하고 있으며, 관련 사례들을 컨퍼런스 또는 블로그 등을 통해 발표하고 있습니다.이슈를 논할 수 있는 커뮤니티와 다양한 회사에서 도입 사례들의 공유, 제트브레인의 전폭적인 지원이 있기에 시행착오를 줄일 수 있다고 생각합니다.이외에도 코틀린이 지원하는 기능들은 더 있습니다만 여기서 언급한 기능들이 도입을 결정한 가장 큰 이유입니다. 코틀린을 도입함으로써 코드를 더 간결하게 표현할 수 있고, 간결하게 표현함으로써 코드에서 발생할 수 있는 버그를 줄이며, 익숙해지면 기존 자바 코드보다 더 나은 가독성을 가진다고 생각합니다. 하지만 코틀린도 은 탄환은 아닙니다. 많은 장점을 얻을 수 있지만 여전히 설계는 온전히 개발자의 몫이며 간결한 코드 이상으로 어떤 설계를 가져갈 것인가 역시 전체 애플리케이션 개발에 있어 정말 중요한 부분이라고 생각합니다.모든 행위의 동인에는 개인이나 집단의 욕망이 반영되어 있다.앞서 말했듯이, 코틀린은 은 탄환이 아닙니다. 새로운 기술을 도입하고자 할 때는 그 기술에 강점과 약점을 명확하게 이해하고, 해결하고자 하는 문제에 대한 인식, 그리고 팀을 포함 주변 상황을 잘 살펴보고 판단하고자 하는 노력이 필요하다고 생각합니다.팀에서 코틀린을 도입하는 데 있어 삿된 욕망이 아예 없다고는 할 수 없을 것 같습니다. 코틀린을 사용하면서 알게 되는 새로운 개념과 패러다임을 익혀가는 과정은 개발자로서 성장에 즐거움을 안겨줄 것이며, 성장에 대한 피드백은 서비스 프로덕트를 더 효율적이고 안정적으로 개발하고 운영할 수 있도록 해줄 것입니다.Google I/O 2017에서 코틀린이 안드로이드 공식 언어로 지정됐습니다.",http://woowabros.github.io/experience/2017/07/18/introduction-to-kotlin-in-baeminfresh.html,woowabros,"php,android",NULL,2017-07-18
이직초보 어느 개발자의 이력서 만들기,"안녕하세요 저는 올해 2월부터 우아한형제들의 배라개발팀에서 일하고 있는 구인본입니다. 작년 연말에 잠시 휴식을 가진 후 1월부터 이직을 준비하면서 경험했던 것 중에 이력서를 쓰면서 생각하고 느꼈던 것들을 정리해보았습니다. 이력서는 이렇게 써야 해 저렇게 써야 해라는 것보단, 제가 저만의 이력서를 쓰면서 나름대로 시도하고 적용해본 경험을 공유해보고자 합니다.본격 나만의 이력서 만들기이직하기 전의 스타트업 회사에서는 지인의 소개와 면접 위주의 심사를 통해 채용된 경우라 이력서를 쓰기 위한 시간을 많이 할애하진 않았었습니다. 그런데 막상 이력서를 다시 준비하려다보니 한글로 만들었던 고전적 양식의 한 장짜리 이력서 밖에 없었지요. 거기엔 사진과 이름, 생년월일, 주민번호, 학력, 경력, 자격증, 그리고 보유기술이 짧게 적혀있었습니다. 이대로 이력서를 제출할 순 없었기에 스타트업에서 맡았던 업무와 적용기술을 목록 형식으로 나열해서 내용을 추가해보았습니다.스타트업에서의 경험했던 일들이 제겐 자신감으로 남아있었고 뭐든지 할 수 있다는 포부(혈기^^)로 구직사이트를 통해 이력서를 뿌리다시피 제출했습니다. 그런데 며칠 지나지도 않아서 구직앱에서 불합격통보가 줄줄이 오는 것을 보고, 처음의 자신감은 곤두박질. 이건 뭔가 잘못됐어! 뭐가 문제지?사실, 지금 돌아보면 그때의 이력서를 지금의 것과 비교해보니 떨어지는 것도 당연하다는 생각이 들더군요. 먼저는 첫인상부터 10년은 넘었을 것 같은 옛날 이력서의 모양새, 성의 없어 보이는 경력소개, 지원하는 회사의 업무와 연관성이 적어 보이는 경력들. 제 이력서를 보고 불합격시킨 당사자의 시각으로 보려고 하니 이력서 전형에서 통과시킬 이유를 찾기 힘들더군요. 스타트업에 있으면서 팀원을 충원하기 위해 이력서를 받아보았던 경험이 있어서 내 이력서를 볼 사람의 상황에 쉽게 감정이입이 되었습니다. 아마도 내 이력서는 10초도 안 되어 지나가버렸을지도.이 사실을 깨닫는 데 오래 걸리진 않았습니다. 그런데 문제는 이미 이력서를 제출한 곳이 많다는 것과 정말 일하고 싶어 한 회사에도 이미 그 이력서를 제출했다는 것! 다행히 다시 업데이트 할 수 있는 기회가 있었고 자유로운 포멧으로 제출할 수도 있었기에, 온전히 이력서를 개선하는 것에 집중하기로 했습니다.내 이력서는 나중에 봐주오, 오 제발!이전의 이력서의 틀로는 제가 할 수 일들과 강점을 잘 보여줄 수 없다고 판단하고, 원점에서 다시 만들기로 했습니다. 절박하니 오히려 아이디어들이 샘솟더군요. 먼저 생각한 것은 어떻게 하면 내 이력서를 보게 만들까?, 어떻게 하면 첫 페이지에서 좋은 인상을 줄 수 있을까?였습니다. 내가 아닌 내 이력서를 볼 사람, 즉 독자의 관점에서 생각해보았습니다. 수많은 지원자의 이력서를 보면서 지쳐있을 독자에게, 뭔가 달라 보이고 다음 페이지가 궁금해지는 첫 페이지를 만들고 싶어졌습니다.저 자신을 잘 어필할 수 있는 재료가 무얼까 고민했습니다. 알맹이가 있어야 껍데기도 의미 있는 것! 먼저는 어릴 때부터 프로그래밍을 접했었다는 점, 대학과 대학원을 거치면서 여러 가지 실험적인 기술들을 접해왔다는 점, 소규모 스타트업에서 사용했던 여러 기술과 스펙을 나열해보았습니다. 그런데 이것들을 목록으로 정리해보고 텍스트 정렬도 바꿔보고 글자 두께도 바꿔보고 해봤지만, 도무지 좋은 인상을 줄 수가 없었습니다. 그래서 글자로만은 안되겠다 싶어 그림을 그리기 시작했습니다. 여러 번의 수정 끝에 나온 것이 개발이력 timeline이었습니다.절박하면 뭐든지 나오긴 나오네요만들어왔던 크고 작은 결과물들을 시간순으로 시각화해보니 한 눈에 볼 수 있고 접했던 기술들을 기간에 맞춰 나열해보니 제법 그럴 듯해 보였습니다. 또한, 기술을 글자로 나열하기보다 심볼과 아이콘으로 표시해서 보니, 이력서를 보는 기술직 담당자에게 친숙할 만한 기술들이 쉽게 눈에 들어온다는 걸 알 수 있었습니다. 그림을 페이지의 가운데로부터 하단에 안정감 있는 위치에 배치했습니다. 일단 첫 페이지에 들어갈 큰 그림이 채워지니, 나머지는 좀 더 편하게 접근할 수 있더군요.첫 페이지 상단에 들어가야 할 내용을 골라보았습니다. 기본적인 인적사항은 필수겠지요. 이름을 한글과 영어로 넣고, 전화번호와 이메일 주소를 넣었습니다. 이전의 이력서에서는 주소라든지, 성별이라든지, 몇 가지 자잘한 인적사항이 있었는데, 꼭 필수적인 것도 아니고, 첫 페이지에 들어갈 필요는 없다고 느껴져 과감하게 제외했습니다. 이왕에 기존 틀에 얽매이지 않기로 했으니까요.오히려 그 자리에 블로그, 개인 Github, 트위터 링크를 넣었습니다. 링크를 따라 들어가보기 전부터, 이 지원자는 SNS 활동도 하고 Github도 하는구나!라는 인상을 줄 수 있겠지요. 화면으로 이력서를 보고 있다면 쉽게 링크를 타고 들어가볼수도 있겠고요. 사진은 처음에 증명사진으로 넣었다가, 너무 딱딱해보여 뺐습니다. 요즘은 사진도 필수는 아니라고 하니까요. 마침 첫 페이지에 어울리는 적당한 사진을 찾을 수 있어서 그걸로 다시 넣었습니다.여전히 첫 페이지에 남아있는 공간을 무엇으로 채울지 고민했습니다. timeline을 통해 어떤 일을 해왔는지 보여줬으니, 이제는 내가 어떤 개발자인지 알리기로 했습니다. 그런데 첫 페이지이니만큼, 구구절절이 자기소개를 하고 싶진 않았습니다. 글이 길면 다 읽어보기 힘들 테니까요. 제겐 이전 회사에서 일했던 가장 최근의 경력이 지원하는 회사의 일과 가장 연관성이 높았기에 그것을 중심으로 간략하게 한 단락으로 적었습니다.그리곤 일반적인 이력서들과 마찬가지로 제일 위에 제목으로 “이력서”라고 써보았습니다. 문득 이런 생각이 들더군요. 이력서인 건 이미 알고 있을 텐데, 적을 필요가 있을까? 영혼이 자유로워지고 있습니다 그 자리에 나를 표현하는 의미 있는 제목을 적고 싶어졌습니다. 이 제목은 사실 이력서를 마감하는 마지막 순간까지 계속 고쳐나갔습니다.결과적으로는 세 가지로 압축했습니다. 트렌드 모니터링 습관, 코딩은 결벽적 미니멀리즘, 함께 성장하는 팀웍. 영어로도 표현하는 건 덤입니다. 직역하기엔 공간이 맞지 않아 비슷한 의미로 넣었습니다. 최근에는 가운데 문구를 바꾸기도 했습니다. 테스트 기반의 견고한 코딩이제 좀 현실감각이 생기고 있네요.. 결벽적 미니멀리즘이라니…막상 제목을 이렇게 만들어보니 뜻밖의 효과가 생겼습니다. 면접을 볼 때면 자주 나오는 질문에 대하여 정돈된 표현으로 답을 할 수 있더군요. 이제 첫 페이지가 완성되었습니다. 다시 자신감이 장전되고 있습니다.생각해보았습니다. 만약 첫 페이지에서 관심을 가지고 다음 페이지를 넘길 때 독자가 기대하는 것이 무엇일까? 어렸을 때부터… 이런 건 아닐 테고, 내 사생활, 구체적인 인적사항도 아니라고 생각했습니다. 최근에 했던 프로젝트부터 보여주고 점점 거슬러 올라가면서 개발이력들을 펼치기로 했습니다. 본격적으로 세부적인 내용을 채워가면서 참고가 되었던 글이 있었습니다. RSS로 구독하던 블로거 중에 변정훈님의 “이력서“에 대한 글을 보면서 내용의 순서나 기본적인 페이지 레이아웃을 잡아갈 수 있었습니다. 지난 스프링캠프 때 직접 만나 감사의 인사를 했었지요. 본격 유명한 개발자의 이력서 따라하기!! 순서는 아래와 같습니다. 특별히, 최근 프로젝트에서 했던 일에 대해 쓸 때 많은 수정을 거쳤는데요, 어떤 관점에서 적을지 좋은 힌트를 얻을 기회가 있었습니다. 이력서를 쓰기 몇 달 전 “훌륭한 개발팀장이 되려면?“이라는 주제로 넥슨의 박종천님의 강연을 들었었습니다. 거기서는 팀장으로서의 업무를 세 가지 관점으로 분류했습니다. Technical Lead, Project Lead, 그리고 People Management. 강연을 들으면서 느낀 바도 많았고, 돌아가서 팀에 적용하면서 체험한 것도 있었던 터라 이 세가지 틀을 사용하니 내용을 정리하기가 쉬워졌습니다. 그때의 강연을 꼭 추천해드리고 싶은데 올라온 영상이 없어서 안타깝네요.지금까지 개발자로서 일해오고 접해본 것들을 보여주긴 했는데, 여전히 2% 부족하다 느꼈습니다. 첫 페이지에서도 timeline을 통해 해왔던 일을 보여주었지만, 내가 어떤 개발자인가를 어필하기 위해 제목과 간략한 소개를 썼었지요. 이쯤에서 내가 어떤 개발자인지 좀 더 보여주고 싶었습니다. 이력서를 보는 독자가 좀 더 실감 나게 저를 상상해 볼 수 있도록요. 만약 같이 일하는 모습을 상상하고 있다면, 이미 반쯤 넘어온 거겠죠.이미 나와 일하고 있다! 이제 스스로 정신승리에 이르고 있습니다…제 자신이 주도했고 좋은 성과가 있었던 일 중 2가지를 꼽았습니다. 그리고 각각에 대해 일을 진행했던 과정을 정리해보았습니다. 어떤 문제에 직면했을 때 그 상황을 잘 파악하고 원인을 알고 그 해결책을 잘 제시하며, 결과물을 만들어 내는 과정을 보여주기 위해 아래와 같은 구성으로 편집해보았습니다. 제 경우 내용을 채우고 나니 왼쪽 제목 공간이 좀 허전해 보여서 두 가지 사례를 추가로 간략하게 넣기도 했습니다.사실 여기까지 쓰면 업무에서의 전문성은 다 보여준 거라고 생각했습니다. 이미 이력서 분량이 네 장이 되었기 때문에 집중해서 이력서를 볼 수 있는 분량으로는 최대한이라고 판단했지요. 이제 남은 것은 자기소개와 기.타.등.등일텐데 이 부분을 다시 집중해서 읽게 하기란 어려울 것 같았습니다. 그래서 자기소개는 좀 편하게 볼 수 있는 내용으로 작성했습니다.자기 철학이나 개인사를 드러내기보단 개발자로서 살아왔던 이야기를 친구나 지인에게 이야기하듯 써보았습니다. 한 번에 너무 길면 보기 힘드니 저의 경우 컴퓨터를 처음 접했을 때와 대학 시절 한 단락, 대학원 과정 중의 경험 한 단락, 스타트업에서의 경험 한 단락, 이렇게 세 부분으로 나누어서 썼습니다. 쓰고 나이 첫 페이지부터 계속 얘기해왔던 것들의 반복이라는 느낌도 들었지만, 좀 더 편한 문체로 풀어쓴다는 생각으로 채웠습니다.이왕 편한 마음으로 보라고 한 페이지니, 왼쪽 제목 공간에 관련된 사진을 작게 넣어 보았습니다. 글로 쓰진 않았지만, 자연스럽게 운동도 좀 했어요 라고 어필도 되구요. 지금에 와서 그때 썼던 페이지를 다시 보니, 좀 길어보이긴 하네요. 세 부분으로 나누어 놓았으니 단락을 좀 더 나누어서 너무 답답하지 않게 보이게 하면 더 좋았겠네요.정말 제목 그대로입니다. 자세히는 안 보았을지라도 장장 다섯 페이지를 넘긴 독자에게 보내는 감사의 멘트와 연락처로 마무리 하고 싶었습니다. 그런데 문제는 감사멘트와 연락처를 넣는 것으로는 한 페이지를 채울 수 없으니, 두 가지 선택지를 생각했습니다. 한 페이지 더 만들어서 마무리하는 것과 이전 페이지의 내용을 좀 줄여서 공간을 만들고 하단에 배치하는 것. 제 경우는 그동안 넣고 싶었지만, 마땅히 넣기 힘들었던 글감과 이야기가 있었던 터라 그 내용을 추가해서 새로 페이지를 구성하기로 했습니다.첫째로 개발자로서의 지속적인 성장과 촉(?)을 기르기 위해 업무와 직간접적으로 연관된 외부 강연이나 컨퍼런스를 참가하였던 경험을 썼습니다. 둘째로는 개인적인 취향일 수도 있지만, 어느 정도 업무와도 연결될 수 있는 취미를 소개했습니다. 취미 부분은 일부러 글쓰기 문체보다는 말하기 문체로 썼습니다. 제 경우는 폰트덕후로서 해왔던 소소한 경험들과 픽셀 단위의 틀어짐을 구분하는 매의 눈(?)을 자랑했는데요, 여기서는 너무 가볍지도 딱딱하지도 않은 분위기로 썼습니다.요즘엔 특별한 이력서 양식 없이도 이력서를 낼 수 있는 서비스들이 제법 있습니다. 물론 입사 전형이 진행되면 최종적으로는 각 회사에서 관리하는 이력서양식으로 다시 써야 하겠지만, 처음으로 자신을 PR할 수 있는 문서인 이력서를 다양한 방법으로 쓸 수 있다는 것은 좋은 기회라고 생각합니다.제 경우는 일반적인 이력서 양식이나 틀에 맞추려고 하면 나이에 비해서 경력이 다소 적어 보이는 것과 대학원 과정에서의 경험들이 잘 드러나지 않는 것이 제 발목을 잡았습니다. 저는 이것을 만회하기 원했고 제가 가진 장점과 능력을 최대한 잘 보여주려고 했습니다. 물론 없던 것을 만들거나 과장한 것은 면접에서 몇 마디 해보면 드러날 것이기 때문에 그런 점에서는 조심스럽게 쓰기도 했습니다.그리고 또 한편으로 중요하게 생각한 것은 잘 보이게하자는 것이었습니다. 사람들은 이력서나 문서들을 볼 때 직감적으로 문서의 모양새를 먼저 보게 될 테니까요. 대학원 과정 중에는 발표자료와 논문을 쓸 일이 많았는데 그 과정에서 얻은 팁을 아래에 간략하게 정리해보았습니다.사실, 페이지의 모양새를 다듬고 나니 이력서가 홍보물이나, 브로셔처럼 보였었습니다. 처음엔 이래도 괜찮을까 생각도 들었지만, 자신을 PR한다는 입장에서는 나쁘지 않은 방식이라고 생각했습니다.아마도 처음 이력서를 쓰는 사회초년생의 경우에는 이력서를 쓰려고 하면 무척이나 막막할 겁니다. 그리고 그 상황에 정해진 틀을 눈앞에 두고 있으면, 더더욱 무엇을 쓸지 도무지 떠오르지 않는 경험을 하게 됩니다. 최근에 취업을 준비하는 후배와 대화하는 중에 느낀 것이 있었습니다.열정도 있고 호기심도 많고 나름대로 경험도 있는 후배인데 이력서 양식 앞에서 잘 쓰지 못하고 있었습니다. 저도 그 틀 안에서는 당장 교정을 해주거나 조언을 해주기도 쉽지 않았습니다. 그래서 그냥 몇 가지 질문을 해봤는데, 이야기로는 술술 풀어내는 것이었습니다. 그래서, 먼저는 틀에 매이지 말고 네가 해왔고 잘하는 것들을 풀어서 써보자고 했습니다. 일단 글감을 많이 풀어서 만들어 보자고 했습니다. 그랬더니 그 후배가 다시 자신감을 찾은 것 같았습니다.나름대로 해보았던 경험들을 풀어서 썼지만, 역시 이건 저 자신을 위한 이력서 만들기였습니다. 그리고 이력서의 모양을 잘 다듬는다 해도 그것만으로는 좋은 결과를 얻기 힘들 것입니다. 실제로 경력과 실력이 우수한 사람은 이력서는 부차적인 것이 될 수도 있습니다. 몇 장의 문서보다 함께 일한 사람의 추천이 더 믿을 수 있는 것이기도 하지요. 하지만 거기에 더해서, 자신이 스스로에게 주는 추천서로의 이력서도 하나쯤 정성들여 만들어 놓으면 좋지 않을까요? :)",http://woowabros.github.io/experience/2017/07/17/resume.html,woowabros,,NULL,2017-07-17
훅으로 Git에 훅 들어가기,"안녕하세요. 우아한형제들 CTO실 주문시스템개발팀의 라태웅입니다.요새 Git은 어느 조직이건 개인이건 많이 사용하고 계신데요, 굉장히 많은 기능이 있죠. 이중 몰라도 큰 상관은 없지만 좀 더 편리하게 Git을 사용할 수 있도록 도와주는 기능인 Git Hook에 대한 소개드리려고 합니다.여러분은 낚이고 계신겁니다(?)Git은 특정 상황에 특정 스크립트를 실행할 수 있도록 하는 Hook이라는 기능을 지원하고 있습니다. 따로 무언가를 설치할 필요는 없고, 모든 git repository에서 이미 지원이 되고 있는데요.터미널로 아무 repository나 접근해서 cd .git/hooks/를 해봅니다..sample 확장자로 된 파일이 많죠?목록을 보시면 .sample 확장자로 되어 있는 파일이 10개 있는데요! 이게 Git에서 지원하는 Hook의 전부랍니다! 몇개 없죠?방금 설명드렸듯이, Git Hook의 정의는 특정 상황에 특정 스크립트를 실행하는 것이고, 따라서 Git Hook이 지원하는 특정 상황은 10개인 것을 알 수 있습니다.각 스크립트가 어느 상황에서 실행되는지에 대한 자세한 설명은 이곳을 참고해주세요!.sample 이라는 확장자를 지우면 각 상황에 샘플이 바로 적용됩니다!이 글에서는 pre-commit(단어 뜻 그대로 커밋 직전에 실행되는 Hook 이랍니다!)이라는 Hook을 통해 커밋 전 이미지를 자동으로 압축하는 스크립트를 작성해보려고 하는데요. 이를 통해 Git Hook을 잘 쓰면 정말 편하겠구나! 좋은 기능이구나! 하는 생각이 드셨으면, 그리고 적용해보셨으면, 공유해주셨으면! 하는 바람입니다!아쉽게도 이 글은 Mac 전용으로 작성되었습니다. Git Hook에 대한 내용은 플랫폼에 관계없이 동일합니다!먼저 이미지 압축 유틸리티인 ImageOptim를 다운로드 받은 뒤, Application 폴더에 넣습니다. (ImageOptimCLI의 기본 참조 경로가 Application이기 때문)그 다음, shell script에서 ImageOptim을 쓸 수 있도록 ImageOptimCLI를 설치하고, PATH를 잡아줍니다.위에서 .sample 확장자를 지우면 샘플이 바로 적용된다고 말씀드렸었죠?그렇습니다. Git Hook을 적용하려면 ‘OS가 실행가능한 파일을 .git/hooks/ 디렉토리에 파일명을 맞춰서 넣어주면’ 됩니다. 정말 쉽죠?이 글에서는 pre-commit Hook을 적용할 것이기 때문에 .git/hooks/pre-commit 파일을 만들어주면 되겠죠!pre-commit 파일을 생성한 뒤, 아래의 내용을 적도록 합니다.끝입니다.정말로요.정말 쉽죠?진짜 되는지 해볼까요?이미지 파일을 추가한 뒤 commit 했더니 자동으로 ImageOptim이 실행되어 압축이 진행되는 모습얼마나 압축되었는지도 친절하게 알려준답니다!이렇게 적용하기 쉬운 Git Hook, 언제까지 수동으로 압축하실건가요! (그러다 까먹고)짧고 간단하지만 강력하고 깊이 파고들면 훅 하고 낚이는 Git Hook! 지금 바로 커밋 전 귀찮은 작업을 해주거나 실수한 것들을 자동으로 체크해주는 Hook을 적용해보시는 것은 어떨까요?감사합니다!",http://woowabros.github.io/tools/2017/07/12/git_hook.html,woowabros,,NULL,2017-07-12
아이튠즈커넥트의 신기능 - 자동업데이트 사용자를 대상으로 점진적출시,"새로 배포하는 버전에 문제가 있을지도 몰라..점진적 출시는 2017년 6월 초에 아이튠즈커넥트 내에 새로 생긴 기능입니다. 점진적 출시에 대해 알기 위해서 우선 알아야 할 사항은, 자동 업데이트 기능입니다. 이 기능은 다운로드한 앱의 새로운 버전이 배포가 되면 자동으로 업데이트를 시켜줍니다.설정 > iTunes 및 App Store > 업데이트 켜기설정 앱에서 iTunes 및 App Store에 있는 업데이트 기능을 켜면, wifi 환경에서는 기존의 다운로드한 앱에 업데이트가 있을 경우 자동으로 업데이트합니다. 셀룰러 데이터 사용을 체크하면 100M 이하의 앱은 셀룰러 데이터를 사용할 때도 업데이트가 됩니다.바로 여기에서 점진적 출시가 동작하게 됩니다. 1 아이튠즈커넥트에서 앱 배포를 위해 새로운 버전을 추가하면, 아래의 이미지처럼 점진적 출시를 설정하는 메뉴가 생겼습니다 2 리뷰 심사가 완료되고 배포를 하면 점진적 출시라는 표시가 나타나고, 모든 사용자에게 출시라는 버튼이 노출됩니다.  이 버튼을 통해 점진적출시를 하고 있는 중에도 모든 사용자에게 출시가 가능합니다. 3 배포 후에는 점진적 출시를 설정하는 메뉴 위치에 아래의 이미지처럼 점진적 출시 상태를 나타내주게 됩니다. 또한, 점진적 출시를 일시정지할 수 있습니다. 아래의 이미지에서 보는 것처럼 업데이트 대상 비율은 매일매일 일정량으로 늘어나지 않습니다. 배포 후 5일 동안 20%의 사용자에게만 배포될 정도로, 배포 초기 며칠 동안은 많은 사용자에게 배포되지 않습니다. 이 기간에 혹시 문제가 된다면, 여기 있는 점진적 출시 일시정지 버튼을 이용하여 자동 업데이트 배포를 멈출 수 있습니다. 4 일시정지는 30일의 기간 안에 몇 번이든 변경이 가능합니다. 만약, 새로 배포된 버전에 정말로 문제가 있는 것이 확인된다면 우선 자동 업데이트 배포를 일시정지 상태로 변경하고, 빠르게 다음 버전을 배포하는 방법으로 사용자의 불편을 최소화할 수 있습니다저희는 버그 없이 개발하려고 노력하지만, 예외적으로 치명적인 에러가 담긴 버전이 출시될 가능성은 있습니다. 새로 생긴 점진적 출시 기능을 사용하면 완벽하진 않지만, 버그를 겪는 사용자의 수를 줄여줄 수 있는 가능성이 있습니다.사용법이 어렵지 않으니, 다른 앱들도 적용해서 배포했으면 좋겠습니다~글에서 담지 못한 몇몇 가지 궁금점은, 아이튠즈커넥트에서 제공하는 Q&A를 번역하는 식으로 제공하겠습니다. 링크. iTunes Connect Resources and HelpYou can release an update to your iOS app in stages by enabling Phased Release for Automatic Updates in iTunes Connect. With phased release, your version update will go out to an increasing percentage of users with automatic updates turned on, over a 7-day period. The percentage of users completing the automatic update each day during the phased release period will be displayed in iTunes Connect. All users will still be able to manually update your app directly from the App Store and new customers will always see your most recent Ready for Sale version. If you find an issue with your version update, you can pause the phased release at any time, for a total of up to 30 days, regardless of the number of pauses. Learn more.아이튠즈에서 점진적 출시를 사용할 수 있음. 아이폰에서 자동 업데이트를 킨 사람 중에 7일 동안 퍼센티지별로 배포가 됨. 점진적 배포 기간 동안에는 아이튠즈커넥트에서 얼마나 업데이트가 완료됐는지 살펴볼 수 있음. 배포 후 직접 앱스토어에서 업데이트하는 버전은 가장 최신 버전으로 모든 유저가 같음. 만약 새로 업데이트한 버전에서 문제가 발생된다면 멈춤 횟수와 상관없이 최대 30일까지 배포 멈춤 가능Users with automatic updates turned on are selected randomly, based on their Apple ID, not their device. If a user has multiple devices, and each one has automatic updates turned on, they will receive the automatic update in the same time frame while an app is in phased release.업데이트 대상자는 자동 업데이트를 킨 사람 중에서 apple id를 기반으로 하여 랜덤으로 선택됨. 사용자가 여러 기기를 가지고 있고 모두 자동 업데이트를 켰다면, 그 사용자는 동시에 자동 업데이트가 됨No, the percentage of users completing the automatic update each day during the phased release period is set as shown below, and will be displayed in iTunes Connect.점진적 출시를 사용할 경우 하루에 완료될 사용자의 비율을 조정할 수 없음. 완료될 사용자의 비율은 아래와 같이 고정되어 있음.No, it’s not possible to target users by specific demographics, such as age, gender, territory, or device information such as OS version or device type. Users are selected at random.개발자가 업데이트할 대상을 선택할 수 없음. 대상자는 랜덤으로 선택됨.If you find an issue with your version update, you can pause the phased release at any time, for a total of up to 30 days (regardless of the number of pauses), and then submit a new version. It’s not possible to pull back a version update or prevent customers from manually updating a Ready for Sale version.배포를 도중에 취소할 수는 없고, 점진적 출시를 멈춤은 가능. 멈춰놓고 새로운 버전을 출시하면 됨. 이전 버전으로 되돌리는 것은 불가능After your version update is paused for more than 30 days, the release will resume on the day that it was paused, and you won’t be able to pause your release again.점진적 출시를 멈춰놓고 30일이 지나면 자동적으로 재개된다. 그 이후에는 다시 멈춤이 불가능",http://woowabros.github.io/tools/2017/07/11/phased_release.html,woowabros,,NULL,2017-07-11
Java Enum 활용기,"안녕하세요? 우아한 형제들에서 결제/정산 시스템을 개발하고 있는 이동욱입니다.이번 사내 블로그 포스팅 주제로 저는 Java Enum 활용 경험을 선택하였습니다.  이전에 개인 블로그에 Enum에 관해 알게 된 점들을 정리했음에도 선택한 이유는 제가 Enum을 통해 많은 도움을 얻었기 때문입니다. 상반기 팀 최대 과제인 신규 정산 플랫폼을 개발하면서 Enum이 정말 많은 문제를 해결해주고 예방해주었습니다. 그래서 새로운 주제, 신기술보다 기본적이지만 실질적으로 저에게 도움을 주었던 Enum을 다시 정리하게 되었습니다.이미 기존의 많은 블로그와 책에서 Enum의 정의와 기본적인 내용을 소개했기 때문에 그런 부분들은 생략하고, 여기서 소개드릴 것은 “프로젝트를 진행함에 있어 발생한 문제를 Enum을 통해 어떻게 해결했는가” 입니다. “얘는 이런 것도 몰랐구나” 라는 넓은 마음으로 봐주시면 될 것 같습니다.(뉴비는 아니지만 뉴비와 같은 마음과 실력으로 갑니다!)여기에서 사용된 코드는 실제 회사에서 사용한 코드는 아니며, 포스팅을 위해 최대한 유사하게 만들어진 별도의 샘플 코드임을 먼저 말씀드립니다.개발을 진행할때 Enum을 통해 얻는 기본적인 장점들은 아래와 같습니다.이 장점들은 모든 언어들의 Enum에서 얻을 수 있는 공통된 장점입니다. 하지만 Java의 Enum은 이보다 더 많은 장점을 갖고 있습니다. C/C++의 경우 Enum이 결국 int값이지만, Java의 Enum은 완전한 기능을 갖춘 클래스이기 때문입니다. (이 글의 제목이 Enum 활용기가 아닌, Java Enum 활용기인것도 이 때문입니다.)예제로 그 장점들을 하나씩 소개드리겠습니다.이펙티브 자바의 Enum 파트를 보시면 더 다양하고 깊은 사례를 보실 수 있으십니다.매일 배치를 돌며 하나의 테이블(테이블명 : origin)에 있는 내용을 2개의 테이블(테이블명 : table1, table2)에 등록하는 기능이 있습니다.문제가 됐던 것은 origin 테이블의 값은 “Y”, “N”인데, table1, table2는 “1”/”0”, true/false 형태인 것입니다. 그러다보니 구 정산 시스템에선 이를 분류하는 메소드를 만들어 사용해왔습니다.기능상의 문제는 없지만, 몇가지 문제가 있었습니다.그래서 이 부분을 Enum으로 추출했습니다.“Y”, “1”, true 가 한 묶음으로, “N”, “0”, false가 한 묶음이 된 것을 코드로 바로 확인할 수 있습니다. 또한 추가 타입이 필요한 경우에도 Enum 상수와 get메소드만 추가하면 됩니다. (만약 lombok의 @Getter을 사용하신다면 Enum의 get 메소드까지 제거가 되어 더욱 깔끔한 코드가 됩니다.) 이를 사용하는 곳에서도 역시 깔끔하게 표현이 가능합니다.TableStatus라는 Enum 타입을 전달받기만 한다면, 그에 맞춘 table1, table2값을 바로 얻을 수 있는 것을 확인할 수 있습니다.서로 다른 계산식을 적용해야할 때가 있습니다. 예를 들어 DB에 저장된 code의 값이 “CALC_A”일 경우엔 값 그대로, “CALC_B”일 경우엔 *10 한 값을, “CALC_C”일 경우엔 *3을 계산하여 전달해야만 합니다. 가장 쉬운 해결 방법은 아래와 같이 static 메소드를 작성하여 필요한 곳에서 호출하는 방식일 것입니다.이렇게 메소드로 분리하고 실제로 사용해보면, 코드는 코드대로 조회하고 계산은 별도의 클래스&메소드를 통해 진행해야함을 알 수 있습니다.이 상황에 문제가 있다고 생각했습니다. LegacyCalculator의 메소드와 code는 서로 관계가 있음을 코드로 표현할 수가 없기 때문입니다.뽑아낸 Code에 따라 지정된 메소드에서만 계산되길 원하는데, 현재 상태로는 강제할 수 있는 수단이 없습니다. 지금은 문자열 인자를 받고, long 타입을 리턴하는 모든 메소드를 사용할 수 있는 상태라서 히스토리를 모르는 분(저와 같은^^;)들은 실수할 확률이 높습니다.“DB의 테이블에서 뽑은 특정 값은 지정된 메소드와 관계가 있다.” 이 사실을 항상 문서와 구두로만 표현해야 하는게 올바른 방식일까 고민하였습니다. 더불어 역활과 책임이라는 관점으로 봤을때, 위 메세지는 Code에 책임이 있다고 생각하였습니다. 그래서 이를 해결하기 위해 Enum을 활용하였습니다.보시는것처럼 각각의 Code가 본인만의 계산식을 갖도록 지정하였습니다. (Java8이 업데이트 되면서 이제 인자값으로 함수를 사용할 수 있게 되었습니다. 물론 내부적으로는 인터페이스를 사용하니 완전하다고 할순 없겠죠^^;)Entity 클래스에 선언하실 경우에는 String이 아닌 enum을 선언하시면 됩니다.JPA를 사용하시는 경우 위 처럼 @Enumerated(EnumType.STRING)를 선언하시면 Enum 필드가 테이블에 저장시 숫자형인 1,2,3이 아닌, Enum의 name이 저장됩니다. 여기서는 CALC_A, CALC_B, CALC_C등이 저장된다고 생각하시면 됩니다. ordinal(숫자형)을 사용하게 되면 Enum 상수 값들 사이에 하나가 추가 될 경우 (ex: CALC_B_2) 3이란 ordinal은 CALC_C가 아닌 CALC_B_2를 가리키게 됩니다. 전체 값이 변경되버리는 위험한 일이기 때문에 Enum에선 @Enumerated를 함께 사용하시는걸 추천드립니다. (자바 ORM 표준 JPA 프로그래밍 4.7.2절을 참고하시면 좀 더 자세히 확인하실 수 있습니다.)그리고 실제로 사용하는 곳에서도 이젠 직접 Code에게 계산을 요청하면 됩니다.값(상태)과 메소드(행위)가 어떤 관계가 있는지에 대해 더이상 다른 곳을 찾을 필요가 없게 되었습니다. 코드내에 전부 표현되어 있고, Enum 상수에게 직접 물어보면 되기 때문입니다.추가로 Java7 이하 버전을 사용하시는 분들은 추상메소드를 활용하여 상수별 메소드 구현을 하시면 됩니다.Enum의 필드로 추상메소드를 선언하고, 이를 상수들이 구현하도록 하면 Java8의 Function 인터페이스를 사용한 것과 동일한 효과를 보실수 있습니다.결제라는 데이터는 결제 종류와 결제 수단이라는 2가지 형태로 표현됩니다. 예를 들어 신용카드 결제는 신용카드 결제라는 결제 수단이며, 카드라는 결제 종류에 포함됩니다. 이 카드 결제는 페이코, 카카오페이등 여러 결제 수단이 포함되어 있다고 생각하시면 될 것 같습니다. 간단하게 그림으로 표현하자면 아래와 같습니다.(배민에도 간편 결제인 배민페이가 있답니다.)결제된 건이 어떤 결제수단으로 진행됐으며, 해당 결제 방식이 어느 결제 종류에 속하는지를 확인할 수 있어야만 하는 조건이 있습니다. 이를 해결하는 가장 쉬운 방법은 (또!?) 문자열과 메소드, if문으로 구현하는 것입니다.여기에서도 여러 문제가 있다고 생각하였습니다.특히 3번 문제가 결정적인 이유였습니다. 만약 결제종류를 기준으로 Print 하는 기능과 Push 하는 기능이 필요하다고 가정해보겠습니다. 그럼 문자열+테이블 조합으로는 어쩔수 없이 아래와 같이 구현될 수 밖에 없습니다.각각의 메소드는 원하는 떄에 사용하기 위해 독립적으로 구성할 수 밖에 없는데, 그럴때마다 결제종류를 분기하는 코드가 필수적으로 필요하게 됩니다. 이건 좋지 못한 방법이라는 생각이였습니다.결제종류, 결제수단등의 관계를 명확히 표현하며, 각 타입은 본인이 수행해야할 기능과 책임만 가질 수 있게 하려면 기존 방식으로는 해결하기가 어렵다고 생각하였습니다. 그래서 이를 Enum으로 전환하였습니다.(Enum에서 메소드를 사용하는 방법은 위 2번 사례에서 진행했기 때문에 여기선 생략하겠습니다.)Java의 Enum은 결국 클래스인 점을 이용하여, Enum의 상수에 결제종류 문자열 리스트를 갖도록 하였습니다. 각 Enum 상수들은 본인들이 갖고 있는 문자열들을 확인하여 문자열 인자값이 어느 Enum 상수에 포함되어있는지 확인할 수 있게 되었습니다.관리 주체를 PayGroup에게 준 결과로, 이젠 PayGroup에게 직접 물어보면 됩니다.여기까지 진행 후 코드를 해결하지 못한 문제가 하나 남아 있었습니다. 결제수단이 문자열인 것입니다. DB 테이블의 결제수단 컬럼에 잘못된 값을 등록하거나, 파라미터로 전달된 값이 잘못되었을 경우가 있을 때 전혀 관리가 안됩니다. 그래서 이 결제수단 역시 Enum으로 전환하였습니다.이렇게 Enum으로 결제종류를 만들고, PayGroup에서 이를 사용하도록 하겠습니다.그리고 이를 사용하는 코드가 아래와 같이 변경되었습니다.DB 혹은 API에서 PayType으로 데이터를 받아, 타입 안전성까지 확보하여 PayGroup 관련된 처리를 진행할 수 있게 되었습니다.정산 플랫폼은 수많은 카테고리가 존재하기 때문에 UI에서 select box로 표현되는 부분이 많습니다. 구 정산 시스템에선 카테고리 관련 데이터를 DB에서 관리하고 있었습니다.(기존에 관리되던 코드테이블)코드 테이블을 별도로 두고 이를 조회하여 사용하다보니, 계속해서 문제가 발생했습니다.특히나 카테고리의 경우 6개월에 1~2개가 추가될까말까한 영역인데 굳이 테이블로 관리하는 것은 장점보다 단점이 더 많다고 생각하였습니다. (물론 CI가 구축되어 하루에도 몇번씩 배포할 수 있는 상황이기에 가능하다고 생각합니다.) 카테고리성 데이터를 Enum으로 전환하고, 팩토리와 인터페이스 타입을 선언하여 일관된 방식으로 관리되고 사용할 수 있도록 진행하게 되었습니다.Enum을 바로 JSON으로 리턴하게 되면 상수 name만 출력이 됩니다. 저에게 필요했던건 DB의 컬럼값으로 사용될 Enum의 name과 View Layer에서 출력될 title 2개의 값이기 때문에 Enum을 인스턴스로 생성하기 위한 클래스 선언이 필요했습니다.먼저 클래스의 생성자로 일관된 타입을 받기 위해 인터페이스를 하나 생성하였습니다.값을 담을 클래스(VO)는 이 인터페이스를 생성자 인자로 받아 인스턴스를 생성하도록 합니다.Enum은 미리 선언한 인터페이스를 구현(implements)만 하면 됩니다.이젠 필요한 곳에서 Enum을 Value 클래스로 변환한 후, 전달하기만 하면 됩니다.원했던대로, JSON 결과가 나오는 것을 확인할 수 있습니다.Enum을 중심으로 해서 View Layer와 Application, DB가 하나로 관리되도록 변경은 되었지만 한가지 아쉬운 점이 발견되었습니다. 필요할 때마다 Enum.values를 통해 Value 인스턴스를 생성하는 과정이 반복되는 것 이였습니다. 런타임에 Enum의 상수들이 변경될 일이 없기에, 관리 대상인 Enum들은 미리 Bean에 등록하여 사용하도록 변경해보았습니다. Enum Value들을 담을 팩토리 클래스를 생성하고,이를 Bean으로 등록하였습니다.View Layer에서 사용하길 원하는 Enum 타입들은 EnumMapper라는 Bean에 등록하기만 하면 됩니다.Enum을 적극적으로 활용하면서 많은 장점을 얻게 되었습니다.도대체 이 코드가 어디에서 쓰이는 것인지, 이 필드에는 어떤 값들만 허용 가능한 것인지, A값과 B값이 실제로는 동일한 것인지, 전혀 다른 의미인지, 이 코드를 사용하기 위해 추가로 필요한 메소드들은 무엇이고, 변경되면 어디까지 변경해야하는 것인지 등등 불확실한 것들이 너무 많았던 상황에서 Enum을 통해 확실한 부분과 불확실한 부분을 분리할 수 있었습니다.특히 가장 실감했던 장점은 문맥(Context)을 담는다는 것이였습니다.  A라는 상황에서 “a”와 B라는 상황에서 “a”는 똑같은 문자열 “a”지만 전혀 다른 의미입니다. 문자열은 이를 표현할 수 없지만, Enum은 이를 표현할 수 있었습니다. 이로 인해 실행되는 코드를 이해하기 위해 추가로 무언가를 찾아보는 행위를 최소화 할 수 있게 되었습니다.  이 코드의 의미와 용도를 파악하기 위해 컨플루언스를 검색하고, 엑셀과 워드 파일을 찾고, 레거시 테이블을 Join & Group by 하고, PHP 코드를 다시 찾는 과정이 정말 정말 비효율적이였습니다. (역설적이게도 해당 시스템을 가장 잘아시는분이 문서를 작성할수록, 당연한 내용의 범위가 넓어 누락되는 내용이 많아지고 위 과정이 더 많아지게 되었습니다.)Enum을 사용하는데 있어 가장 큰 허들은 “변경이 어렵다“란 의견입니다. 정말 코드를 추가하거나 변경해야 하는 일이 빈번하다면, 매번 Enum 코드를 변경하고 배포하는것보다 관리자 페이지에서 관리자가 직접 변경하는 것이 훨씬 편리할 수 있다고 생각합니다. 하지만 우리가 관리하는 이 코드 테이블은 과연 얼마나 자주 변경되나요?만약 위와 같은 상황이라면 테이블로 관리함으로써 얻는 장점이 정적언어를 활용함으로써 얻는 장점을 버릴정도로 더 큰지 고민해봐야할 문제라고 생각합니다. 실제로 신규 정산 플랫폼은 단순 코드 테이블이 하나도 없습니다. 구 정산 플랫폼은 3개의 코드테이블에서 수백개의 코드를 관리하고 있었지만, 이를 모두 제거하였습니다. 그만큼 Enum을 적극적으로 사용하고 있고 그 효과를 보고 있습니다. (물론 망치질밖에 모르는 사람은 모든 것이 못으로 보인다는 말처럼 Enum으로 모든걸 해결하려고 하면 안된다고 생각합니다. 적정선에서 Enum으로 관리할 부분과 테이블로 관리할 부분을 잘 나누어야 된다고 생각합니다.)제가 준비한 내용은 여기까지입니다. 부족함이 많은 글임에도 끝까지 읽어주셔서 감사합니다. 다음에도 이와 같이 기본적인 내용이지만, 프로젝트에서 도움을 받는 일이 발생한다면 잘 정리해서 공유드리겠습니다. 그럼, 다음에 또 뵙겠습니다. 감사합니다!(사용된 모든 짤은 레진코믹스의 레바툰입니다.)",http://woowabros.github.io/tools/2017/07/10/java-enum-uses.html,woowabros,android,NULL,2017-07-10
레거시 코드를 파괴하는 Vim 벽돌 깨기,"혼돈! 파괴! Vim!누군가 마음속에서 속삭이더군요.그래서 정신 나간 Vim 플러그인을 하나 만들어 보았습니다.플러그인을 설치한 다음 코딩하다 분노가 느껴지는 타임이 도래했을 때 :VimGameCodeBreak를 입력하면 해당 코드를 스테이지 삼아 벽돌 깨기 게임이 시작됩니다. 게임으로 박살 난 코드가 원본 파일에 저장되지는 않으니 와장창 다 때려 부수면 됩니다. 플레이가 귀찮으면 볼을 떨궈도 Life가 줄지 않는 GOD MODE를 켜고 사라져가는 코드를 구경해도 좋습니다.와아!  파괴를 부르는 생산성 저하 도구 등장!개발에는 대략 3주 정도 걸렸습니다. 본업이 게임 개발도 아니고 업무 시간에 코드를 파괴하며 놀 수는 없으니, 점심시간이나 퇴근 후에 시간을 내서 코드를 작성했으며 주말에도 틈틈이 컴퓨터 앞에 앉아있었어요. 사실은 작은 게임들을 만드는 걸 좋아해서 (취미라고 할 수도 있을 것 같습니다) 집에서는 계속 CodeBreak만 잡고 있었다고 할 수 있습니다.이 때까지만 해도 여흥으로 만든 이 게임이 흥하게 될 줄은 아무도 몰랐습니다….아무튼, 성격상 프로토타입을 빠르게 만들고 뒤이어 리팩토링하는 방식을 선호하여 다음과 같이 작업했습니다.만드는 도중에 몇 가지 까다로운 문제들을 마주하고 어렵사리 해결하기도 했습니다. 여러 가지 재미있는 문제들이 있었지만… 특히 다음의 세 문제가 기억에 많이 남습니다.Vimscript는 VimL이라고도 부르며 일반적으로는 Vim plugin 제작을 위해 작성되고 Vim 내에서만 돌아가는 DSL 입니다. Python이나 Perl이 떠오르는 특징들이 보이기도 하지만 곰곰이 살펴보면 두 언어의 이념을 따르는 언어가 아니란 것도 알 수 있습니다. 아마 C++나 Java와 같은 엄격한 언어들에 익숙한 분들께 이 언어는 지옥일 수 있을 겁니다.예를 들어 다음의 코드는 축약의 차이만 있을 뿐 똑같은 세 함수를 정의합니다. 알아보기 힘든 코드를 짜는 데에는 환상적이겠죠.한편 List를 다루는 방식은 Python의 괴상한 친척 같은 느낌도 듭니다.Vim 편집기 명령어의 특성상 상당수 명령어에 축약 표현이 있고 비슷한 문법을 가진 다른 대중적인 언어의 관용구와 차이점이 있으며, 테스트 코드를 작성하기에도 어려움이 많습니다(Vader.vim이라는 훌륭한 테스트 프레임워크가 있지만, 아직 공부를 못했어요). 아마 여기까지 읽어주신 분들이라면 가급적 멀리하고 싶은 언어로 생각하시겠네요. 하하하 ;ㅁ;하지만 Vimscript는 Vim의 DSL인 만큼 익숙해질수록 나름의 편리함과 유쾌함을 느낄 수 있으며 답답한 만큼 무언가를 만들어냈을 때의 즐거움이 큰 편입니다. 제가 Vim을 좋아해서 그런 것도 있겠지만, Vim에서 작업하는 것은 대체로 게임같이 즐거운 일이죠.아무튼, 완벽한 대안이 있는 것도 아니고, 테스트 코드 작성도 어려우므로 저는 Vim plugin 개발에서 가장 중요한 것은 가독성이라고 여기게 되었습니다. 외국의 다른 분들이 만든 멋진 Vim plugin 코드를 읽을 때도 가독성 때문에 어려움이 많았거든요. 따라서 다음과 같은 원칙을 생각하게 되었습니다.다음은 개발을 시작한 지 일주일쯤 되었을 때의 프로토타입입니다.영상을 보면 다음과 같은 문제들을 발견할 수 있습니다.이 세 문제는 각자 다른 카테고리에 속한 것처럼 보이지만, 속도 저하와 관련이 있다는 특징이 있습니다. 다음과 같은 방식으로 느려터진 속도를 다소 만회할 수 있었습니다.UTF-8에서 한글은 3 byte로 구성됩니다. MARK 21 Specification의 Code Table Korean Hangul 표를 살펴보면 초성 중성 종성이 1 byte씩 차지하기 때문인 것을 알 수 있습니다.1 한편 Vim에서는 문자 위에 커서를 놓고 g8을 입력하면 다음과 같이 손쉽게 문자의 byte 값을 볼 수 있습니다.오 byte 단위로 작업할 일이 있다면 정말 편리하겠네요? 그런데 이것이 이 게임에서는 좀 짜증 나는 문제가 됩니다. 소스코드에 multibyte 문자로 주석이 달려 있을 때 공이 이상하게 움직이는 것을 발견했거든요.고의로 문제를 유발한 위의 gif 영상을 잘 살펴보면 공이 한글이 있는 라인을 지나갈 때 순간적으로 기대한 위치보다 왼쪽으로 점멸하는 것을 볼 수 있습니다. 이유를 이해하기 쉽게 관계된 사실들을 나열하자면 다음과 같습니다.즉 한글이 왼쪽에 있다면, 최종적으로 표현된 공의 x 좌표 위치가 왜곡되어 보인다는 것입니다. 그뿐만 아니라 만약 공이 한글의 3 byte 중 영 좋지 못한 곳을 지나가면 2개의 byte 문자가 화면에 나타나기도 했습니다.이 문제를 해결하기 위해서 머리를 싸매고 고민을 했습니다.“라인별로 string 길이와 byte 길이를 비교해서 두 길이가 같지 않으면 multibyte 문자가 있다고 가정하고, 그 차이를 2로 나누면 multibyte 문자의 수가 나올 텐데… 아 이것만으로는 multibyte 문자의 위치를 확정할 수는 없구나. 임의의 x 값에 대해 왼쪽에 있는 multibyte 문자의 수를 구하는 것이 중요하니 라인별로 이진 탐색을 할까?”그리고 진짜로 이진 탐색 코드를 작성하기 시작할 무렵… 이전까지 알지 못했던 Vim 명령어를 하나 알게 되었습니다.아… |를 입력하면 l 처럼 움직이지만, 실제로는 screen column 기준으로 움직이는구나! 역시 매뉴얼을 잘 읽어야 고생을 덜 한다는 교훈을 얻고 |를 사용해 x 좌표 문제를 해결할 수 있었습니다.위의 문제들까지 나름 무난하게 해결하고 나서는 개발이 다 끝났다고 생각했고 마무리 작업으로 돌입했습니다. 아직 이런저런 작은 문제들이 남아있긴 했지만, 천천히 해결하면 된다고 생각했거든요. 며칠 후 이 정도면 됐다는 생각이 들어 트위터에도 올리고 회사 동료들과 개발자 친구들에게 보여주며 신나게 놀았습니다.그런데 팀 동료인 허승원 주임님이 이 게임을 해커 뉴스에 올려보면 어떻겠냐는 조언을 주시더군요. 별다른 생각 없이 해커 뉴스에 가입하고, CodeBreak의 Github 저장소 링크를 올렸습니다.그런데 1~2시간 후 누가 트위터에서 제 저장소가 Hacker News 트위터에 떴다고 알려주길래 들어가서 봤더니 Hacker News 제일 윗자리에 제 글이 있었습니다. 그리고 저녁때쯤 되자 팀 동료인 남규진 님이 Github 트렌드에 제 저장소가 올라갔다고 알려주셨어요.그리고 저장소에 별이 찍히기 시작했습니다.다음 날 아침이 되자 pull request도 두 개나 들어와 있고 issue도 등록되어 새벽 다섯시에 일어나 pr을 검토하고 머지해주고 issue도 읽어보고 처리해주었습니다. 엄청난 행운이 다가온 느낌이었습니다.해커 뉴스 첫 번째 위치에 5시간 정도 올라가 있었습니다.다음 날이 되자 Trending Repositories 순위도 올라서 2번 위치까지 올라갔습니다;;가문의 영광이 글을 쓰고 있는 지금(이틀 후) 확인해보니 Github Star 가 910 개에 이르렀습니다. 광고 이메일이 오기도 하고, 트위터와 구글로 검색해보니 CodeBreak에 대해 대화하는 사람들의 글도 찾아볼 수 있었습니다. 대체로 웃고 즐거워하는 분위기의 글들이 많아 무척 기뻤고 많은 사람에게 재미를 준 것 같아 행복을 느끼고 있습니다. 아마 이런 즐거움도 소프트웨어 개발의 아름다운 측면이 아닐까 생각해 봅니다.마지막으로 Reddit에서 CodeBreak에 대한 스레드를 하나 발견했는데 큰 감사와 부끄러움을 동시에 느끼게 하는 코멘트가 있었습니다.rathrio: “This is absolutely amazing! I encourage everyone to skim over the code! It’s surprisingly readable Vimscript.”rathrio님 감사합니다. 그리고 CodeBreak를 다운받은 분들과 이 글을 읽어주신 분들께도 감사를 드립니다.VimGameCodeBreak github repositoryEOB바로잡습니다. UTF-8에서 한글의 초성, 중성, 종성이 각각 1 byte 씩 차지한다는 것은 제 추측이었으며 잘못된 정보입니다.Frank Hyunsok Oh님께서 첨부한 멘션을 인용합니다. 중간에 “초성 중성 종성이 1 byte씩 차지하기 때문”은 잘못된 정보같습니다. 한번 더 확인해 보시면 좋을것 같아요. 말씀하신 초중종성 분리 가능은 원래의 유니코드 한글 소리마디(Hangul Syllables) 코드포인트의 특징이고, 이를 인코딩한 UTF-8은 원래의 16비트 xxxxyyyyyyzzzzzz를 1110xxxx 10yyyyyy 10zzzzzz 처럼 인코딩합니다. 원래의 한글 소리마디 코드포인트에서는 ((초성 값 x 21) + 중성 값) x 28 + 종성 같은 형식으로 인코딩이 되어 있고요. ↩",http://woowabros.github.io/tools/2017/07/06/vim-game-code-break.html,woowabros,,NULL,2017-07-06
우리가 부르는 시니어 개발자는 누구인가?,"큰 프로젝트를 마치기 전에 저의 진로를 두고 많은 고민을 하였습니다. 개발을 한지 10여년이 지났고, 짧은 시간안에 저의 Technology Tree에서 큰 가지가 나누어 질 것이라고 생각이 들었기 때문에 이 고민은 자연스럽게 삶에 대한 고민으로 이어지고 있었습니다. 그리고 수 많은 고민중에 “나는 어떤 개발자인가?”를 스스로 묻게 되었고, 그 중에 가장 먼저 들었던 생각이 시니어 개발자라는 뜻은 무엇이고, 나는 시니어인지를 되묻게 되었습니다.이 글을 쓰는 지금은 시니어라는 의미에 대해 나름대로 일단락 지었고, 수 많은 자의적, 타의적 질문 시간을 가지면서 정리를 하였습니다. 물론 이렇게 일단락 지어진 내용은 결론이 아니라 진행형이고 언제든지 바뀔 수 있다고 생각합니다. 그리고 이제 더 나은 결론을 위해 제가 그동안 고민했고 일단락 맺었던 내용을 공유할까 합니다.가장 먼저 “senior development”라는 간단한 키워드로 구글링을 해보면, 관련된 주제를 가지고 여러 블로그의 글들이 쉽게 검색이 됩니다. 그리고 stack exchange에서도 수백개의 비슷한 질문들을 연결시켜 주는 내용이 검색이 될 것 입니다. 또한 도서 중에서는 로버트 마틴 옹의 “Clean Coder”나 론 제프리스 옹의 “The Nature of Software Development”에서도 좋은 개발자에 대한 가치관이나 행동들을 이야기 하며, 소프트웨어 장인에 대해서 서로 비슷하게 이야기를 풀어 가는 모습을 찾을 수 있을 것 입니다.다음은 클린코더에서 말하는 소프트웨어 마스터, 즉 장인에 대한 글 중 일부 입니다.장인은 한가지 이상의 중요 소프트웨어 프로젝트를 주도했던 프로그래머들이다.  그들은 전형적으로 10년 이상의 경력을 가지고 여러 다른 시스템, 언어 및 운영 시스템 작업을 해왔다. 그들은 복수의 팀들을 주도하고 조정하는 법을 알며, 능숙한 디자이너와 건축가들이며, 힘들이지 않고 다른 모든 이들을 위해 코드를 처리할 수 있다. 그들은 경영직 제안을 받고도 이를 거절하거나, 자신들의 주된 기술적 역할과 통합 시켰다.또한 판독, 연구, 실행, 및 가르치기를 통해 그런 기술적 역할을 유지한다.the guardian의 개발자 블로그 포스팅 중에 “What does it mean to be a senior developer”에서는 시니어 개발자란 “다른 동료 보다 더 많은 전문지식을 가진사람과 다른 개발자를 리딩하거나 방향을 제시하는 사람”으로 이야기를 하고 있습니다.하지만 현실은 앞선 기준들과 다르게 시니어를 규정짓곤 합니다.첫번째로 많은 개발 그룹은 연차에 비례해서 시니어와 주니어를 구분짓고 있습니다. 앞선 블로그의 글이나 유수한 책에서 다뤘던  기술력, 판단력, 소통능력을 중심으로 한 시니어에 대한 판단 기준들보다 우리는 개발 경력이 몇년정도 되는가로 시니어 개발자를 구분짓곤 합니다. 아마도 그 이유는 시간이 지나면 관련 지식도 늘어날 것이라는 생각과 시간에 따라 경험이 쌓일 것이라는 전제를 가지고 있기 때문일 것 입니다. 물론 1만 시간의 법칙처럼 끊임없이 어느 단계이상의 수준을 보이려면 절대적인 시간이 필요하다고는 하지만, 모든 사람들이 연차 만큼의 노력을 한다고 생각하는것은 적지않은 오류를 범할 수 있습니다. 그리고 정작 연차가 많아도 경력이 적은 사람과 지식의 차이가 나지 않거나 경험의 차이가 나지 않는 경우를 우리는 쉽게 접하곤 합니다.두번째로 스타 개발자라는 명성으로 시니어 개발자를 판별하고 그의 모든 능력이 시니어에 가까울 것이라고 기대할 때도 있습니다. 물론 스타 개발자들 중에서 훌륭한 역량을 가지고 계신분들도 존재하지만, 반대로 여러가지 커뮤니티나 강의 또는 저서를 통해 한 순간에 스타 개발자가 만들어 질 때도 있습니다. 그래서 모든 스타 개발자가 시니어 개발자로 지칭되는 것은 매우 위험한 발상입니다. 특히 스타 개발자를 선망하는 분위기가 그룹내에 팽배해 있다면, 외부 활동을 하지 않고 묵묵히 현업에서 일하는 것을 중시하는 개발자는 마치 성장없는 개발자로 비춰지기까지 합니다. 가족 모임에 눈치를 보며 시스템 장애를 처리를 하고, 수 많은 트래픽을 받을 수 있도록 구현을 하며, 버그로 인해 끼니를 거르거나, 상용 배포에 너무 많은 신경을 쏟아부어 하루종일 두통을 겪은 현업 중심 개발자보다, 사람들이 모여드는 컨퍼런스에서 강연을 하고, 잘팔리는 책을 쓰는 개발자를 더 인정하는 이상한 문화가 만들어 질 수도 있습니다.세번째로 특정 언어나 코딩 능력만으로 시니어 개발자를 판단하는 기준을 세울때도 있습니다. 협업 경험이 적은 개발자분들의 경우, IDE의 환경과 Development Kit에 해박한 개발자와 페어 프로그래밍을 하다보면 마치 선배 개발자의 손은 마술사의 손을 보는듯하고, 그의 아우라는 신을 보는 듯한 신성한 느낌을 받곤 합니다. 특히 신입에게는 선임이 짜 놓은 코드는 문제지의  정답풀이처럼 느껴지곤 합니다. 그래서 선임이 개발 해 놓은 코드를 보며 공부도 하고 이유를 묻기도 하며 하루하루를 감동의 나날들을 보냅니다. 그리고 선배에게 충성을 다 합니다. 하지만 이런 로멘스는 최대 반년이 지나면 여지없이 쌍욕으로 돌변하곤 합니다.  그럼에도 불구하고 개발을 잘한다고 생각하는 사람들의 코드는 오랫동안 후배 개발자의 입에 오르내리게 되는데 그 사람들의 코딩 결과물이나 그들이 가진 개념들을 이야기 해보면 다음과 같은 패턴이 보입니다.하지만 앞선 3가지 모습만을 갖춘 개발자를 시니어라 부를 수 있을까요? 그러기에는 뭔지 모를 2% 부족함이 느껴졌고 개발자에게 언어를 넘어서 어떤 부분을 채워야 하는지 고민이 되었습니다.대내외적으로 시니어라 불리우는 여러 사람들과 좋은 개발자의 모습에 대해 이야기를 나누고 메모를 하며, 그 기준을 4가지로 정리해 보았습니다. 1. 기술적 리딩2. 업무적 리딩3. 생산성 우위4. 난제의 해결앞서 수립한 기준으로 저를 비롯한 많은 분들에 대해서 생각해 보았습니다. 하지만 현실에서 이런 4가지를 모두 만족하는 시니어는 매우 드물었고, 우리가 시니어라고 많은 분들을 이야기 할 만큼 흔하게 볼 수 없었습니다. 결국 현실에서는 전지전능한 시니어 개발자는 없거나, 만약 있다한들 가뭄에 콩날듯 아주 조금 밖에 없을 것 이라고 생각이 들었습니다. 이렇게 생각하는 것이 정신건강에 좋을 것 같았습니다.이런 힘빠지는 이야기를 언급한 이유는 시니어를 바라보는 우리의 시선이 잘못된 경우를 심심치 않게 볼 수 있기 때문입니다. 특히 “시니어 개발자는 모든 문제를 다 풀수 있을 것”이라는 막연한 기대감이 우리에게 존재하는 가장 흔한 오류입니다. 이것은 팀으로 영입되는 시니어에게도 지독한 부담감을 주게 됩니다. 이러한 마스터적 기대감과 부담감은 서로에게 좋지 못한 결과를 낳기도 하는데, 가장 큰 문제는 불신과 과장을 낳는다는 겁니다. 영입된 시니어에게 품은 지나친 기대감으로 비롯된 편협한 특정 상황의 지식 비교는 시니어의 실력을 낮추어 평가하는 극단적인 결과를 초래하기도 합니다.오히려 전지전능한 시니어 개발자는 팀이 만들어 가는 것이라고 생각합니다. 어쩌면 시니어는 존재하지만 시니어의 기준은 존재하지 않는다는 궤변을 말하고 싶습니다.왜냐하면 A라는 그룹에서는 시니어로서 역량을 펼쳤던 사람이 B라는 그룹에서는 전혀 시니어로서 요구되는 역할을 하지 못하는 경우가 현실에서는 비일비재하게 일어나고 있습니다. 특히 앞서 제시한 4가지 기준에서 기술적 리딩과 업무적 리딩은 조직의 성숙도나 요구사항에 따라 달라질 수 있기 때문에 전지전능한 시니어 개발자라는 기준은 다시 매우 모호해지게 됩니다. 오히려 그룹에서 원하는 시니어의 조건들을 정확하게 세우고 구성원들과 공감하며 그 기준점에 대해 지향한다면 그룹에 맞는 전지 전능한 시니어 개발자는 우후죽순 많아질 것이라고 생각합니다.지금의 등수라는 것은 비교할 수 있는 수천가지 중에서 몇 가지를 기준으로 선택한 거예요. 그렇게 등수를 매기다 보니까 ‘재는 공부 잘하고, 얘는 못하고’이렇게 되지만 등수 매기는 주제를 바꿔버리면 결과도 바뀌겠죠. 그 상황, 그 시대, 그 시간, 그 조건에서는 서로 비교해서 그사람이 어떠어떠하다고 말할 수는 있어요. 그러나 그렇다고 그 사람이 우월한 것도 아니고, 그렇다고 그 사람이 열등한 것도 아니에요.법륜 스님의 즉문즉설 중에서…기술 트랜드는 빠르게 바뀌어 가고, 수 많은 라이브러리는 쏟아지며, framework는 나날이 고도화 되어가고 있습니다. 특히 새로운 패러다임이 세상에 안착되고 나면, 그와 관련된 지식들은 파생되어 에어리언처럼 또 다른 지식들을 낳아버리곤 합니다. 그리고 수 많은 진영들이 비슷한 모습을 이루며 발전되어 선택되거나 버려지고 있습니다. 이런 가운데, 특정 지식이나 기술의 경험으로 시니어를 분간하는 것은 큰 오류를 범할 수 있을 것 같습니다. 소프트웨어를 만드는 데에 절대적으로 올바른 방법은 없는 것처럼 시니어 역시 절대적인 기준은 없는 것 같습니다.",http://woowabros.github.io/woowabros/2017/07/03/senior.html,woowabros,,NULL,2017-07-03
배달의민족 안드로이드 7.27.0 장애 회고,"지난 5월 23일 주소개편과 주문페이지 업데이트를 진행하였다. 기존 주소설정페이지는 외식배달과 일반업소에서 서로 다른 화면을 사용 중이었으나 이번 개편작업으로 통합하게 되었다. 통합하는 과정에서 일반업소에서도 보다 정확한 주소입력을 요구하게 되었으며 스키마도 변경되었다. 배달의민족은 주소를 기반으로 하는 서비스이기에 내부적으로는 많은 부분에서 수정작업이 이루어졌고 레거시 코드도 적지않게 변경되었다. 그 과정에서 생각하지 못한 이슈가 발생하였고 많은 유저들이 불편을 경험하게 되었다. 지금부터 어떤 이슈가 발생하였으며 어떻게 해결하였는지 그 과정을 공유하려고 한다.업데이트 초기에 전화전문이 불가능한 상황이 발생. 전화주문 버튼을 누르면 앱 크래시배달의민족에서는 여러가지 서비스 지표를 수집하고 있다. 이 상황은 전화주문 시도 시 주문한 지역을 수집하는 부분에서 발생하였다. 주소개편 작업을 시작하면서 주소와 관련된 레거시 코드를 파악하고 모두 삭제하고 진행하였으나 확인하지 못한 부분에 레거시 주소를 사용하는 부분이 남아 있었고 그 부분에서 NullpointerException이 발생하였다.전화주문이 불가능한 상황이었기 때문에 신속하게 업데이트가 진행되어야했고 간단하게 수정할 수 있는 부분이라고 생각하고 신규 코드로 대체하여 바로 업데이트를 진행하였다. 이때까지는 추가로 이슈가 있는 것을 확인하지 못하였다.주문페이지에서 위치를 수정 할 경우 배달이 불가한 지역이라는 메세지가 표시됨 실제로는 권역 안에 있는 주소배민에서는 당연하게 난독화툴을 사용중이고 당연히 난독화를 하고 있다. 난독화를 하는 과정에서 javascript interface에서 사용하는 dto가 난독화 되어버렸다. 테스트 중에 발견되어야 했으나 build script에도 오류가 있어 테스트를 진행한 빌드 파일이 난독화가 되지 않았음을 확인하게 되었다. 배민에서는 여러 빌드 flavor를 사용중인데 테스트배포 버전이 debug 스크립트를 복사하여 초기화 되었으며 이로인해 테스트배포 버전이 난독화 되지 않는 이슈가 발생하게 되었다.dto필드에 @SerializedName 추가하여 이름을 넣어주었다.이슈를 대응하면서 전체적인 이슈를 파악하지 못 하고 눈에 보이는 이슈를 처리 후 바로 hotfix를 진행하였다. 이슈자체가 간단하기도 했지만 앱 이용에 크리티컬한 이슈로 판단되어 내부적으로 바로 hotfix를 진행하기로 하였고 이슈를 수정할 때마다 업데이트를 진행하였다.주소가 저장되지 않는다는 리뷰가 다수 접수되기 시작했으며 내부에서도 상황을 파악하기 시작했다.이슈를 접수하고 개발자, 기획자, QA 모두 현상을 재연하려고 하였으나 재연을 할 수 없었다. 개발자는 로직을 확인하였고 기획자와 QA는 직접 사용하며 테스트 했지만 동일한 현상을 재연 할 수 없었다. 하지만 주소가 저장되지 않는다는 이슈는 지속적으로 접수되고 있었다. 아무도 현상을 재연 할 수 없어 버그가 아닌 다른 이슈라고 판단하고 다른 쪽으로  이슈를 생각하게 되었다.개선 된 위치설정 프로세스에서는 저장된 위치가 없는 유저에 한하여 GPS로 초기위치를 설정하고 사용하도록 하였다. GPS로 설정된 초기위치는 내부에 저장하지 않았고 유저가 직접 설정한 위치정보만 내부에 저장하도록 하였다. 이는 기존에 동작하는 방식과 다른 방식이었다. 기존에는 한번 설정한 위치는 저장하고 있었으며 실행시에 사용하였다.스토어 리뷰에서 “주소가 저장되지 않는다” 피드백을 통해서 우리는 사용자가 초기 GPS로 설정된 위치가 계속 유지되기를 기대하다고 있다고 가정했다.가정한 사실 외에는 이슈를 재연할 방법이 없었기 때문에 프로세스의 개선을 진행하기로 했다. 사용자가 직접 설정하지 않은 위치정보도 내부적으로 저장하여 사용하도록 하였다. 역시 빠르게 수정하여 업데이트를 진행하였다. 업데이트를 진행하였지만 마음속으로 이슈를 해결했다는 생각이 전혀 들지 않았지만 가정 자체가 너무 억지스럽기도 했고 스토어 리뷰와도 맞지 않는 부분이 있었기 때문이다. 하지만 여전히 재연되지 않았고 다른 프로젝트도 진행하고 있었기 때문에 업데이트를 진행하고 다른 작업을 하게 되었다.프로세스를 개선하여 업데이트를 진행하였지만 “주소가 저장되지 않는다”는 스토어 리뷰는 지속적으로 늘어나고 있었다.재연을 하려는 노력은 계속되고 있었고 내부적으로 코드도 지속적으로 확인을 하고 있었지만 원인을 찾지 못하고 있었다. 그러던 중 고객대응팀장님으로부터 재연되는 디바이스가 있다는 이야기를 듣고 바로 달려가 디버깅을 시작하였다. 현상을 확인한 결과 접수된 이슈내용과 동일했다. 보지 못한 현상을 드디어 발견한 것이다.배민 내부적으로 주소를 저장할 때 Realm을 사용하고 있다. 주소를 저장하기 위해서 Realm 초기화 하는 과정에서 IllegalArgumentException이 발생함을 확인하였다.IllegalArgumentException은 언제 발생하는가?현재 설정된 RealmConfiguration은 version 1이었고 null아니었다. 표시되는 메세지로 판단했을 때도 두번째 경우에 해당하는 것을 쉽게 알 수 있었다.Realm on disk is newer than the one specified: v2 vs. v1현재 저장된 realm 파일이 version2라는 것을 확인했다.새로 작성된 코드의 version이 1이었기 때문에 legacy 코드를 확인하기 시작했다.파일명이 같았다. legacy코드에서 사용중인 realm파일과 새로 작성된 코드에서 같은 파일명을 사용중이었고 IllegalArgumentException이 발생 할 수 있음을 확인했다. 여기서 다시 문제가 의문의 들었다. 업데이트 테스트도 통과한 상황이었기 때문이다. 이전 버전에서 업데이트 후 테스트 했지만 같은 이슈가 발생하지 않았다. address.realm 파일이 이전버전에서 생성되지 않았기 때문이다.처음 realm을 도입한 시기는 2016년 2월이었다.legacy코드를 확인하면서 추가로 RealmMigrationNeededException도 발생할 수 있음을 확인하였다.(2016년 2~7월 배포버전을 A버전, 2016년 8월 이후부터 최신버전 직전까지의 배포버전을 B버전 이라 부르겠다.)Realm 초기화 간에 발생 할 수 있는 이슈를 해결한 후 배포했다. 원인과 해결이 명확했다.재앙을 불러온 원인들이 알고보니 정말 사소한 것들이었고 휴먼에러 기인한 것들이었다.최근들어 배민앱 안드로이드 파트에서는 설계나 작업을 대부분 작업자 혼자 진행하고 PR을 리뷰받는 형태로 진행했다. 때문에 커밋을 다른 작업자가 알기쉽게 작업단위로 나누어 해야한다. 하지만 위치설정페이지를 작업하면서 배민라이더스 앱의 지면을 배달의민족의 화면에 맞게 마이그레이션하는 과정에서 수 많은 파일을 한 커밋으로 올리면서 코드리뷰를 어렵게 만들었다.416개 파일, 1만줄이 넘는 코드추가와 삭제, 이를 리뷰 받는것은 어렵다고 판단했고 우선 머지하고, 발생하는 버그는 수정하기로 했다. 하지만 위에서 언급했듯이 2016년 8월 이전 버전에서 최신버전으로 업데이트 한 경우에만 발생하기 때문에 오류를 발견하기가 힘들었다.이번 업데이트에는 유래가 없는 hotfix를 진행하였고 1주일 간 6번의 업데이트를 진행했다. 첫 업데이트 직후 크래시 상황에 직면했고 여러 작은 이슈들이 발생했다. 극단적이지만 업데이트를 취소하고 좀 더 길게 이슈를 바라보았다면 이런 거대한 장애상황을 회피할 수 있지 않았을까?위치저장 관련 리뷰가 계속 접수되는 상황에서 문제를 너무 내부적으로 해결하려고 했던 것 같다. 이슈를 해결하고 나서 알게 된 사실이지만 회사 안의 다른 팀에서도 이슈가 발생하는 디바이스들이 많이 있었던 것 같다. 좀 더 빨리 이슈를 전사적으로 공유하고 도움을 요청했다면 지금보다 더 빠르게 원인을 찾을 수 있었을 것이라 생각한다.1인이 진행했을 때 생길 수 있는 단순한 오류를 잡아내고 품질을 높이는 방법으로 항상 페어로 작업을 진행했으면 한다. 작업 효율면에서 손해를 볼 수도, 두 작업자의 호흡이 맞지 않아 원수가 될 수도 있겠지만 우리 팀에서는 그런 일은 없을 것이라 생각한다.기존과 동일한 리뷰방식을 유지하고, 규모가 크거나 구조의 이해가 어려울 때는 리뷰어가 작업자에서 설명을 요청하도록 하는 것이다. 작업자는 리뷰어에게 직접 코드를 설명하고 대화로 리뷰를 이어가는 것이다. 기존 방법보다 시간은 오래 걸릴 수 있으나 하나하나 대화로 풀어가는 것이 의미가 있을 것이라 생각한다.장애 상황이 생겼을 때 너무 내부적으로 해결하려하기 보다 적극적으로 동료들의 도움을 받아야겠다고 생각했다. 이번에도 가까운 곳에  도움을 받을 수 있는 여러 동료들이 있었으나 이슈가 공유되지 않아 도움을 받지 못한 부분이 있다고 생각한다. 백지장도 맞들면 낫다. 맞는 말이다.대표님의 한마디로 대신 하겠다.",http://woowabros.github.io/experience/2017/06/20/memoir.html,woowabros,,NULL,2017-06-20
배민 API GATEWAY - spring cloud zuul 적용기,"서비스를 운영하고 개발하는 팀이라면, LEGACY라는 거대한 괴물이 얼마나 다루기가 힘든 일인지 동감 할 것이다. 이 괴물이 오래되면 될수록, 크면 클수록… 제가 운영하고 개발하고 있는 팀에도 7년 묵은 괴물이 살고 있습니다. 이 괴물을 한번에 팍~하고 변화시키기에는 너무나 많은 개발 비용이 듭니다. 그리고 운영은 어쩔… 그래서 저희 팀에서는 API GATEWAY를 도입하여 이 괴물을 고립시키고, 도메인 단위로 괴물의 feature를 조금씩 조금씩 떼어내기로 결정했습니다. 자~ 이제부터 본격적으로 API GATEWAY 적용기를 시작하겠습니다.출처 - https://www.facebook.com/75911537320/photos/a.10151028112312321.423930.75911537320/10154488365657321/?type=3&theaterMicroservice Architecture(이하 MSA)에서 언급되는 컴포넌트 중 하나이며, 모든 클라이언트 요청에 대한 end point를 통합하는  서버이다. 마치 프록시 서버처럼 동작한다. 그리고 인증 및 권한, 모니터링, logging 등 추가적인 기능이 있다. 모든 비지니스 로직이 하나의 서버에 존재하는 Monolithic Architecture와 달리 MSA는 도메인별 데이터를 저장하고 도메인별로 하나 이상의 서버가 따로 존재한다. 한 서비스에 한개 이상의 서버가 존재하기 때문에 이 서비스를 사용하는 클라이언트 입장에서는 다수의 end point가 생기게 되며, end point를 변경이 일어났을때, 관리하기가 힘들다. 그래서 MSA 환경에서 서비스에 대한 도메인인 하나로 통합할 수 있는 API GATEWAY가 필요한 것이다.API GATEWAY를 도입하기 위해서 먼저 오픈소스를 찾아보았다. KONG, API Umbrella 등이 있었다. 별다른 고민은 없었다. 선택은 Netflix였다. 이유는 JAVA 프로젝트이며, 세계적으로 MSA를 가장 잘하고 있는 서비스이다. 무엇보다 Martinfowler 아저씨가 정의한 MSA환경, MSA에서의 문제점을 충분히 고려하여 설계된 모든 컴포넌트를 오픈소스화 하였기때문이다. 한마디로 Netflix가 잘 닦아놓은 길을 우리는 그대로 걸으면 된다. 물론 서비스가 다르고, 상황이 다르다. 우린 다만 필요한 것을 선택해서 취하면 된다.Netflix wki에 위와 같이 정의하고 있다.한마디로 Netflix 사용하고 있는 API GATEWAY이다.출처 - https://github.com/Netflix/zuul/wiki클라이언트 요청은 많은 트래픽과 다양한 형태(예상하지 못한 형태)의 요청으로 경고없이 운영에 이슈를 발생시킨다. 이러한 상황에 신속히 대응할 수 있는 시스템 zuul을 개발하였다. zuul은 이런한 문제를  신속하고, 동적으로 해결하기 위해서 groovy 언어로 작성된 다양한 형태의 Filter를 실행한다. Filter에 기능을 정의하고, 이슈사항에 발생시 적절한 filter을 추가함으로써 이슈사항을 대비할 수 있다.출처 - https://medium.com/netflix-techblog/announcing-zuul-edge-service-in-the-cloud-ab3af5be08ee내 생각에는 위 그림이 zuul 시스템을 가장 이해하기 좋은 그림 같다.Zuul Filter는 크게 4가지 Filter로 나누어 진다.출처 - https://medium.com/netflix-techblog/announcing-zuul-edge-service-in-the-cloud-ab3af5be08ee위와 같이 요청이 들어면 PRE Filter를 실행하고, ROUTING Filter에 의해 원하는 서버로 요청을 보낸다. 원하는 서버에서 응답이 오면 POST Filter를 실행시킨다.zuul은 zuul-core, zuul-simple-webapp, zuul-netflix, zuul-netflix-webapp 4개의 컨포넌트로 구성한다.API GATEWAY를 구축하기 위해서는 zuul-simple-webapp를 사용하다는 것은 MSA 환경에서 아주 유용한 NetflixOSS library를 포기하는 것이다.  zuul-netflix-webapp을 도입하기에는 학습곡선이 크다. 그래서 찾은게 spring cloud netflix 프로젝트이다.spring boot에 NetflixOSS를 통합적으로 제공한다. annotation과 yml설정 만으로도 아주 쉽게 NetflixOSS를 사용할 수 있다.spring boot 프로젝트에 artifact id spring-cloud-starter-zuul를 추가하고 main class에 @EnableZuulProxy또는 @EnableZuulServer라고 명시해주면 zuul 서버가 구축된다.zuul-core의 ZuulServlet을 그대로 사용하여, 아래 그림과 같이 spring MVC 위에서 동작하기 위해 몇가지를 추가하였다.Spring Cloud Zuul은 @EnableZuulProxy와 @EnableZuulServer 두 종류의 annotation으로 Zuul을 구동시킨다. 두개는 완전히 다른 것이 아니고 @EnableZuulProxy가 @EnableZuulServer을 포함한다. @EnableZuulServer에서 PreDecorationFilter, RibbonRoutingFilter, SimpleHostRoutingFilter를 추가하면, @EnableZuulProxy가 되는 것이다.더 자세한 설명은 http://cloud.spring.io/spring-cloud-netflix/spring-cloud-netflix.html에 있고, 더 완벽한 설명은 소스를 보면 된다. 소스가 그렇게 많지 않아 같이보길 권장한다.여기까지 Spring Cloud Zuul에 대한 설명였다.자, 이제부터 우리팀에서 API GATEWAY를 어떻게 적용했는지 설명하겠다.흔히 보는 그림이다. Monolithic Architecture의 전형적인 구조이다. 우리 배민 API 서버의 대략적인 현재 모습이다. 다행인것은 Amazon Web Service(이하 AWS) 에 올라가 있고, auto scaling group에 묶여있어 그나마 운영하기가 편하다. 그러나 DB쪽 도메인 분리가 더 필요한 상황이다.현재는  Monolithic Architecture 단점을 그대로 가지고 운영하고 있다.우린 현재 MSA가 필요한 상황이 온 것 같다. 아마 몇년 전 부터 필요한 상황인지도…그런데 한번에 LEGACY 서버를 도메인별로 분리하다는 것은 엄청난 위험과 개발비용이 필요하다. 도메인별로 디비 분리하고 스키마를 재정의하고 마이그레이션을 완료했는데, 스키마 정의가 잘못 되거나 데이터 정합성이 깨졌다면 서비스는 완전 망가질수도 있다.그래서 우린 LEGACY 서버를 고립시키고 도메인별로 하나씩 분리하는 작업을 진행하야겠다는 판단을 했다. 그런데 도메인을 분리하면 몇가지 문제점이 생긴다.그래서 우리는 이런 문제를 해결하기 위해서 API GATEWAY 도입하였다. API GATEWAY가 PATH에 대한 Routing을 관리하면, 모든 클라이언트들은 하나의 URL를 보면 된다.위 그림과 같이 API 서버를 설계하였다. 기존 API 서버에 사용했던 ELB에 API GATEWAY를 구성했고, 두 개의 ELB를 더 생성하여, 하나의 ELB에는 기존 LEGACY API 서버를 구성하였고, 또 하나의 ELB에는 새로운  API 서버(특정 도메인)로 구성하였다. 앞으로 도메인 늘어날 때 마다 ELB는 더 늘어날 예정이다.   클라이언트에서 들어오는 요청을 API GATEWAY에서 구분하여 새로운 API서버와 LEGACY API서버로 라우팅을 한다.  라우팅 기준을 URL PATH이다.위와 같이 예와 같이 http://www.test.com/info/notice라는 요청이 들어오면, 새로 만들어진 API 서버의  /v1/notice PATH로 라우팅 한다. 나머지는 원래 LEGACY API 서버로 라우팅된다. 이런식으로 새로운 API가 만들어질때  마다 location을 명시해준다.왜 Eureka를 사용하여 serviceId로 라우팅하지 않았나?아직 Eureka 도입 시기는 아니라고 판단된다. 시스템은 필요에 의해 변경되어야 된다. 우선 LEGACY API 개선이 먼저이다.  도메인이 늘어나고, 서버 리스트가 늘어나면 그때 필요에 의해 Eureka를 도입할 것이다. 지금 당장 필요한 것은 API GATEWAY이다.Zuul은 Filter를 실행하는 Application이다. Filter를 추가함으로써 자신만의 API GATEWAY를 만들 수 있다. Spring Cloud Zuul은 Filter를 @Bean으로 설정할 수도 있다. 이때는 JAVA언어로 Filter를 정의하고 정적으로만 사용가능하다. 실시간으로 이슈 대응해야 되는 API GATEWAY에서는 뭔가 부족하다. 그래서 동적으로 Filter를 정의하기 위해서  FilterFileManager를 사용했다. 아래와 같이 FilterFileManager에 Filter file 디렉토리를 지정해주면 Netflix Zuul처럼 지정 디렉토리에 있는 파일을 일정주기로 읽어오고 파일을 수정하면 런타임에도 반영가능하다.지금까지 API GATEWAY를 왜 구성했으며, 어떻게 구성했는지에 대해서 이야기했다. 아직까지는 MSA로 가기 위한 초기단계이다. 앞으로 필요에 따라 Eureka, Archaius 등을 구축해야 되고, API GATEWAY의 FIlter도 추가해야 된다. 무엇보다 도메인 분리가  시급하다. 도메인별로 서비스가 분리되면, 이에 따른 많은 문제(배포, CircuitBreaker, 모니터링 등)가 발생할 것이다.  이 문제들은 Netflix OSS의 모범 해법을 보고 하나씩 하나씩 문제를 풀면 될 것 같다. ribbon, hystrix, servo등…  기회가 된다면, MSA의 컴포넌트들을 도입할 때 마다 소개하고 싶다.Announcing Zuul: Edge Service in the CloudNetflix Zuul WikiSpring Cloud Netflix",http://woowabros.github.io/r&d/2017/06/13/apigateway.html,woowabros,"angular,ruby,java,django,android,react",NULL,2017-06-13
[모집] 우아한테크캠프 참가자를 모집합니다.,"우아한테크캠프 참가자를 모집합니다.이미 외부에는 우아한형제들에서 인턴을 모집하는 것으로 공고가 나가고, 몇몇 분들이 공유도 해 주신 상황인데요. 이번에 진행하는 행사의 정확한 명칭은, 우아한형제들의 인턴모집이 아니라 우아한형제들이 개최하는 우아한테크캠프이며, 이 캠프에 참가하실 분들을 모집하고 있습니다.이번 캠프는, NHN NEXT에서 교수님으로 계셨던 김정님, 윤지수님, 정호영님 등이 운영하시는 코드스쿼드라는 회사와 같이 진행합니다. 코드스쿼드 사이틀를 방문해 보시면, 고품질 소프트웨어 교육 전담팀이라는 문구를 보실 수 있는데요. 우아한테크캠프도 고품질 소프트웨어 교육캠프를 지향합니다.간단히 커리큘럼을 말씀 드리면, 다음과 같습니다.우아한테크캠프의 모집 링크를 눌러 보시면 상세한 정보를 보실 수 있고, 간략히 요약한 내용은 아래 그림에서 보실 수 있습니다.  위에서 얘기한 바와 같이, 우아한테크캠프는 현재 우아한형제들의 실무 중 일부분을 경험하는 것보다는, 좀 더 소프트웨어를 잘 만들기 위한 교육 쪽에 방점이 찍혀 있습니다. 이러한 방향성은, 이번에 새로 생긴 것이 아니라 예전에 진행했던 배민학당이라는 인턴 프로그램에서도 마찬가지였습니다. (참고: 배민학당 링크)마지막 배민학당 프로그램은 2016년 1월~2월에 진행되고, 작년 여름과 올해에는 운영을 하지 않았는데요. 잠시 운영을 하지 않았던 이유는, 우리 회사가 인턴 프로그램을 기대하고 오는 분들에게 그 분들의 기대와 소중한 시간에 걸맞는 프로그램을 제공하고 있는 것이 맞나 하는 고민이 들었기 때문입니다. 그리고 이러한 고민은, 앞으로 우아한형제들이 계속 성장하기 위해서 필요한 좋은 신입/주니어 개발자들을 어떻게 확보할 수 있을 것인가하는 것과도 연결되는 고민이었습니다.‘프로그래머라는 정체성으로 자신의 커리어를 발전시키고 싶은 사람들이 배우고 경험하고 싶은 것이 있고, 반대로 회사에서는 학교에서 배운 것과는 다르게 실제로 일을 할 때 필요한 것들을 갖춘 사람들을 원하는데… 단기적인 해결책이 아니더라도, 장기적으로라도 이런 부분을 해결하기 위해서는 무엇이 필요할까.’구인을 하는 많은 회사에서는 사람이(특히 좋은 신입/주니어 개발자들이) 없다고 얘기하고, 구직을 하는 사람들은 어떻게 하면 개발을 잘 하는지 경험할 수 있는 기회가 없다고 얘기하는 상황. 그래서 다들 경력만 찾는데, 신입으로/주니어로 경험할 수 있는 기회는 더욱 찾기 힘들기도 하고요.그래서 생각한 것이, 이미 준비가 되어 있는 좋은 신입/주니어 개발자를 잘 선별하여 뽑는 것에만 초점을 맞추지 말고, 정말 좋은 개발자가 되고 싶어하는 사람들이 있다면 그 사람들에게 실제로 일을 어떻게 수행하는지를 가르치고 키울 필요가 있다는 것입니다.우아한형제들이라는 회사는 아직도 갈 길이 멀고, 큰 이익을 내는 회사도 아닙니다. 하지만 지금까지 회사가 성장하는데 있어서 이미 좋은 경험을 갖고 있던 사람들의 도움을 많이 받았다고 생각합니다. 앞으로 우리 회사가 계속 성장하고 싶고, 좋은 신입/주니어 개발자를 채용하여 그 성장을 지속하고 싶다면, 회사가 지금까지 받았던 도움을 이 업계에 다시 환원하고, 그를 통해서 다시 도움을 받는 것이 필요한 것 같습니다. (너무 거창하게 쓴 것 같아 부끄럽네요)우아한형제들이 당장 NHN NEXT와 같은 교육 기관을 만들 수는 없다고 생각합니다. 하지만, 두 달이라는 짧은 기간이지만, 이러한 취지에 깊은 공감을 하고 프로그래밍을 가르치는 것과 관련한 많은 경험을 갖고 있는 코드스쿼드와 함께라면, 충분히 의미있는 캠프를 운영할 수 있다고 생각했습니다.우아한테크캠프와 관련한 우아한형제들의 목표는, 우리나라에서 앞으로 개발을 업으로 삼고자 하는 개발자들이라면 꼭 참가하고 싶은 캠프가 되는 것입니다. 이 캠프에 참가한 분들이 우아한형제들에 안 와도 좋습니다. 사실 저희가 그것을 강제할 방법도 없고요. 하지만 우아한테크캠프가 정말로 의미있는 경험이 된다면, 그것에 많은 사람들이 동의를 하고 같이 인식한다면, 우아한형제들이 개발 조직을 얼마나 중요하게 생각하는지 충분히 잘 전달될 것이라고 봅니다.그리고 이것이 정말 의미있게 자리잡아서, 우아한형제들뿐 아니라 우리나라의 다른 회사들도 비슷한 고민을 하고 비슷한 기회를 제공할 수 있게 된다면, 우아한형제들이 앞으로 계속 성장하기 위해 꼭 필요한 좋은 신입/주니어 개발자들을 만날 수 있는 가능성이 더 높아지겠지요.이번에 같이 우아한테크캠프를 진행하게된 코드스쿼드도 이러한 취지에 적극 공감하셨기에, 원래 준비하던 프로그래밍 교육 과정을 뒤로 미루고 저희 회사와 같이 해당 캠프를 진행하게 된 것입니다. 많은 회사들이, 이미 합격을 한 신입사원들 대상의 교육 프로그램 운영에는 관심있어 하지만, 해당 회사에 올 지 안 올지 모르는 사람들을 대상으로 이런 교육 기회를 제공하는 경우는 별로 없다고 말씀하시면서, 위에서 말씀 드린 우아한테크캠프의 비전이 꼭 달성되길 바란다는 응원도 같이 해주셨고요. :-)Q ) 우아한테크캠프 모집 대상자는? A ) 개발에 대한 기본 지식과 관심을 가지신 모든 분들이라고 한 이유는, 학력과 경력에 제한을 두고 있지 않기 때문입니다. 고등학생, 대학생, 대학원생, 직장인. 모두 다 지원 가능합니다. 7/3~8/31까지 우아한테크캠프에 전념할 수 있는 분이면 됩니다.Q ) 우아한테크캠프 운영 시간 및 장소는? A ) 월요일 1시~6시, 화~금 9시~6시. 우아한형제들 사무실에서 진행됩니다. 우아한테크캠프를 위한 교육장 및 사무공간도 세팅되어 있습니다. :-)Q ) 우아한테크캠프 참가자에 지급되는 금액이 있나요?  A ) 월 150만을 지급합니다.Q ) 우아한테크캠프에서는 Web Frontend와 iOS App 개발을 가르치는데, 왜 Android나 Backend는 없나요?  A ) 프로그래밍 언어를 가르치는 것이 아니라, 서비스 개발을 배우고 경험하는 캠프이기 때문에 App개발에서는 하나만 택하였습니다. Backend에 대한 부분은 캠프 진행 도중 우아한형제들의 서비스 관련 API를 제공하기 때문에 그 부분을 이용하여 서비스를 개발하게 되고, 두 달이라는 짧은 기간동안 모두 경험하는 것이 힘들 것 같아 제외하였습니다.Q ) iOS App 개발을 위해서는 개인이 Macbook 을 준비해야 하나요?  A ) 장비는 회사에서 대여하여 캠프 시작시에 지급합니다.Q ) 코딩 테스트는 어떤 언어로, 어떻게 진행되나요?  A ) 프로그래밍 언어는 지원하시는 분들이 편한 것을 이용하시면 됩니다. 온라인으로 접속하시면 문제가 주어지고, 해당 웹사이트 내에서 프로그래밍하고 테스트하실 수 있습니다.Q ) 지원서에 보면 경력란이 있던데, 학생이나 신입개발자는 적을 경력이 없습니다. 경력이 있는 사람만 지원할 수 있나요?  A ) 저희 채용 시스템이 지원서 파일을 하나만 등록할 수 있어서, 일반적인 입사 지원서 형식을 제공하여 혼란을 드리는 것 같습니다. 회사 경력이 없더라도 지원하실 수 있으며, 본인이 수행한 프로젝트나 여러 활동 등은 자기소개서에 자유롭게 기재하시면 됩니다.Q ) 우아한테크캠프 참가자에 대한 입사 특전이 있나요?   A ) 위에서 설명한 바와 같이 우아한테크캠프 자체가 채용만을 목적으로 만든 프로그램은 아닙니다. 따라서 공식적인 특전은(예: 서류전형 제외라거나 코딩테스트 제외라거나) 없습니다. 하지만, 우아한테크캠프에서 좋은 모습을 보여준 분이 저희 회사에 관심을 가지신다면 당연히 회사 입장에서는 환영할 일이겠죠. :-)위에서 말씀 드린 바와 같이, 우아한테크캠프는 직접적인 채용 프로그램도 아니고, 저희가 하는 업무중에서 가볍게 수행할 수 있는 업무를 할당받아 수행하는 형태의 프로그램도 아닙니다. 우아한형제들이 후원 및 운영하는 개발자들의 캠프 프로그램인 것이죠. 그렇다면, 우아한테크캠프 기간 동안 우아한형제들의 개발 조직과는 전혀 교류가 없이 운영되느냐… 그렇진 않습니다.우아한테크캠프 진행 도중, 위에서 말씀 드린 웹 개발, 앱 개발 뿐만 아니라 우아한형제들의 개발자들이 진행하는 세션도 다수 존재합니다. 이러한 세션을 통해서, 또는 프로젝트마다 지정된 멘토를 통해서, 우아한형제들의 개발자와도 많은 교류를 가질 수 있는 기회가 있습니다. 그리고, 우아한테크캠프에 참석하시는 분들은 캠프 도중에 본인이 경험하고 느낀 부분들에 대해 우아한형제들 기술 블로그에 글을 써 달라는 부탁 받게 됩니다. :-)우아한테크캠프 참가자는, 캠프 기간 동안, 우아한형제들의 구성원들이 이용하는 것과 동일한 회사 계정을 받게 되고, 개발자들이 이용할 수 있는 AWS 계정을 받아서 내부에서 운영하고 있는 AWS 놀이터에서 여러 기능들을 사용해 볼 수도 있습니다.이번이 첫 프로그램인지라, 우아한테크캠프가 얼마나 좋은 기회인지 자랑스럽게 말씀 드리기는 어렵습니다. 아직도 캠프의 상세 내용에 대해서는, 저를 비롯해서 담당하시는 분들이 어떻게 하면 더 좋은 시간과 기회로 만들 수 있을지 고민하고 있습니다. 하지만, 우아한형제들이 이번 캠프를 바라보는 시각과 의도만큼은 분명합니다. 우아한테크캠프가 우리나라의 개발자들이 꼭 경험하고 싶은 그런 캠프로 만들고 싶습니다.분명 많이 부족하겠죠. 하지만, 서비스가 하나씩 하나씩 개선해 나가는 것처럼, 우아한형제들도 조금씩 조금씩 성장해 나가고 있고(우아한형제들의 Baby Steps), 이와 마찬가지로 우아한테크캠프도 계속해서 발전시켜 나가겠다는 것. 그것만큼은 자신있게 약속드릴 수 있습니다.이번 캠프를 통해서 만나게 될 많은 분들… 그 분들이 당장 취업을 원하시는 분일 수도 있고, 몇 년 후에 취업을 생각하시는 분일 수도 있겠죠. 지금 당장 같이 일하는 동료는 아니지만, 넓게 보면 우리나라의 IT 업계에서 계속 만나고, 또 교류할 수 있는 인연을 만드는 기회가 되면 좋겠습니다.이번 여름,더운 날씨만큼이나 치열하고, 치열한만큼 의미있고 즐거운, 그런 시간으로 같이 만들어갈 분들을 모집합니다.많은 관심과, 많은 지원 부탁 드립니다. (우아한테크캠프 지원 페이지)",http://woowabros.github.io/woowabros/2017/05/15/woowa_techcamp.html,woowabros,,NULL,2017-05-15
프로세스 개선이 현업에서 정착되려면,"이 글은 프로젝트 프로세스의 개선에 관련된 이야기 입니다. 그리고 몇 달전 프로젝트에서 프로세스 구상하고 적용했던 경험들을 이야기하려 합니다.  만약 누군가가 우리팀이 겪은 것과 비슷한 상황에 처해 있다면 이 이야기가 조금이나마 도움이 될 것이라고 기대합니다.어느 겨울  군부대에서 이등병이 차가운 물로 걸레를 빨고 있었습니다. 그 모습을 대대장이 우연히 보게 되었고 대대장은 안타까워하며 이등병에게 취사장에 가서 따뜻한 물을 얻어다가 빨래를 하라고 합니다. 이등병은 대대장의 말만 믿고  기쁜 마음으로 취사장으로 뛰어가 따뜻한 물을 달라고 합니다. 하지만 이등병의 예상과는 다르게 취사장에 있던 선임들은 군기가 빠졌다는 구박만하고 이등병을 쫓아 버립니다. 호되게 구박만 당한 이등병은 아무런 소득없이 다시 차가운 물로 빨래를 하게 되었습니다. 그리고 얼마되지 않아 이번에는 중대장이 지나가며 손에 동상 걸릴지 모르니 취사장에서 따뜻한 물을 얻어다가 빨래를 하라고 합니다. 하지만 구박 당할것이 뻔하기 때문에 이등병은 영혼없는 대답만하고 취사장으로 더 이상 가지 않습니다. 그리고 이번에는 행정보급관이 지나가며 이등병에게 자기가 세수를 해야하니 따뜻한 물을 떠오라고 합니다. 당연히 이등병은 어렵지 않게 취사장에 가서 따뜻한 물을 얻어와 행정보급관에게 가져다 줍니다. 행정보급관은 이등병이 떠온 따뜻한 물로 세수를 하지않고 오히려 이등병에게 따뜻한 물을 건냅니다.“따뜻한 물이 얼마되지 않지만, 이걸로 손을 녹이면서 빨래를 하게”대대장과 중대장 모두 이등병의 어려운 현상을 보고 “취사장의 따뜻한 물”이라는 해결책을 제시했지만 실질적인 도움이 되지 못합니다. 하지만, 행정보급관은 경험에서 나오는 상황 판단과 해결방법을 제시함으로서 이등병에게 실질적인 도움을 주고 있습니다.현업에서 코드품질 개선이나 개발조직의 프로세스 개선이 쉽게 정착되지 않는 이유는 앞선 예시와 같이 개선 방법으로 제시한 내용이 실질적이고 빠르게 피부에 와닿지 않기 때문입니다.한때 만능키 처럼 여겨졌던 애자일은 오히려 요즘에는 금기어로 통용될 만큼 부정적으로 생각하는 시람들을 쉽게 만날 수 있습니다. 왜냐하면 만능키라고 믿었던 애자일은 구성원들에게 더 많은 신경을 쓰게 하고, 더 많은 커뮤니케이션의 비용을 발생시키며 결국 구성원들을 더 많이 피곤하게 만들었기 때문입니다. 더욱 큰 이유는 도입을 해도 사람과 환경 모두 이전과 크게 달라지질 않은 결과 때문일 것 입니다. 곳곳에서 생겨나는 회의적인 의견들은 다른 프로젝트에도 영향을 미치고 긍정적인 애자일 프렉티스들 조차도 쉽게 얼어붙게 만들어 버리곤 합니다.만약 애자일을 성공적으로 도입하고 지속적인 문화로 안착 시키려면 “애자일은 애자일이라는 단어를 버리고 시작”해야 합니다. 어쩌면 이렇게 이야기 하는 것이 앞선 군인 예화의 등장 인물 중 대대장과 같은 해결책을 말하고 있다고 생각할 수 있습니다. 하지만 지난 수 년의 경험에서 비춰보면, 스크럼이나 칸반 방법론을 도입하여 프로젝트를 수행하면서 개별 요소의 적용범위나 이해관계가 명확한 적이 한번도 없었습니다. 더군다나 같은 패턴으로 진행되었던 프로젝트도 전무합니다.“조직변화 , 경쟁사 변화로 인한 마감일 변경, 정책의 변경이 일어났지만 일정은 고정인 상황, 구성원 퇴사, 도메인에 대한 이해 부족, 기술에 대한 난해함”등 이유는 차고 넘칩니다.그래서 누군가 신규 프로젝트를 진행하는데, 처음부터 “우린 스크럼 프로세스로 진행하겠습니다” 라고 선포하려 한다면 신발벗고 나서서 말리고 싶은 심정입니다. 물론 리딩을 하는 사람은 당연히 애자일을 도입하는 목적과 범위, 그리고 구체적인 프로세스를 알아야 하지만, 모든 구성원이 처음부터 스크럼을 강제로 알게 만들 필요는 없습니다. 이런 프렉티스를 모르거나 회의적인 의견을 가진 구성원에게는 오히려 일거리만 더 늘었다고 생각할 수 있고, 진행중에 프랙티스가 잘 지켜지질 않은 순간이 생기면 비판의 목소리로 커져 갈 수 있기 때문입니다.처음에는 조직에 맞게 프렉티스 중 몇 개만 가볍게 도입하는 것이 좋은 방법입니다. 관련된 용어도 정의할 필요가 없습니다. 특히 개발 속도 추정, 에픽/스토리/테스크에 대한 구분점을 명확하게 하려는 시도는 굉장한 혼란과 피로감을 줄 수 있고 일정만 잡아먹게 되는 원흉이 될 가능성이 큽니다. (칸반에서 이슈의 크기를 비슷하게 만들려는 노력 역시 멘붕의 주범이기도 합니다.)초반에는 아침에 가볍게 모이는 습관을 만들고 기능 구현이 완료되면 리뷰를 하는 정도의 회의로 시작하는 것이 효과적일 것 입니다. 그리고 어느정도의 시간이 지나면 구현하거나 수행해야할 일의 단위를 파악하고 나누는 시간을 구현전에 할 수 있도록 독려하는 것이 필요합니다. 특히 자연스럽게 구성원들 프로세스 개선의 주제에 대한 논의를 할 수 있다면 이 시그널을 바탕으로 점진적으로 프로세스를 도입하는 로드맵을 다 함께 논의하면 됩니다. 또한 프로젝트가 명확한 기준점이 생기고 리듬있게 프로젝트가 진행된다고 판단되면 일을 하는데 집중을 할 수 있도록 부가적인 회의나 추정에는 시간을 적게 쓸 수 있도록 변화시켜야 합니다.조직의 상황이 빠르게 이슈등을 쳐야 하는 상황에 직면에 있다면 이슈를 만들고 관리하는 시간을 줄이는 전략을 선택해서 이슈 트레킹 자체도 간소화 시킬 수 있다면 충분히 간소화 시키는 것도 방법입니다.이제, 조금 더 구체적으로 이야기 해보도록 하겠습니다.  우아한 형제들에서는 새로운 서비스를 위해 TFT가 만들어졌습니다. 이 TFT는 2017년 3월 31일, 아직 우리에겐 생소한 “배민라이더스” 라는 서비스를 세상에 탄생 시켰습니다.  배민라이더스 서비스를 만들면서 정말 많은 이야기 소재가 있는데, 그중에서 이번 주제에 맞게 프로세스 중심으로 이야기를 풀어보도록 하겠습니다.먼저 프로젝트를 시작하면서 세웠던 유일한 원칙이 있었습니다.“현실을 직시하며 프로세스를 만들어 간다.”이것은 어떤 이유든지 변하지 않는 유일한 원칙이였고, 이 원칙 아래에서 모든 프로세스의 전략이 구상되었습니다.흔히 TFT는 서로 다른팀의 특정 인원들이 모여 하나의 팀이 만들어지곤 합니다. 이렇게 팀을 만드는 가장 큰 이유는 의사결정을 빠르게 내리기 위해서 입니다. 그리고 TFT가 구성되면 소요 일정을 빠르게 결정하거나 그 전부터 고정되어 있는 경우가 대부분 입니다. 이렇게 정해진 일정은 규모산정이 잘못되는 경우가 많으며, 규모산정과는 별개로 일정이 수립되는 경우도 있기 때문에, 결국 구현에 필요한 시간은 절대적으로 부족하게 됩니다.저희도 전략적인 일정이 있는 상태에서 TFT는 시작되었고 서로 다른팀의 인원들(기획자, 디자이너, 서버개발자 , 클라이언트 개발자)이 모여서 한팀을 이루게 되었습니다.  손발이 척척 맞아도 일정안에 구현을 할 수 있을지 불투명한 판인데, 구성원 중 서로를 처음 보는 사람도 있었습니다.  이런 현실은 업무 조율에 있어 난항이 일어날 것이라고 쉽게 예상할 수 있었으며 이를 해결하는 것이 급선무 였습니다. 이 문제가 해결되지 않은 상태에서는 프로세스 수립은 먼나라 이야기였습니다. 그래서 커뮤니케이션의 문제를 빠르게 해결하려 노력했습니다.보통 커뮤니케이션 문제의 원인은 서로 다른 업무의 행태에 대한 이해가 없고, 처해있는 상황에 대한 공감이 부족하기 때문에 발생한다고 생각했습니다.  예를 들면 “기획의 정책이 어떤 과정을 거쳐 발생했는지, 구현의 난제는 무엇인지, 표현의 한계가 무엇인지, 연동하는 주요 사항과 예외 사항은 무엇인지, 구현의 경중이 무엇이고, 본질은 무엇인지”등 입니다. 이런 오해 요소들은 프로젝트 진행하는 내내 곳곳에 산재되어 있었습니다.그래서 이런 문제를 해결하기 위해서 다음과 같은 행동과 자의적,타의적 환경이 만들어져서 프로젝트은 진행되었습니다. 물론 단점이 있었습니다. 1번의 문제 해결은 다른 곳에 있는 대형 공기 청정기를 반 강제로 가져 왔었고, 2번의 문제 해결은 2번째 스프린트 중반부터 자연스럽게 해결 되기 시작했습니다.이렇게 행동과 환경의 변화를 통해 구성원들은 빠르게 공감대를 형성하게 되었고 서로의 입장과 처해 있는 상황을 이해하게 되었습니다.앞서 가장 중요한 문제의 해결은 서로 다른 지식과 상황 그리고 일의 종류를 가진 구성원들이 서로 이해하고 공감하는 것이였다면, 두번째 난관은 각 파트간의 책임지지 않는 영역을 좁히는 것이였습니다.프로젝트를 진행하면서 책임지지 않는 영역이 발생하는 부분은 다음과 같았습니다.먼저, “정책 및 요구사항의 수립 후 구현이나 테스트에서 빠져있는 영역”을 해결하기 위해서는 품질 책임자가 프로젝트 막바지에 투입되어 테스트를 수행하는 것이 아니라 프로젝트 초반부터 투입되어 품질을 보다 자세하게 챙겨가는 것이였습니다. 이 결정은 시간이 지나면 지날수록 프로젝트에 지대한 영향을 주었으며, 프로젝트 일정의 반환점을 도는 시점에는 전략에 하나의 큰 축으로 자리잡게 되는 매우 중요한 결정이였습니다. 이 글에서 품질책임자와 그들이 프로젝트에서 진행했던 규격화된 액티비티들을 자세하게 다룰수는 없지만, 프로젝트 초반의 품질책임자가 투입되는 것은 매우 현명한 선택이였다고 회고되고 있습니다.다음으로 “디자인에서 표현 안된 영역”은 다시 두가지 관점으로 나뉘는데, “요구사항을 포함한 디자인이 도출되었는가”와“어플리케이션으로 구현되어야하는 상황이 모두 디자인 되었는가”입니다. 이를 해결하기 위해 기획 업무를 재정의 하였습니다. 먼저 제품을 큰 덩어리로 분할하여 기획하고 기존에 PPT로 와이어 프레임을 그리던 업무를 하지 않았습니다. 정책과 요구사항을 텍스트로 상세히 남기는 작업에 집중하고 텍스트로 전달되지 않는 의견은 박스와 화살표로 서비스 흐름을 표시하여 좀 더 의견을 명확하게 전달하는데 집중하였습니다. 이런 문서는 품질과 디자이너와 공유되고, 다시 개발자와 공유 되었습니다. 그리고 빠짐이 생기는 부분을 품질과 기획이 챙기면서 의사소통을 진행하게 만들었습니다. 마지막으로 “클라이언트와 서버간 요청 데이터 설계와 실 구현의 상황 차이에서 오는 변경 영역”은 앞선 정책 및 요구사항 리뷰시에 대략적인 의견을 교류하였습니다. 그리고 프로젝트 초반에는 Restful에서 요청과 응답에 대한 패턴을 인지시킬 수 있도록 관련 문서를 정의하였습니다. 이후 클라이언트와 서버간의 패턴의 인지가 성숙되고, 코드에서 리포팅되는 프레임워크를 사용하면서 이와 관련 문서는 더이상 쓸모가 없어졌다고 판단되었기에 폐기하였습니다. 물론 이런 변화와 수고에도 불구하고 회색영역이 완전히 사라지는 마법은 없었습니다. 하지만 3가지가 구성원들의 업무와 습관적 프렉티스로 완전히 녹아들게되고 회색 영역은 빠르게 줄어들었습니다.신규 프로젝트가 얼마나 걸릴 것인가에 대한 생각은 다들 다를 수 있습니다. 그리고 각자 자신이 경험을 바탕으로 일정 추정을 하곤 합니다. 추정이라는 뜻은 원래 “추측하여 정한다”라는 불명확성을 내포하고 있기 때문에, 정확한 수치를 원하는 것은 본래 불가능한 일 입니다.PO, PM, 기능 구현 담당자는 모두 다른 관점을 가지고 있습니다. 이런 시각차이를 줄이는 방법은 초반 규모산정으로 대립각을 세우기보다 프로젝트를 진행하면서 우리의 현 상황을 투명하게 보여주고 이를 바탕으로 합당한 규모 산정을 이룰 수 있도록 하는 것이 효과적일 것입니다. 그러려면 많은 책에서 언급되어진 것처럼 지속적으로 산출물을 보여주고 이를 수치화하여 정량적인 판단을 내리게 하는 것입니다. “지속적으로 산출물을 보여준다”라는 것은 알겠는데, 어떤 방식으로 보여줘야 하는지는 정형화되어 있지 않는 것이 현실입니다.물론 테스트가 가능한 단위가 짧은 완성의 주기라고 정의 할 수 있습니다. 하지만 이것은 저희 프로젝트에는 맞지 않은 정의였습니다. 프로젝트는 출시일이 굳어져 있었고 테스트가 가능한 단위의 짧은 완성은 불가능했습니다. 왜냐하면 전체를 테스트가 가능한 기능 단위로 나누었을때 출시일을 훌쩍 넘어버리는 일정으로 파악 되었기 때문입니다. 즉, 몇 개의 기능을 테스트가 가능한 짧은 완성 주기로 구성한다면 일부의 모습만 완성되기에 전체의 모습을 볼 수 없게 되고 합당한 규모 재산정을 할 수 없음을 의미하는 것이였습니다.결국 짧은 완성은 “테스트 가능한 기능 단위의 완성”이 아닌  “소비자 입장에서 전체를 파악할 수 있는 수준의 시나리오”라는 목표로 짧은 완성을 정의하여 스프린트를 구성하였습니다.총 7번의 스프린트로 나뉘어 진행되었고, 평균 50% 정도의 구현이 진행 되었습니다.그리고 7번의 회고 중 5번의 시연과 2번의 외부 공유를 통해 진행 상황을 가시화 하였습니다.  프로젝트는 지라를 통해 파트별 이슈가 관리되었고, 전체 백로그와 이슈관리는 한 사람이 진행하였습니다. 서로 다른 파트의 이슈를 하나의 현황판으로 관리하고 파트별 스프린트를 어떻게 나누어서 동시 다발적으로 진행했는지에 대한 내용은 이번에 다루는 주제 범위를 넘어서기 때문에 기회가 되면 다음에 다뤄보도록 하겠습니다. 물론 이런 방법으로 나뉘어진 스프린트는 몇가지 우려 사항이 있었습니다.하지만 이 두 가지는 뒤에서 설명할 “테스트 케이스 중심 프로세스”를 통해 많은 부분 해결되었습니다. 또한 부족한 일정으로 진행하는 프로젝트에서 출시일을 맞춰서 제품을 출시하는 것에 대해 잠깐 짚고 넘어가야 할 것 같습니다.부족한 일정으로 진행하는 프로젝트에서 출시일을 맞춰서 제품을 출시하는 것은 많은 사람들의 이해와 설득의 과정을 겪습니다. 이는 프로젝트의 많은 기능들 중에 포기하거나 완벽하지 않은 상태로 출시되는 것을 허용하겠다는 것을 의미하기 때문이죠.그리고 흔히들 기능의 포기나 완벽하지 않은채로 출시한다는 것을 안일하게 제품을 만들어 출시하겠다는 것과 동일시 합니다. 이 생각은 잘못된 생각입니다.제품의 출시일이라는 것은 제품을 만드는 것만 영향을 미치는 것이 아니라, 제품과 관련된 마케팅이나 제품과 연동되어 있는 다른 시스템의 영향 그리고 출시일과 맞춰져 있는 사업적 리스크까지 포함하는 일정이기에 결코 단순하지 않습니다. 그렇기 때문에 “제품의 출시가 늦어졌을때 리스크”와 “불완벽한 제품 요소의 리스크”를 비교해서 최선책과 차선책을 결정해야 하는 문제이고 안일함이라는 자세의 문제와는 다른 주제입니다.주제와는 다소 멀리왔기에 다시 프로세스의 이야기로 돌아오겠습니다. 다음 주제를 들어가기에 앞서 여태까지 내용을 정리해보면 공감을 바탕으로 회색영역을 없애고 이후 짧은 주기의 완성본을 만들면서 스프린트를 진행하는 경험을 공유하였습니다.  그리고 다음은 불 확실하게 구현된 제품을 확실하게 만드는 것을 어떻게 보장할 것인가에 대한 문제를 해결하는 경험을 공유하겠습니다.테스트 케이스 중심의 프로세스라고 말하는 것은 코드 단위 테스트를 작성하는 프로세스를 말하는 것이 아닙니다. 메뉴얼 테스트를 하기위해 작성하는 테스트 케이스 문서를 중심으로 프로세스를 진행하는 것을 말합니다.어떻게 보면 문서를 중심으로 개발을 하는 것이 시대에 역행하는 듯한 느낌을 받으며, 폭포수 개발 방식을 연상케 하기도 합니다. 하지만 어떤 프로세스든지 절대적인 장점이나 단점을 가지고 있다고 생각하지 않습니다.  이 프로세스는 불확실하게 구현된 제품의 상황과 대략적인 전체 시나리오를 돌아본 프로젝트 상황에서는 최선의 방법이였습니다.  이 프로세스의 가장 중요한 것은 구성원 모두가 테스트 케이스를 가장 중요하게 여기게 만드는 것이였습니다.앞서 이야기 한 것 처럼 이런 테스트 중심의 프로세스를 TFT 초반부터 적용하지 않았습니다. 전체 구현체가 50% 정도 구현되었을때 이 프로세스를 적용하였습니다.프로젝트 초기에는 품질책임자의 역할이 명확하지 않았기 때문에 할 일에 대한 규정을 하기가 매우 어려웠습니다. 하지만 품질 책임자는 기획,디자인,개발에서 발견되지 못한 부분의 의견을 이야기하고, 유사 제품을 테스트하면서 일어났던 오류나 정책의 모순점을 개선할 수 있는 방향을 스스로 제안하면서 많은 이들이 이 제안과 가이드에 도움을 받게 됩니다. 그리고 품질책임자가 테스트케이스를 작성함에 있어서 메뉴얼테스트를 하는 담당자를 위한 테스트케이스가 아닌 모두가 보고 활용할 수 있는 테스트 케이스를 만들게 되었고 이는 프로젝트 중반에 위기에 처해있던 프로젝트를 구하는데 큰 도움을 주는 프로세스로 자리매김하게 됩니다. 품질 책임자의 업무에 대해서 좀 더 자세히 이야기 해보면, 품질 책임자는 우선 정책 및 요구사항이 도출되면 이에 대한 검토를 기획자와 함께 진행합니다. 그리고 요구사항들이 디자인 될 시점에도 어김없이 검토를 진행합니다. 이런 검토를 바탕으로 요구사항이 정상적으로 구현되었는지에 대한 체크리스트와 정상이 아닌 예외사항에 대한 체크리스트를 문서화 합니다. 체크리스트는 관련 그룹과의 주기적인 리뷰를 통해 확실한 가이드로 자리를 잡게 만듭니다.이렇게 완성된 체크리스트는 다음과 같은 효과를 보였습니다. 결국 테스트 케이스 중심의 개발이 진행되었고, 테스트 케이스를 바탕으로 기획자와 품질 담당자들이 기능의 단위 테스트를 진행 하였습니다.  결국 제품의 출시일을 앞두고 품질 담당자들의 전수 테스트와 알파 테스트의 결과 크리티컬한 이슈나 소소한 버그 수정 이슈 발생률이 적었습니다. 프로젝트는 전수테스트와 알파 테스트를 거치고 안정적으로 출시되었습니다. 수 많은 일들과 에피소드를 남기고 프로젝트는 이제 종료를 앞두고 있습니다.제품을 만들기 위해 프로젝트는 존재하고 효율적인 프로젝트를 위해 프로세스는 존재합니다. 때로는 프로세스를 위해 프로젝트의 목적을 다른 방향으로 변경하는 상황이 발생합니다. 이것은 특정 프로세스에 매몰되거나 지적 충족을 우선시하는 생각에서 흔히 발생합니다. 이와같은 매몰됨과 편협한 생각은 누구나 할 수 있고 프로젝트의 시작서부터 끝까지 항상 발생하기 때문에 늘 경계해야 합니다.여기서 다룬 내용을 다시한번 상기 해 보겠습니다. 프로세스 개선이 현업에서 정착 되려면 프로젝트의 상황에 따른 프로세스를 만들어야 한다는 대전제는 변함없어야 합니다. 그리고 서로 다른 파트의 공감대를 형성하는 것, 이들의 업무 중 공간이 발생되는 회색 영역을 최소한으로 만들고, 규모 산정에 오해가 있다면 짧은 주기의 완성본을 이해 관계자에게 제공함으로서 오해를 줄여서 규모 산정을 명확하게 만듦니다. 더불어 테스트 케이스 중심의 프로세스는 매우 안정적인 제품을 출시하는데 도움이 됩니다.그리고 중요한 요소 중에 하나는 프로세스라는 것을 사람들에게 인지시키려면 순간적인 학습을 통해서 인지시키는 것이 아니라 반복적 실천을 중심으로 자연스럽게 내재화 될 수 있도록 환경과 작은 행동 범위 단위를 만들어 내는 것입니다.이 글을 읽고 독자분들에게 프로젝트 프로세스에 대한 아이디어가 떠오르길 기대하고 바랍니다.부족한 글을 끝까지 읽어 주셔서 감사합니다.",http://woowabros.github.io/woowabros/2017/04/18/process.html,woowabros,,NULL,2017-04-18
배민 신춘문예 개발기,"인생은 멀리서 보면 희극이고 가까이서 보면 비극이다. ~ Charlie Chaplin배민신춘문예는 매년 이맘때 진행하는 이벤트로 그 해 마케팅실의 염원을 담아 대규모로 진행하는 이벤트이다. 보통 우리 회사에서는 이벤트를 마케팅실에서 직접 정해진 템플릿을 이용해 구현하나 신춘문예같은 복잡한 형태의 이벤트는 팀(웹UI개발팀)에서 작업해주는 케이스가 있다.배민 신춘문예 사이트: http://spring.baemin.com이번 프로젝트는 회사에서 새로 도전하는 스펙이었기 때문에 초기 기획단계에서 디자이너 & 개발자(나) & 기획자가 함께 모여서 프로젝트를 진행했는데, 처음으로 시도해 보는 거라서 많은 연구와 구현가능성에 대한 이슈를 가질 수밖에 없었다.프로젝트를 진행하면서 최초에 만든 프로토타입은 http://codepen.io/ChoEun/pen/YNmGwN나 http://codepen.io/ChoEun/pen/LxMdwX 같이 기획에서 의도하는 다양한 기능이 구현 가능한가에 대한 연구를 위해 구현하였으며, 이를 실제 서비스에 적용하지는 않았으나 마케팅실과 디자인실에서 해당 프로토타입을 보며 어떤 기능이 구현 가능할 지 불가할 지 여부를 체크하여 기능을 정의하고 디자인하였기 때문에 작업을 하면서 매끄럽게 진행할 수 있었다고 생각한다.이번 프로젝트에서 프로토타이핑을 통해 얻을 수 있던 인사이트가 크게 세가지 있었는데,특히 처음 기능을 구현할 때 ‘이게 가능할까?’라는 생각을 했지만 프로토타입을 구현해나가는 과정에서 가능할 거란 생각이 들기 시작했고 그를 바탕으로 올해 배민신춘문예를 캔버스 방식으로 구현하게 되었다.하지만 프로토타입이 아닌 실제 제품을 구현하기 시작하면서 애초에 의도한 것과 달리, 사용자 흐름을 다시 정리해야할 필요가 있었는데 구현 가능한 범주에서 최상의 사용성을 제공하기 위해서 수정해야하는 것이 많았다.Figure 1. 디자이너가 보면 죽는 짤우리가 이번 작업을 진행해나가면서 겪게 된 것 중 긍정적으로 평가하는 혹은 가치있는 시간이라고 생각하는 것 중 대표적인 건, 서로 이야기를 해나가면서 문제를 해결해나갔다는 점이라 생각한다. 서로 특정한 지점에서 문제를 발견했을 때 주저 않고 공유하여 문제를 해결해나가는 데 가장 많은 힘을 쏟았고 그를 통해 문제를 빨리 수정하여 다음 단계를 밟을 수 있도록 한 게 이번 프로젝트의 가장 큰 성과라 생각한다.Figure 2. 프로젝트가 끝나갈 때다만 이 프로젝트가 비교적 짧은 시간동안 진행되었고 많은 수정은 곧 많은 작업을 의미했기 때문에 좋은 제품을 만들어 나가기 위해 짧고 굵게 고통받았다. 이 포인트에서 우리가 겪었던 걸 반드시 좋은 경험이라 부를 수는 없겠지만, 좋은 제품을 만들기 위한 공통의 목표에서 서로가 각자의 영역에서 맡은 바 최선을 다했다고 생각하고 있다.물론 코드 품질 등에서는 많은 아쉬움을 가지고 있지만, 이 내용을 바탕으로 더 나은 무언가를 만들 수 있을 수 있지 않을까 생각하고 있다.Figure 3. 이미지 정렬 문제가 해소되었을 때우리가 정리했던 초기 스펙은이 스펙에서 주된 키워드는 이미지를 만들고 배경을 선택하여 저장하여 공유한다 였는데, 이런 형태의 UI를 구현하는 데에 Canvas가 적합하다고 생각하여 처음에는 HTML5 Canvas API를 기본 형태로 사용하여 구현하고자 하였으나 프로토타이핑을 거친 후 이런 형태가 적합하지 않다고 생각하였고, 사용 가능한 유용한 라이브러리를 찾던 중 Fabric.js를 채택하였다.Fabric.js는 오픈소스 캔버스 라이브러리로 각 객체의 크기 변형, 패턴 지정, 배경 지정 등 이번 프로젝트에서 필요로 하는 모든 기능을 제공해주고 있어서 개별 이슈에 하나하나 고민을 하는 게 아닌 로직에서만 고민할 수 있게 해주어 구현하는 데 이슈가 덜하게 만들어주었다.구현을 하며 겪었던 몇가지 이슈 중 굵직한 것들만 몇가지 살펴보자면.Q. 한나체를 적용해야하는데 canvas에 폰트를 삽입하는 순간 서버에서 한나체를 다운로드 받기 시작하여 한나체가 적용되려면 캔버스를 한번 유저가 강제로 클릭해줘야 했던 이슈A. 최초에 캔버스를 초기화할 때 빈 텍스트객체를 사전에 넣어 한나체로 지정해두었다. 이렇게 하여 페이지에 접근하여 캔버스를 초기화하는 단계에서 한나체를 서버에서 불러오고, 유저가 실제로 시를 입력하여 반영하는 단계에서 한나체가 제대로 적용될 수 있었다.–Q. 사용자가 지정한 이미지를 넣을 경우 이미지가 정사각형인지, 직사각형인 지 구분할 수 없었고 크기가 다양했기 때문에, 우선 캔버스 크기에 우겨넣었더니 이미지가 깨지는 효과가 나타났다.A. 이미지를 받고 난 후 중앙정렬을 시켜주도록 로직을 다시 설계했고, 이미지 자체를 변형하는 게 아닌 스케일을 조정하여 이미지가 확대되거나 축소되도록 설계했다.–Q. 페이스북 공유하기를 og_shares라는 걸로 구현했는데 현재 API 버전에서는 더이상 사용하지 않아 페이스북 공유하기가 팝업까지는 뜨나 실제 공유하기로 넘어가지 않았다A. 페이스북 공유하기는 더 상세히 살펴보니 feed_dialog라는 게 있어 그걸로 구현하였다. 페이스북 공유하기라는 버튼의 텍스트에 너무 집착하여 share_dialog만 생각하고 있었다. 만약 이미지가 수정되는 형태의 공유하기라면 feed_dialog 사용을 검토해보자.배민신춘문예는 내가 처음 기대했던 것 이상으로 어려운 작업이었고, 또 성공한 작업이라고 생각한다. 함께 작업해준 멤버들에게 고맙다는 인사를 꼭 전하고 싶고, 내년에는 내가 안할거다.Figure 4. 함께해서 즐거웠고 다시 만나지 맙시다",http://woowabros.github.io/woowabros/2017/03/20/spring.html,woowabros,"html,javascript,jquery",NULL,2017-03-20
OSORI 권한관리 플랫폼,인증(Authentication)과 인가(Authorization)중  Authorization부분을 담당하며 권한 관리를 쉽게 해주는 플랫폼으로  UI형태의 관리 페이지와 라이브러리를 제공함으로써 최소한의 비용으로 연동할 수 있도록 개발되었습니다.  [Osori-Admin 메인화면]서비스 아키텍쳐가 모놀리틱 아키텍처에서 마이크로 서비스 아키텍처 (aka. MSA)방식으로 전환되면서 기존 백오피스  어플리케이션도 물리적으로 분리가 불가피했습니다. 여기서 문제는 각 서비스별 백오피스가 떨어져 나오면서  각자 권한을 관리해야하는 이슈가 생겼습니다. 한팀에서 관리하는 어플리케이션이 여러개인 경우가 많아서 물리적으로 떨어져 있지만 공통적으로 관리를 해주는 무언가가 필요하게 되었습니다. [마치 이런느낌처럼(?)] [모듈 구성도] Osori는 총 3개의 모듈로 구성되어있습니다.동작방식은 간단합니다. 서버에 요청을 보내기전에 먼저 Osori에 유저ID와 접근할 URL을 파라미터로 전송하면 Osori에서는  URL에 대한 접근 유효성을 판별후 결과값을 리턴하게됩니다.  [동작흐름도]심플함을 지향하면서 개발했지만 기능적으로 부족한 부분이 많습니다. 여유가 생기면 OAuth도 붙이고 LDAP도 붙이고  점점 기능들을 추가해가면서 나중에는 계정을 총괄하는 시스템으로 진화하는게 최종 목표입니다만…개인적으로  먼저 개선하고 싶은건 Osori-Admin에 있는 front layer를 React나 Angular같은 UI프레임워크로 교체를 하고싶네요 (이게 제일 시급합니다ㅜㅜ)Osori는 사내 표준 개발언어가 자바로 바뀐이후로 제가 처음으로 개발한 어플리케이션 입니다. 기획단계때만 해도  복잡한 로직이 필요한게 아니니깐 금방 끝나겠구나 라고 생각했었습니다. 외부 혹은 타팀에 제공목적을 두고 개발을 해야 했기 때문에 특정 플랫폼에 의존성을 낮추고 최소한의 설정으로 구동이 가능하게끔 해야했고 삽질도 많이하다보니 의외로 시간이 걸렸던 프로젝트였습니다. 끝으로 개발하면서 개발방법과 팁 그리고 아낌없는 조언을 해주신 서오석 선임님께 감사하다는 말을 전하고싶습니다 :),http://woowabros.github.io/tools/2017/03/07/osori.html,woowabros,"angularjs,typescript,vue,angular,reactjs,react",NULL,2017-03-07
AWS KMS를 이용한 암호화 API 구축하기,"서버 없이 쉽고 빠르게 암복호화 API서비스를 만들어 봅니다.지난해 우아한형제들은 정보보호관리체계(ISMS)인증 심사를 준비하며 개인정보 암호화 키를 물리적으로 분리하여 보다 안전하게 관리할 수 있는 AWS Key Management Service(이하 KMS) 도입을 결정했습니다. 그리고 운영 리소스를 최소화하고 트래픽에 유연하게 대처하기 위해 AWS 서버리스 서비스들을 적극적으로 활용하여 암복호화 API를 구현했습니다. API 서비스를 구축함에 있어 인프라 이슈를 배제하고 로직에 집중할 수 있다는 건 행복한 일이니까요 :) 암복호화 API 서비스를 만들기 위해서는 라우터 역할을 할 AWS API Gateway와 함수 실행을 위한 AWS Lambda 그리고 키 관리를 위한 KMS가 필요한데, 각 서비스들의 주요 기능과 장단점에 대한 설명은 생략하는 걸로…Customer Master Keys (CMKs)를 가지고 직접 암복호화를 수행하는 것에 따른 보안 위험성과 이 때 발생하는 네트워크 로드를 줄이기 위해 봉투 암호화(Envelope Encryption) 방식을 사용하여 데이터 보안을 확보하고 Data Keys(DKs) 요청에만 네트워크 비용이 발생하도록 하는 것이 좋습니다. 이 때 사용되는 Key들과 AWS Encryption SDK에서 제시하는 암복호화 프로세스에 대해 간단하게 설명하겠습니다.순서는 KMS Master Key를 생성하고 Lambda에서 암복호화 함수를 만들고 마지막으로 API Gateway에 Lambda를 연결해주고 테스트하면 끝납니다. 참 쉽죠~AWS관리 콘솔에 로그인합니다. 그리고 KMS라는 서비스가 있어야 하는데… 어랏 보이지 않습니다만, 고객님, 그땐 당황하지 마시고 IAM을 선택하고 진행하면 됩니다(메뉴조차 비밀스럽습니다). IAM 화면 좌측 메뉴 하단에 “Encryption Keys”를 클릭한 뒤 서울 Region을 먼저 선택하고 “Create Key”를 눌러 생성하면 됩니다. 시스템 관리자 권한으로 접근하여 생성할 수 있습니다.Lambda 함수는 Python, NodeJs, Java가 지원됩니다(2016년 6월 시점). 우아한형제들에서는 Python을 사용해 구축했습니다.Lambda 서비스를 선택한 뒤 “Create a Lambda function” 버튼을 클릭, 다음 화면에서 좌측 메뉴 “Configure function”을 선택하면 Lambda 함수를 설정할 수 있는 화면이 나타납니다. 본격적으로 함수 구현 스타트~Boto3는 AWS에서 제공하는 Python용 SDK로 Low-level에 직접 접근할 수 있을 뿐 아니라 사용하기 쉬운 객체 지향 API를 제공합니다.Master Key를 이용하여 Lambda class 로드 시, 암복호화에 필요한 Data Key(plaintext_key, ciphertext_blob)를 초기화합니다.평문 Data Key를 이용하여 암호화 객체를 생성, 문자열을 암호화하고 base64로 인코딩 후 이미 생성된 암호화된 Data Key(ciphertext_blob)와 함께 반환합니다. 이때 반환되는 암호화된 Data Key는 복호화에 필요한 평문 Data Key를 얻기 위해 꼭 필요한 정보이므로 어플리케이션에서 관리되어야 합니다.전달 받은 암호화된 문자열(encrypted_data)과 Data Key(ciphertext_blob)로 평문 Data Key를 반환 받아 암호화 역순으로 암호화된 문자열을 base64로 디코딩한 뒤 복호화해서 반환합니다.어플리케이션에서 요청(req_type)한 유형에 따라 위 구현 메소드를 수행할 처리 로직 및 예외상황에 대해 구현해 줍니다.AWS Lambda에서 구현한 함수 실행을 위해 API를 생성하고 설정합니다. API 리소스 생성을 위해 “Create API”를 버튼을 클릭한 뒤 “Actions”의 Create Resource를 선택해 이름을 지정하고 생성합니다.Rest 메소드 추가하기 위해 다시 “Actions”의 Create Method를 통해 리소스에 연결될 HTTP 메서드(예: POST)를 선택한 뒤 Region과 이미 생성해 놓은 Lambda 함수를 지정합니다.API 배포를 위해 생성한 메소드에서 “Actions”를 눌러 Deploy API를 선택합니다. 설정 화면에서 “[New Stage]”를 선택한 뒤 배포할 스테이지 정보(예: test, prod 등)를 입력합니다. 위 작업까지 완료됐다면 생성된 배포용 API 호출 URL을 확인할 수 있습니다.추가로 API 호출 시 메소드에 보안 설정을 구성하고 URL이 외부에 유출되더라도 불필요한 유입을 차단하도록 API Key를 설정할 수 있습니다.API Key 설정 자! 이제 모든 설정이 끝났으므로 암복호화를 테스트만 해보면 되겠네요.AWS에서 제공하는 대부분의 서비스들은 기본적으로 Limit이 존재합니다. 클라우드 서비스에서 리소스를 효율적으로 관리하기 위해 당연하겠지만, API Gateway, Lambda에 대해 거의 무제한으로 사용 가능한 다른 Region에 비해 서울 Region에서는 아직까진 계정당 최대 Limit이 제한되어 있어 트래픽이 많은 서비스를 구현하기엔 부담스럽다는 부분입니다. Limit을 고려하지 않을 경우, 임계치에 도달하여 API가 정상적으로 동작하지 않거나 응답 속도를 보장 받을 수 없습니다. 따라서 상황에 따라 계정을 분리하여 사용하거나 AWS 서비스 도입 전 구축 서비스의 트래픽을 잘 가늠하여 진행하는 것을 권장합니다.AWS Key Management Service FAQHow Envelope Encryption Works with Supported AWS ServicesWhat Is the AWS Encryption SDK?신규 AWS Encryption SDK로 빠르게 데이터 암호화 구현하기Boto 3 - The AWS SDK for Python참고. boto3 Lambda function Github",http://woowabros.github.io/experience/2017/02/06/aws-kms.html,woowabros,"python3,java",NULL,2017-02-06
"빌링 시스템 장애, 이러지 말란 Maria~","안녕하세요! 우아한형제들에서 빌링/정산 시스템 개발을 맡고 있는 이주현이라고 합니다.  저는 지난 7월 입사한 이래로 배민에서 진행하는 다양한 이벤트에 대응하며 짧지만 강한 경험들을 하고 있습니다. 그중 얼마 전 있었던 빌링 시스템 장애와 관련된 이야기를 해보려 합니다.질문: “선임님, 우리 회사는 왜 퇴근 시간이 6시 30분인가요?”대답: “응 그건 바로 6시 이벤트에 대응하기 위해 서지..”(사실은 점심 시간이 11:30 ~ 13:00라 그렇습니다. ^.^)빌링시스템은 사용자의 결제 요청을 PG사에 전달하고 응답을 잘 정리하여 주문 시스템에 넘겨주는 역할을 하고 있습니다.  총 7대의 Spring boot application 서버와 Mariadb로 구성되어 있으며 mariadb-connector-j와 JDBC Connection Pool을 이용합니다. 할인 이벤트는 대부분 오후 6시에 진행되기 때문에 퇴근 전까지 긴장을 늦추지 않고 NewRelic, Pinpoint를 통해 모니터링하며 여러가지 상황에 대비합니다.지난 달 오후 6시. 선착순 1000명에게 3,000원을 할인해주는 카드사 이벤트가 시작되었습니다. 그런데 무난하게 초록색을 그리며 올라가던 Pinpoint 그래프에 얼마 지나지 않아 빨간 불이 들어오기 시작했고 약 1분간 14000개의 요청중 140개의 에러가 발생했습니다. 결제를 시도하려는 단계에서 에러가 발생했을 수도 있지만 결제 인증을 완료하고 승인하는 과정에서 문제가 생겼을 수도 있습니다. 특히 후자의 경우 결제 수단에 대한 모든 정보를 입력한 사용자 입장에서 정말 화가 날 수 있습니다.에러 내용은 대부분 빌링 시스템에서 보낸 요청을 네트워크 문제로 PG사에서 받지 못해 발생한것으로 보였습니다. 그런데 빌링 시스템 문제로 추정되는 다른 에러도 발견되었습니다.어디한번 확인해봅시다.DataAccessResourceFailureException: Unable to acquire JDBC Connection; nested exception is org.hibernate.exception.JDBCConnectionException: Unable to acquire JDBC ConnectionCaused by: java.sql.SQLNonTransientConnectionException: Could not connect to xxx.xxx.xxx.xxx unexpected end of stream, read 0 bytes from 42016-12-08 18:00:55 xxxx [Warning] Aborted connection 37170 to db: ‘unconnected’ user: ‘unauthenticated’ host: ‘xxx.xxx.xxx.xxx’ (Unknown error)처음 보는 에러입니다. ㅠㅠ 몰라 뭐야 그거 무서워Connection Pool 설정을 의심하고 확인해봤지만 특별한 문제점을 찾지 못했습니다. 시간이 지남에 따라 에러는 더 이상 발생하지 않고 소멸되었지만 언제 또다시 이런 일이 발생할지 모릅니다. ‘별거 아니겠지’는 큰 재앙을 불러올 수 있습니다. 우선 위의 메세지를 토대로 DB 커넥션을 추가적으로 연결하려고 했지만, 인증단계에서 실패한 것으로 추정했고 ‘mysql unauthenticated user’를 중심으로 구글링 하기 시작했습니다.검색 결과는 대부분 --skip-name-resolve 옵션에 대하여 언급했습니다. MySQL(Mariadb)은 새로운 커넥션 요청이 있을 때 인증을 위해 클라이언트의 IP 주소를 통하여 hostname이 host_cache 테이블에 있는지 확인합니다. 만약 없거나 인증 flag가 false라면 IP 주소로 hostname을 알아내는 과정을 거치게 됩니다. 이때 오류가 발생하거나 시간이 오래 소요되어 너무 많은 클라이언트가 연결에 성공하지 못하면 해당 호스트의 추가 연결을 차단하게 됩니다.MySQL 공식 문서에 따르면 DNS가 느리거나 많은 호스트들을 가지고 있다면 --skip-name-resolve 옵션을 my.cnf 파일에 추가하여 위와 같은 과정을 무시(disable DNS lookup) 할 수 있다고 합니다. (인증 관련 문제가 생길 수 있기 때문에 사전에 확인하시기 바랍니다.)하지만 저희는 이미 사용 중인 옵션이었습니다.이럴 때면 머리가 복잡해집니다.  그런데 말입니다.. 의외로 쉬운 부분을 놓치고 있었습니다.저희 팀은 io.spring.dependency-management 0.5.6 버젼을 사용중입니다. 이 버젼은 자동으로 mariadb-java-client 1.4.6 버젼을 지정해주는데요 같은 팀의 선임님께서 mariadb-connector-j 최신 버젼 1.5.5를 사용하도록 gradle 설정을 변경하고 난 뒤에 문제가 재현되지 않았습니다.결국 driver 문제로 생각되고.. 문제는 해결된 것 같지만.. 도대체 왜! 그런지 알 수 없는 상태가 되었습니다.우선 mariadb-connector-j의 changelog를 하나씩 찾아본 결과 의심되는 패치 내역을 확인했고 해당 jira issue를 찾아 어떤 내용이 등록 되었는지 살펴보았습니다.새로운 커넥션을 생성하는데 DriverManager.getConnection()에서 SQLNonTransientConnectionException이 발생한다.mysql connector를 사용하면 문제가 사라진다.PID를 가져오는 ManagementFactory.getRuntimeMXBean().getName() 부분에서 문제가 발생하는것 같다.증상이 일치하네요! commit 내역을 살펴봅시다.https://github.com/MariaDB/mariadb-connector-j/commit/77834ccc7dad77f3c7dbc0c26637e12b7a3d5644변경 전 코드를 보시면 SendHandshakeResponsePacket.java에서 인증 정보를 송신하기 위해 현재 pid@hostname을 받아오는 부분이 있습니다. 이때 hotname을 가져오기 위해 InetAddress.getLocalHost().getHostName()을 호출하는데 문제는 getLocalHost()에서 발생합니다. 해당 기능은 자바에서 제공되는 클래스로 hostname을 기반으로 IP 주소를 찾아 반환하는 기능을 담당하는데요 아래는 그 소스를 간략화한 것입니다.현재 hostname이 ‘localhost’라면 loopback 주소를 바로 반환하겠지만 만약 아니라면..? getAddressesFromNameService()메서드에서 DNSNameService Class의 lookupAllHostAddr()라는 보기만 해도 무섭고 복잡한 메서드를 호출합니다. 해당 메서드는 호스트네임을 가지고 IP 주소를 조회하는 역할을 하는데 만약 DNS 상태가 좋지 않아 시간이 지연된다면 데이터베이스에서는 connect_timeout 설정값에 따라 더 이상 기다려줄 수 없는 상황이 오게 됩니다. 저희 웹 애플리케이션 서버에서 테스트 결과 lookupAllHostAddr() 메서드에서 약 6초 정도가 소요되는 것으로 확인되었습니다. 빌링 데이터베이스의 connect_timeout 설정값이 5초였기 때문에 당연히 에러가 발생하겠지요.이러한 문제를 JNA를통하여 현재 pid만 반환하도록 하는 내용이 commit되었으며 2016년 10월에 1.5.4버젼으로 릴리즈 되었습니다.빌링 웹 애플리케이션 서버에서 새로운 DB 커넥션을 생성할 때 dnslookup이 6초 이상 걸리는 바람에 DB 서버의 connect_timeout(=5초)이 발생한 문제라는 것을 알 수 있게 되었습니다.문제를 해결하기 위한 또 다른 방법!hostname을 localhost로 사용합니다./etc/hosts에 IP주소와 hostname을 등록하여 최우선적으로 IP 주소를 반환하도록 합니다.무엇보다 라이브러리는 최신 버젼을 지향하는 게 정신 건강에 이롭습니다 ^.^mariadb-connector-j issue CONJ-360commit1: 77834ccccommit2: 11f8caaeNaver D2 Commons DBCP 이해하기Java에서 JNA를 사용하여 pid 알아내기 - stackoverflow",http://woowabros.github.io/experience/2017/01/20/billing-event.html,woowabros,"android,java",NULL,2017-01-20
소소한 배민라이더스 BROS 2.0 오픈 이야기,"배달의민족앱은 배달음식점을 앱을 통해 주문하는 것인데, 배민라이더스 는 그동안 배달을 하지 않던 맛집(?)을 앱으로 주문할 수 있는 서비스입니다. 앱을 주문하는 사용자의 앱을 사용하는 방법은 모두 같지만, 배민라이더스는 배달을 직접 수행합니다. BROS 1.0는 배달의민족에서 주문이 들어오면 해당 주문을 배달 센터에 연계하여 배달 라이더분들이 업소로 음식을 픽업하여 주문 고객에게 전달하게 하는 서비스입니다. 모든 배달 건을 관리하는 관제 Web기능과 라이더전용앱이 주 서비스입니다.기존 1.0은 서비스 출시 시기가 무척 중요했던 시절이라 최대한 빠른 개발으로 서비스를 런칭하는것이 큰 목표였습니다. 이제 서비스의 질적 양적 확장이 중요지고 배달 플랫폼으로써 고도화된 기능이 더욱 필요하게 되었습니다. 배달의민족 주문 기능과 배달 기능을 완전 분리해서 음식 배달 본연의 역할에 집중된 배달 플랫폼이 필요하게 되었습니다.하지만 봄부터 시작한 프로젝트는 여러가지 사정(정말 어려가지)으로 프로젝트는 난항이 계속 되었습니다. 다시 배민라이더스에 집중하자는 결론이 났고 이제 다시 프로젝트를 진행을 하면 되지만, 세상에 없던 서비스가 아닌 1.0이후 2.0을 새로 개발하는것입니다. 이게 뭐가 문제냐면 플랫폼이 교체되면 사용하시는 분을 모두 재교육해야 합니다. 배달업은 날씨에 영향이 많습니다. 추워지거나 비가오면 배달량이 정말 급격히 올라갑니다. 모두다 업무에 바쁜데 새 플랫폼을 반길일이 없겠죠. 입장 바꿔서 생각해보면 개발자 한창 오픈준비할때 개발툴 바꾸라는것과도 비슷하니(아 이 적절한 비유) 그래서 12월 전에 오픈이 또한 목표가 되었습니다. 젠장명시적으로 애자일을 표방한것도 아닙니다. 처음부터 개발 꺼리가 있던것이 아니라서 처음에는 상위기획을 기획자분과 같이 진행하였고, 스프린트마다 개발할 부분을 정해서 어쨌거나 스프린트(2주단위)를 돌렸습니다. 개발자가 기획에도 참여를 했기 때문에 제품에 대한 이해도가 평소보다는 좋았지만, 기능에 대한 변경이 매우 자주 발생했습니다. 어떻게 하나요. 이런 문제를 해결하는게 서비스 개발자의 사명인걸.기술 블로그이니 기술을 적어보죠기술 구성서브모듈 구성5개의 api server를 구성하였고, 구현된 service componets를 사용하는 형태로 api server를 구현하였습니다. 주문,업소 api는 현재 사용하고 있는 데이타를 api서버로 구성해서 bros 2.0과는 별개로 작동하게 구성하였습니다. 그리고 주소 DB는 새로 구축해서 사용했습니다.(juso.go.kr 데이타 사용)Data 구성확정된 기능이 아니라 잦은 구현 변경에 도움이 되었던 기술들을 꼽아보았습니다. 서비스 개발자는 정말 기능 변경이나 기능 추가에 유연한 개발을 해야 합니다. 모두 작동된다 해도 똑같은 제품이 아니라고 생각하는 뜻으로 아래 3가지 기술을 나열해봅니다.데이터를 요구사항에 맞게 표현을 하기 위해서는 여러 Entity를 조합해서 처리를 해야하는데, JPA자체만 쓰게 되면 Entity 구성에 따른 쿼리 튜닝을 별도로 하기에 너무 척박한 환경이라, 원활한 데이타 조회를 위해 QueryDSL을 사용하게 되었습니다.개발중 Entity가 수정이 되고, QueryDSL queryType을 재생성 하게되면 Java타입이 맞지 않아 강력한 빨간 라인으로 쿼리가 깨짐을 알수 있습니다. 그리고 JPA를 사용하게 되면 LAZY 처리를 잘못해서 N+1쿼리를 자주 접하게 되는데, JPQL fetch join을 선언하게 되면 내부적으로 join문이 작동해서 필요한 데이터를 쿼리 한번에 가져올수 있습니다.개발중 api 문서는 별도로 관리하지 않고, 개발중인 Source를 이용해서 API 문서와 작동을 확인할 수 있는 Swagger를 사용하여, 문서작업에 대한 비용을 제거했습니다. 특정 api마다 적절한 Annotation을 선언하게 되면, Swagger 설정이 적용된 서버에서 api 문서를 제공해줍니다.실제 연관관계를 모두 끊고 테스트해야 할 부분만 집중해서 만들기란 어렵고, 복잡한 도메인일수록 더욱더 어렵습니다. TDD는 왜 쉬운 도메인만 하는지 모르겠어요. 하지만. 그럼에도 불구하고 테스트코드가 있다면 합격. 기능이 변경이 될 때, 예기치 못했던 부분이 깨지고 버그를 발견했다면 진짜 합격. 서버 개발자이자 프로젝트 PM을 했습니다. 지나고 나서는 PM의 역할보다는 개발자의 역할이 좀 더 강했고 그로 인해 프로젝트 관리를 많이 놓쳤습니다. 일정 산정도 중요하지만, 가용 자산으로 현재 어떻게 지내왔고 앞으로 어떻게 진행될 거라는 예상을 어느 정도는 해야 했고, 또한 개발자마다 진행 상황을 자세히 알아야 했고, 상호 연동을 잘할 수 있도록 판을 깔아 줘야 했지만. 못했습니다. 그래서 사단이 생겼습니다.문제를 좀더 빨리 파악을 했더라면 다른 선택지가 있었을텐데, 개발일이라면 자신이 있었지만, 프로젝트 관리 잘못하는 PM덕분에 많은 사람이 고생을 했습니다. 머리숙여 사과. 하지만 보상은 없습니다. 알아서들 셀프 보상 하세요.여러 사람이 모여서 팀을 이룰 때 모두 다 같은 생각을 가지는 것은 사실 매우 힘든 일입니다. 개개인의 모든 가용가산을 끌어다 쓴다는 것은 큰 부채를 지는 것과 같습니다.이미 미래의 자산을 끌어 쓴 샘이죠. 이럴 때 만약 프로젝트가 실패로 접어든다면 해당팀은 정말 다시 일어나기 힘듭니다. 엄청난 위험 부담을 지게 되는 것이죠. 이렇게 되지는 않았어요!!!QA를 시작하고 정확히 3주 후부터 제품이 안정기에 진입했습니다. 잘 돌아가지도 않던 기능을 QA 하시느라 사경을 헤매신 QA 분들 정말 죄송합니다. QA 기간을 절반 줄이고 개발 기간을 좀 더 늘렸다면 어땠을까 후회가 됩니다.정말 이런 메일을 받아 볼 수는 있을까? 너무나 큰 걱정을 가지고 임했던 프로젝트는 과정은 성공적이지 못했지만, 결과는 성공했습니다. 매 순간 잘못된 선택으로 고생한 사람들에게 심심한 위로를 드려요. 다음 기회가 있을지는 모르겠지만 좀 더 잘해볼게요.",http://woowabros.github.io/experience/2016/12/27/baemin-riders-project.html,woowabros,,NULL,2016-12-27
좌충우돌 실전 프로젝트 개발 스토리,"우아한형제들의 배민B2C개발팀에서 서비스 개발을 맡고 있는 이수홍입니다. 이번에 제가 맡게된 통합인증 프로젝트를 진행하면서 좌충우돌 겪었던 이야기를 들려 드리고 싶어서 이렇게 글을 적어봅니다.입사 후 드디어 프로젝트를 맡게 되었습니다. 그것은 다름 아닌 통합인증 프로젝트! 이 프로젝트가 진행된 계기가 사내에서 “배달의 민족” 서비스뿐만 아니라 “배민프레시”, “배민라이더스”, “배민쿡” 등 여러 가지 서비스들이 생기고 성장함에 따라 인증을 통합할 수 있는 서비스의 필요성이 생겼기 때문이었습니다. 저 같은 경우 그전까지는 보통 B2B 시스템 개발과 프로젝트 초기의 애플리케이션 베이스 구성과 공통 개발 등을 담당하는 역할을 했었습니다. 그래서 많은 트래픽이 있는 B2C 서비스의 개발을 실질적으로 처음 맡게 부분이어서 “잘 해야겠다”는 마음과 “잘할 수 있을까”등의 부담을 가졌었습니다. AWS를 사용하여 인프라 구성, CI 구성, APM 시스템 연동, 기존 시스템 분석, 애플리케이션 설계 및 개발, 관리자 시스템 개발 등 기존에는 딱 정해져 있던 임무에서 범위가 많이 넓어지게 되었습니다. 처음에는 인증 시스템이라는 부분과 팀장님과 같이 이야기하면서 요구사항 등을 파악했었습니다. 당시 어떤 인증 시스템을 구축할지 의논했을 시 로그인 API와 공통 로그인 화면, 그리고 여러 가지 서비스와의 연동 등을 생각했을 때를 생각해서 OAuth2 형태의 시스템이 가장 최적이라고 생각했었습니다. 그렇게 시스템 형태를 결정한 후 저의 경험대로 프레임워크를 구성 -> (요구 분석에 따른) 데이터 모델링 -> 인증시스템 개발 -> API 개발 순서로 진행했습니다.인증 시스템이 만들어지면서 기존 시스템에 연동하는 작업을 시작하게 되었습니다. 문제는 여기서 발생하기 시작했습니다. 기존 시스템의 회원 구조를 분리해서 새로 만들어진 인증 시스템과 연동이 시작되면서 기존 시스템의 보이지 않던 문제가 점점 발견되기 시작했습니다. 현재 설계에서 고쳐지지 않는 구조적 문제를, 정해진 일정 내에서는 해결할 수 없다는 결정이 내려지게 되었습니다. 그렇게 프로젝트는 잠시 중지되고 기존 시스템을 설계 부분을 고치더라도 그 부분을 해결해야 되는 숙제가 생겼습니다. 다시 프로젝트 구성원들이 서로 모여서 왜 그 부분을 미리 발견할 수 없었는지 등 현재 프로젝트가 무엇이 문제였는지 다시 한번 이야기를 하게 되었습니다. 서로 간의 현재 프로젝트의 인식들을 다시 맞추고 새롭게 시작하였습니다. 프로젝트 참여원들의 고생과 우여곡절 끝에 기존 인증 부분의 아키텍처를 고치고 나서 프로젝트는 다시 진행하게 되었습니다.  기존 시스템에서 숨겨져 있던 기존 버그까지 수면 위로 올라오는 것을 목격하면서 새롭게 시스템 만드는 것보다 기존 시스템의 변경 비용이 확실히 크다는 것이 몸소 느껴졌습니다. 대부분의 프로젝트가 그렇듯이 막판에는 자잘한 버그와 변경된 정책의 검증, 인증서버 특성상 보안 문제, 현 시스템과 연동 테스트, 기존 회원 정보 이관 문제, 운영서버 환경 결정, 애플리케이션의 성능 테스트, 병목지점에 대한 수정과 캐시 설정, 데이터 이관 등등 바쁜 나날을 보내고 시스템을 (평탄치는 않았지만) 오픈하였습니다.  [보이지는 않지만 중요한 이부분]우여곡절 끝에 마무리된 프로젝트였지만 지금 생각해보면 미리 초반 생각했었으면 좋았을 것 같은 부분을 적어 보았습니다.제가 했던 역할에서 현재 와서 보면 정해진 인원과 시간에서 현행 인증 시스템을 개선하는 프로젝트의 목적보다 인증 플랫폼 개발에 치중한 부분이 있었다고 생각되었었습니다. 어느 정도 중간을 잡고 진행을 했어야 했던 부분이 필요했었던 것 같습니다. 어렵게 프로젝트를 마무리하게 되면서 고생한 동료들의 소중함이 새삼 다가왔었습니다. 지금도 시스템이 어느 정도(몇 번 사고는 있었지만 ㅠㅠ) 문제없이 돌아가는 것을 보면서 놀랍기도 하고 (문제 생길까봐) 무섭기도 합니다. 그래서 현재는 인증시스템의 문제를 측정하여 원인을 알 수 있는 여러가지 도구들을 만들어 가용성을 높게 만들려고 노력 하고 있습니다. 그리고 인증시스템에서 (이왕?!) 만들어둔 스펙들, 우리 회사의 서비스들이 지금보다 많이 흥해서 확장할 때 도움이 되었으면 좋겠다는 생각도 문득 듭니다.(__) 마지막으로 B2C 프로젝트 처음과 끝을 함께한 경험을 가지게 된 것이 큰 행운이라 생각되며 앞으로의 저에게 큰 밑거름이 되지 않을까 생각됩니다. 프로젝트 진행하면서 같이 고생한 팀원들에게 다시 한 번 정말 고맙고 감사하다는 말씀을 드리고 싶습니다. ",http://woowabros.github.io/experience/2016/12/23/baemin-auth-project-developer-story.html,woowabros,,NULL,2016-12-23
누군가에게는 빼빼로데이. 누군가에게는?,"11월 11일 빼빼로데이. 많은 인터넷 서비스 회사들이 빼빼로데이를 맞이하여 여러 이벤트를 준비한 것처럼, 배민 또한 이벤트를 준비했습니다. 아침 11시부터 선착순 1,111명에게 11,000원 할인쿠폰을 발급하는 이벤트. 선착순 이벤트의 특성상 짧은 시간에 과도한 부하가 걸리기 마련이고, 이 때 시스템 장애로 이어진 경우가 있다보니, 치도스 공격이라는 말까지 있었는데요. 이 기억때문인지 뽐뿌에서는 배민고시라는 말까지 나오며 이번 이벤트에 대한 설왕설래가 있었습니다. 그리고 슬프게도…  이번 이벤트에 배달의 민족 서비스는 분명히(어쩌면 반드시) 이벤트 트래픽을 버티지 못하고 다운될 것이라는 예측이… ㅠㅠ  [고객들의 기대에 부응해야 하는 것인가? ^^;]위에서도 언급했듯이, 배달의민족 이벤트의 특성은 트래픽이 수초 이내에 급격히 상승했다가 소멸된다는 특징이 있습니다. 이러한 트래픽의 형태는 AWS에서 제공하는 Auto-Scale 마저도 무용지물로 만들어 버립니다. Auto-Scale이 될 시점이면 이미 이벤트는 끝나버리기 때문이죠.따라서 단순히 트래픽에 따른 서버 증가가 아닌, 이러한 이벤트를 처리하기 위한 별도 시스템을 구성하기로 결정했고, 이 시스템의 구성 목표는 순간 트래픽을 유연하게 처리하면서도 기존 서비스 시스템에 최소한의 영향을 미쳐 이벤트로 인한 서비스 지연 등의 장애 포인트를 없애는 것으로 잡았습니다.시스템은 다음과 같이 크게 세 개의 파트로 분리했습니다.Node.js와 Redis의 조합은 Node 인스턴스 하나로 25,000 tps를 버틸 수 있는 것으로 알려져 있는데요. 물론, 25,000 tps라는 숫자는 몰려드는 트래픽을 처리하기 위한 process라는 것이 지극히 단순한 경우이지만 충분히 기대해볼만 하다고 생각했습니다.  다만 인증 파트가 기존 서비스에 연동되어야 한다는 부분은 부담이 될 수 밖에 없었습니다.인증과 이벤트 메인 시스템은 AWS ElasticBeanstalk 위에 Node.js로 구성했고, 인증과 이벤트 참여 여부에 대한 검사는 AWS ElastiCache(Redis)를 활용했습니다. 이벤트에 참여한 기록에 대한 것은 AWS SQS를 이용해 저장하고 후처리는 AWS ElasticBeanstalk Worker로 구성했습니다.  [시스템 구성도]위 그림에서 전면에 이벤트 트래픽을 그대로 받아드리는 Node.js는 총 5대의 Instance로 구성했고, 뒤에 인증정보와 이벤트 참여 정보를 저장하는 Redis는 마스터 노드 하나와 리플리케이션 노드 두대로 구성했습니다. 전면의 Node.js에서는 값을 참조할 경우는 Read Replication을 참조하고 인증이나 이벤트 관련 정보를 저장할 때는 Master Node를 보도록 구성했고요. (하지만 이 구성의 맹점은 여기에 있었으니, 뒤에서 공유하겠습니다. ㅠㅠ)이렇게 시스템 구성을 끝내고, 부하테스트 환경을 통해 이벤트 시스템에 부하를 가하면서 시스템의 상태를 점검하고 튜닝하는 과정을 진행했으나… 테스트 환경에서는 ELB의 Warm-up이 되어있지 않은 이유로 50만 트래픽까지 부하를 주지는 못하고 그 이하 수준에서 종료하게 됩니다. (여기서도 얻은 한 가지 교훈은 부하테스트를 하려면, 테스트환경의 ELB도 AWS쪽에 pre warm-up을 신청해 놔야 한다는… -_-;)드디어 이벤트 당일. 이벤트 시간이 점점 다가올수록 처음 느긋함과는 다르게 조금씩 긴장이 되기 시작했습니다.시스템 점검은 완료했고 요청했던 ELB의 warm-up도 완료되었다고 연락을 받은 후, CTO실 사람들뿐 아니라, 유관부서의 담당자들이 점점 자리에 몰려들기 시작하고… 다른 구성원들도 혹시 있을지 모르는 과부하 발생으로 인한 장애에 대비하게 됩니다. 다들 각자 모니터에 CloudWatch와 NewRelic를 띄워 놓고, 모니터링을 진행하던 두 눈에 힘을 주기 시작했습니다. ^^; 미리 이벤트를 찔러(?) 보는 고객들의 요청으로 인해 트래픽이 증가하기 시작하고…이제 십여초 전…이벤트에 참여하려는 고객들의 인증 요청을 시작으로 트래픽이 급격히 상승하기 시작합니다. 그리고 몇 초가 지나자, 시스템 전체적으로 트래픽이 수직 상승하며 이벤트가 진행중임을 실감하게 만들었습니다.그리고… 11시 정각… 1초, 2초… 엥??약간의 환호와 ‘버텼어!!’라는 외침과 함께 이벤트가 종료됩니다. 이벤트가 원활하게 수행된 정도가 아니라, 좀 싱거울 정도로 허무하게 몇 초만에 마무리되고 시스템은 바로 평상시 모드로 돌아오게 됩니다. 흐흐흐. 아래는 해당 시간 트래픽 변동에 대한 그래프입니다.너무나 평온하게 끝난 이벤트. 11,000원 할인이기에 작년과 재작년에 진행했던 블랙프라이드데이보다 더 많이 사람들이 몰릴 거라 예상했는데, 성공적으로 끝낸 기쁨에 다들 축하하며.. 그렇게 11월 11일의 오전 시간이 지나갑니다.이렇게 아름답게 끝났어야 했는데… 이쁘기만 했던 이벤트 트래픽 그래프 뒤로 숨어있는 폭탄이 있었는데요. 이벤트에 당첨된 회원들에게 쿠폰을 발급하려는데 문제가 생겼습니다.. 어? 1,111명 보다 많은데?? 1,111명보다 많은 수가 이벤트 당첨 기록에 남아 있었습니다. 뭐지??일단 당첨은 당첨이니, 마케팅실과 협의하여 초과된 당첨에 대해서도 쿠폰은 발행하고, 문제가 된 부분을 찾기 시작합니다. 소스코드를 여러 번 살펴봐도 잘못된 점이 보이질 않았는데요. 한참을 살펴 본 후, 원인을 찾아냅니다. 문제는 소스코드가 아닌, 시스템 구성에 있었습니다.앞에 이야기한 것처럼 Redis를 마스터노드 하나와 리플리케이션 노드 둘로 구성했는데요. 이 Redis의 주요한 기능 중의 하나는, 당첨자를 제한하기 위한 카운터였습니다. 이벤트에 당첨된 고객이 나오면 카운터를 증가시켰고 이벤트에 참여하려는 회원은 반드시 이 카운터를 참조해 기회가 있는지 조회하는 구조였죠. 이 때, 카운터 증가는 마스터 노드에 하고 참조는 리플리케이션 노드에서 수행하게 됩니다.바로 이 부분이 문제였습니다.워낙 짧은 시간에 많은 요청이 있었기 때문에, 마스터 노드에 증가된 카운터 값이 미처 리플리케이션 노드에 복제되기 전에 밀고 들어온 이벤트 참여자의 경우 카운터 제한에 걸리지 않고 참여할 수 있었던 거죠.결국 이 정도의 트래픽 러쉬에서는 카운터와 같은 기능은 복제를 쓰지 말고 마스터를 참조해야 한다는 큰 깨달음을 얻었습니다. 이런 경험을 통해 분명 또 다른 포인트를 배웠지만, 정말 처음부터 끝까지 완벽하게 수행하고 싶었던 욕심이 있었기에 한편으로는 너무나 맘이 아프고 안타까운 오점을 남기고 말았네요. ^^ 참. 마지막으로 공지사항 하나.올해도 블랙후라이드데이 시즌3가 진행됩니다. 많은 관심 부탁 드립니다. ^^;",http://woowabros.github.io/experience/2016/11/28/woowahan_4one_event.html,woowabros,"mysql,mongodb",NULL,2016-11-28
AWS IoT 버튼을 활용하여 차임벨 만들기,"  우아한형제들 사무실 입구에는 이런 안내문이 붙어 있습니다. 사원증을 깜박하고 출근한 직원들이 문을 두드리면 문 근처의 직원들이 일에 집중하기 힘들다는 것이 그 이유였는데요. 재치있고 재밌게 쓰여 있지만 결국 한줄로 요약하면 ‘문 두드리지 마세요.’인 것. 하지 말라고 하는 것보다 더 좋은 방법이 없을까를 고민하던 중 일전에 재있을 것 같아 구입해서 테스트만 잠깐 해보고 서랍에 고이 모셔둔 AWS IoT 버튼이 생각났습니다. 지름교 신자들은 일단 지른 다음 용도는 나중에 생각합니다. 마침 타이밍 좋게 Line Bot API에 단체방에 메세지를 보낼 수 있는 API도 추가되었습니다. 게다가 먼저 삽질을 다 해본 팀원이 있어 삽질해야 할 위험도 줄었습니다.  간절히 바라니 우주가 도와주는 것만 같습니다.  원하는 기능은 아래와 같습니다.이를 위해서는 AWS IoT, Lambda와 라인의 Line Bot API를 사용하면 될 것 같습니다.(나중에 추가로 AWS API Gateway도 사용해야 했습니다.)AWS IoT 버튼은 AWS IoT 서비스를 사용합니다. 위사진의 빨간 원으로 표시된 Connect AWS IoT Button을 클릭한 다음 이어지는 설명에 따라서 차분히 진행하면 모든 세팅이 완료됩니다.서비스를 연동하기 위해 Lambda를 연결하여 프로그래밍 하도록 합시다.  Line Bot API를 사용하기 위해서는 일단 Line Business Center에 계정을 만듭니다.  현재 LINE@, Line Login, Messaging API 세가지 서비스를 제공하고 있는데 라인봇을 만들기 위해서는 Messaging API를 사용하면 됩니다.계정의 이름과 사진 업종 정보를 입력하면 계정이 생성됩니다.  생성한 다음 추가로 해야 할 작업은 WebHook URL을 구해서 입력하는 것과 Channel Access Token을 얻는 것 두가지만 하면 됩니다.  Channel Access Token은 Rest API로 메세지를 보낼 때 인증을 위해 필요합니다. WebHook URL은 Messaging API만 사용할 때는 따로 사용할 필요는 없습니다만…메세지를 보낼 때 어디로 보낼지를 알리기 위해 JSON Data에 ‘to’에 키값을 알아야 하는데 이 키 값은  다른곳에서는 알 수 없습니다.  WebHook URL을 세팅해두면 Bot이 Line 서버에서 받는 데이터들이 해당 URL로 JSON 포맷으로 전달됩니다.  별도로 사용하는 서버가 있으면 서버에 간단한 프로그램으로 Body Data를 확인할 수 있는 URL을 확보해서 확인해도 되지만  전 노는 서버도 없고 Web 프로그램을 해본지 오래되어 기억이 나지 않기때문에 간단히 AWS API Gateway를 사용하여 Lambda에서 간단히 확인해보기로 했습니다.  (우아한 형제들은 개발자들이 자유롭게 테스트하기 위해 놀이터라고 부르는 AWS 서비스를 무제한으로 사용할 수 있는 계정을 제공하고 있습니다.) 이 코드에서 남기는 Console Log는 Cloud Watch에서 확인할 수 있습니다. groupId(일반 대화방은 roomId)를 구했으니 Lambda를 이용하여 LINE Messaging API를 호출하는 코드를 작성해서 연결해주면 됩니다.  위의 CURL 샘플에 있다시피 헤더에 인증키를 설정하고 Body에 정해진 JSON 포맷으로 전달하기만 하면 되는 심플한 구성입니다. 그래서…는 훼이크고 본 글 말미에 Node.js로 작성된 소스를 다운받을 수 있는 링크가 있습니다. (거듭 말씀드리지만 전 프론트, 서버를 망라하여 Web을 해본지 정말 오래된 개발자입니다. 참고용으로만 사용하세요.)이렇게 하면 대략 개발해야할 항목은 끝났습니다. 작성한 Bot을 친구로 추가한 다음 사용할 단체방에 초대해줍니다.   버튼을 문앞에 붙이고 안내문을 붙인다음 전체방에 공지를 하면…첫날은 이렇게 장난벨이 폭주합니다.(아휴 이런 촌것들…)이 글을 쓰는 지금 이틀이 지나고 안정적인 상황으로 접어들었습니다. 뭔가 싶어 눌러보는 사람도 이제 별로 없고 조금 더 살펴본 후 안정적으로 서비스가 제공된다고 판단되면 적당한 단체방으로 이관하여 사용할 예정입니다. LINE API나 AWS IoT와 같이 심플하고 쉽게 접근할 수 있는 서비스를 엮어 거기에 약간의 아이디어를 더해 재미있고 편리한 서비스를 만들어 내는 것이 최근 뜨거운 IoT서비스의 묘미가 아닌가 합니다.모두가 만족하는 해법은 반드시 존재합니다. 감사합니다.Source Code Download",http://woowabros.github.io/study/2016/10/28/woowahan_chime_bell.html,woowabros,"jquery,java,xml,javascript,android,react",NULL,2016-10-28
Sql server 2012 / Event ID 36888 Schannel Error,"데이터서비스팀은 10월 정기점검일을 맞아 메인 서비스 DB로 운영중인 Windows Server 2012 R2, SQL Server 2012 2기를 업데이트 및 리부팅 작업을 진행하였습니다.  강력한 IO 성능을 위해 도입한 FusionIO 의 점검도 하고, Table 들의 인덱스도 손보고 각종 점검도 했습니다. 간단한 서비스 테스트를 진행한후 서비스를 오픈했지요. 그런데 갑자기 로그시스템에 에러가 조금씩 보이기 시작하고 대쉬보드가 빨간색으로 바뀝니다.살펴보니 DB connection 이 제대로 맺히지 않고 끊기는 문제들이 발생하고 있는데, 모든 connection 에 에러가 있는 것도 아니고 좀 이상합니다.노트북에서 python 을 사용해서 테스트를 해봤습니다.10 번에 한번쯤은 exception 이 발생했습니다.Windows Event Log 에는 다음과 같은 에러들이 무수히 찍혀있네요.폭풍 검색을 해보지만 딱 맞는게 잘 안보입니다. 하지만 전반적으로 TLS에 관련된 이야기, negotiation 과정에서의 에러 등등의 내용이 검색되었습니다.sql-server-freetds-freetds-fails-to-connect-to-sql-server-after-recent-windows-patches-and-tls1-being-disabled그리고 이런 글도 보입니다. 윈도에서 특정 패치를 롤백하라는 내용입니다. 디비서버라 건드리기 무서워서 이건 최후의 수단으로 생각하고 미뤄두었습니다. (게다가 글에 언급된 패치번호도 없어서 설치된 핫픽스들을 일일이 내용파악해야 했죠.)pymssql 에서 출력하는 에러만으로는 뭔가 부족해서 또 구글신의 도움을 받습니다. freetds 라이브러리는 로그를 남기는 기능이 있어서 자세한 상황을 볼 수 있습니다. 이 로그는 append 되지 않고 한번의 세션에 대한 로그라서 에러가 남는 상황에서 딱 봐줘야 합니다. ~/.freetds.conf 파일을 작성하고, shell script 에서 에러가 난 경우 바로 빠져나오도록 테스트했습니다. 에러로그를 살펴봅니다. /Users/nazgul33/tds.dump.log SQL server 쪽에서 연결을 강제로 끊은 상황입니다. 아마도 session negotiation 중에 에러상황이라고 판단하고 끊었다고 생각됩니다. 암호화 session 이 문제가 되었거나 tds 프로토콜 핸들링의 문제일 것이라고 더 확신하게 됩니다.서버가 업데이트되었으니 클라이언트도 업데이트해보기로 결심했습니다. 제 노트북 환경 ( El Capitan, Home brew ) 에서 일단 테스트해봐야겠죠. pymssql, freetds, openssl 을 업데이트합니다.일단 다 삭제!openssl 1.0.2j 와 freetds 1.00.15 가 설치되었습니다. 이제 pymssql 을 설치합니다. 컴파일이 안됩니다. 구글은 모든 것을 알고 있습니다. pymssql 2.2.0 dev 버전이 freetds 1.00 버전에 대해 에러 없이 컴파일 된다고 합니다. 깃헙에서 pymssql을 clone 하고 설치해봅니다.이제 또 테스트해봅니다. connect - select 1 - close 계속 실행시켜봅니다. 3000번쯤 실행해도 에러가 나지 않습니다.php로 구동되는 서버들과 python 에서 에러가 떨어진다는 점에 착안하여 freetds 아니면 openssl 이 범인이라고 생각했습니다. 둘중에 어떤것인지 다시한번 알아보기 위해 각각 하위버전으로 설치하여 테스트해봤습니다.openssl, freetds 를 직접 소스를 받아서 설치 설정하는것은 매우 귀찮은 일이므로 brew 를 활용해보기로 합니다. 역시 폭풍 검색을 한 후, brew 를 하드코어적으로 다뤄줘야 한다는 것을 깨닫습니다. 하지만 나도 하드코어니까 괜찮아.그냥 여전히 잘되네요. freetds 를 다운그레이드해봅니다.네 문제가 발생하네요!! freetds 의 구버전 0.91 이 문제가 된다는 사실을 알 수 있습니다.이제 서비스 서버들에 freetds 설치를 해야하는 마지막 과정이 남았어요. 우아한 형제들이 사용하는 시스템들을 보니 두가지 입니다.두가지 모두 rpm 으로 시스템 패키지를 관리하는데, 둘다 freetds 1.00.15는 준비된 rpm 파일을 찾을 수 없었습니다. 어쩔 수 있나요? 직접 컴파일 해야 합니다. shared object ( .so 파일 ) 들이 설치된 경로를 찾아봅니다.라이브러리들은 /usr/lib64 에 설치되어 있네요. 설정파일은 /etc/freetds.conf 파일입니다.설치경로를 찾는 다른 방법은 rpm 명령을 이용하는겁니다.경로들을 알았으니 컴파일을 해봅시다.테스트를 해보니 php 코드에서 exception 이 발생합니다. sql server 의 datatime type을 php DateTime type 으로 받는 과정에서 발생하는 것으로 생각되는데, 에러로그를 남겨두지 않아 정확한 메시지를 쓸 수는 없지만 다음과 같은 내용이었습니다.아마도 최하위버전의 tds protocol 이 선택된 경우 날짜를 문자열로 전송하는 것으로 생각됩니다. tds version = 8.0 인 설정에서는 최하위 버전의 tds 프로토콜을 사용하는 것으로 보입니다.이것은 /etc/freetds.conf 에서 tds version 을 변경하는 것으로 해결됩니다. sql server 버전 별 tds versionphp, python 을 사용하는 모든 서버에 freetds 를 설치한 후 모든 에러가 사라지고 서비스가 정상화되었습니다.sql server 에서 access violation 에러가 발생하여 정기점검때 os/db patch 를 적용하는 것으로 정했으나 (급박하게) 미리 테스트해볼 생각을 하지 못했습니다. 서비스 DB 의 OS, DB engine 패치 작업은 Beta 환경에서 먼저 적용/테스트 한 후 수행하는게 실제 장애 상황을 방지하는 좋은 방법입니다. 이 글은 교차투고되었습니다. wordpress ",http://woowabros.github.io/experience/2016/10/19/schannel-36888.html,woowabros,"python,mysql,java,php",NULL,2016-10-19
배달의민족 연성체를 맞이하며,"연성체 때문에 행복한 연성이 아빠가2016년 한글날을 맞아 네 번째 발표된 배달의민족 연성체는 제게 좀 특별한 의미입니다.인원이 10명도 되지 않던 시절부터 우아한형제들은 약간 특이한 행보를 해 오고 있습니다. 2012년부터는 PC용 폰트를 만들기 시작했고, 그 이듬해부터 매년 하나씩 폰트를 발표하고 있습니다. 처음에는 이렇게 많은 사랑을 받게 될 지 (저는) 정말 몰랐고, 배달의민족 한나체를 사용한 인쇄물, 광고, 책, 간판이 나올 때마다 구성원들은 사진을 찍어 서로에게 공유하며 기뻐했는데, 지금 서점을 가 보면 굉장히 많은 책 표지에 사용되고 있고, TV 자막으로 한나체, 주아체, 도현체를 끊임없이 볼 수 있게 됐습니다. 많은 분들이 사랑해 주셔서 너무 즐겁습니다. [왼쪽부터 한나체, 주아체, 도현체, 연성체 포스터]많이들 궁금해 하시는 걸 먼저 말씀드리자면, “우아한형제들의 김봉진 대표님이 하고 싶어서 시작된 폰트 제작”은 매년 하나씩 발표하고, 5개년 개발계획으로 시즌1이 진행되고 있습니다. 이제 하나 밖에 안 남았다, 왜 다섯 개만 만드느냐, 더 만들었으면 좋겠다 등의 이야기들이 많은데, 작은 회사 입장에서 폰트 제작을 언제까지고 계속 할 수 없어서, 시작할 때 5개를 목표로 꾸준히 해 나가고 있다고 합니다.이미 여러 차례 공개된 적이 있지만, 우아한형제들은 폰트의 이름을 구성원들의 아이 이름 중에서 선택하고 있습니다. 첫 번째 한나체와 두 번째 주아체는 김봉진 대표님의 두 아이들 이름을 따서 정해졌고, 세 번째부터는 전체 구성원들의 아이 이름을 그 구성원의 근속년수 만큼 통에 넣어, 뽑기를 진행했습니다. 자연스럽게 근속기간이 긴 사람이나, 아이가 많은 사람이 배려되는 룰인데, 오래 근속했고, 아이가 많다고 해서 꼭 선택되지는 않는 것이 더 즐겁게 만드는 것 같습니다. [연성체 Ideation Development에서 발췌]세 번째 폰트에서 이런 방식이 발표됐고, 이미 제외대상이 된 대표님을 제외하면 근속년수와 아이들 수의 곱이 가장 많은 사람은 저였습니다. 아직 돌도 안 지난 다른 분의 아이의 이름이 선택되며 이 방식이 얼마나 재밌는지 실감했고 ㅎㅎ, 2015년 네 번째 폰트로 제 첫째 아들 이름이 불렸을 때, 직장 생활 18년 중 이렇게 기쁜 적이 있었던가 싶게 기뻤습니다. 사실 무슨 소유권을 갖게 되거나, 어떤 형태의 물질적인 이익이 생기는 것은 전혀 없는 이 혜택은 당사자로서는 정말 재밌는 경험을 하게 하는데, 전사 구성원들에게 계~속 축하를 받고 있습니다. 뽑기에 뽑혔을 때부터, 네 번째 폰트를 어떤 모양으로 만들기로 했다 (와~ 축하해요) 첫 번째 시안이 나왔다 (폰트 너무 예뻐요, 축하해요~) 연성이 생일선물로 시안을 가지고 포스터를 만들었다 (연성이 생일 축하해요~) 마무리 단계이니 검수를 함께 하자 (PC에 설치하실 수 있어요, 축하해요~) 거기다 지금은 2016년 한글날을 기념으로 폰트를 발표했는데 축하는 제가 받고 있습니다. ㅎㅎㅎ [연성체 Ideation Development에서 발췌]우아한형제들은 이것저것 뽑기를 정말 많이 합니다. 업무 상의 결정이 아닌, 생활에서의 우선권(?)을 공평하게 나누는 방법으로 많이 사용하는데, 이런 뽑기는 약간의 물질적인 이익이 생기게 됩니다. 예를 들어, 영화관람권이나 문화상품권이 생겨서 세 명에게 나눠 준다거나, 회사로 들어온 명절 선물을 나눠 준다거나.. 이런 뽑기에 제가 선택되지 않아도 모두들 궁시렁거릴 틈도 주지 않습니다. 더 큰거 뽑히셨잖아요, 그거면 됐지요, 올해 운을 다 쓰셨어요… 위에 말씀드렸듯이 폰트 이름은 뭔가 물질적인 이익은 전혀 없습니다. 더 재밌는 것은, 저도 뭐 그런거 하나도 안 뽑혀도 괜찮습니다. 앞서 발표된 한나체나 주아체, 도현체의 성장 과정들을 봐 왔지만, 연성체는 아직 어떻게 성장할 지 알 수 없고, 앞으로 많은 분들의 사랑을 받게 될 지는 정말 모르겠습니다. 하지만, 이렇게 여러 감정으로 풍부하게 행복한 경험과 미래가 기대되는 기분을 느낄 수 있다는 것은 무엇과도 비교하기 어렵고, 즐거운 일입니다. [우아한형제들 2015년도 전사플레이샵에서. 아싸~]축하와 칭찬을 받아야 하는 분들은 제가 아니죠. 지금까지 1년 동안 연성체를 제작하기 위해 노력을 아끼지 않은 분들이 주인공이고, 그 수고에 많은 박수를 보냅니다. 컨셉을 정하고, 실제 제작도 함께 하신 김봉진 대표님의 이야기와 우아한형제들 블로그의 글를 함께 소개해 드립니다. 담당인 민지희 선임디자이너의 이야기를 들어보니, 제주도 호박엿 입간판에서 본 느낌을 살리기 위해 붓펜으로 열심히 써 봤는데, 생각보다 붓펜이 너무 얇아서… 처음엔 의도한 느낌이 제대로 표현되지 않았다고 하네요. 그림으로 그려 보기도 하고, 일러스트레이터로 외곽선을 일일이 다듬었다는 이야기를 듣고 숨은 수고가 많이 느껴졌는데요, 입간판을 직접 쓰신 그 분이라면 나머지 글씨들을 어떻게 썼을까 상상하며 스케치를 계속 해 나갔다고 합니다. 특히 숫자나 영문, 기호들은 아예 힌트를 얻을 수 없는 영역이라 아이디어가 많이 필요했다고 하네요.세 번째 폰트인 도현체부터는 폰트 전문업체인 산돌커뮤니케이션과 함께 제작하고 있는데, 산돌의 석금호 대표님과 이도경 팀장님, 강주연 디자이너가 함께 연성체의 꺾임과 공간을 다듬어 나갔다고 합니다. 특히 넘사벽의 경험을 가지고 계신 석금호 대표님이 직접 참여를 하셨다고 해서 깜짝 놀랐습니다.연성이는 지금 초등학교 5학년입니다. 자신의 이름을 따서 나온 이 폰트가 어떤 의미인지 알고, 어떻게 활용하는지도 잘 알고 있는 것 같습니다. 연성체가 예쁘고, 간판에 많이 사용될 것 같다고 하네요. 정식 연성체 포스터를 받자마자 선생님이나 친구들과 연결된 클래스팅에 사진과 글을 올리며 좋아하고 있습니다. 저와 페이스북 친구라서, 연결된 많은 글들과 링크들을 보며 “아.. 나는 끼면 안 되겠다..”라는 생각을 했다네요. 벌써 연예인병이… >_< 좀더 학년이 올라가고, 성장하면 연성체 때문에 더 즐거운 날들이 되지 않을까 생각합니다.물론 저와 제 아내도 함께 재밌는 날들이 될 것 같습니다. 이 자리를 빌어 감사드리고 싶네요. 고맙습니다.",http://woowabros.github.io/woowabros/2016/10/10/font_yeonsung.html,woowabros,,NULL,2016-10-10
9X년생 개발자 모임 참석 후기,"9X년생 개발자 모임 5회차 참석 후기입니다 :)이번 9X년생 개발자 모임1은 우아한형제들에서 진행이 되어 한 번도 참여해본 적 없던 저도 참석하는 행운을 누렸습니다.  모임은 우아한형제들 키친에서 7시에 개최되는 것이었습니다.  모임 30분 전인 6시 30분경부터 기념품이 준비된 데스크를 통해 우아한형제들 키친으로  참석자분들이 입장을 시작하셨는데 한결같이 약간 설레는 표정들이었습니다. 한 명 두 명 점차 사람들이 모이기 시작했는데 거의 서로가 초면이어서 조금 어색하던 차에,  모임 스태프분들이 아이스 브레이크 겸 가까이 앉은 사람들끼리 인사를 나누라고 하셨습니다.  얼굴을 마주 보며 미소로 인사를 나누다 보니 어느결에 어색한 분위기는 사라지고  도란도란 이야기 나누는 소리가 우아한형제들 키친에 가득 찼습니다.준비된 피자와 치킨을 챙기라는 사회자의 말에 음식과 함께 맥주와 음료수도 챙기기 위해 분주히 움직였습니다. 맥주라는 말에 참석자 분들의 얼굴에 웃음꽃이 핀 것 같은 느낌은 제 마음 탓이었을까요? :) (맥주 맥주 !) 허기진 배를 조금 채운 후 자기소개를 하며 서로에 대해 알아갔습니다. 90년대생 개발자 모임이라 그런지 학생분들도 많이 참여했는데  특히 미성년자분은 90년대 초 태생인 저에게는 부러움의 대상이었습니다. (어리시다니…!)갓 입사한 신입, 이게 내 길일까 고민하는 컴공 학생, 현업에서 달리는 개발자들이  함께 나눌 수 있는 이야기를 가지고 모이는 자리이어서 뜻깊었습니다.  90년대생 개발자 모임은 같은 또래에게 자극을 받으며 더 성장할 수 있는 좋은 기회의 장이 될 수 있는 곳 같습니다.저녁 식사 후 참석한 인원 전부가 돌아가며 15초간 자기소개를 했는데  그 많은 인원이 15초라는 짧은 시간에 자기소개를 하는 거였는데도 꽤 기억에 남는 사람들이 많을 만큼 재밌었습니다. :)그 후 다음 세션으로는 발표자분들이 한 분 한 분 발표를 했습니다.  사내 벤처에서 정규팀까지 서비스 개발기 (우 태균님) – VOLO 서비스 개발기  세 명이 함께 시작한 VOLO 서비스 개발기. 회사에서 살다시피 했던 험난한 우여곡절이 담긴 개발기를 공유해주셨습니다.  듣고만 있어도 처음 개발 당시의 시행착오를 극복해가며 고생 많이 하신 것을 느낄 수 있었는데  결국 끝까지 해내시어 정규팀까지 이루게 된 좋은 발표였습니다. 만약 저였더라면 어찌하였을지 생각하게 하는 발표였습니다. 디자이너의 코딩 도전기 (박 혜정 님)  시작은 UI 디자이너지만 파이썬도 공부하고 뭐든 열심히 배우고 알아가는 도전기를 공유해주셨습니다.  배포까지 하신 대단하신 분! 일일 커밋을 꾸준히 하고 계시다네요!  발표를 보며 정말 많은 자극이 되었고 더 열심히 공부하고 배워야겠다는 생각을 갖게 해주셨습니다.  일일 커밋 정말 쉽지 않은 건데… 더 분발해야겠네요 ㅎㅎ  잘은 몰라도 Java to Kotlin (이 강산 님)  웹 개발할 때에는 웹 소스를 분석하고, 앱 개발 시에는 앱 소스를 분석하시면서 사수 없이 혼자 개발하셨다던 발표자님.  롬복을 쓰고 싶지 않아서 코틀린을 시작하셨다던데 간단한 코틀린 비교 예제와 함께 코틀린 스터디를 대 모집하셨습니다.  들으면서 코틀린을 스터디하고 싶어지게 만드는 발표였습니다.  중간에 발표가 잠시 끊기는 일이 있었지만 언제 끊김이 있었냐는 듯 쉬운 설명과 흐름으로 잘 이해할 수 있었습니다.  O2O 서비스에서의 소프트웨어 이야기 (차 용빈 님)  스타트업에서 개발하는 한 개발자의 이야기를 발표해주셨습니다.  O2O회사를 다니면서 어려웠던 점들 등 직접 체험하신 현실적인 이야기들을 공유해주셨습니다. 발표자분들 중 한 분은 오시다가 등이 찢어지셔서 못오시게 되셨다 하여 총 네 분이 발표를 하셨습니다. (괜찮으신가 모르겠네요)흥미롭고 다채로운 주제들로 인하여 즐거웠던 발표 이후에는 네트워킹 타임을 가졌는데  자기소개 시간 때 관심이 가는 사람들이나 새로운 사람들과 네트워킹을 하러 다들 자리를 이동했습니다.  같은 길을 가고 있고 또 가고자 하는 90년대생들의 스스럼없는 적극적인 모습이 너무 보기가 좋았습니다.  초면이어서 어색할 수도 있었음에도 모두가 적극적으로 서로에 대해 알아가고 관심 분야를 얘기하는 유익한 시간이었습니다.   네트워킹 시간이 끝난 후 기념품 외에도 예측 블가능한 질문들을 통해 많은 상품들을 받을 수 있었습니다.  정말 9X년생들답게 경품이 걸린 톡톡 튀는 여러 질문들이 나와서 즐거운 분위기가 더욱 고조되었습니다.  그중 기억에 남는 질문들 몇 개를 공유하겠습니다. 시간이 어떻게 흘러가는지도 모르게 빠르게 흘러 어느새 모임이 끝나고 돌아갈 시간이 되었는데  많은 분들이 자신이 앉은 자리를 정리해주시고 가시는 모습에 깊은 인상을 받았습니다. (덕분에 뒷정리를 금방 할 수 있었습니다 감사합니다 :) !! ) 한 번이라도 참여하면 계속 참여하고 싶어진다며 입에 침이 마르게 칭찬하고 간증하는 9XD라고 들었는데 정말 그 이유를 알 수 있는 좋은 시간이었습니다. 같은 분야에서 다양한 경험들을 공유할 수 있는 좋은 사람들을 알게되고  그 사람들에게서 많은 자극을 받을 수 있는 유익한 시간을 갖게 해주셔서 감사합니다. 다음 모임에도 꼭 참석하고 싶네요 :) !9X년생 개발자 모임이 공식명칭입니다. ↩",http://woowabros.github.io/experience/2016/09/26/9XDconf.html,woowabros,,NULL,2016-09-26
다 때가 있다 - 우아한형제들 개발자 모집,"우아한형제들에서 같이 일하고 함께 성장할 개발자분들을 모십니다.우아한형제들에서 같이 일하실 개발자들을 모집합니다. 이번 모집은 서버 개발자, 모바일 개발자, 프론트엔드 개발자, 보안 엔지니어, 네트워크 엔지니어 등 여러 직무에 걸쳐서 진행됩니다. 각 직무의 채용 공고는 우아한형제들의 채용 공고 페이지에서 보실 수 있으며, 바로 아래에도 편하게 보실 수 있도록 기재해 놓았습니다.제가 이 회사에 합류한 지, 만 1년이 조금 더 되는 시간이 지났는데요. 공식적인 채널로 개발자 분들을 대규모로 채용한다고 알리는 것은 처음인 것 같습니다. 작년 9월에 회사에 합류한 후, 석 달 정도는 적극적인 리쿠르팅 활동을 하지 않고 기존의 업무/프로세스/조직/사람을 이해하는데 시간을 많이 쏟았고, 석 달이 지난 12월부터 제가 원래 알던 분들, 그리고 소개 받은 분들을 중심으로 한 분 한 분 만나서 리쿠르팅을 진행해 왔었습니다.이 과정에서 계속 염두에 두었던 것은, 우아한형제들이 함께 성장할 수 있는 조직이 되기를 원했고, 조직에서 같이 일하는 분들이 함께 성장하는 것을 중요하게 생각하는 분들로 구성되어야 한다는 것입니다.이것은 새로 합류하는 사람들만의 힘으로 되는 것도 아니고, 원래 있던 사람들만의 힘으로 되는 것도 아니고, 모두가 같이 어울려서 같은 의지를 갖고 행동하면서 다시 좀 더 강한 믿음이 생겨날 때, 그리고 그 믿음이 다시 행동으로 이어지면서 선순환을 이룰 때 가능하다고 생각했습니다.리쿠르팅이 진행되고 조직의 변화가 본격적으로 시작된 3월부터 약 반 년이 지난 지금. 이제는 조금 더 많은 분들을 대상으로 함께 성장하고 싶은 분을 모신다고 좀 더 큰 목소리로 말할 수 있을 것 같아서 이렇게 구인의 글을 쓰게 되었습니다.리쿠르트 초기에는 주로 시니어 개발자 분들을 많이 만났는데요. 그 분들에게 제가 했던 얘기는 다음과 같습니다.시니어 개발자의 역량이라는 것은 그 사람이 갖고 있는 지식과 경험의 양으로만 볼 수 없다고 생각한다. 그리고 시니어 개발자의 성과라는 것 또한 그 사람 개인이 작성한 코드의 양과 질로만 평가할 수 있는 것은 아니라고 생각한다. 제가 생각하는 좋은 시니어 개발자는 다음과 같은 것을 할 수 있어야 한다. 위와 같은 과정을 실제로 겪었고, 그 경험을 통해서 다시 같은 경험을 반복하여 만들어낼 수 있는 사람이야말로 정말 훌륭한 시니어 개발자라고 볼 수 있다고 얘기를 했고, 이런 점에서 시니어 개발자들에게 가장 필요한 사람은 본인이 어떤 얘기를 했을 때 그것에 대해 진심으로 열려 있는 자세로 듣고 같이 동참할 수 있는 동료 개발자라는 얘기를 했습니다.우아한형제들의 Baby Steps라는 글에서도 얘기를 한 바 있지만, 우아한형제들은 이런 부분에서 개발자와 비개발자를 막론하고 서로의 얘기에 귀기울여주고, 달을 가리키면 손가락을 얘기하지 않고 그것이 가리키는 달에 대해서 얘기할 수 있는 문화를 가지고 있었습니다.그래서 자신있게 얘기를 했죠. “시니어 개발자의 성장이라는 것은, 결국 본인이 얼마나 잘 하느냐가 아니라 제가 방금 얘기했던 변화와 성과를 이끌어낸 경험이 있느냐이고, 그 경험을 실제로 만들어볼 수 있는 곳이라고 생각한다. 이런 점에서, 우아한형제들에서 일을 하는 것이 본인한테도 성장의 기회가 될 수 있다고 믿는다.”다른 사람을 돕는 것보다 본인 성과를 내는데만 집중하고, 그를 바탕으로 연봉과는 별개로 지급되는 많은 인센티브를 바라는 분은 사양합니다. 우아한형제들은 성과 평가에 의한 인센티브 제도 자체가 없습니다. 우아한형제들이 원하는 분은, 본인이 가진 좋은 지식과 경험을 기꺼이 나누고, 같이 일하는 사람들이 긍정적인 방향으로 변화하여, 그를 통해 성과를 만드는 것에서 즐거움을 느끼는 분. 이 과정에서 본인의 성장을 느낄 수 있는 분을 원합니다. [작년에 진행된 개발인턴 모집 공고 이미지]리쿠르팅 초기에는 주로 시니어 개발자 분들 위주로 만났지만, 시간이 지나면서는 꼭 시니어 개발자뿐 아니라 5년차 이하의 개발자 분들도 많이 만나게 되었습니다. 이 분들께는 우아한형제들에 합류한다는 것이 어떤 의미가 있을까 곰곰이 생각해 보았죠. 주니어 개발자 분들에게 중요한 것은 두 가지라고 생각했습니다.경험이라고 하는 것은 얼마나 많은 것을 보고 듣느냐 하는 것도 있겠지만, 실제로 일을 하면서 다양한 것들을 직접 겪어보는 것을 얘기합니다. 이런 점에서는 이미 많은 부분들이 성숙되어 있는 회사도 좋은 선택이지만, 아직은 미진한 부분이 많지만 확실한 의지로 개선안을 만들고 적용하는 과정을 겪는 것이 가장 좋은 경험이라고 생각합니다.이슈 관리를 어떻게 하는지 모르다가, 간단한 티켓을 만들어서 이슈 관리를 할 수 있게 되고, 거기서 좀 더 발달하여 Scrum Board와 Kanban Board를 쓸 수 있게 되고… 이런 변화의 과정에서 왜 그런 선택을 했는지, 어떤 경우에 선택을 다시 바꾸고 다른 선택을 하는지 등을 직접 보면서 배울 수 있다면 더 좋지 않을까요? 말로는 변화할 거라고 얘기하지만 변화하지 않는 조직은 정말 최악이지만, 다행히 우아한형제들은 이런 변화의 과정을 잘 밟아 나가고 있는 것 같습니다.그리고 개발과 관련된 논의를 편하게 진행할 수 있다는 것은, 개발 조직에서는 너무나 당연한 것으로, 어떤 이슈에 대해 논의할 때 경험의 많고 적음과 관계 없이 자신의 의견을 얘기할 수 있고 좀 더 바람직한 안이 무엇인지에 대해서 같이 논의한다는 것입니다. 모든 의견이 논의 끝에 하나의 결론으로 모아지면 좋겠지만, 때때로 기술적인 주제임에도 선택의 영역으로 남겨지는 이슈들이 있고, 그 경우에는 해당 이슈에 대해 책임지고 의사 결정을 하는 사람이 있겠죠(당연히 있어야만 하고).하지만 그 결정이 내려지기 전까지 논의를 하는 단계에서는 의견을 자유롭게 얘기할 수 있어야, 논의 과정에서 (설혹 틀린 의견이었더라도) 좀 더 배울 수 있고 그를 통해 성장할 수 있다고 생각합니다.우아한형제들에 오면 모든 것이 잘 갖춰져 있어서, 나는 그냥 회사에서 시키는 대로 일만 하면 잘 배우게되겠지… 라고 생각하시는 분이라면 사양합니다. 이 조직은, Baby Steps라는 단어와 같이 이제 첫 걸음을 떼고 있고 주니어 개발자라도 그 과정에 같이 동참해야 합니다. 물론 옆에 많은 동료들이 있을 겁니다. 본인이 동참할수록 더 많은 것을 배울 수 있습니다. 수동적인 배움이 아니라 적극적인 참여를 통해 배우는 분, 그리고 틀리더라도 그것을 부끄러워하는 것이 아니라 몰라서 가만히 있는 것을 부끄러워하는 분. 적극적으로 부딪혀서 본인의 성장을 하고 싶은 분을 원합니다.제가 합류하고 1년 3주가 지난 지금. 이 시간 동안 배달의민족은 앱 내에서의 주문이 세 배 가까이 성장하고, 배민라이더스는 십수배 이상 주문이 늘어났으며, 배민프레시도 열 배 이상 성장하고 있습니다. 이 말씀을 드리는 이유는, 개인이 성장을 하는 데 있어서 중요한 요소 중 하나가 본인이 일하고 있는 조직/서비스의 성장이 큰 영향을 끼친다고 생각하기 때문입니다.우아한형제들의 사업 분야는 Food e-Commerce 입니다. 우리나라의 Commerce 시장은 오픈마켓 서비스와(예: 11번가) 소셜커머스라고 불리웠던 서비스들의(예: 쿠팡) 경계가 무너지면서 치열하게 경쟁을 하고 있는데요. 우아한형제들은 “좋은 음식을 먹고 싶은 곳에서”라는 비전 하에, 음식이라는 카테고리에서 No.1 e-Commerce 사업자가 되겠다는 목표를 갖고 있습니다.모바일 시대가 오기 전에는 음식이라는 카테고리가 e-Commerce 안에 생긴다는 것이 어색했는데요. 지금은 우리 주변에서 꽤 많은 사람들이 물과 같은 음료수 외에도, 여러 음식들을 주문하는 것을 볼 수 있습니다. 지금이야 이 비중이 낮아 보이지만, 현재 인터넷 쇼핑의 킬러 카테고리로 자리 잡은 패션 카테고리도 처음 나왔을 때는 누가 인터넷으로 옷을 사 입겠냐고 평가를 했었습니다. :-)배달의민족 서비스를 얼핏 보면 배달음식에 대한 주문 중개 서비스로 보이지만, 그 구조를 가만히 살펴 보면, 오픈마켓처럼 여러 음식점들이 셀러로 등록해 있고, 고객은 그 중에서 상품(음식)을 골라서 주문하면 바로 배송해 주는 전형적인 e-Commerce 사업 모델을 가지고 있습니다. 배민라이더스는, 배달을 하지 않던 맛집의 음식들도 고객이 즐길 수 있도록, 주문과 함께 배달 기능까지 직접 제공하는 서비스인 거죠. 그리고 배민프레시는 이미 익숙한 쇼핑사이트 형태 그대로 음식을 판매하고 있습니다.올해 배달의민족을 통해 거래되는 금액은 약 2조 정도가 될 것으로 예상하고 있고, 배민라이더스, 배민프레시까지 합하면 그 규모는 더욱 커질 것입니다. 쿠팡의 2016년 상반기 거래액이 1조 8천억이니, 하반기 늘어나는 것을 감안하면 연간 거래액이 4조 정도라고 할 때 배달의민족 서비스만으로 거래액 규모는 쿠팡의 50% 정도 수준에 육박합니다.음식이라는 영역에만 한정되어 거래액 규모가 크지 않을 것 같았는데, 쿠팡의 50% 라면 굉장히 큰 거래 규모를 갖고 있는 시장입니다. 그리고 더욱 고무적인 것은 음식이라는 영역은 앞으로 e-Commerce로의 전환률이 더 올라갈 부분이 많이 있다는 사실입니다. 심지어 한국의 Food e-Commerce 시장은 미국에 비해서도 작지 않은데요. 음식이라는 특성상 대도시 중심으로 거래가 이뤄지게 되는데, 한국의 10대 도시 인구와 미국의 10대 도시 인구를 비교해 보면 양쪽 모두 2천 5백만명 이상으로 거의 비슷한 수치가 나옵니다. 물론 객단가를 고려하면, 인구수가 비슷하더라도 시장의 규모는 미국이 더 크긴 하겠지만요.1인 가구, 맞벌이 부부가 많아지는 사회의 변화가 맞물려서, Food e-Commerce 시장의 전체 규모는 한동안은 계속 확대될 거라고 생각합니다. 우아한형제들은 이 시장을 바라보고 있고, 현재 No.1 사업자로서 확실한 위치를 차지하고 있으며, 앞으로 다양한 형태로 나타나게 될 Food e-Commerce 시장에서 여러 가지 시도를 계속하고 있습니다. 배민쿡도 그러한 시도 중 하나고요.함께 성장한다는 것이 뭘까요? 여러 관점에서 다양한 의견이 나올 수 있을 것 같습니다.개발 조직 내를 살펴 보면, 3월부터 8월까지 21개의 주제로, 총 24번의 세미나가 있었습니다. 2~3개 정도는 어떤 일이 일단락되었을 때 그 경험을 공유하기 위한 세미나였고, 거의 대부분은 각자 일을 하면서 공부를 하면서 익히고 정리했던 내용들을 자발적으로 공유하는 세미나였습니다. 세미나 뿐 아니라, 이 블로그에는 공유되지 않았지만 내부 위키에서 경험을 공유하는 글들은 90개 정도가 쓰여졌습니다. 이처럼 함께 성장한다는 것은, 본인의 경험을 나누는 것부터가 출발이라고 생각하는데요.우아한형제들은 여기서 좀 더 확장하고자 합니다.가장 널리 알려진 것은, 이미 많은 분들이 사용하시는 한나체/주아체/도현체의 폰트를 공개한 것으로, 이 폰트는 개인 및 기업 사용자를 포함한 모든 사용자에게 무료로 제공되며 자유롭게 수정, 재배포가 가능합니다.이 폰트는 디자인실에서 만든 것을 배포한 것인데, 우아한형제들의 개발 조직은 그에 맞는 방식으로 저희가 익히고 만든 것을 나누고자 합니다.그 첫 번째가 얼마 전 이 블로그를 통해서 밝힌, WoowahanJS를 오픈소스화하여 공유하는 것입니다. 내부 비즈니스 로직이 있는 코드는 공유가 힘들겠지만, 그렇지 않고 독립적으로 모듈화하여 사용할 수 있는 부분들은 운영 부담이 크지 않은 선에서 같이 나눌 수 있는 방법을 계속 고민할 생각입니다. 꼭 코드가 아니더라도, 아주 작은 나눔이지만, 소프트웨어 팀을 위한 Confluence 활용 가이드 문서의 번역본도 공유한 바 있습니다.우아한형제들은, 아직은, 정말 뛰어난 개발 조직은 아닙니다. 하지만 변화하고 발전하고 싶은 의지와 그것을 실행으로 옮길 수 있는 환경은 어느 회사에도 뒤지지 않는다고 생각합니다. 아직 덜 갖추어져 있지만, 그래서 더 많은 것을 기여할 수 있는, 그래서 더 많은 것을 배울 수 있는 조직이라고 생각합니다.함께 성장하는 기쁨을 느끼고 싶습니다. 그 기쁨을 나누고 싶습니다. 우아한형제들의 어떤 팀에서 어떻게 코드 리뷰를 하는지, 어떤 툴을 사용하는지보다 더 중요하게 말씀 드리고 싶은 것은, 현재 우리가 무엇을 하고 있느냐보다 앞으로 우리가 어떻게 발전할 지를 같이 논의하고 실천할 분들과 이러한 것들을 같이 만들어가고 싶다는 것입니다.많은 좋은 회사들이 있습니다. 바라보는 관점에 따라 우아한형제들이 현 시점에서 최고의 회사는 아니라고 생각하실 수 있습니다. 하지만 우아한형제들이 바라보는 시장, 그 시장 내에서의 현재 위치, 그리고 앞으로 추진/변화하려는 의지는 최고를 바라보고 있습니다. 최고를 향해 가는 여정을 통해 같이 성장하고 싶은 분이라면 그런 분과 같이 일하고 싶습니다.관심 있으신 분들은 채용 공고 페이지를 통해서 지원 부탁 드립니다.",http://woowabros.github.io/woowabros/2016/09/22/all_in_good_time.html,woowabros,,NULL,2016-09-22
[공유] 소프트웨어 팀을 위한 컨플루언스 가이드,"컨플루언스를 좀 더 효과적으로 활용할 수 있는 방안을 정리한 문서를 공유합니다.제가 6월에 우아한형제들의 Baby Steps 라는 글을 쓸 때, Confluence(위키)를 도입한 과정에 대해서 간단히 적은 바 있습니다. 그 때 적은 글을 다시 발췌하면…무엇부터 접근해야 할까 고민하며 살펴 보니, 회사가 바로 제가 입사하기 한 두 달 전에 Confluence와 JIRA를 도입했더군요. 하지만 Confluence는 텅텅 비어 있는 상태. (두둥!)Confluence라는 Tool 은 사실 개발 조직만 써서는 효과가 안 나고, 전사적으로 문서가 모이고 공유되어야 효과가 있는데요. Wiki를 처음 접하는 분들에게는 사용하기 어려운 부분이 있습니다. 그래서 제가 Admin 권한을 획득한 후에 RefinedWiki라는 플러그인을 구매한 후, 사람들에게 익숙한 계층 구조를 만들고, 저도 이해할겸 “배민서비스의 이해”라는 페이지를 만들어 컨텐츠를 만들어 제공하면서 조금씩 활성화를 시켜 나갔습니다. [Confluence에 RefinedWiki Theme을 적용한 예]이 과정에서 제가 놀랐던 것은, 지금까지 겪었던 어떤 조직보다도 빠르게 변화를 받아 들이고, 그것에 익숙해지고 난 후 바로 옆 사람과 옆 조직에 빠르게 전파가 되었다는 점입니다. 일을 더 잘 하고 싶은 마음, 더 가치 있는 일을 하고 싶은 마음이 가득했고, 밀려 오는 파도를 두려워하지 않고 오히려 몸을 맡기는 서퍼처럼, 이러한 변화의 물결을 피해서 도망가는 것이 아니라 그 물결 위에 올라타는 모습들을 보았습니다.그 결과로 지금은 Confluence를 이용한 문서화 수준을 넘어서, 각 프로젝트마다 특성에 맞게 Scrum 또는 Kanban Board를 만들고, 업무들의 진행 상황을 같이 살펴 보고 논의하며 일을 하고 있습니다.위에서 간단히 언급한 RefinedWiki라는 플러그인 외에도, 위키를 좀 더 효과적으로 사용하기 위한 고민을 하다가 Atlassian에서 만든 Software Team’s Guide to Confluence 문서를 발견했는데요. 해당 문서에는 다음과 같은 내용들이 있었습니다. 대부분의 기술 문서들이 솔루션이나 서비스의 개별 기능을 사용하는 법을 설명하고 있는 것에 반해, 이 문서는 컨플루언스를 활용하여 우리가 무엇을 할 수 있는지, 또 반대로 우리가 일상적으로 만들고 정리해야 하는 문서를 컨플루언스를 이용하면 어떻게 편하게 할 수 있는지를 설명하고 있습니다. 문서의 내용을 읽으면서 회사의 상황에 맞게 조금씩 바꾸어야 할 부분은 많겠지만, 각 회사에서 한 번쯤 고민해봤을 법한 문서화와 관련된 문제들을 어떤 식으로 접근하고 해결하는지를 살펴 볼 수 있다는 점에서, 그대로 적용하지 않더라도 배울 부분이 있다고 생각합니다.좋은 문서라고 생각해서 Google Drive에 올리고 전사 메일로 공유했는데… 그리고 몇 주가 지나서 사람들과 얘기를 해 보니 역시나 가장 큰 난관은 영어의 압박. ^^;아무리 좋은 지식이라도 일단 받아 들이는 단계에서부터 난관이 있다보니 전사적으로 살펴 본 분들은 극히 적더라고요. 그래서 해당 문서를 번역하게 되었습니다. 그 결과물이 바로 소프트웨어 팀을 위한 컨플루언스 가이드 문서입니다. 이 문서가 번역된 지 벌써 반 년이 지났는데요. 아직 우아한형제들도 이 문서에서 정리된 내용을 그대로 적용하고 있지 않습니다. 각 팀과 프로젝트의 상황에 맞게 적절한 형태로 변형하여 사용하고 있고요. 어떤 부분은 이제 제대로 정리를 해 보려고 생각 중인 것도 있습니다. 예를 들면 새로운 개발자 분이 입사했을 때의 On-boarding 문서와 같은 것들이죠.최근에 On-boarding 문서를 다시 만드는 과정 중에 다시 이 문서의 존재가 생각이 났는데요. 위에서도 말씀 드렸다시피, 해당 문서는 이미 영어로 잘 정리가 되어 나와 있는 문서인지라 이 문서의 내용 자체가 특정 회사의 차별적인 노하우나 그런 것들이 될 수는 없다고 봅니다.그래서 이 문서를 비슷한 고민을 하시는 다른 분들과도 나누는 것이 더 좋겠다고 생각을 했습니다. 생각이 난 김에 Atlassian 측에 번역한 문서를 공유해도 될 지 문의를 했고, 원문 내용이 변경되지 않은 단순 번역이고, 이 내용이 다시 또 변경되어 재배포가 되지 않는다면 기술 블로그를 통해 공개가 되어도 괜찮다는 의견을 받았습니다.한 번 더 번역본의 링크를 공유 드리면 다음과 같습니다. 비슷한 고민을 하시는 분들께 도움이 되면 좋겠습니다. ",http://woowabros.github.io/woowabros/2016/09/13/confluence_guide.html,woowabros,java,NULL,2016-09-13
"우아한, WoowahanJS","사람들이 행복해하는 소프트웨어를 만드는 프로그래머가 되는 것을 목표로 살아가는 아들 바보 프로그래머. 우아한형제들에서 웹 프런트앤드 프레임워크, 서비스, 제품 등을 만들고 있습니다.아마도, 많은 웹 프론트앤드 개발 조직은 나름의 자체 프레임워크이 있을 것입니다. 우아한형제들의 웹 프론트앤드 팀에서도 나름의 필요에 의해 자바스크립트 프레임워크를 만들어 사용하고 있습니다. 오픈소스 프레임워크인 BackboneJS 기반의 WoowahanJS를 오픈소스로 공개하며 어떤 문제를 해결하기 위해 만든 제품인지 생각을 나누고 공유해 보려 합니다.React, Angular, Backbone, Ember 등 범용적이고 활발한 커뮤니티를 보유한 많은 프레임워크가 있습니다. 대부분의 경우 나열된 것 중 하나를 선택하여 문제없이 웹앱을 개발할 수 있습니다. 그러나 실무에선 다양한 문제가 발생하기도 합니다. 심각하다고 생각하는 몇 가지 문제는 다음과 같습니다.이 문제는 가장 큰 현실적인 문제입니다.제가 경험했던 개발팀들은 대규모 웹 애플리케이션 개발을 함에 있어 충분한 경험과 기술력을 가진 시니어가 부족했습니다. 비교적 작은 규모에선 문제가 드러나지 않지만 코드 베이스가 커지면 티 나지 않았던 문제가 극복할 수 없는 심각한 문제로 확대 대기도 합니다. 우아한형제들은 다양한 서비스를 개발하고 있고 수많은 B2B, B2C용의 많은 웹앱을 개발하고 있으나 모든 프로젝트에 충분히 숙련된 프론트앤드 개발자가 투입되기는 현실적인 어려움이 있었습니다.유명한 프레임워크를 도입한다 해서 이 문제가 사리지지는 않습니다. 프레임워크의 형태에 따라 더 큰 설계 역량이 필요하기도 합니다. React 같은 경우 뷰의 랜더링 부분만을 담당하는 작은 라이브러리처럼 보이지만 규모가 커질 경우 뷰 컴포넌트의 설계가 견고하지 못하면 고통스러운 경험을 할 수 있습니다. 이는 어떤 프레임워크라 하더라도 완전히 해결되기는 어려운 문제라 생각합니다.대부분의 프로그래머는 최신 기술을 도입하고 사용해 보는 것에 대한 욕망이 있고, 있어야만 한다고 생각합니다. 때론 그 욕망이 너무 과한 나머지 만들어야 하는 서비스나 제품의 상황과 맞지 않는 적정 기술 도입에 실패하곤 합니다. 노련한 프로그래머라면 욕망과 현실의 제약 조건 사이에서 적절한 타협점을 찾을 수 있어야 합니다.SPA - Single Page Application - 형태의 웹앱이 웹앱 생태계를 주도하면서 HTML을 데이터와 결합하는 방식에 대한 많은 방법이 제시되어 왔습니다. 안타깝게도 그러한 결합 방법들은 Javascript 코드로 다루기 유리한 형태로 발전되어 왔습니다. 프론트앤드 템플릿 엔진의 도입, 비표준 태그의 사용, data-* 를 기반으로 한 방식은 물론, 최근에 React를 중심으로 Virtual-DOM 으로까지 이르렀습니다. 새로운 방법들이 제안될수록 아이러니하게도 퍼블리셔와의 협업은 더욱더 어려워지고 있습니다. 최종 결과가 될 HTML과의 형태적 괴리감은 커지고 결합도를 예측하기 힘들 정도로 뷰는 작은 조각으로 파편화될 수 있습니다. 이런 경향은 과연 올바른 것일까요? 여러분의 프로젝트는 이 문제를 어떻게 해결하고 계신가요?커뮤니티가 충분히 성숙한 프레임워크라 해도 해결하기 힘든 문제는 언제나 발생하기 마련입니다. 프레임워크 자체의 버그일 수 도 있고, 개발된 애플리케이션의 버그일 수 도 있습니다. 다양한 서드파트 라이브러리와의 종속성 문제일 수 도 있고 문제는 다양하게 발생합니다. 이런 문제를 극복하기 위해 사용하는 프레임워크의 학습 숙련도는 매우 중요합니다. 대부분의 경우 사용자 수준의 학습 비용을 치르고 개발을 하게 됩니다. 정신없이 진행되는 개발 일정 속에서 원인이 불명확한 이슈 발생은 개발자를 괴롭힐 수 있습니다. 팀 내에 사용중인 프레임워크의 코드 분석이 가능한 멤버가 없다면 적절한 이슈 대응에 실패하여 프로젝트 진행에 심각한 타격을 주기도 합니다.조직마다 상황에 따라 다양한 해결책을 찾을 수 있을 겁니다. 우아한형제들은 자체 프레임워크를 만드는 방법을 선택했습니다. 프레임워크를 만듦에 있어 주요 테마는 협업과 생산성 이었습니다.현재도 그렇지만 개발 초기에 빠르게 형태를 잡기 위해 Backbone 기반으로 작성되었으며, 현재 버전은 0.1.5이며 Backbone의 흔적은 초기와 다르게 상당히 희석된 형태를 유지하고 있습니다.향후 Backbone 종속성을 완전히 제거할 계획도 가지고 있습니다.자, 이제 WoowahaJS를 소개해보도록 하겠습니다.이 글 내에 등장하는 모든 예제는 편의를 위해 Webpack, ES2015 환경을 전제로합니다.Woowahan 어플리케이션 인스턴스를(app) 생성한 후 app.start() 메소드를 호출하여 어플리케이션을 시작합니다. app.start() 메소드는 인자로 라우팅을 기술한 객체를 받습니다. 라우팅 객체는 라우팅을 경로와 연결될 뷰 컴포넌트의 바인딩을 처리하고 적절한 순간에 뷰를 로딩하고 제거하는 역할을 수행합니다. 대개의 경우 웹앱은 하나 이상의 페이지로 구성되기 때문에 라이팅 객체 역시 계층적 구조로 기술될 수 있습니다.WoowahaJS의 모든 View 컴포넌트는 Woowahan.View.creat()로 생성됩니다. 가장 간단한 뷰 컴포넌트는 다음과 같습니다.뷰는 뷰 이름과 뷰 내용을 기술한 객체로 구성됩니다. 뷰 객체는 HTML 템플릿 역할을 하는 template 키를 최소 요건으로 구성됩니다.웹앱을 구성하는 기본 구성 요소인 뷰 컴포넌트는 결국 데이타를 결합한 HTML로 랜더링되게 됩니다. 이를 위해 WoowahanJS는 React 컴포넌트의 라이프 사이클과 유사한 라이프 사이클을 제공하며 다음과 같은 순서로 실행됩니다.HTML을 랜더링하기 전 호출됩니다. 인수로 HTML과 결합할 renderData 객체가 전달되며 랜더링 되기 전 데이타를 변경하거나 새로운 데이타를 주입시킬 수 있습니다. 변경된 renderData 를 return 함으로서 Template에 데이타를 전달할 수 있습니다.HTML을 랜더링하고 DOM에 마운트한 후 호출됩니다. DOM에 마운트된 다음 수행할 처리가 있다면 viewDidMount에서 할 수 있습니다. 인수로 전달되는 $el 객체는 랜더링된 DOM의 최상위 엘리먼트를 참조하고 있는 jQuery 객체입니다.뷰가 제거되기 전에 호출됩니다. 이벤트 리스너를 제거하거나 삭제될 컴포넌트가 있다면 이곳에서 기술할 수 있습니다.뷰의 UI 요소와 이벤트 리스너를 연결하기 위해 events를 기술할 수 있습니다. events 기술 방법은 Backbone의 방식 그대로 사용하고 있습니다.Backbone 이벤트와는 다른 이벤트를 제공합니다. @ 이벤트라 부르는 형식이며 위 예제의 onSearch 함수가 @ 이벤트입니다. @ 이벤트는 이벤트와 리스너를 연결할 때 리스너에 기술된 DOM 셀렉터의 값을 추출하여 리서너 함수에 인수로서 전달합니다. FORM의 Submit 처리나 검색 버튼 클릭시 하나 이상의 검색 옵션을 리스너에 전달하게 되는 경우가 많습니다. 이 때 뷰 코드에서 반복적인 DOM 접근 처리를 제거하기 위한 방법으로 @ 이벤트를 제공하고 있습니다.모든 뷰는 자식 뷰를 몇개라도 소유할 수 있습니다. 자식 뷰를 추가하기 위한 addView() 와 자식 뷰를 업데이트하기 위한 updateView를 제공합니다. 두 메소드 모두 첫 번째 인수는 자식 뷰가 추가될 컨테이너의 셀렉터 문자열 입니다. 두 번째 인수는 뷰 컴포넌트이며, updateView인 경우 세번째 인수로 데이타를 기입하여 뷰에 전달할 수 있습니다. 자식 뷰는 보모 뷰가 제거될 때 자동으로 제거되며 중첩된 깊은 뷰의 계층 구조를 가지고 있다 해도 정확히 동작합니다.WoowahanJS는 뷰와 데이타 처리(API 연동) 로직을 완전히 격리한 후 Action을 기반으로 느슨하게 연결된 아키텍처를 제공합니다. 이런 구조는 네트워크 처리 등 뷰와 관계없는 코드를 뷰와 분리함으로서 뷰의 코드를 가볍게 유지할 수 있도록 합니다. 기본 아이디어는 Redux 및 Flux 아키텍처와 유사합니다.Action은 특정 작업을 시작하게하는 “키”로서 정의되며 Reducer와 1:1 관계를 가집니다. Action을 Reducer에 전달하기 위해서 dispatch를 제공하며 어떤 View에서도 호출할 수 있습니다.액션을 쉽게 만들 수 있는 Action Creator 유틸리티를 제공합니다. dispatch에 전달된 액션 객체를 직접 기술할 수도 있으나 Action Creator를 사용하면 좀 더 편리합니다.모든 뷰는 dispatch를 제공합니다. dispatch로 액션을 보낼 수 있으며 액션의 수행 결과는 지정한 핸들러를 통해 받을 수 있습니다. 핸들러가 없는 액션이 있을 수도 있기 때문에 핸들러는 옵션입니다. 다음과 같이 사용할 수 있습니다.Reducer Creator로 리듀서를 만들 수 있습니다. WoowahanJS에서 리듀서의 역할은 약속된 액션의 작업을 처리하는 작업 처리자입니다. 웹 어플리케이션에서 작업 처리자가 처리해야할 주된 작업 중 하나는 API 호출과 관련되어있습니다. Ajax로 대변되는 XHR 처리는 리듀서가 담당하며 보다 효과적인 처리를 위해 몇 가지 헬퍼 함수가 제공됩니다. 사용자 정보 API를 호출한 후 결과를 반환하는 전형적인 코드는 다음과 같습니다.getData는 GET XHR 요청을 보내는 함수이며 첫 번째 인자로 URL을 받습니다. HTTP 메소드 타입에 대응하는 postData, putData, deleteData가 제공됩니다. XHR 요청이 완료되면 this.onSuccess로 결과 값이 반환됩니다. 응답 처리를 위해 onSuccess 구현은 필수 요소입니다.리듀서의 처리 결과를 dispatch한 핸들러에 보내기 위해 finish 메소드가 제공됩니다. 리듀서 내에서 언제든 finish 메소드를 호출함으로서 리듀서 수행을 종료하고 결과를 dispatch시 지정된 핸들러로 전송할 수 있습니다.만들어진 리듀서가 사용되기 위해선 등록 과정이 필요합니다. 리듀서 등록은 어플리케이션이 처리합니다.One-way 데이타 바인딩, 전역 및 지역 오류 처리, 리듀서에 전달된 데이타 검증용 스키마, 전역 공통 컴포넌트 등록 및 사용 등 설명하지 않은 많은 기능들을 WoowahanJS는 포함하고 있습니다. 좀 더 구체적이고 상세한 내용은 Github 저장소의 문서와 예제 코드를 참고해 주세요.Github WoowahanJS점진적으로 다양한 웹앱 개발을 WoowahanJS로 하고 있습니다. 그러나 프레임워크 보다 프론트앤드 개발에 익숙하지 않은 개발자들에게 UI 개발은 큰 허들로 작용합니다. 주로 백오피스 형태의 웹앱을 많이 만들다 보니 Bootstrap 기반의 UI를 많이 사용합니다. UI 프레임웍은 Bootstrap 기반으로 개발한 후 이를 이용하여 다양한 UI를 WoowahanJS 기반으로 사내에 제공하고 있습니다.UI-MART란 사내 서비스가 있고 개발자들은 필요한 UI컴포넌트를 선택적으로 다운로드할 수 있습니다. WoowahaJS 기반이 기본 형태이고 경우에 따라 HTML과 CSS만을 다운로드할 수 도 있습니다. 이런 내부 서비스를 통해 모든 팀이 빠르게 웹앱을 개발해 나갈 수 있도록 돕고 있습니다.다양한 의견과 PR 언제든 환영합니다.:-)",http://woowabros.github.io/tools/2016/09/07/woowahan-js.html,woowabros,,NULL,2016-09-07
Happy Code,"사람들이 행복해하는 소프트웨어를 만드는 프로그래머가 되는 것을 목표로 살아가는 아들 바보 프로그래머. 우아한형제들에서 웹 프런트 앤드 프레임워크, 서비스, 제품 등을 만들고 있습니다.우아한형제들에 입사한 후 다른 회사와 많이 다르게 느껴지는 부분은 자발적 나눔이 참 많다는 것입니다. 사내 식당인 “우아한 키친”의 운영 조직인 “밥상회” 또한 직원 자치로 운영되고 있습니다. 음식을 만들고 먹는 것을 즐기는 편이다 보니 식당이 운영되는 방법 또한 궁금하기도 했습니다. 때마침 3기를 모집하고 있어 참여 신청을 했고 3기 밥상회 멤버가 될 수 있었습니다.규모가 큰 대기업이라면 회사에서 운영되는 일들은 대부분 시스템화 되어있고 사내 서비스로서 제공됩니다. 하지만 작은 규모의 회사는 필요한 것 모두를 시스템화할 수 없는 경우가 많습니다.밥상회 멤버로는 저 같은 개발자도 있지만 대부분 비개발 직군의 분들입니다. 코드의 도움이 필요한 많은 경우가 밥상회에도 있었습니다.키친에서 제공되는 메뉴 스케줄은 어떻게 알 수 있을까? 월요일 간식으로 운영되는 “셰프의라면”을 예약제로 운영해 볼 수 있을까? 같은 것들 말이죠. 프로그래머라면 작은 나눔을 실천할 수 있는 좋은 기회가 아닐 수 없습니다. (그리고 하고 싶은 데로 제품을 만들어 볼 수 있는 기회이기도 하고요. ^^)키친의 메뉴는 셰프님이 매일매일 구글 스프레드시트 문서에 기록을 하고 있었습니다. 그 문서를 JSON 형태로 읽어 달력 UI로 보여주는 웹앱이 있었고, 이는 사내의 다른 개발자의 나눔의 결과였습니다.좋기는 했지만 조금 아쉬웠습니다. 달력 형태의 UI가 메뉴를 보여주는데 효과적인가에 대한 의문이었습니다. 한 달치 메뉴를 매번 궁금해하는 사람이 얼마나 될까? 이런저런 생각을 하던 중 팀 메신저에 링크 하나가 공유됩니다.순식간에 또 다른 재능 기부 메뉴판 디자인이 도착한 것이죠. 새 디자인이 도착했으니 새로운 옷을 입혀주었습니다. 메뉴가 기록된 스프레드시트에 모든 날짜의 메뉴를 보여주기는 하지만 주 단위로 표시되어 가시성이 높아졌습니다. 앱이 로딩되면 오늘이 포함된 주 슬롯으로 자동 이동되는 기능을 덧붙이고 점심 메뉴 항목의 첫 번째 메뉴는 언제나 주메뉴가 위치하기 때문에 스타일링을 추가하여 메인 메뉴의 가시성을 높였습니다.우아한 형제들의 월요일 출근시간은 오후 1시입니다. (최고의 복지!! ㅎㅎ ) 집에서 점심을 먹고 오기 참 애매하기도 하고, 키친에서 운영하는 12시 점심을 먹기 위해 일찍 출근하기도 좀 망설여지기도 합니다. 그래서 배고픔이 특별히 밀려오는 월요일 오후에 키친에서 라면을 팔아보기로 했습니다.운영 계획은 대략 이랬습니다. 월요일 오후 4시부터 90개의 라면 끓여 판매한다. 그런데 90명이 올까? 더 많이 오면 어떻게 하지? 하는 문제가 있었고 간단히 수량 파악을 위한 예약을 받기로 했습니다.구글 앱스의 설문 등록 폼을 이용하면 예약 페이지를 만드는 건 아주 손쉬운 일이었습니다. 실제로 만들어 놓기는 했는데 그렇게 해보니 영 쓸데없는 일인 것 같았습니다. 예약자 이름과 대략 4시, 4:30, 5:00 이렇게 시간대를 입력받았는데 실제 사람들이 내려오면 누가 누군지 확인할 길이 없었던 것이죠. 문서 열어놓고 이름 물어보면 되겠지만 그렇게까지 할 일이 아니었습니다. 그래서 이름을 빼버리니 시간대만 남았고, 결국 대략 먹을 사람들의 수만 파악하는 용도가 돼버린 것이죠. “너무 공급자 편의적인 발상 아닌가?” 싶은 생각이 들었습니다. 그러나 수량 파악은 필요했기 때문에 그렇다면 이쁘게라도 만들어보자는 생각이 들었습니다.그래서 MaterializeCSS 기반의 간단한 수량 파악 페이지를 만들게 되었습니다. 기능은 워낙 간단해서 등록용 HTML 페이지 만들고, 예약을 처리할 Node 서버에 예약 수량 기록을 위한 DB로 MongoDB를 연결했습니다. 회사 인프라를 사용하면 일이 커지는 느낌이니 간단하게 Heroku에 올렸습니다. Mongo는 500MB까지 무료로 주는 MongoLab 이용 세상 참 편해졌죠 ^^몇 년 전부터 유행한다는 최신(?) 카드 UX로 설계되었습니다. ㅎㅎ 3개의 타임 역할을 하는 3개의 예약 카드가 있고 90그릇의 라면을 로드밸런싱 하기 위해 타임별로 30그릇만 예약되도록 제한을 걸었습니다. 그냥 예약만 되면 재미가 없으니 Socket.io를 이용하여 실시간으로 예약되는 그릇 수를 보여주도록 했습니다. 빨리 예약 안 하면 못 먹을 것 같은 긴장감을 주기 위한 장치 정도가 되겠네요. 실제로 그런 긴장감을 발생시키는데 성공은 못한 것 같지만 소소한 재미 정도는 준 것 같습니다.주말 두 시간 투자해 만든 예약 페이지로 많은 사람들이 행복해하는 것 같습니다. 하지만 실제 운영이 많이 행복하지는 않았습니다.시간대로 예약을 분산하여 사람이 극도로 몰리는 문제는 어느 정도 약화시키는 효과는 있었습니다. 그러나 라면 주문을 받고 (파송송 라면과 치즈 라면 두 개의 메뉴 운영) 번호표를 수기로 나눠주고 라면이 나오면 번호를 불러주는 상황이 매번 반복됐습니다. 즉, 접수대에 사람이 필요했고 밥상회 멤버들이 돌아가며 30분씩 시간을 내야 했습니다. 번호표를 만들고 주방과 주문자에게 나눠주는 방법도 여러 가지 시도해 봤지만 뭘 해도 불편할 수밖에 없었습니다.3주 넘게 운영해본 결과 새로운 방법이 필요했습니다.주문자와 주방 사이에 접수받는 사람을 없앨 수 있는 방법이 있을까?접수자를 없애는 아이디어를 스케치해봤습니다. 주방 앞에 태블릿을 하나 두고 주문자들이 직접 와서 주문하면 주문이 들어가고 주방에선 주문받는 별도 화면에서 조리를 시작하고 완료되면 완료 처리, 그러면 주문자의 번호가 뜨는 아이디어였습니다.이 아이디어에는 두 가지 심각한 문제점이 있었습니다.첫 번째 문제는 주문이 이렇게 순조롭게 순차적으로 들어오지도 않을뿐더러 주문자가 접수대 앞에서 계속 내 번호 표시될 때까지 기다려야 한다는 것이었죠. 생각만 해도 아수라장이 될 것이 눈에 보였습니다.두 번째 문제는 기존 1.0 버전의 예약 기능으로 인한 주문 분산이 안된다는 것이었습니다.예약 기능이 꼭 필요했습니다.주말에 집에서 라면을 끓여 먹으며 고민을 해봤습니다. 두 가지 문제를 해결할 묘책은 진정 없을까? 없을 리는 없겠죠? 결국 최종적으로 다음과 같은 기획이 만들어지게 됩니다.간단히 설명하면 예약 번호를 발급하고 실제 주문이 시작되면 대기 번호를 발급하는 시스템입니다. 하지만 왠지 좀 복잡하고 주문자가 이 흐름을 잘 따라갈 수 있을지가 걱정이 되었습니다.그래서… 팀원 몇 명을 꼬드겨 설명 동영상을 제작합니다.그래, 이 정도면 잘 될 것 같아!! 라는 생각을 했습니다. 그러나… 잘 된 부분도 있고 제대로 안 되는 부분도 있었습니다.두 가지 문제가 발견되었는데요.첫 번째는 로그인이 없기 때문에 주문자 식별을 할 수 없다는 것이었습니다. 꼭 주문자 식별을 할 이유는 없지만 정작 주문자가 주문한 브라우저를 기억하지 못해 주문 확인 요청을 못하는 경우가 생기는 것이었습니다. 주문 정보를 브라우저에 로컬 스토리지에 저장하기 때문에 발생하는 문제였습니다. 카톡 같은 메신저 앱에서 공유된 주문 링크를 따라 인앱 브라우저에서 예약을 하면 다시 들어가도 로컬 스토리지가 유지되지 못하는 경우가 많았습니다. 사실 이것은 충분히 예상하고 있어서 소개 동영상에도 관련 내용을 넣어 놓았죠. PC로 주문해서 PC 들고 온 주문자 설정이 그것인데요. 그 설정이 이용자들에게 잘 받아들여질 것이란 건 순전히 제작자의 착각일 뿐이었습니다. ^^두 번째는 예약한 라면 수와 실제 먹게 될 라면 수가 달라지는 경우가 있다는 것입니다. 8그릇 예약하고 6명이 오는 경우죠. 라면을 먹는 건 문제가 없지만 시스템에 8그릇으로 주방에 표시되는 것이 문제였습니다. 이게 6그릇짜리 주문이라는 걸 계속 커뮤니케이션해야 하는데 여러 개의 주문이 동시에 처리되고 있는 정신없는 상황에서 이것을 일일이 기억하는 건 쉽지 않았습니다.오늘 셰프의 라면 2.1 패치가 배포되었습니다. 로그인 기능이 구현되어 이제 주문자를 식별할 수 있게 되었습니다. 주문자 식별보다 더욱더 좋은 것은 어디서든 예약하고 아무 브라우저나 로그인만 하면 주문을 진행할 수 있게 된 것이죠. 그리고 조리 시작 시 주문서 변경이 가능해졌습니다.앞으로 셰프의 라면은 얼마나 더 발전하게 될까요? 잉여로 시작한 일이지만 소프트웨어를 단단하게 만드는 건 매우 흥미로운 일인 것 같습니다.무엇보다 그 과정에서 많은 사람들이 즐거움을 느끼는게 더욱더 행복한 일이겠죠.",http://woowabros.github.io/woowabros/2016/09/05/happy_code.html,woowabros,,NULL,2016-09-05
쉽고 재밌는 정규식 이야기,"PC 주문접수 프로그램에서 개인정보 보호법을 적용하기 위해 취소된 주문의 개인정보를 숨겨야 할 필요가 생겼습니다. ‘앱의 주소검색 모양새를 보아하니 서버에서 두개의 필드를 받아서 처리해야겠군!’ 이라고 생각한 것이 저의 첫번째 착각. 하지만 그런거 없고 주소정보는 한 필드에 저장하고 있습니다!  그러면 주문접수 앱은 어떻게 처리하고 있을까?문제는?그러면 어떻게 해야 할까? 정규식은 가장 널리 사용되는 Perl정규식을 사용하기로 합니다. perl.or.kr 교훈: 사용자는 개발자가 의도하는 방향으로 프로그램을 사용하지 않는다.  일단 해당 필드에는 주소정보만 입력된다는 전제가 있어서 문제는 더 수월해집니다. 읍,면,동 위치를 찾아서 ‘산’ 주소가 있는지 찾은 다음 몇길, 몇로 정보를 찾으면 기준이 되는 위치를 찾을 수 있습니다. 추가로 ‘지하’ 번지도 찾아봅시다.  최초의 정규식   솔직히 이런 정규식을 보면 멘붕에 빠지는것이 정상입니다. 저도 한달정도 밖에 안됐는데 기억이 나지 않아 여러번 매뉴얼을 찾아봤습니다. 정규식의 특성상 식을 보고 의도를 파악하는 것은 매우 어렵습니다. 절대 무공의 정규식 고수가 아니라면 처음부터 다시 짜거나 잘 만들어진걸 베끼는 것을 추천합니다.(벤치마크!!!) 정규식의 특성상(대괄호, 중괄호, 소괄호가 혼재하는 구조에 많은 예약어) 복잡하게 보이는 것일뿐 찬찬히 뜯어보면 별로 어렵지 않습니다. 조금씩 뜯어서 살펴볼까요?한글로 시작하고 중간에 숫자가 아예 없거나 최대 다섯자리까지 있는 경우 끝이 읍,면,동,가,리로 끝나는 위치를 찾는다. 바로 빈칸이 있거나 혹은 없을 수도 있는데 그 뒤로 숫자-숫자 혹은 숫자만 있고 뒤에 가,리가 붙는 경우를 찾는다. ‘산’주소를 찾거나 로, 길로 끝나는 주소를 찾는다.  샘플로 약 100개정도 주소를 돌려봅니다. 빠짐없이 잘 동작합니다.(천재가 아닐까 잠시 생각합니다.) 추가테스트를 해보고 배포하기로 합니다. 추가 테스트를 진행하자 문제가 발생합니다.이쯤되자 한번의 정규식으로 추출하는 것은 비효율적이라는 결론에 도달합니다. 시, 구까지 추출하는 정규식으로 한번 거르고 그것이 성공하면 성공한 위치부터 다시 추출하기로 합니다.  시, 군, 구를 추출하는 정규식해당 정규식을 추가했음에도 분석되지 않는 주소들이 발견됩니다. 의외의 패턴을 발견합니다. 문제가 특별시와 광역시에 집중됩니다. 특별시와 광역시는 시 이름의 뒤에 ‘시’를 붙이지 않고 주소를 쓰는 경향이 있었습니다. 이놈의 광역부심! 패턴을 조금 더 수정하기로 합니다.시, 구를 추출하는 정규식 Ver.2이건 잘 되는 것 같으니 원래 정규식을 다듬습니다. 동이름에 ‘.’가 들어가는 것을 찾도록 합니다. 수정하는 김에 위의 시,구를 추출하는 공식에서 빠질것을 대비해 ‘남동구’도 제외할 수 있도록 정규식을 일부 수정합니다. 한글로 시작하고 중간에 ‘숫자’, ‘숫자.숫자’, ‘숫자,숫자’가 들어가는 읍,면,동,가,리뒤에 ‘구’가 붙지 않은 것최종 정규식5000건쯤 데이터를 돌려봅니다. 다 의도한대로 동작하고 있는것을 확인합니다. 하지만 안걸리는게 있으면 어떡할까요? 물론 현재의 정규식으로 100% 걸러내는건 불가능합니다. 사람이 손으로 입력한 패턴이기에 어떤 문제가 발생할지 장담할 수 없습니다. 정규식으로 패턴검색을 하는 경우 늘 오탐과 미탐사이의 밸런스에 대한 고민이 있습니다. 오탐을 줄이려고 하면 미탐이 발생하고 미탐을 줄이려고 하면 오탐이 발생합니다. 이 경우에는 어떻게 해야 할까요? 저는 미탐지 되는 경우 전체 주소를 숨김처리했습니다. 왜냐하면 처리하는 않은 경우 법적문제가 발생하니까요.(주소가 사라졌다고 욕을 먹을 수는 있겠네요.)알아두면 좋은 것2016.08.16 19:30 추가함",http://woowabros.github.io/study/2016/08/16/easy_and_fun_reg_exp.html,woowabros,,NULL,2016-08-16
첫 Java 프로젝트의 생생한 후기,"이번에 처음으로 Java 8 + Spring Boot + JPA 를 이용하여 프로젝트를 진행 하였는데, 그 때 느꼈던 점을 공유 하고자 합니다.저는 이전 회사에서는 Java 를 사용했었지만, Spring Framework 은 사용 하지 않았습니다. 주로 책을 보며 개념을 익혔고, 사외에서 스터디 등을 통해서 관련지식을 쌓아오고 있었습니다. 그래서 이번 프로젝트를 많은 기대를 하면서 시작 하게되었습니다.이번 프로젝트에서는 주요 비지니스로직에는 Unit Test 코드를 꼭 작성하고자 했고, TDD 를 통한 개발이 아닌 TDD 를 지향하여 개발을 하였습니다. (사실 완전한 TDD 로 개발을 진행하기엔 스스로 내공이 부족하다고 느끼고 있습니다.)결론부터 말씀 드리자면, JPA가 익숙하지 않았고, 객체지향프로그래밍이 익숙하지 않았으며 테스트코드 작성하는 것도 서툴렀습니다. 그래서 개발기간도 예상했던 것 보다 더 많이 걸렸지만 이 프로젝트를 통해서 경험한 것은 엄청나게 많은 것 같습니다.몸으로 느낀걸 공유하기 위해 기록으로 남기게 되었습니다. 문자로 모든걸 전달하는데는 한계가 있을 것 같지만 그래도 천천히 읽어 보시면 감사하겠습니다.Legacy 시스템은 MS-SQL 에 Stored Procedure 를 사용한 절차지향프로그래밍을 해왔다고 볼수 있겠습니다. View + Stored Procedure 의 구성으로  2~3개의 소스파일로 특정 기능을 개발하다보니 Java 프로젝트를 하면서 Class 를 잘게 나누는데에 낯설었던것 같습니다.프로젝트 초기에는 Controller, Service, Repository, Entity 를 중심으로 Layer 로 나누어 개발을 시작 하였습니다. (기능별로 Layer 당 class 하나씩 생성했다고 보시면 될듯합니다.) 개발이 진행되면서 클래스의 덩치가 커지고 있었는데 여러 클래스로 나누는 것이 불편할 것 같다는 무의식적인 벽이 존재 했었던 것 같습니다. (현재 팀내에서도 스터디하고 있는) “소프트웨어 개발의 지혜“ 책에서 보았던 것을 떠올려 보면 다음과 같은 원칙을 알수 있습니다.SRP (Single Responsibility Principle): 단일 책임의 원칙, 클래스는 단 한가지의 변경 이유만을 가져야 한다.처음에는 상품구매라는 추상적인 책임을 가지고 접근을 했었습니다. 그러다보니 구매하기위한 유효성체크의 책임 결제처리의 책임 기타등등 여러 책임들이 추가되면서 Service Class 는 엄청나게 비대 해졌습니다. (물론 Unit Test 코드도 엄청나게 많아졌지만 이는 다음 단락에서 설명하도록 하겠습니다.)QA 단계에서 버그를 수정하거나 리팩토링을 진행할 때, 비대해진 (많은 책임을 가지고 있는) 클래스를 수정하기는 쉬운일이 아니였습니다. 프로젝트가 진행되면 될수록 작은 책임단위로 클래스를 나눠야 한다는것을 깨닫게 되었습니다.  만약 처음 프로젝트를 진행하신다면 두려워 하지말고 클래스로 과감하게 나누길 바랍니다. (그게 후에 정신건강에 좋습니다.)혹시, 너무 많은 클래스가 있어서 전체적인 흐름을 파악하기에 어렵다고 생각하시나요? 다음 인용구를 보시죠. 출처 « 로버트 C.마틴 - Clean Code 177page »  작은 클래스가 많은 시스템이든 큰 클래스가 몇 개뿐인 시스템이든 돌아가는 부품은 그 수가 비슷하다.  (중략) “도구 상자를 어떻게 관리하고 싶은가? 작은 서랍을 많이 두고 기능과 이름을 명확한 컴포넌트를 나눠 넣고 싶은가? 아니면 큰 서랍 몇 개를 두고 모두를 던져 넣고 싶은가?”  클래스의 덩치가 커진다는 것은 해당 객체의 책임도 많아 진다는 뜻입니다. 따라서 단 한가지 이유만으로 클래스를 수정 할 수 있어야 하며, 여러가지 이유로 수정할 이슈가 생긴다면 그건 설계가 잘못된 것이라고 합니다.저는 TDD 를 지향하는 개발을 하고 있었기 때문에 대부분의 중요 클래스에 Unit Test 를 작성하고 있었습니다.Mockito를 이용하여 다른 객체간의 관계를 Mocking 하면서 개발을 했었는데 프로젝트 초기에는 하나의 클래스를 테스트하기 위해 10개 가량의 Mock 객체가 필요했습니다. 이건 Mocking 해야 할 객체간의 Collaboration 들이 엄청나게 많다는 뜻이였죠. 이게 무슨 문제일까요?글로 적는것 보다 실제 코드를 보여주는게 좋을 것 같아 (부끄럽지만) 제가 작성한 실제 코드를 보시면 좋을 것 같습니다.그냥 보기에도 엄청 많은 객체들과의 관계가 존재하여서 Mock 객체들이 엄청 많이 존재했었습니다. 실제 테스트코드를 보면 다른 사람이 파악하기도 어려운 테스트 코드를 작성하고 있습니다.처음 작성할 때는 코드의 대부분이 제 머릿속에 로딩이 되어 있었기 때문에 개발을 원활이 진행 할 수 있었습니다. 하지만 몇일이 지나고 이 코드를 머릿속으로 로딩하는 시간이 아주 많이 걸렸습니다.왜 그럴까요? 위에서도 설명했듯이 한 클래스에 너무 많은 책임을 가지고 있기 때문입니다. 제가 읽었던 책에서 몇가지 문구를 인용해 보도록 하겠습니다. 출처 « 신정호, 박상오, 이규일, 전우균, 조건희 - TDD에 대한 오해와 진실 TDD 이야기 50 page » “ 자신의 테스트 코드에 지나치게 많은 Mock객체가 필요하다면 테스트 코드 작성 이전에 리팩토링의 냄새가 있는지 확인해봐야 한다. “ 지금 심하게 많은 Mock 객체가 이용되고 Mocking 하는 역할(Method)도 엄청나게 많습니다. 리팩토링 냄새가 엄청나게 나는 코드라고 볼 수 있습니다. 프로젝트를 진행하면서 대부분의 클래스가 이런식으로 작성이 되어서 다른 분이 본다면 파악하기 무척 어려울 것 같습니다. 다행히도 프로젝트 막바지에는 많이 나누려는 시도를 했고, 그 중 한 코드를 소개해 드립니다.어떤가요? 딱 원하는 책임을 가지고 테스트하고 있다는 것이 느껴지시나요? Unit Test 를 잘 작성한다는 것은 객체별로 역할을 잘 나누었다는 것이고, 그에따라 설계도 잘되었다고 볼 수 있을 것입니다.자, 처음에도 말했지만 핵심음 두려워 말고 클래스를 나눠라! 입니다. 클래스를 나누는 것 부터 시작이며 후에 설계는 어떻게 잘 할건지에 대해 고민하면 좋을 것 같습니다.그럼 어떤 상황에서 클래스를 나눠야 할까요? 항상 그런건 아니겠지만 다음과 같은 상황이 아닐까요? 출처 « 신정호, 박상오, 이규일, 전우균, 조건희 - TDD에 대한 오해와 진실 TDD 이야기 77, 78page » private 메서드가 너무 비대하거나 복잡하다면, 클래스 하나가 책임을 너무 많이 지고 있는 건 아닌지 고민해봐야 한다.  private 메소드에 대한 테스트 고민이 설계상의 경고가 아닌지 의심해 봐야한다. 객체지향적으로 잘 된 설계를 하는건 봐야할 책도 많고 알아야 할 지식도 많은 것 같습니다. 하지만, 시작단계에서는 클래스를 잘 나누는게 중요 한것 같습니다.이 내용은 Test First 로 작성할 때 해당되는 내용입니다.프로젝트 초기에 테스트의 단위를 너무 크게 잡아서 빠른 피드백(흔히 테스트를 성공하는 것에대해 초록막대 본다고 합니다.)을 받지 못해서 흐름이 깨지는 경우가 생겼었습니다.너무 일을 크게 잡고 시작했을 수도 있고 컨디션이 좋지 않았을 수도 있습니다. 그리고 구현 하려는 클래스의 역할이 너무 많아서 일지도 모르죠. 그럴 때는 과감하게 처음부터 시작하세요.위 내용은 켄트백의 TDD by Example 에 나왔던 내용입니다. 그 책을 읽고 나서 프로젝트를 진행 했음에도 불구하고 나는 “원칙”을 까마득하게 잊어버리고 있었던 것이였죠.초록막대를 보기위해 엄청 고생을 하고 Twitter 에다가 징징거렸었는데, 아샬 님이 해답을 일깨워 주었습니다. 한 곳만 보고 달려가다 보니 뒤돌아 보지 못하고 점점 진흙탕에 빠질 때도 있을지 모릅니다.리팩토링은 항상 해야한다고 머릿속으로는 알고 있었지만, 이번 프로젝트에서는 리팩토링을 거의 진행하지 못한것 같습니다.  “취소하기”라는 기능을 구현하는데 5일의 개발기간을 가져갔다면. 5일 동안 구현을 끝내고 정상적으로 동작한다면 개발을 끝냈던 것 같습니다.프로젝트가 끝난 지금 생각해보면 4일은 구현을 하고 하루 정도는 코드에 금칠을 하는 시간을 가질수 있도록 플래닝을 했어야 하지 않을까 싶습니다.물론 더 좋은 방법은 하나의 기능 구현을 위해 Test Case 를 작성하고, 구현하고, 코드를 리팩토링 하는 사이클을 가져가는게 제일 좋은 방법이 것 같은데 아직 익숙하지 않다는 게 문제죠.*Extream Programing 실천방법에서는 테스트, 코드, 리팩터링 을 꾸준한 리듬으로 가져가길 권한다. * 그래서 요구사항 구현을 끝냈다고 개발이 끝난게 아니라는 걸 말하고 싶습니다. 즉, 개발공수를 잡을때 리팩터링을 위한 버퍼를 어느정도 가지고 가는건 어떨까요? 아니 강력하게 추천합니다.저는 프로젝트 기간 동안은 리팩터링을 거의 못하고 끝났지만 리팩터링을 하고 싶은 마음은 굴뚝 같습니다. 시간나는 대로 조금씩 리팩터링을 진행해야 하지 않을까 생각하고 있습니다.저는 TDD 스터디, 객체지향스터디, Spring 스터디 등을 해왔지만 실제 프로젝트 단계에서는 이론으로 공부했던 대부분의 원칙들이 떠오르지 않았습니다. 그래서 처음 Java 프로젝트를 진행하면서 겪었던 경험들을 꼭 공유해주고 싶었습니다.책으로 읽히는 이론적인 면도 중요하지만, 무엇보다도 직접 경험 해보는게 가장 중요하다고 생각합니다. 실제 프로젝트 도중에 책을 읽으면서 무릎을 탁! 쳤던 경험도 한두번이 아니더라구요.지금 여러분이 Java 를 처음 시작하는 단계에서 적어도 이 한가지만 기억하시면 될 것 같습니다. 두려워 하지 말고 클래스를 나누세요.프로젝트 QA를 끝내고 최철우 수석님이 해주신 말이 기억에 남아서 공유 드립니다. (정확한 워딩인지는.. 기억이 가물가물..)“설계에 대한 고민은 항상 하기 마련이예요. 좋은 설계를 위해 꾸준히 고민하고 리팩터링 한다는게 좋은 것 같아요.”",http://woowabros.github.io/experience/2016/08/02/first_java_project.html,woowabros,android,NULL,2016-08-02
좋은 퍼블리셔란 무엇일까?,"지난 주 금요일에 한국인터넷전문가협회에서 주관하는 인터넷 에코 어워드 퍼블리셔 부문에서 개인공로 최우수상을 받았다. 도대체 내가 뭘 해서 상을 받았고 다른 좋은 사람도 많은데 왜 내가 받았을까에 대한 고민을 몇가지 해보다가 이 글을 쓴다. 이 글은 수상후기이기도 하며 미래에 더 공부할 사람들에 대한 이야기, 그리고 내가 앞으로 해나갈 이야기이기도 하다.내 모든 커리어의 시작은 20살 첫 회사에서 퍼블리싱을 시작한 거였고, 그로 인해서 퍼블리싱 업계에 들어오게 되었다.  그 전에는 실업계 고등학교의 외국어과를 나왔고 성적도 그렇게 좋은 편은 아니었다.첫 회사에서는 아무것도 몰랐는데 그 당시 사수님이 “표준을 봐야한다” 라는 이야기를 해주셨다. 당시에는 영어를 몰라서 하루에 5분 보고 접고, 다시 펼쳤다가 5분만에 접고 했었던 기억이 난다. 5분이 10분이 되고, 10분이 20분이 되고, 20분이 1시간이 되고 하다보니 지금은 하루종일 표준만 읽을 수도 있다.물론 그러면 많이 지치지만 말이다.내가 4년차에 들었던 생각은 “이렇게 좋은 걸 왜 안읽을까?”였다. 의외로 매우 단순한 곳에 문제가 있었는데그러다보니 내가 차마 다른 사람에게 “표준 읽으세요”라고 하기가 그런 것이다. 나도 읽기 힘들었는데 이제 내가 다른 사람에게 강요하고 있으려니 이게 뭐하는 짓인가 싶기도 했다. 그래서 번역을 시작했다.처음에는 일본어를 한국어로 번역했지만, 그 다음에는 영어를 일본어로 번역한 뒤 일본어를 다시 한국어로 번역한다. 의외로 일본어가 단어의 조합이 매끄러운 케이스가 많아서 나는 주로 그렇게 한다.영 모르겠다 싶으면 번역기 돌려보고 다시 문장을 짜맞춰보기도 한다. 그렇게 하면 조금은 더 나은 번역이 된다.그렇게 해서 지금 번역된 스펙을 읽는 사람은 얼마나 되느냐고 묻는다면, 아쉽게도 그렇게 많지 않다. 실제로 내 블로그의 조회수 기록을 보면 많이 낮은 편에 속한다. 오히려 예전에 개인 블로그를 운영할 때보다도 낮은 편에 속한다. 나는 이런 상황을 개선해야한다고 생각한다.개발자는 항상 코드와 함께 지내야한다. 코드에는 반드시 정답이 있는 건 아니다. 이 부분에 대해서는 표준에서도 모호성을 지니기 때문에 반드시 그렇게 해야한다는 법칙은 없다.다만 웹에서 표준 기술이라는 건 모든 브라우저에서 표준을 따르기로 협의되어있고, 표준을 따르지 않는 브라우저는 “특출난” 게 아닌 “도태된” 것에 조금 더 가깝기 때문에 사실상 표준을 지키지 않는 상황은 예외상황이라 볼 수 있다.한국에서는 여러 이해관계로 인해 오래된 브라우저를 쓰는 사람도 많지만, 그럼에도 불구하고 표준을 제대로 따른다면 어느정도의 상황까지는 구현이 가능하다. 웹에서 표준이라는 건 문제가 발생했을 때 문제의 원인을 추측해나가는 과정에서, 표준에 명시되어있는 내용이라면 바로 해결할 수 있고, 그런 상황이 아니라면 브라우저의 문제라는 걸 바로 알 수 있단 점에 있다.즉 문제 해결과정이 단순해진다.  그리고 표준을 잘 지킨다는 건 표준을 준수하는 모든 브라우저에서 내 웹사이트가 잘 나올 거란 걸 기대할 수 있단 이야기이기도 하다. 그렇게 함으로써 더 나은 웹을 만들어 나갈 수 있다.항상 표준을 지키며 개발하기는 어렵지만, 표준을 지키지 않고 개발하기는 너무 쉬운 일이라서, 꽤 많은 사람이 표준을 지키지 않는 쪽으로 점점 방향을 바꾼다.하지만 표준을 지키지 않은 코드는 먼 훗날 이슈가 발생한다. 그 이슈가 발생했을 때가 되어서야 “표준을 준수했어야하는데”라 후회한들 돌이키기 어렵고, 결국 레거시를 안다가 코드를 바꾸는 경우가 대다수다.“잘 돌아가는 코드인데 왜 굳이 새로 구현해?” 라는 질문에 답하기란 생각보다 어려운 일이다. 표준을 안다는 건 내가 새로운 문제를 접했을 때, 어디의 어느 부분을 어떻게 찾아나가야하는 지 알 수 있다는 거고, 그걸 앎으로써 문제 해결과정이 깔끔해지며, 유관 개발부서와의 협업도 깔끔해지고 문제해결과정도 깔끔해진다.내가 생각하는 좋은 퍼블리셔란 단순하다. 표준을 잘 이해하고 활용할 수 있는 사람. 미래의 표준을 사전에 대비할 수 있는 사람 그렇게만 한다면 적어도 멋진 퍼블리셔가 될 수 있지 않을까란 생각을 해본다. 물론 내 앞날 챙기기도 바쁘지만 말이다.",http://woowabros.github.io/woowabros/2016/07/15/good_publisher.html,woowabros,,NULL,2016-07-15
"생각하라, 객체지향처럼","2년차 쪼랩이가 객체지향을 처음으로 접하고 공부를 하면서 나름대로 정리해보았습니다.안녕하세요. B2B시스템개발팀 김승영입니다.먼저, 이 글은 지난 02월에 작성되어 사내 위키에 공유되었던 글임을 미리 알려드립니다. 참고로 현재는 Biz상품개발팀에서 지내고 있습니다.ㅋㅋ이번 글은 < 객체지향의 사실과 오해 >라는 책의 ‘07장. 함께 모으기’ 중 커피 전문점 도메인 설계 및 구현 예제에 대한 내용을, 마치 제가 설명 하듯이 적어보았습니다.사실 책을 보고 제가 다시 설명하는 방식으로 적었지만, 책의 설명을 그대로 옮긴 부분도 많습니다. (잘 설명되어 있는 책을 굳이.. 왜 그랬을까..ㅋㅋ) 그래도 제가 설명하다보면 더 공부도 되지 않을까해서 어설프게나마 끄적끄적 적어봤습니다.ㅎㅎ저는 다른 객체지향 책을 읽어보지는 않아서 잘 모르지만, < 객체지향의 사실과 오해 >를 읽으셨다면 메시지, 책임, 자율, 협력 등 용어가 좀 더 익숙하실 것이라고 생각합니다.앞으로 많은 경험을 하면서 더 많이 공부하고 더 실력을 쌓아서, 나중에 이 글을 다시 읽을 때는 부끄러워서 얼굴이 빨개질 수 있도록 하려고 합니다. 그 때는 더 고급지고 우아하게 멋진 개발 관련 글을 적어볼께요. 그러니까 ‘아, 객체지향을 이해하려고 애쓰고 있구나..’ 라고 너그럽게 봐주십쇼.ㅋㅋㅋ내용상 오류나 좀 더 추가적으로 설명해주실 좋은 의견이 있으시면, 개인적으로 알려주시거나 댓글에 남겨주시면 정말정말 감사할 것 같습니다!!커피 전문점 도메인 예제를 통해 도메인 모델에서 시작해서 최종 코드까지의 구현 과정을 간략하게나마 설명할 것입니다.다음 예제의 목적은 커피 전문점에서 커피를 주문하는 과정을 객체들의 협력 관계로 구현하는 것입니다. 1. 객체들로 구성된 작은 세상으로 바라보자객체지향 패러다임에서 가장 중요한 것은? 당연히 객체이죠. (클래스가 아니라.. 라는 얘기를 최근에 주위 분들께 많이 들었습니다.ㅋㅋ) 그렇기 때문에 먼저, 커피 전문점을 구성하는 요소들(손님, 바리스타 등)을 객체들로 보고 커피 전문점은 그 객체들로 이루어진 작은 세상으로 생각해보겠습니다. 손님이 커피를 주문하는 이 예제를 한 줄로 요약해보면 다음과 같습니다.→ 손님이 메뉴판에서 4가지 메뉴 항목들 중 하나를 선택해서 바리스타에게 선택한 메뉴(커피)를 주문하고, 바리스타는 커피를 제조해서 손님에게 건네줍니다.여기서 손님, 메뉴판, 메뉴 항목들(4가지), 바리스타, 커피(4가지)가 각각 하나의 객체가 될 수 있습니다. (저는 처음에 혼자 생각해볼 때 4가지의 메뉴 항목들까지 객체로 생각하지는 못 했습니다. 근데 사실 아직도 어색하긴 합니다..ㅋㅋ)모델링에 대해서는 아직 잘 모르지만, 순서대로 보면 손님 객체와 바리스타 객체를 먼저 생각할 것 같습니다. 그리고 손님 객체가 주문을 하기 위해 메뉴가 필요할 것이고, 그럼 메뉴 객체들이 있는 메뉴판 객체가 있어야겠죠. 또한 바리스타 객체가 손님 객체의 주문에 따라 만들어서 제공해야 할 커피 객체들이 필요할 것입니다.즉, 객체지향의 관점에서 커피 전문점이라는 도메인은 손님 객체, 메뉴 항목 객체, 메뉴판 객체, 바리스타 객체, 커피 객체로 구성된 작은 세상인 것입니다. 커피를 주문하는 과정을 객체지향 관점에서 다시 설명해보면, 아래처럼 말할 수 있을 것 같습니다.→ 손님 객체는 메뉴판 객체 안에 적힌 메뉴 항목 객체들 중에서 하나를 선택해서 바리스타 객체에게 전달(주문)하는 것입니다. 그리고 바리스타 객체는 주문을 받은 메뉴에 해당하는 커피 객체를 제조하는 것이죠.이와 같이 객체지향의 관점에서 객체들로 이루어진 커피 전문점 작은 세상을 그림으로 정리하면 아래와 같이 표현된다고 합니다. 글로만 보면서 머릿속으로 그리다가 직접 그림으로 보니까 눈에 확 들어오더라고요. [그림 7.2 객체들로 구성된 커피 전문점 세상] 2. 객체들 간의 관계지금까지는 어떤 객체가 존재하는지 보았습니다. 어렵지 않지만 저처럼 기억력이 안좋은 분들은 위의 그림 7.2를 다시 한번 보시면 좋을 것 같습니다!다음으로는 각 객체들 사이의 관계에 대해서 살펴보겠습니다. 사실 그림 7.2에서도 각 객체들 사이의 관계는 쉽게 알 수 있죠.손님은 메뉴판에서 커피를 선택할 수 있습니다. 이런 관계가 있는 것이죠. 손님과 바리스타, 바리스타와 커피도 마찬가지에요. 메뉴판과 커피와는 직접적으로 관계가 없는 것도 알 수 있습니다.3. 객체들의 분류이제는 동적인 객체들을 정적인 타입으로 간단하게 추상화해보겠습니다. 이를 위해 객체들을 분류할 건데, 분류를 위해서는 타입(type)을 사용합니다. 4가지 커피 객체들을 모두 같은 ‘커피 타입’으로 분류할 수 있는 것입니다.동일한 상태와 동일한 행동을 가질 수 있는 객체는 같은 타입의 인스턴스로 분류할 수 있습니다.각 객체들은 아래와 같이 모델링 할 수 있습니다. 4. 타입 간의 관계각 객체들을 타입별로 분류 했으니 이제는 그 타입들 간의 관계를 살펴보겠습니다. 어떤 객체들이 존재하는지 보고 객체들 사이의 관계를 알아본 것처럼 말이죠.이어서 나올 내용에서 관계의 종류(합성관계, 연관관계)가 중요한 것처럼 나오는데, 사실 중요하지는 않다고 합니다. 단지, 설명을 위해서 관계들을 구분하는 것입니다.오히려, 도메인 모델을 작성하는 단계에서는 다음 두 가지에 초점을 맞추는 것만으로도 충분하다고 합니다. 4-1. 메뉴판 타입과 메뉴 항목 타입 간의 관계메뉴 항목 객체가 메뉴판 객체에 포함되어 있으므로, 메뉴판 타입과 메뉴 항목 타입은 합성(composition) 관계로 단순화할 수 있습니다. 아래 그림 7.3이 둘의 관계를 나타냅니다. [그림 7.3 메뉴판 타입과 메뉴 항목 타입 간의 포함 관계] 검은 마름모는 포함(containment) 관계 또는 합성(composition) 관계를 나타내고, 숫자 4는 메뉴판에 포함되는 메뉴 항목의 갯수를 의미합니다. 4-2. 손님과 메뉴판 사이의 관계손님 타입은 주문을 하려면 메뉴판 타입을 알아야 하지만, 그렇다고 메뉴판 타입은 손님의 일부가 아니므로 이 관계는 합성 관계는 아닙니다.이 경우는 단순한 선으로 연결하고, 연관(association) 관계라고 합니다. [그림 7.4 손님과 메뉴판 사이의 연관 관계] 위와 마찬가지로 손님 타입과 바리스타 타입의 관계나 바리스타 타입과 커피 타입의 관계도 동일한 연관 관계입니다.이렇게 해서 그림 7.5와 같이 커피 전문점 도메인을 구성하는 타입들의 종류와 관계를 표현하게 되었습니다.이처럼 소프트웨어가 대상으로 하는 영역인 도메인을 단순화해서 표현한 모델을 도메인 모델이라고 합니다. [그림 7.5 커피 전문점을 구성하는 타입들] 5. 객체지향 설계지금까지 커피 전문점이라는 도메인을 단순화해서 이해해봤습니다. 객체지향의 세계는 협력하는 자율적인 객체들의 공동체라는 얘기가 이 책의 초반부터 계~속 나옵니다.다음 단계는 각 객체들의 협력을 설계하는 것입니다. 즉, 적절한 객체에게 적절한 책임을 할당하는 것입니다.객체지향 설계의 첫 번째 목표는 훌륭한 객체를 설계하는 것이 아니라 훌륭한 협력을 설계하는 것 입니다! 훌륭한 객체는 훌륭한 협력을 설계할 때만 얻을 수 있습니다.설계 과정에 대해 요약하면 다음과 같습니다. 협력을 설계할 때는 객체보다는 메시지를 먼저 선택하고 그 후에 메시지를 수신하기에 적절한 객체를 선택해야 합니다. 즉, 메시지가 객체를 선택하게 하는 것이죠. 그 후 메시지를 수신할 객체는 메시지를 처리할 책임을 맡게 되고 객체가 수신하는 메시지는 객체가 외부에 제공하는 공용 인터페이스에 포함됩니다.이제 실제로 커피를 주문하는 협력을 설계해보겠습니다. 첫 번째 메시지는 ‘커피를 주문하라’일 것입니다. [그림 7.6 협력을 시작하게 하는 첫 번째 메시지] 메시지 위에 붙은 화살표는 메시지에 담아 전달될 부가 정보인 인자를 의미합니다. 나중에 ‘메뉴를 주문하라(아메리카노)’와 같이 인자를 포함하는 형식으로 구현될 것입니다.메시지를 찾았으니 (설계 과정 요약에서 설명했듯이) 이제 메시지를 수신하기에 적절한 객체를 선택해야 합니다.어떤 객체를 선택해야 할까요? 어떤 객체가 커피를 주문할 책임을 져야 할까요?당연히 손님이겠죠? ㅎㅎ 따라서 메시지를 처리할 객체는 손님 타입의 인스턴스입니다. 이제 손님 객체는 커피를 주문할 책임을 할당받았습니다. [그림 7.7 첫 번째 메시지가 손님이라는 객체를 선택했다.] 그런데 손님이 ‘커피를 주문하라’는 메시지를 받자마자 스스로 할 수 있는 것이 없습니다. 메뉴 항목에 대해서 모르기 때문에 스스로 바로 주문할 수 없는 상황인 것입니다. 스스로 할 수 없는 일이 있다면 다른 객체에게 이를 요청해야 합니다. 이 요청이 손님 객체에서 외부로 전송되는 메시지를 정의하고요.손님은 자신이 선택한 메뉴 항목을 누군가가 제공해 줄 것을 요청합니다. (누구인지는 아직 모릅니다.) 여기서 ‘메뉴 항목을 찾아라’ 라는 새로운 메시지가 등장하는 것입니다. [그림 7.8 스스로 할 수 없는 일은 메시지를 전송해 다른 객체에게 도움을 요청한다.] 화살표 위에 있는 ‘메뉴 이름’이라는 인자를 포함해 함께 전송하고, 화살표 아래에 붙은 ‘메뉴 항목’은 손님에게 응답해야하는 것을 의미합니다.즉, ‘메뉴 항목을 찾아라’ 라는 메시지를 수신한 객체는 ‘메뉴 이름에 대응되는 ‘메뉴 항목’을 반환해야 하는 것입니다. 그럼 새로운 메시지인 ‘메뉴 항목을 찾아라’를 수신해서 메뉴 항목을 찾을 책임을 어떤 객체에게 할당하는 것이 적절할까요?메뉴판 객체가 메뉴 항목 객체를 포함하고 있으므로 가장 적절해 보입니다. [그림 7.9 두 번째 객체를 찾았다.] 이제 손님은 자신이 주문한 커피에 대한 메뉴 항목을 얻었으니 이제 메뉴 항목에 맞는 커피를 제조해달라고 요청할 수 있습니다.새로운 요청은 새로운 메시지가 필요하다는 신호이므로, 메시지를 먼저 정의합니다. 손님은 ‘커피를 제조하라’는 메시지의 인자로 ‘메뉴 항목’을 전달하고 반환값으로 제조된 커피를 받아야 합니다. [그림 7.10 새로운 메시지를 찾았다.] 그럼 커피는 누가 제조해야 할까요? 당연히 바리스타겠죠!? [그림 7.11 커피를 제조하라는 메시지가 바리스타라는 객체를 선택했다.] 위에서 보면 알 수 있듯이 ‘커피를 제조하라(메뉴 항목)’는 메시지를 먼저 정의하고, 그 메시지로 객체를 선택했다는 것을 잊지 말아야 합니다. 지금까지 계속해서 메시지를 먼저 정의하고 그 메시지를 수신할 객체를 선택해왔습니다.바리스타는 아메리카노를 만드는 데 필요한 정보와 기술을 함께 구비하고 있는 전문가입니다. 아메리카노를 만들기 위한 지식은 바리스타의 상태로, 기술은 바리스타의 행동으로 간주할 수 있습니다. 이런 관점에서 바리스타는 스스로의 판단과 지식에 따라 행동하는 자율적인 존재라고 할 수 있습니다.커피 주문을 위한 협력은 이제 바리스타가 새로운 커피를 만드는 것으로 끝납니다. [그림 7.12 커피 주문을 위한 객체 협력] 이로써 협력에 필요한 객체의 종류와 책임, 주고받아야 하는 메시지에 대한 대략적인 윤곽이 잡혔습니다. 이제 남은 일은 각 객체의 인터페이스를 구현 가능할 정도로 메시지들을 상세하게 정제하는 것입니다.지금까지 우리가 얻어낸 것은 객체들의 인터페이스입니다. 객체가 수신한 메시지가 객체의 인터페이스를 결정한다는 사실을 기억해야 합니다!메시지가 객체를 선택했고, 선택된 객체는 메시지를 자신의 인터페이스로 받아들입니다. 각 객체를 협력이라는 문맥에서 떼어내어 수신 가능한 메시지만 추려내면 객체의 인터페이스가 됩니다. 객체가 어떤 메시지를 수신할 수 있다는 것은 그 객체의 인터페이스 안에 메시지에 해당하는 오퍼레이션이 존재한다는 것을 의미합니다.각 객체별로 설명하면 다음과 같습니다. [그림 7.13 각 객체들이 수신하는 메시지는 객체의 인터페이스를 구성한다.] 실제로 소프트웨어의 구현은 객체들을 포괄하는 타입을 정의한 후 식별된 오퍼레이션을 타입의 인터페이스에 추가해야 합니다.객체의 타입을 구현하는 일반적인 방법은 클래스를 이용하는 것입니다. 협력을 통해 식별된 타입의 오퍼레이션은 외부에서 접근 가능한 공용 인터페이스의 일부라는 사실을 기억하라! (책에서 계속 이야기 하는 내용입니다.)따라서 인터페이스에 포함된 오퍼레이션 역시 외부에서 접근 가능하도록 공용(public)으로 선언돼 있어야 합니다. 클래스의 인터페이스는 자바의 문법을 이용해 표기합니다. 클래스의 인터페이스를 식별했으므로 이제 오퍼레이션을 수행하는 방법을 메서드로 구현해보겠습니다.먼저 Customer의 협력을 살펴보겠습니다. Customer는 Menu에게 menuName에 해당하는 MenuItem을 찾아달라고 요청해야 합니다. 그리고 MenuItem을 받아 이를 Barista에게 전달해서 원하는 커피를 제조하도록 요청해야 합니다. [그림 7.14 손님의 구현은 메뉴판과 바리스타와 협력해야 한다.] Customer가 Menu 객체와 Barista 객체에 접근하기 위해서, 즉 메시지를 전송하기 위해서는 어떠한 방법으로든 자신과 협력하는 Menu 객체와 Barista 객체에 대한 참조를 알고 있어야 합니다.객체 참조를 얻는 다양한 방법이 있지만 (Spring에서의 DI가 그 중 하나이겠죠?) 여기서는 Customer의 order() 메서드의 인자로 Menu와 Barista 객체를 전달받는 방법으로 참조 문제를 해결하기로 합니다.그럼.. Customer의 인터페이스를 변경해야겠죠? 이제 order() 메서드의 구현을 채워보겠습니다! Menu는 menuName에 해당하는 MenuItem을 찾아야 하는 책임이 있습니다.도메인 모델을 설계할 때처럼 간단히 Menu가 내부적으로 MenuItem을 포함하게 하겠습니다.Menu의 choose() 메서드는 MenuItem의 목록을 하나씩 검사해가면서 이름이 동일한 MenuItem을 찾아 반환합니다.. Menu는 menuName에 해당하는 MenuItem을 찾아야 하는 책임이 있습니다. 도메인 모델을 설계할 때처럼 간단히 Menu가 내부적으로 MenuItem을 포함하게 하겠습니다. Coffee는 자기 자신을 생성하기 위한 생성자를 제공합니다. Coffee는 커피 이름과 가격을 속성으로 가지고 생성자 안에서 MenuItem에 요청을 보내 커피 이름과 가격을 얻은 후 Coffee의 속성에 저장합니다. MenuItem은 getName() 과 cost() 메시지에 응답할 수 있도록 메서드를 구현해야 합니다. 아래 그림 7.15는 커피 전문점 코드를 클래스 다이어그램을 나타낸 것입니다. 몇 가지 사소한 관계는 생략되어 있지만 중요한 측면은 모두 포함하고 있습니다. [그림 7.15 커피 전문점을 구현한 최종 클래스 구조.] 와우!! 드디어 구현까지 끝났습니다!!오류도 많고 이상한 부분도 많겠지만, “객체지향적인 설계와 구현이 무엇인지 이해하기 시작했을 것이다.” 라고 책에는 쓰여있는데… 네.. 그렇죠, 이제 시작이죠.ㅎㅎ중요하면서 기억해야 할 개념들을 정리해보겠습니다.메시지가 객체를 결정한다는 말의 의미→ 어떤 요청(메시지)을 처리하기에 적절한 객체를 선택 했었죠.책임을 따라 설계가 이뤄지는 과정→ 기억나시죠? 위에서 계속 메시지를 정한 후에 그 메시지를 수신하고 처리할 책임이 있는 객체를 정했어요.인터페이스와 구현의 분리   → 인터페이스는 인터페이스 대로 정의하고나서 그 후에 구현을 했습니다.먼저 긴 글 읽어주셔서 감사합니다! ㅎㅎ마치 제가 저자가 된듯이 설명을 하니까 읽기만 했을 때보다 더 공부가 되는 것 같았습니다. 물론 설계와 구현을 글과 말로 끝낼 수는 없겠죠?! 실제로 직접 설계도 해보고 구현도 해보아야 그때부터 저의 진짜 지식이 되고 실력이 될테니까요. 그래서 요즘 우리 B2B시스템개발팀에서 진행하고 있는 스터디와 실습, 그리고 3~4월부터 시작할 신규시스템 개발을 하는 경험을 통해 더 많이 배워서 더 실력을 갈고 닦아보려고 합니다!!일도 하고 공부도 하면서 준비할 것도 많은 요즘, 누구보다도 저 자신부터 스스로 더더더 화이팅 하려고 합니다. 모두 화이팅 하시고, 주변에 저 같은 쪼랩이들도 많이 가르쳐주시면서 가치 있고 멋진 2016년 보낼 수 있었으면 좋겠습니다!!그럼.. 전 이만 물러나보도록 하겠습니다~ㅎㅎ 긴 글 읽어주셔서 다시 한 번 감사합니다!끗.",http://woowabros.github.io/study/2016/07/07/think_object_oriented.html,woowabros,,NULL,2016-07-07
우아한형제들의 Baby Steps,"우아한형제들은,어제보다 성장함에 의미를 두고,함께 성장하는 것을 꿈꾸는 조직입니다.”2016년도 딱 반이 지난 6월 30일. 지난 반 년을 돌이켜 봅니다. 반 년 동안 어떤 일들을 했나 돌이켜 보다가 생각난 것이, 바로 우아한형제들 기술조직 블로그를 개설한 것인데요. 생각난 김에, 이 블로그를 만들 때 생각하던 것을 말씀 드릴까 합니다.이 블로그는 우아한형제들 기술조직의 “성장일기”입니다.저는 작년 9월에 우아한형제들에 합류했는데요. 그 시점에서 냉정하게 판단하고, 솔직하게 말씀 드리건대, 우아한형제들 기술조직이 엄청나게 뛰어난 기술력과 좋은 개발 문화/프로세스를 갖고 있다고 보기는 어려웠습니다. 개인적으로 잘 하는 분들이야 많이 있었지만, 개인 역량의 단순 합이 조직 역량과 같지는 않으니까요.5년이라는 시간 동안 서비스의 성장에 맞춰서 누구보다 간절히 노력하고 쉼없이 달려왔기에, 정말 많은 사람들이 인지하고 사용하는 배달의민족 서비스가 되었지만, 그 과정에서 만들어진 기술부채로 인한 부담을 안고 있던 상황이었습니다. [다양한 기술부채 청산 도구들…]무엇부터 접근해야 할까 고민하며 살펴 보니, 회사가 바로 제가 입사하기 한 두 달 전에 Confluence와 JIRA를 도입했더군요. 하지만 Confluence는 텅텅 비어 있는 상태. (두둥!)Confluence라는 Tool 은 사실 개발 조직만 써서는 효과가 안 나고, 전사적으로 문서가 모이고 공유되어야 효과가 있는데요. Wiki를 처음 접하는 분들에게는 사용하기 어려운 부분이 있습니다. 그래서 제가 Admin 권한을 획득한 후에 RefinedWiki라는 플러그인을 구매한 후, 사람들에게 익숙한 계층 구조를 만들고, 저도 이해할겸 “배민서비스의 이해”라는 페이지를 만들어 컨텐츠를 만들어 제공하면서 조금씩 활성화를 시켜 나갔습니다. [Confluence에 RefinedWiki Theme을 적용한 예]이 과정에서 제가 놀랐던 것은, 지금까지 겪었던 어떤 조직보다도 빠르게 변화를 받아 들이고, 그것에 익숙해지고 난 후 바로 옆 사람과 옆 조직에 빠르게 전파가 되었다는 점입니다. 일을 더 잘 하고 싶은 마음, 더 가치 있는 일을 하고 싶은 마음이 가득했고, 밀려 오는 파도를 두려워하지 않고 오히려 몸을 맡기는 서퍼처럼, 이러한 변화의 물결을 피해서 도망가는 것이 아니라 그 물결 위에 올라타는 모습들을 보았습니다.그 결과로 지금은 Confluence를 이용한 문서화 수준을 넘어서, 각 프로젝트마다 특성에 맞게 Scrum 또는 Kanban Board를 만들고, 업무들의 진행 상황을 같이 살펴 보고 논의하며 일을 하고 있습니다.가끔 회사 외부 분들을 만나서 대화를 나누다 보면, 배달의민족은 어떤 언어를 이용하여 구현했냐는 질문을 받는데요. 크게 보면 대부분의 서비스 로직이 MS SQL Server라는 DBMS의 Stored Procedure로 구성이 되어 있고, API 요청을 받는 쪽은 PHP로 구현이 되어 있었습니다.DBMS에 모든 부하가 몰리는 구조이기 때문에 서비스 요청이 많아지면서 특정 요청에 대한 처리가 잘못되면 DBMS 부하로 장애가 나타나는 현상이 많았습니다. 근본적인 해결책은 DBMS에 있는 서비스 로직을 Application 서버 단에서 처리하는 것이고, 어떤 프로그래밍 언어를 쓸까 고민하다가 Java를 선택하게 되었습니다. (왜 Java를 선택했는지에 대해서는 나중에 다른 글에서 말씀 드리지요)작년 4사분기. 서비스와 밀접하게 연결되어 있는 빌링 모듈을 별도로 분리하여, 아예 물리적으로도 별도의 시스템으로 구축해야 하는 상황. 이미 PHP로 개발이 진행된 부분이 있었음에도 불구하고, 해당 프로젝트를 수행하는 분들이 저에게 Java로 바꿔서 진행해 보면 어떻겠냐는 의견을 주었고, 저는 일정을 약간 조정해서라도 한 번 시도해보는 것이 좋을 것 같다고 의견을 드렸습니다.그와 동시에 배달의민족 서비스를 Micro-service architecture 형태로 분리하는 첫 걸음이자 Java/Spring을 도입하는 첫 걸음이기도 했습니다. [고생 뒤에 영광. 얼굴만 보면 고생은 내가 다 한 듯]이 때도 정말 놀랐던 것이, 보통은 자신이 감당해야 할 부담이 늘어날 수 있기 때문에 익숙함을 선택하기 마련인데, 프로젝트를 진행하던 분들이 우리가 가야 할 변화의 방향이라면, 힘들더라도 그 당시에 피하기보다는 정면으로 맞서서 어떻게 해서든 해보려고 했다는 점입니다.이러한 일들을 진행하면서, 작년 12월부터 본격적으로 구인을 시작했습니다. 그 때, 제가 많은 분들에게 드렸던 말씀은 다음과 같습니다.이미 잘 하는 조직이니까 여기에 오면 좋다는 것이 아니라, 변화를 만들어 가는 과정에 같이 참여하고 그것을 통해 경험할 수 있는 것이 많다는 점에서 좋은 조직. 그것이 우아한형제들의 기술조직이라고 생각합니다. 다행히 이런 생각에 동참하는 분들이 합류하기 시작했고… 이 분들이 합류하면서 이러한 변화의 방향이 더욱 빨라지고 있는 것 같습니다.이러한 변화가 조금씩 체감되면서, 조직 내에서는 점점 공유가 활발해졌는데요. 공유에 있어서 중요한 것은, 내가 뭔가 대단한 것을 알아서 공유하는 것이 아니라, 내가 새롭게 알게 된 것을 공유함으로써 나 스스로 한 번 더 정리를 하고, 혹시 나와 비슷한 경험을 하게 될 사람들을 돕는다는 것입니다.모르는 것은 부끄러운 것이 아니라는 것. 모르는 것을 모른다고 말하지 않는 것이 부끄러운 것이라는 생각. 현재 실력이 뛰어난 것이 중요한 것이 아니라, 계속 발전하기 위한 노력을 하느냐 안 하느냐가 더 중요한 것이라는 생각.이런 생각이 퍼지면서, 이 블로그가 만들어지기 전 작년 12월부터 사내 Confluence에 여러 개의 글들이 올라오기 시작했습니다. 그리고 7개월이 지난 지금, 130개 정도의 글이 올라와 있습니다. [글목록을 보시면 월간 잡지도 있습니다. ㅎㅎ]보시면 아시겠지만, 그 글의 주제가 정말 대단한 것이어서가 아니라, 새로 Java를 하면서 알게 된 사실들, AWS를 쓰면서 알게 된 것들, 본인이 편하게 일하기 위해 알아보고 수정한 내용들… 그런 것들입니다. 얼마 전 올라온 IntelliJ의 VIM 플러그인 개조한 글도 사내에 먼저 공유된 글입니다.다시 말씀드리지만, 이 블로그는 우아한형제들 기술조직의 성장일기입니다.그래서 이 블로그에는 기술적으로 대단하고 멋진 글이 올라오는 것이 아니라, 우아한형제들이 Java로 전환하는 과정에서 새롭게 배우는 것들, AWS로 이전하고 운영하면서 알게된 것들, 개발자로서 관심을 가지고 살펴 보다가 정리가 필요해서 정리한 것들… 이런 글들이 올라오게 될 겁니다.모르고 있다 새롭게 알게 된 것에 감사하는 마음. 그것을 새롭게 적용해 보고 원하는 결과가 나왔을 때의 벅찬 느낌. 이러한 변화를 이끌고 따라가고, 떄로는 역할이 바뀌어서 따라가고 이끄는 과정에서 느끼는 감정들. 이런 것들을 우아한형제들에 있는 사람들과, 또 저희를 관심있게 지켜 봐 주는 분들과 나누고자 합니다.비단 개발자뿐 아니라, 사람이 가장 밀도있게 성장하는 때는, 잘하는 것을 계속하는 것이 아니라, 어제보다 나은 오늘과 오늘보다 나은 내일이 끊임없이 반복될 때라고 생각합니다.걸음마를 걷다 보면, 아직 미숙하기 때문에 당연히 많이 넘어질 수밖에 없습니다. 넘어지는 것이 두려워서 발걸음을 내딛지 않는 것이 아니라, 넘어지더라도 씩씩하게 발걸음을 내딛고, 옆에 있는 동료가 힘들어하면 같이 부축해서 걸을 수 있는 조직. 우아한형제들 기술조직이 그런 조직이 될 수 있으리라 믿습니다.그래서 이 블로그는 작게는 우아한형제들이 기술적으로 발전해 나가는 걸음마의 기록이고, 좀 더 크게는 비슷한 고민을 하던/하시는 분들과 부족한 경험이나마 같이 나눌 수 있는 그런 공간이 되었으면 좋겠습니다.",http://woowabros.github.io/woowabros/2016/06/30/woowabros_cto.html,woowabros,android,NULL,2016-06-30
IntelliJ 의 VIM 플러그인 마개조하기,"마개조 그거슨 개발자의 로망   …이 아니라, 불편한 것을 고쳐 씁시다.이 글에서 다루는 IDEA 의 VIM 플러그인인 IdeaVIM의 버전은 2015년 11월 2일에 나온 0.44 버전을 기준으로 합니다. (2016년 6월이 되었는데도 아직 다음 버전이 나오지 않았습니다)5월 11일부터 회사에서 라이선스를 받은 IntelliJ IDEA 를 사용하고 있습니다. 한 달 정도 지났군요. 물론 IDEA 만 사용하고 있는 건 아니고, VIM 플러그인이 워낙 불편해서 VIM 과 함께 사용하고 있습니다.IdeaVim 은 매우 구립니다. 차라리 VIM 에 다양한 플러그인을 올려 쓰는 쪽이 낫겠다는 생각이 들 정도죠. 일단 생각나는대로 나열해보기만 해도 다음과 같은 문제들이 있습니다.:shell 명령어가 없습니다. IDE 에 내장된 터미널을 실행하려면 단축키를 사용해야 합니다.mark 가 제대로 작동하지 않습니다. m[a-z] 는 잘 작동하지만, m[A-Z] 에 문제가 있습니다.    예를 들어, a 파일의 3 번 라인에서 mA 를 입력해 mark 한 다음, b 파일을 열고 'A 를 입력하면     a 파일의 3 번 라인으로 이동하는 게 아니라 b 파일의 3 번 라인으로 이동합니다. 매우 짜증납니다.q 로 레코드해서 사용하는 @ 매크로가 엄청나게 느립니다.   같은 파일을 VIM 에서 열어 작업하는 쪽이 훨씬 빠릅니다./ 검색시 incsearch 가 되지 않습니다. set incsearch 옵션이 없어요.  :set incsearch 를 입력해도 unknown command 라는 경고 메시지만 출력됩니다.   IdeaVIM GitHub 에 올라와 있는 set-commands.md에는    incsearch 가 명시되어 있는 걸 보면 다음 버전에는 incsearch 가 지원될 것 같습니다. set showcmd 가 없어서 NORMAL 모드에서 입력중인 커맨드를 볼 수 없습니다.:actionlist 로 IDEA 의 기능 리스트를 볼 수 있고 :action 명령으로 IDEA 의 기능들을 다양하게 사용할 수 있다는 장점이 있습니다만,   이 장점을 묻어버리는 치명적인 단점이 있어요. 새로운 탭이나 창을 띄우는 종류의 액션의 경우 (예 : nnoremap \<F10\>r :action GotoFile\<CR\> )   해당 창이 활성화되자마자 커서를 에디터로 다시 옮겨버리기 때문에 결국 마우스에 손이 가게 만듭니다.    검색 창을 띄웠으면 검색 창에 검색할 문자열을 입력할 수 있도록 커서가 남아 있어야 검색을 할 텐데 말이에요.두번째 키스트로크로 0 이외의 숫자를 받아들이는 커맨드가 f, F, t, T 뿐입니다. :action 으로 IDEA 의 bookmark[0-9] 를 지정하는 것이 가능하길래    .ideavimrc 에서 nnoremap 으로 m[0-9], '[0-9] 를 지정해 보았으나 m0, '0 만 되고 나머지는 작동하지 않습니다..ideavimrc 에서도, command line 에서도 :command 명령을 사용할 수 없기 때문에  사용자 정의 command 를 만들 수 없습니다.function 을 정의할 수 없습니다.이건 딱히 IdeaVIM 의 잘못은 아닌데, 옆집 Eclipse 의 VIM 플러그인인 vrapper 는 :vim 을 입력하면 현재 편집하고 있는 파일을 VIM 에서 열어줍니다.   지구방위대 후뢰시맨이 거대 로봇 후뢰시 타이탄을 소환하는 것과 같은 막강하고 훌륭한 기능입니다.  vrapper 는 됩니다. IdeaVIM 은 안됩니다.    이 기능 하나만으로도 vrapper 는 IdeaVIM 보다 백만배는 좋은 VIM 플러그인입니다. IdeaVIM 의 github 을 보면 Emulated Vim Plugins 기능이 지원된다고 나와 있는데 (surround.vim 을 사용할 수 있다고 합니다)    0.44 버전은 지원하지 않습니다.VISUAL 모드에서 ~ 은 잘 되지만, gu 와 gU 가 안 됩니다.0.44 버전이 릴리즈된 것은 2015년 11월 2일입니다. 그런데 master 브랜치의 최근 커밋을 보니 2016년 4월 30일입니다.  커밋 로그를 읽어보니 그동안 수정된 버그와 추가된 기능들이 꽤 있습니다.  다음 버전을 기다리기보다 빌드해서 써 보는 것도 괜찮겠다는 생각이 드는군요.IdeaVIM 의 개발 환경 구성 방법을 참고하여 IdeaVIM 을 fork 하고 다운받아 빌드한 다음, IntelliJ IDEA 에 설치해 보았습니다. 슥슥 사용해 보니 몇 가지 개선점들이 눈에 들어옵니다. 일단 위에서 언급한 문제점들만을 살펴보도록 합니다.incsearch 가 되는 것과 검색 창을 사용할 수 있게 된 것, 그리고 surround 를 쓸 수 있게 된 것이 눈에 띕니다. easymotion 도 가능했으면 좋겠지만 아직까지는 surround 만 사용할 수 있습니다.  (extention 패키지를 열어보 surround 만 있습니다. 취미삼아 괜찮은 VIM 플러그인을 하나씩 포팅해 추가해보는 것도 재미있겠어요.)최신 개발 버전을 설치하니 그나마 좀 나아지기는 했습니다. 그러나 .ideavimrc 를 편집하는 것만으로는 부족한 점이 많습니다. 그렇다면 커스터마이징을 해야죠. IdeaVIM 의 소스코드를 고쳐봅니다.파일이 너무 많아 막막한데, 일단 생각나는대로 hello 부터 찍어 봅시다.  그러려면 echo 부터 검색해 봐야 겠군요.  (참고로 :echo 'test' 를 입력해 보면 test 라는 문자열이 스테이터스 라인에 출력됩니다.) EchoHandler.java 라는 파일이 검색되어 나오네요. execute 메소드의 소스 코드를 읽어 봅시다. 이제 새로운 커맨드 라인 명령어를 추가할 수 있을 것 같습니다.  다음과 같이 JohnGribTestHandler 라는 이름의 클래스를 새로 만들어 보았습니다.  ‘test’ 를 입력하면 제 영어 이름을 부르며 인사하는 기능입니다.  새로운 커맨드를 사용하려면 CommandParser.java 의 registerHandlers 메소드에도 등록을 해줘야 합니다.  (해당 메소드를 열어보면 다른 커맨드들이 new new new 되어 있는 것을 볼 수 있을 것입니다.) 빌드 후 다음과 같이 입력을 해 보면 원하던 문구가 출력이 됩니다. 이제 다른 기능도 붙여 볼 수 있을 것 같네요. :tabonly 와 비슷한 기능을 하나 만들어 보는 것이 좋을 것 같습니다.  :only 또는 :onlytab 을 입력하면 현재 편집중인 에디터를 제외한 다른 에디터를 모두 종료해주는 기능을 붙여 보죠.1처음에는 VimPlugin.getFile().closeAllButCurrent(); 를 써서 종료해보려 했는데 이게 이제는 안 쓰는 메소드더군요. 그래서 아래와 같이 작성하였습니다. 와아~ 테스트해보니 잘 되네요. 여러 파일 탭을 열어놓은 상태에서 :only 를 입력하니 편집중인 탭 하나만 남고 다 닫힙니다.그러면 이번에는 불만사항 1 번이었던 :shell 명령어를 구현해 봅시다. :actionlist term 으로 검색해보니 ActivateTerminalToolWindow 액션이 있네요. 이걸 쓰면 될 것 같습니다. :shell 뿐만 아니라 :sh 로도 실행되게 해 줍니다. CommandParser 의 registerHandlers 에 등록해주는 것도 잊지 말고 해줍니다. 빌드 후 :shell 을 입력해 보면, IDEA 의 터미널 윈도우가 빰 하고 나타납니다. 이제 얼마든지 새로운 커맨드 라인 명령어를 만들어 붙일 수 있게 되었군요. 입맛에 맞게 고쳐 쓰면 될 것 같습니다.마개조는 이제부터 시작입니다.IdeaVIM githubIdeaVIM REFERENCE MANUAL by Rick MaddyIdeaVIM set optionsIdeaVIM 의 개발 환경 구성 방법위에서 작업한 예제 소스코드는 제 github에서도 볼 수 있습니다.:shell 구현:only 버그 수정EOB사실 :only 는 이미 구현되어 있는 기능입니다. 하지만 deprecated action 을 사용하기 때문에 작동하지 않습니다. 디버깅은 이 글의 목적이 아니니 일단 기능을 추가하는 내용으로 작성하였습니다. 해당 기능을 디버깅한 코드는 여기에서 읽어볼 수 있습니다. ↩",http://woowabros.github.io/tools/2016/06/18/ideavim-customize-00.html,woowabros,,NULL,2016-06-18
스타워즈 깨어난 포스 리뷰,"우아한형제들의 CTO실 사람들이 새로운 기술이나 개발 코드만 얘기하지는 않습니다.   여행담이나 새로 산 전자 기기에 대한 얘기, 영화에 대한 감상도 많이 나눕니다.  작년 겨울, 스타워즈 깨어난 포스에 대한 관련 정보와 감상 리뷰를 사내 위키에 올렸었고, 그 글을 옮겨봅니다.알게 모르게 개발자와 스타워즈는 여러 관계를 가지고 있습니다.  포토샵은 스타워즈의 특수효과를 담당하던 ILM에서 사용하던 그래픽 편집툴을 어도비에서 사들여 상용화한것입니다.  스티브 잡스의 재기에 기여한 픽사는 원래 ILM과 함께 루카스필름의 디지털 특수효과를 담당하던 부서였습니다.  자바에서 꽤 알려진 Datasource 관리 라이브러리중에 c3p0라는 라이브러리가 있습니다. 어디서 따온 이름인지 아시겠죠?  우아한형제들에서 쓰는 github의 마스코트인 옥토캣의 가장 인기있는 버전은 Octobi Wan Catnobi 입니다. 존재 하지 않는 페이지를 방문하면 쉽게 볼수 있습니다. 2012년에 스타워즈의 아버지 조지 루카스는 스타워즈 관련 권리와 루카스필름 계열사를 모두 디즈니에게 팔았습니다.  쉽게 말해 스타워즈의 모든 것은 디즈니에게 넘어갔습니다. 이후 디즈니랜드의 여러 곳에서 스타워즈를 볼 수 있습니다.하지만 천하의 디즈니랜드가 라이드 몇 개 추가하려고 스타워즈를 산건 아니겠죠.  스타워즈로 가장 큰 돈을 버는 방법은… 그렇습니다. 후속작을 만드는 것이죠.클래식 3부작이 끝나고 많은 사람들이 1-3편과 7-9편을 기다렸습니다. 그리고 15년이 넘어 에피소드 1편이 개봉을 합니다. 하지만 팬들이 바랬던 방향과 45도 정도 어긋난 1편 때문에 조지 루카스는 기존 팬들에게 있는대로 욕을 얻어먹습니다. 그나마 2편, 3편으로 가면서 아나킨이 다쓰베이더로 변하는 모습으로 멋지게 마무리를 하였습니다만, 프리퀄에는 엑스윙의 화려한 자태도, 타이 파이터의 ‘우아아앙’ 하는 울림도, 밀레니엄 팔콘의 매끈한 비행도 없었습니다. 훨씬 화려해진 라이트세이버 대결과 드론 vs 클론 트루퍼의 물량전 전투라는 지상전 쪽은 매우 발전되었지만 다른 한 축인 우주전쪽이 너무 미약했던 부분은 큰 아쉬움으로 남게 됩니다.원래 루카스의 계획이나 EU의 후속편들이나 시퀄 3부작은 은하 제국 몰락 직후의 이야기를 다루고 있었습니다. 루크 일행과 제국 붕귀후 잔당과의 대결을 다룬 쓰론 제독 3부작이나, 다시 부활한 황제에 맞서는 루크의 이야기 등등이죠. 하지만 프리퀄이 나오면서 후속작의 시간대와 클래식 3부작 배우들의 나이가 안 맞게 되었습니다. 주역을 맡아야 할 배우들이 중년, 노년이 되어 버린 것이죠.그렇다고 완전히 새로운 배우와 이야기들로 후속편을 만든다?  프리퀄은 그래도 아나킨, 오비완, 요다 같은 익숙한 캐릭터들이 연결점을 만들어 주고 있습니다만, 생판 모르는 이름을 가진 캐릭터들이 나와서 ‘네가 익숙하진 않겠지만, 이거 스타워즈 이야기 맞어’ 이러고 있으면 받아들이기가 쉽지 않죠. 루크,레아,한의 자식들이 나오든, 다른 인물들이 나오든 최소한 7편은 기존 작품들과의 연결점을 가지고 있어야 하고 가장 연장자인 한 솔로 (해리슨 포드)가 아직 현역에서 뛰고 있는 지금에서 더 이상 미룰 수가 없는 상황인것이죠.클래식 3부작이 끝난 이후에 제국의 몰락 이후 혹은 영화화 되기 한참 이전 시대를 다룬 소설과 게임, 만화들이 나옵니다. 이 소설, 게임, 만화 등은 팬픽이나 단순한 2차 창작이 아니라 루카스의 관리를 받고 계약을 맺고 나온 작품들입니다. (다만 우리나라에는 거의 수입이 되지 않아서 접하기가 어렵습니다.) 여기에서 작가의 창작력이 덧붙여지면서 새로운 이야기와 설정들이 늘어나게 됩니다. 이런 설정 중에는 조지 루카스가 다시 흡수해서 프리퀄 3부작에 반영한 것들도 있습니다. 영화라는 가장 큰 축을 중심으로 수 많은 영화화되지 않은 이야기를 모아 Extended Universe (EU)라는 하나의 세계관으로 묶어 놓았고 이 설정 체계는 스타워즈 캐논이라 불립니다.수 많은 설정 충돌을 견디지 못하고 죄다 평행 세계로 갈라버린 DC나 마블과는 다른 방향으로 발전한 것이죠.모든 설정에서 가장 최우선 순위는 조지 루카스입니다. 하다못해 루카스가 지나가다 ‘제다이는 원래 결혼 할 수 있어’ 라고 한 마디라도 던지게 되면, 에피소드 2, 3에서 비밀 결혼 하고 몰래 데이트 하던 아나킨과 아미달라의 행적은 뻘짓이 되버리는 거죠. 그러면 설정 담당자들이 머리를 쥐어 짜서 ‘원래 제다이는 결혼 할 수 있는데, 수련을 하다보니 오래전부터 결혼 안하는게 암묵적 관행이 되었고 결혼을 해도 드러내지 않는다’ 라고 구구절절 설정을 뜯어고쳐야 하는 것이죠.그 다음은 영화화된 내용. 영화화된 에피소드 1~6과 클론워즈3D가 가장 중요한 공식 설정이 됩니다. 다른 어떤 참신한 설정도 영화화된 내용과 불일치 하게되면 받아들일 수 없습니다.그리고 TV로 방영된 클론워즈와 레벨즈가 있고, 그 외 소설, 만화, 게임 등등은 등급별로 관리를 받고 있습니다.중요한건 이 모든건 등급의 차이는 있지만 공식 설정이’었‘다는 것이죠.그렇지 않습니다. 현재는 영화 1-6편과 클론워즈 3D만 유효하고 나머지는 리부트 되었습니다. 기존의 EU는 스타워즈 레전드로 바뀌어 불리게 되었습니다.왜 이렇게 되었냐 하면, 후속작을 만들려고 보니 기존의 설정이 너무 촘촘하게 깔려있었기 때문입니다. 이 틈을 비집고 설정을 무너뜨리지 않으면서 새로운 이야기를 만들기가 너무 힘든것이죠. 더구나 디즈니는 7-9편 시퀄외에도 한 솔로 외전, 저항군의 외전인 로그 원 등의 작품을 계획 중인데 이 들 작품을 끼워넣을 공간이 쉽지가 않았습니다.또 한편 최근 EU의 행보가 불안했던 점도 한 몫했습니다. 이야기는 여전히 루크와 그 일가를 벗어나지 못하고 있고, 시간이 흐르면서 파워 인플레가 일어나서 루크는 엄청난 먼치킨이 되어버렸습니다. 프리퀄 이후에 나왔던 EU 작품의 퀄리티가 중구난방이 되면서 혼란이 많았기도 했고요.여차저차해서 디즈니는 기존의 캐논을 리부트했습니다. 앞으로 만들어질 새로운 영화만이 공식 설정에 추가될 예정입니다. 아니 새로운 설정의 틀 안에서 새로운 영화가 나온다고 봐야겠죠.네. 7편에 기대하는 것은 하나입니다. ‘2010년대의 특수 효과와 클래식의 감수성의 만남’. 기존 클래식 팬들에게는 다행히도 시사회 평은 모두 그렇다고 하네요. 4편에 대한 오마주가 너무 강해서 싫다는 평이 있을 정도니까요. 예고편은 이런 기대감을 충분히 만족시켰습니다. X윙 vs 타이 파이터의 전투, 밀레니엄 팔콘의 비행 장면, 무엇보다 한 솔로의 ‘We are home.’ 대사는 드디어 돌아왔어 라는 느낌 그 자체였습니다.7편 리뷰 쓰겠다고 해놓고 서론만 수십 줄이네요. 한 솔로의 등장같은 예고편에 나왔던 장면은 이미 공개가 됐다고 생각해 그냥 쓰겠습니다.4편에 대한 오마쥬가 너무 강하다는 말은 사실이었습니다. 7편을 제대로 감상하기 위해서는 4편은 필수, 5,6편은 왠만하면 보는것이 좋습니다. 아래 정리한 오마쥬 목록에서 보듯이 클래식 영화와 EU를 알아야만 알 수 있는 장면이 너무 많습니다. 클래식 팬들에게는 추억을 불러일으키는 내용이지만, 잘 모르는 사람에게는 뭐가 웃긴 대사인지 뭐하러 저 장면이 들어갔는지 모르는 부분이 매우 많습니다.  뭐 사실 스타워즈 시리즈란게 뼈대만 놓고 본다면 ‘사막 행성 촌뜨기 + 억류당한 귀하신 몸 + 믿음직하지못한 수다쟁이 + 백전노장 할아버지’ 가  ‘얼굴 안보여주는 검은 옷의 악당 + 슈퍼 우주 병기’ 에 대항해 싸우는 우주 모험 활극이지 않습니까? 그런면에서 본다면 7편은 이미 대대로 굳어진 클리세에 충실히 따르면서 기존의 느낌을 새로운 감각으로 잘 뽑아냈다고 봅니다.  그래도 새로운 부분이 있는가 싶을 정도로 이름만 바꿔서 기존 관계 그대로 나오는 부분이 심하긴 합니다. 은하 제국은 퍼스트 오더로, 다쓰 베이더는 카일로 렌으로, 데스스타는 스타킬러로…  이 부분은 8편에서 얼마나 차별화를 시키느냐에 따라 평가가 달라질 수 있을것 같습니다. 8편까지 5편을 그대로 따라간다면 평가가 더 떨어질 수는 있을것 같습니다.과거 시리즈를 떠올리는 장면들이 많지만 그중에서 저에게 제일 반가운 장면은 ‘우주에서 제일 빠른 고철 덩어리’ 가 등장하는 장면이었습니다. 전혀 예상하지 못하고 있다가 갑자기 기존 시리즈와의 연결점을 확 던져주니 깜짝 놀라면서 뭉클하더군요. 빠질 수 없는 전통의 대사 ‘May the force be with you.’ ‘I have a bad feeling about this.’, ‘We’re doomed’ 3종 세트까지 더해서 말이죠.아마 보고나서 실망하신 분중에는 풀리지 않은 떡밥이 너무 많아서 그런 분들이 꽤 있을겁니다. 그런데 그것마저도 시리즈의 전통이니 어쩌겠습니까… 게다가 감독이 떡밥의 제왕인 J.J.에이브럼스이기까지 하니 시너지가 장난 아닙니다.  기존 시리즈 중에서 영화내에서 완결이 딱부러지게 나는 작품은 4편과 기존 완결편인 6편 뿐이고, 나머지 작품들은 하나같이 다음 작으로 해결을 넘긴 떡밥들이 쌓여있습니다. 대표적인게 5편에서 탄소냉동된 한 솔로이죠. 주인공 3인방 중에 한 명이 잡혀갔는데 그대로 끝나는 영화가 세상에 어딨습니까?암튼 시작부터 끝까지 기존 작품 특히 클래식 3부작의 틀에서 하나도 벗어나지 않는 바람에 이게 좋은 사람에게는 평이 끝내주게 좋은 반면에 익숙하지 않은 사람들에게는 평이 좋기 어렵습니다. 왜 이렇게 과거 작품과의 연결에 집착이 심하냐 하면, 이 작품의 최대 타겟이 클래식 시리즈의 팬들이기 때문입니다. 그 다음이 프리퀄때 유입된 팬. 기존 작품을 모르는 사람은 아예 안봐도 좋다는 걸 각오하고 만들었다고 보입니다.  워낙에 기존 팬덤이 거대하기 때문에 이 사람들에게만 기대도 흥행은 문제 없는거죠. 신규 팬은 어차피 기존 팬들이 아들,딸 데리고 보러올테니 그걸로 늘어날거고요. 프리퀄 팬도 별로 신경을 안쓰는게, 프랜차이즈 상품 중에서 여전히 제일 잘 팔리는건 엑스윙과 타이 파이터이지 나부 파이터가 아니거든요. (일례로 레고 엑스윙은 8개 정도 온갖 사이즈로 반복 출시됐지만, 레고 나부 파이터는 2개…. T_T)결론은 .. 기존 팬이라면 4-6편을 복습하고 나서 본다면 강추입니다. 전 일단 3번 봤습니다. (그리고 기술 블로그에 이 글을 다시 쓰는 현재는 블루레이 타이틀을 구매한 상태입니다.)  하지만 스타워즈를 잘 모르던 사람이 굳이 볼 필요는 없을 것 같다 입니다.",http://woowabros.github.io/nerd/2016/06/02/starwars_force_awakens.html,woowabros,,NULL,2016-06-02
Google Apps Script 사용 이야기 (3/3),"우아한형제들은 협업 도구로 Google Apps를 사용하고 있습니다. 사내 업무를 손쉽게 자동화하기 위하여 Apps Script를 도입한 이야기를 소개합니다. <마지막 이야기>우리는 사내 알람 봇을 가지고 있었다. 서비스 이슈를 모니터링하고 알람을 하는 역할을 한다.  Google Apps Trigger로 알람을 제작하면 서버에 부담이 가지 않기 때문에, 재미있는 알람을 만들어볼 수 있었다. [식단표를 읽어서 오늘의 식단을 알려준다.]우리는 Google 리소스를 사용하여 회의실을 관리하고 있었다.  캘린더에서 회의실 예약을 하는 것은 쉬웠다. 그렇지만 한 눈에 수많은 회의실의 현황을 파악하는 것은 캘린더로는 부족했다. 그래서 Spreadsheet를 이용하여 간단하게 대시보드를 만들어보았다. [캘린더 관리 UI는 편한데..] [어떤 회의실이 사용되고 있는지 파악하기는 불편하고..] [이렇게 봐야지~]통계 메일 자동화를 서버 없이 구현해볼 수 있을 것 같았다. Apps Script가 우리의 DB, API를 접근하고, 어떤 Google 서비스까지 제어할 수 있는지 조사해보았다. [Apps Script가 할 수 있는 것들]마지막으로, 우리는 Google Analytics를 활용하고 있었다. [Analytics의 데이터를 손쉽게 내려받고, 이후의 과정을 자동화했다. ]Apps Script로 구현할 수 있는 모든 기능은 기존에 사용하던 다른 언어와 방법으로 구현할 수 있는 기능들이다.  그렇지만 반복적인 작업을 안정적으로 운영해야 한다면 이야기가 조금 달라진다.  반복적인 작업을 하기 위한 서버를 두어야 하고, 서버에 장애가 생기지 않도록 관리해야 한다.  또한 네트워크와 보안 이슈가 발생하지 않도록 조치하고, 관리해주어야 한다.고작 반복적인 문서 작업과 반복적인 보고 업무를 자동화하기 위해 이런 노력을 누가 들이겠는가.  그렇지만 이 모든 문제를 Google이 해결해준다. 구현하기 위해 코딩해야 하는 양도 적다. 큰 노력이 필요하지 않아졌다. 그리고 많은 사람들이 반복적인 업무를 가지고 있다. 일과 시간의 몇 시간 정도를 반복 업무에 투자하는 사람이 있을지도 모른다. Apps Script로 이런 반복 업무를 제거할 수 있도록 도와준다면, 다들 좀 더 창조적인 업무에 시간을 쏟을 수 있지 않을까?",http://woowabros.github.io/tools/2016/05/30/apps_script_3.html,woowabros,,NULL,2016-05-30
Google Apps Script 사용 이야기 (2/3),"우아한형제들은 협업 도구로 Google Apps를 사용하고 있습니다. 사내 업무를 손쉽게 자동화하기 위하여 Apps Script를 도입한 이야기를 소개합니다. <두 번째 이야기>Google Apps의 운영 Role을 다른 사람이 가져가게 되었다. 사용자 관리의 어려움을 알고 있었기에, 내가 사용하던 스크립트를 간단하게 이용할 수 있도록 범용으로 만들어보기로 하였다.기능은 간단하다. 1) Sheet의 값을 읽어서, 2) 형식에 맞게 사용자를 등록하고, 삭제하고, 수정한다. [Google Spreadsheet에 사용자 정보를 입력하고 버튼을 누르면 끝!]일단 간단하게 기능을 만들고 나니, 굳이 수동으로 조직도를 관리할 필요가 없다는 생각이 들었다. 인사 시스템에서 회사 조직도를 관리하고 있으니, 이 정보를 Google에 연동해보기로 했다. [스크립트가 인사 시스템을 이용해서 모두 자동으로 처리해준다. ]Apps Script의 Trigger가 하루에 3번 조직도 동기화 스크립트를 실행한다.  조직 동기화 스크립트는 신규입사자의 계정을 생성하고, 퇴사자의 계정을 삭제한다.  그리고 조직도가 변경되면, 변경된 조직도에 맞게 Google의 조직도를 수정한다.모든 작업이 자동으로 이루어지는 만큼, 잘 되었는지 확인할 길이 없다. 그래서 메일 자동보고 스크립트를 추가했다. [자동으로 처리한 결과를 자동으로 알려준다. ]처리한 내역을 간단하게 Spreadsheet로 제작한다.  시트의 내용을 표로 구성하여 각 담당자에게 메일로 발송한다.보고서를 간단하게 구성할 수 있다는 점이 굉장히 매력적이었다. 우리는 굉장히 다양한 업무에 Google Spreadsheet를 활용하고 있었다.  그렇기에 또 다른 자동화에 욕심이 생기기 시작했다…",http://woowabros.github.io/tools/2016/05/30/apps_script_2.html,woowabros,,NULL,2016-05-30
Google Apps Script 사용 이야기 (1/3),"우아한형제들은 협업 도구로 Google Apps를 사용하고 있습니다. 사내 업무를 손쉽게 자동화하기 위하여 Apps Script를 도입한 이야기를 소개합니다.  <첫 번째 이야기>Google Apps를 공식적으로 회사에 도입하게 되었다. 초기에 Google Apps를 어려워하던 분들도 있었지만, IT 회사 답게 다들 금세 적응하고 잘 활용하기 시작했다.업무를 좀 더 편하고 매끄럽게 도와주기 위하여 Google Apps를 도입한 만큼, 사람들이 불편을 느끼지 않도록 잘 운영하고 싶었다. 단지 Google Apps의 관리 도구인 Google Admin Console의 UI에서는 다수의 사용자를 효율적으로 관리하기 힘들었다. [Google Apps 관리 도구]2~3명의 이메일 등록이나 수정, 삭제 요청이 들어오면 5분이면 처리할 수 있었다. 하지만 20~30명 정도의 요청이 들어오면 한명 한명 작업하는 게 너무 번거롭고, 실수가 없었는지 확인하기도 힘들었다. 그리고 가장 큰 문제는 Google Apps의 관리 도구가 느리다는 것에 있었다. [로드 중입니다…] [로드 중입니다……]이 작업을 어떻게 편하게 할 수 있을까 고민하다 발견한 것이 Google Apps Script이다.어느 날, 그룹메일에 전 사원의 이메일을 추가해야 하는데, 시스템 메일로 사용할 이메일을 제외해야하는 이슈가 있었다. Google Admin의 그룹메일 관리 기능은 csv로 관리할 수 있는 기능을 제공하지 않는다.  물론 콤마(,)로 분리한 여러 명을 동시에 등록하는 기능은 제공하고 있기에, 엑셀과 적절한 수작업으로 할 수는 있었다. 그렇지만 귀찮았기 때문에 Apps Script로 기능을 만들어보기로 하였다. [간단하다.]너무 간단하게 처리가 되었다. 작성한 코드는 1) 조건에 맞는 사용자를 배열로 가지고 온 다음, 2) 반복문으로 해당 그룹에 사용자를 추가하는 코드 뿐이다. 심지어 인텔리센스 기능을 내장하고 있어서, 함수명으로 기능을 예측하고 몇 번의 테스트를 해본 다음, 기능을 뚝딱 만들어낼 수 있었다.그리고 인텔리센스 목록 중, 굉장한 문자열을 보고 본격적으로 사용 실험을 시작하게 되었다… [헐.. 설마.. 내가 생각하는 그 것이 가능한가 ?? ]",http://woowabros.github.io/tools/2016/05/30/apps_script_1.html,woowabros,"python,xml,json,php",NULL,2016-05-30
[우아한 인터뷰] 신입사원 김용대 편,"우아한형제들의 기술 블로그를 열었습니다. 이 곳에 차곡차곡 쌓여갈 글들은 기술공유와 더불어 우아한형제들의 개발부서인 CTO실 사람들의 이야기를 담을 예정입니다. 그 시작으로 최근에 입사한 신입사원 김용대님을 인터뷰했습니다. [긴장한 기색이 역력한 김용대님]이제 들어온 지 일주일 정도 되어서 인수인계를 받고 있는 중인데요. 방금도 인수인계를 받다 왔네요.(웃음)저는 IT인프라팀에 배속 받았어요. 저희 팀은 우형의 모든 구성원이 보다 편히 일할 수 있도록 내부 서비스를 개발하고 환경을 구축하는 일을 하고 있어요.  인턴 실습 기간 동안 IT인프라팀에서 구글 스크립트를 활용한 업무 자동화 프로세스를 만든 경험이 있는데 앞으로 맡을 업무들도 그런 업무의 연장선 상에 있을 것 같아요. [배민개발학당 인턴 모집 포스터 촬영 중]에피소드는 아닌데, *배민개발학당이 저에게는 두 번째 인턴 경험이었거든요. 인턴 제도가 굉장히 잘 되어있는 회사라는 느낌을 받았어요. 교육기간을 거쳐 개인 프로젝트와 그룹 프로젝트, 실무까지 경험해 보니 무척 체계적인 커리큘럼이라는 생각이 들더라구요. 그래서 인턴 프로그램이 8기까지 이어 올 수 있었구나 싶어요.*배민개발학당 : 우아한형제들 CTO실의 개발인턴 프로그램다른 회사에서 첫 인턴을 마무리하면서 멘토에게 ‘인턴 기간동안 적극성이 부족했다.’는 피드백을 받았거든요.  그 점을 보완하고 싶었어요. 제 개발 실력에 대한 아쉬움도 있었고요.  그래서 ‘아주 큰 대기업과 완전히 작은 벤쳐에서 각각의 아쉬운 점들을 채우고 본격적으로 취준을 해보자!’는 다짐을 했는데 ‘큰, 커져가는 벤쳐’에서 인턴도 하고, 일도 하게 됐죠! 배민개발학당 인턴 생활은 작년 12월의 김용대가 내린 최선의 선택이었다고 생각합니다. [서울사람 김용대]스물 세 살 때요. 저는 문과 출신이어서 미적도 대학교 1학년 때 처음 배웠어요.  전공 수업 때 애들이 hello world 찍고 테트리스 만들면서 흥분할 때도 그 의미를 잘 몰랐죠.  그러다 전역 후에 컴퓨터 공학과에 가면 컴퓨터 수리공 되는거라고 놀리던 친구를 골탕 먹이고 싶어서 해킹 프로그램을 테스트해보기 시작했는데 거기서 재미를 붙였어요.아닙니다.  지금은 한참 열심히 배워나가는데 집중하고 있어요.아닙니다. (웃음) 언젠가 창업을 해보고 싶은 꿈이 있는데요. 대학 때 멋진 앱을 만들어보려고 기획하는 친구와 디자인하는 친구를 모아서 프로젝트를 진행했었어요.  그런데 아무리 멋진 아이디어와 디자인을 가지고 와도 개발하는 제 능력이 부족하니까 만들 수 있는 게 결국 누구나 생각할 수 있는 평이한 수준 밖에 안되더라고요.  그런 상황이 참 싫었거든요. 그 언젠가를 위해 지금은 개발을 ‘잘’ 하는 사람이 되는 것에 최선을 다하고 싶어요.책을 많이 보고 있어요. 특히 제 경우에, 개발과 관련된 공부는 무턱대고 덤비는 것보다 책을 통해 기초를 만들어놓고 덤빌 때 시간 투자를 효율적으로 하게 되더라고요.  낯선 것을 익힐 때는 이해가 안되더라도 책으로 빠르게 읽으면서 익숙한 느낌을 만들어 놓는 게 도움이 되거든요.맞아요.  그런데 책 구매 자체에 대한 지원보다도 회사 전체적으로 책을 읽는 문화가 자리잡혀 있는 게 정말 좋았어요. 누군가에게 ‘이런 것을 공부해보고 싶다.’고 한 마디 던지면 다들 기다렸다는 듯이 술술 다양한 책들을 권해주시거든요.  제가 지금까지 본 책은 전공책, 서점에서 높은 순위에 있는 추천 도서, 혹은 검색을 통해서 본 게 전부라 저보다 앞서 걸어가는 분들로부터 검증된 책들을 추천받을 수 있다는 게 저에겐 정말 꿀팁 중에 꿀팁이죠.치킨입니다!!!!!!!!B모 사의 핫후라이드 치킨요!!!치킨은 무조건 뼈가 있어야 합니다!! 순살은 치킨이 아니죠!! [우아한형제들 워크샵 ‘기발한피플샵’ 중 | 팀원의 생일 케익을 꾸미는 중]서비스, 문화, 사람을 꼽고 싶네요. 어떤 일을 하는 회사인지가 일단 중요하고요.  함께 일하는 사람들, 직장 문화 같은 게 중요한 것 같은데 사람과 문화는 서로 영향을 미치는 요소라고 생각해요.  사람들이 문화를 만들고, 문화가 사람들을 만들고. 우리 회사는 특히 자발적으로 행동하는 문화가 잘 잡혀있는 것 같아요.  예를 들면 스스로 자기 자리를 청소하고, 키친을 청소하고, 정리하고 그런 것들요.  구성원들이 스스로 그런 문화를 지키려고 노력하고 있는게 신기해요.전체적으로 다들 굉장히 재밌고, 이상한 분들이예요. 아직까지는 제가 제일 정상인 거 같은..? [‘굉장히 재밌고, 이상한 분들’의 소통st.]*우형 CTO실에서 ‘이상한 사람’ == 개그욕심 충만, 똘끼 충만, 덕력 충만한 사람을 가리킵니다.아 그래요? (웃음) 농담이고, 다들 굉장히 즐겁게, 열심히 일하고 있는 것 같아요. 특히 저는 인턴 시절에 멘토였던 분들을 눈여겨 보게 되더라고요. 저의 내일, 내일 모레의 모습이니까. 그 분들이 각자 자기 자리에서 열정을 가지고 일하고, 공부하는 모습을 보고 내가 가야할 방향들을 보고 있어요.음.. 저는 역으로, 인턴 때 CTO님께 어떤 개발자가 되고 싶냐고 물어본 적이 있어요. 그 때 CTO님이 ‘어떤 개발자가 되는 게 중요한 게 아니라…’ …잠시만요. 엄청 멋진 말을 들었는데.. ‘어떤 개발자가 되는 게 중요한 게 아니라…’ ……아.. 정말 멋진 이야기였는데 기억이 안나네요..저는 ‘같이 일하고 싶은 개발자’가 되고 싶어요. 그러기 위해서는 유머러스하고, 의사소통도 잘 되는 것도 중요한데요. 사실은 그것보다 개발자로서의 능력을 동료한테 인정 받는 게 가장 어려운 일이라고 생각하거든요. 같이 더 일하고 싶어서, 가지 말라고 붙잡을 만큼의 개발자가 되고 싶습니다.",http://woowabros.github.io/interview/2016/04/28/interview_yongdae.html,woowabros,,NULL,2016-04-28

title,content,url,cnt,source,keyword,image,createdAt
2019 카카오 블라인드 공채 2차 오프라인 코딩 테스트 문제 해설,"지난 10월 6일(토) 2019 블라인드 공채 오프라인 2차 코딩테스트가 진행되었습니다. 작년에는 8시간 동안 온라인으로 진행한 것과는 달리 오프라인으로 5시간 동안 치러졌는데요, 어떤 의도로 출제하였는지 살펴보겠습니다.작년 문제 출제 의도를 기억하시는지요?작년 문제에는 매우 많은 장치가 숨겨져 있었으나 정작 요구사항을 그대로 구현하기만 해도 합격선인 8만 점을 얻기에는 충분했었습니다.그리하여 올해는 시스템 디자인 역량을 좀 더 중점적으로 평가하고자 하였습니다.올해 오프라인 2차 테스트 문제는 다수의 엘리베이터(1대~4대)를 제어하는 시스템을 구현하는 것입니다. 핵심 구현에 집중할 수 있도록 엘리베이터 동작 및 상태는 서버에서 관리하고, 서버와 통신은 작년과 같이 REST API 및 JSON 포맷으로 주고받도록 하였습니다.지원자는 주어진 빌딩별 승객 트래픽을 분석하여 가정 적합한 엘리베이터 제어 알고리즘을 구현해야 합니다.지원자가 제어할 엘리베이터 시스템은 다음과 같습니다.명령에 따른 status 전환을 그림과 표로 표현하면 아래와 같다.엘리베이터 1대의 동작은 대부분 지원자에게 친숙할 것입니다. 우리가 실생활에서 자주 접하는 엘리베이터 알고리즘은 “collective control”, “elevator algorithm” 등으로 불리는데 아래와 같이 2가지 규칙으로 구성됩니다.간단하고 직관적인 알고리즘입니다. 운영체제 수업을 열심히 들은 학생이라면 디스크 스케줄링 알고리즘 중 하나인 look 알고리즘을 떠올릴 수도 있겠습니다.반면, 복수의 엘리베이터를 제어하기 위해서는 추가로 승객의 요청을 어느 엘리베이터에 할당할 것인지를 결정해야 합니다. 얼핏 보면 간단해 보이는 이 요구사항의 추가로 시스템은 제법 복잡해지게 됩니다. 어느 엘리베이터에 승객을 할당하는 것이 효율적인지 비용 계산을 해야 하고, 승객이 어디에 탑승하고 있는지를 관리해야 합니다. 층별로 구역을 나누어 운행한다면(홀/짝, 고층/저층 분리 운영 등) 환승 기능도 구현해야 합니다.1대의 엘리베이터 제어는 쉽고 간단해 보이지만, 3문제를 모두 풀기 위해서는 반드시 복수 엘리베이터를 제어해야 합니다. 또한 각 문제의 승객 패턴도 다르고, 승객 패턴에 따라 효율적으로 엘리베이터를 구성해야 합니다. 따라서 시스템 디자인 시 다양한 엘리베이터 알고리즘을 실험할 수 있도록 추상화 & 모듈화를 통해 변경에 유연하도록 디자인해야 합니다. 실제 내부 모의 검증 시에도 문제 요구사항 분석 없이 1대만 먼저 운행하는 식으로 시작한 피실험자의 경우, 여러 대를 제어하는 시스템으로 리팩토링하는 단계에서 시간을 너무 소모하여 시간 내에 문제를 다 풀지 못하는 경우가 속출하였습니다.엘리베이터 요청은 크게 3가지로 분류할 수 있습니다. (빌딩의 입구는 1층이라고 가정) (참고: https://beta.vu.nl/nl/Images/werkstuk-boer_tcm235-91327.pdf)이번 테스트에서는 총 3개의 빌딩을 제시했습니다.첫 번째 어피치 맨션의 경우 5층 높이의 작은 맨션이고 총 요청은 6개입니다. 쉬운 문제를 통해 엘리베이터 시스템에 익숙해지고 API 연동을 해보는 몸풀기 문제라 할 수 있습니다.두 번째 제이지 빌딩은 25층 건물에 요청은 200개입니다. 위의 3가지 타입의 요청이 적절히 섞여 있는 가장 일반적인 형태의 모델이라고 할 수 있습니다.세 번째 라이언 타워는 25층 건물에 요청은 500개입니다. 라이언 타워는 승객의 패턴을 제공하고, 이에 맞는 효율적인 엘리베이터 분배 알고리즘을 구현하도록 유도한 문제입니다. 입구는 1층이고, 2층-12층은 개별 회사에 임대를 하고, 13층-25층은 카카오가 사용합니다. 따라서 2층-12층 내에서는 층간 이동이 거의 없는 반면, 13층-25층 사이에서는 층간 이동이 빈번합니다. 또한 13층에 카카오프렌즈샵이 위치하여 1층과 13층을 오가는 고객들이 많다는 상황을 설정하였습니다.가장 쉬운 접근법입니다. 요청이 들어온 순서대로 태우고 목적지에 내려준 후 다음 요청을 처리하는 형태입니다. 어피치 맨션의 경우 이 접근으로도 쉽게 풀립니다만, 제이지 빌딩, 라이언 타워의 경우 각각 약 4000, 13000 timestamp로 좋은 점수를 받을 수 없습니다.위에서 설명한 collective control 알고리즘입니다. 가장 친숙한 동작 방식입니다. 1대만 사용했음에도 불구하고 제이지 빌딩에서 972의 timestamp를 기록할 정도로 효율적입니다. 라이언 타워의 경우 약 2000 timestamp를 기록할 수 있습니다.이번 문제의 엘리베이터는 보통의 엘리베이터와 다른 점이 있습니다. 이 부분을 활용하면 고득점을 할 수 있는데요. 출제진도 예상하지 못한 다양한 접근 방법들이 나와 놀랐습니다. 어떤 것들이 있는지 살펴보겠습니다.0번 엘리베이터를 주목해주세요. 3명의 승객을 태우고 올라가던 엘리베이터는 17층에서 승객 1명을 내려주고 내려가는 방향의 승객 2명을 태워 올라갑니다. 일반적인 알고리즘과는 다른 방식인데요. 힌트는 평가 방법에 있습니다. 평가 조건은 모든 승객을 목적 층으로 수송해야 하며 가장 마지막 승객이 목적 층에 하차하였을 때의 시간 기준으로 평가를 합니다. 따라서 엘리베이터 내에 공간이 충분하다면 문이 열린 김에 태워가는 것이, 방향 전환 후 다시 멈추고, 문을 열고, 탑승시키는 것보다 효율적입니다.마찬가지로 승객의 요청이 들어왔을 때 바로 요청을 처리하지 않고 대기하는 지원자도 있었습니다. 승객을 태우기 위해 멈추고, 문을 열고, 닫고, 태우는 것이 모두 timestamp를 잡아먹기 때문에 충분히 기다렸다가 한꺼번에 태우는 것입니다. 또한 대기 중인 승객의 수에 따라 엘리베이터 이동 전략을 달리한 지원자도 있었습니다.그리고 결정적으로 현실의 엘리베이터와 차이가 나는 부분이 있습니다. 바로 요청을 받을 때 목적 층을 사전에 알 수 있다는 것입니다. 이 정보를 토대로 엘리베이터에 승객을 가고자 하는 층별로 그룹화하여 탑승시킬 수 있습니다. 심지어 엘리베이터를 움직이기 전에 모든 승객의 요청을 다 수집한 후에 움직이기 시작한 지원자도 있었습니다.Python이 압도적으로 높은 비율을 보였고 그 뒤를 Java와 Node가 뒤이었습니다.빌딩별 가장 먼저 성공한 시각은 14시 12분 / 14시 40분 / 14시 53분입니다. 어피치 맨션을 2시간 30분 이내에 풀어야 남은 두 빌딩을 최적화하여 고득점 할 수 있을 것이라 예상하였는데, 예상외로 후반부의 집중력이 놀라웠습니다.2차 오프라인 코딩테스트에서 사용한 엘리베이터 시뮬레이션 서버는 직접 돌려볼 수 있도록 수정하여 공개하였습니다. 이 곳에서 내려받아 실행할 수 있습니다.긴 시간 동안 문제 푸시느라 고생하셨습니다! 당락을 떠나 즐겁고 유익한 문제였기를 바랍니다",http://tech.kakao.com/2018/10/23/kakao-blind-recruitment-round-2/,0,kakao,"react,backend,xml,frontend,javascript",NULL,2018-10-23
if kakao 2018 동영상을 공개합니다.,"지난 9월 4일, 코엑스 그랜드볼룸에서 카카오의 개발자 콘퍼런스인 if kakao 2018이 성황리에 마쳤습니다.카카오 이름을 건 첫 번째 개발자 콘퍼런스인 if kakao 2018은 인공지능, 메신저, 택시, 결제/송금, 검색 등 수많은 영역에서 쌓은 카카오의 기술과 노하우를 외부에 공유하고 소통하는 자리였구요.신정환 CTO와 김병학 AI Lab 총괄 부사장의 기조연설과 인공지능, 머신러닝, 멀티미디어 처리, 챗봇, 클라우드, 오픈소스, 추천 등 다양한 주제의 27개 강연 세션을 진행했으며, 카카오의 서비스를 만드는 현직 개발자들이 실제 개발 사례를 중심으로 기술과 노하우를 생생하게 전달하려고 노력했습니다.이번 행사의 스케치 영상을 포함해 기조연설과 모든 강연 세션 동영상을 공개합니다.if kakao 2018 콘퍼런스의 모든 영상은 카카오TV의 if kakao dev 2018 채널에서 확인할 수 있습니다. 아쉽게도 행사에 참석하지 못한 분들 뿐만 아니라, 행사에 참석했던 분들에게도 세션 내용을 다시 확인하는데 도움이 되었으면 합니다.내년에는 더욱 멋진 콘퍼런스를 준비해서 찾아뵙겠습니다. 감사합니다.",http://tech.kakao.com/2018/10/17/if-kakao-dev-2018/,0,kakao,"frontend,javascript,ruby",NULL,2018-10-17
2019 카카오 신입 공채 1차 코딩 테스트 문제 해설,"작년에 이어 올해도 블라인드 전형으로 카카오 개발 신입 공채가 시작되었습니다!그 첫 번째 관문으로 1차 온라인 코딩 테스트가 지난 9월 15일(토) 오후 2시부터 7시까지 5시간 동안 치러졌는데요.지원자분들 만큼이나 준비위원들도 테스트가 문제없이, 공정하게 치러질 수 있도록 많은 준비를 했고 두근 거리는 마음으로 끝까지 온라인 테스트를 모니터링했답니다.문제는 작년과 비슷하게 구현 문제 위주로 쉬운 난이도에서 어려운 난이도 순으로 풀 수 있도록 차례대로 배치했고, 모든 테스트 케이스가 통과해야 문제를 풀이한 것으로 인정되도록 했습니다. 단, 작년과는 다르게 효율성 테스트를 도입하여 같은 문제라도 입력의 크기에 따라 효율적인 풀이를 구현하도록 유도했고, 효율성 테스트가 있는 문제에서는 부분점수가 부여되도록 설계했습니다.그럼, 지금부터 문제 설명과 풀이를 살펴보도록 하겠습니다.카카오톡 오픈채팅방에서는 친구가 아닌 사람들과 대화를 할 수 있는데, 본래 닉네임이 아닌 가상의 닉네임을 사용하여 채팅방에 들어갈 수 있다.신입사원인 김크루는 카카오톡 오픈 채팅방을 개설한 사람을 위해, 다양한 사람들이 들어오고, 나가는 것을 지켜볼 수 있는 관리자창을 만들기로 했다. 채팅방에 누군가 들어오면 다음 메시지가 출력된다.“[닉네임]님이 들어왔습니다.”채팅방에서 누군가 나가면 다음 메시지가 출력된다.“[닉네임]님이 나갔습니다.”채팅방에서 닉네임을 변경하는 방법은 다음과 같이 두 가지이다.닉네임을 변경할 때는 기존에 채팅방에 출력되어 있던 메시지의 닉네임도 전부 변경된다.예를 들어, 채팅방에 “Muzi”와 “Prodo”라는 닉네임을 사용하는 사람이 순서대로 들어오면 채팅방에는 다음과 같이 메시지가 출력된다.“Muzi님이 들어왔습니다.” “Prodo님이 들어왔습니다.”채팅방에 있던 사람이 나가면 채팅방에는 다음과 같이 메시지가 남는다.“Muzi님이 들어왔습니다.” “Prodo님이 들어왔습니다.” “Muzi님이 나갔습니다.”Muzi가 나간후 다시 들어올 때, Prodo 라는 닉네임으로 들어올 경우 기존에 채팅방에 남아있던 Muzi도 Prodo로 다음과 같이 변경된다.“Prodo님이 들어왔습니다.” “Prodo님이 들어왔습니다.” “Prodo님이 나갔습니다.” “Prodo님이 들어왔습니다.”채팅방은 중복 닉네임을 허용하기 때문에, 현재 채팅방에는 Prodo라는 닉네임을 사용하는 사람이 두 명이 있다. 이제, 채팅방에 두 번째로 들어왔던 Prodo가 Ryan으로 닉네임을 변경하면 채팅방 메시지는 다음과 같이 변경된다.“Prodo님이 들어왔습니다.” “Ryan님이 들어왔습니다.” “Prodo님이 나갔습니다.” “Prodo님이 들어왔습니다.”채팅방에 들어오고 나가거나, 닉네임을 변경한 기록이 담긴 문자열 배열 record가 매개변수로 주어질 때, 모든 기록이 처리된 후, 최종적으로 방을 개설한 사람이 보게 되는 메시지를 문자열 배열 형태로 return 하도록 solution 함수를 완성하라.입출력 예 #1 문제의 설명과 같다.첫 번째 문제답게 큰 고민 없이 연관 배열(맵)을 이용해서 쉽게 풀 수 있습니다.record 를 순회 하면서이제 events 를 순회하면서 채팅방에 출력할 메시지를 생성할 때, 연관 배열에 저장된 아이디별 최종 닉네임을 이용하면 됩니다.슈퍼 게임 개발자 오렐리는 큰 고민에 빠졌다. 그녀가 만든 프랜즈 오천성이 대성공을 거뒀지만, 요즘 신규 사용자의 수가 급감한 것이다. 원인은 신규 사용자와 기존 사용자 사이에 스테이지 차이가 너무 큰 것이 문제였다.이 문제를 어떻게 할까 고민 한 그녀는 동적으로 게임 시간을 늘려서 난이도를 조절하기로 했다. 역시 슈퍼 개발자라 대부분의 로직은 쉽게 구현했지만, 실패율을 구하는 부분에서 위기에 빠지고 말았다. 오렐리를 위해 실패율을 구하는 코드를 완성하라.전체 스테이지의 개수 N, 게임을 이용하는 사용자가 현재 멈춰있는 스테이지의 번호가 담긴 배열 stages가 매개변수로 주어질 때, 실패율이 높은 스테이지부터 내림차순으로 스테이지의 번호가 담겨있는 배열을 return 하도록 solution 함수를 완성하라.입출력 예 #11번 스테이지에는 총 8명의 사용자가 도전했으며, 이 중 1명의 사용자가 아직 클리어하지 못했다. 따라서 1번 스테이지의 실패율은 다음과 같다.2번 스테이지에는 총 7명의 사용자가 도전했으며, 이 중 3명의 사용자가 아직 클리어하지 못했다. 따라서 2번 스테이지의 실패율은 다음과 같다.마찬가지로 나머지 스테이지의 실패율은 다음과 같다.각 스테이지의 번호를 실패율의 내림차순으로 정렬하면 다음과 같다.입출력 예 #2모든 사용자가 마지막 스테이지에 있으므로 4번 스테이지의 실패율은 1이며 나머지 스테이지의 실패율은 0이다.문제를 읽어보면 알 수 있듯이 이 문제는 정렬을 이용해서 풀 수 있습니다.먼저 주어진 배열의 길이를 이용하여 전체 사용자 수를 구하고, stages 를 순회하며 각 스테이지에 몇 명의 사용자가 도달했는지 세줍니다.  이렇게 만들어둔 배열(각 스테이지별 사용자 수가 들어있는)을 순회하면서 stages 를 참고하여 스테이지별 실패율을 계산합니다.  이때, 스테이지에 도달한 사용자가 0명인 경우 예외 처리를 해야 합니다. 스테이지별 실패율을 구했다면, 각 스테이지 번호와 묶어서 실패율 내림차순으로 정렬합니다.  실패율이 같은 경우는 스테이지 번호가 작은 것을 먼저 오도록 정렬하면 됩니다.프렌즈대학교 컴퓨터공학과 조교인 제이지는 네오 학과장님의 지시로, 학생들의 인적사항을 정리하는 업무를 담당하게 되었다.그의 학부 시절 프로그래밍 경험을 되살려, 모든 인적사항을 데이터베이스에 넣기로 하였고, 이를 위해 정리를 하던 중에 후보키(Candidate Key)에 대한 고민이 필요하게 되었다.후보키에 대한 내용이 잘 기억나지 않던 제이지는, 정확한 내용을 파악하기 위해 데이터베이스 관련 서적을 확인하여 아래와 같은 내용을 확인하였다.제이지를 위해, 아래와 같은 학생들의 인적사항이 주어졌을 때, 후보 키의 최대 개수를 구하라.위의 예를 설명하면, 학생의 인적사항 릴레이션에서 모든 학생은 각자 유일한 “학번”을 가지고 있다. 따라서 “학번”은 릴레이션의 후보 키가 될 수 있다. 그다음 “이름”에 대해서는 같은 이름(“apeach”)을 사용하는 학생이 있기 때문에, “이름”은 후보 키가 될 수 없다. 그러나, 만약 [“이름”, “전공”]을 함께 사용한다면 릴레이션의 모든 튜플을 유일하게 식별 가능하므로 후보 키가 될 수 있게 된다. 물론 [“이름”, “전공”, “학년”]을 함께 사용해도 릴레이션의 모든 튜플을 유일하게 식별할 수 있지만, 최소성을 만족하지 못하기 때문에 후보 키가 될 수 없다. 따라서, 위의 학생 인적사항의 후보키는 “학번”, [“이름”, “전공”] 두 개가 된다.릴레이션을 나타내는 문자열 배열 relation이 매개변수로 주어질 때, 이 릴레이션에서 후보 키의 개수를 return 하도록 solution 함수를 완성하라.입출력 예 #1 문제에 주어진 릴레이션과 같으며, 후보 키는 2개이다.가능한 모든 어트리뷰트의 조합을 만들고, 이 조합에서 조건을 만족시키는 조합만 추려야 하는 문제입니다.dfs 또는 bit 를 이용한 집합 표현을 이용하여 어트리뷰트의 모든 부분 집합을 만들어냅니다. 만들어지는 각 부분 집합을 이용해서 중복 튜플이 있는지 검사합니다.  만약 중복 튜플이 없다면, 이 부분 집합을 슈퍼 키 집합(유일성을 만족하는 키들의 집합)에 포함시킵니다.슈퍼 키 집합을 구한 후, 여기서 최소성을 만족하는 키들을 선택하여 후보 키 집합을 만들 수 있습니다. 만약 어떤 슈퍼 키 X에 대해 X의 부분집합인 슈퍼 키 Y가 없다면 (X ⊃ Y인 슈퍼 키 Y가 없다면) X는 후보 키로 선택될 수 있습니다.예를 들어 어떤 릴레이션의 어트리뷰트가 ABCDE 이고, 슈퍼 키 집합이 {A, AB, BC, BCE, BDE, …} 라고 해봅시다.따라서 이 경우 후보 키 집합은 {A, BC, BDE, …} 가 됩니다.가능한 모든 조합을 만드는 부분 때문인지 앞쪽에 배치된 문제임에도 많은 지원자들이 어려움을 겪은 것으로 보입니다.* 효율성 테스트에 부분 점수가 있는 문제입니다.평소 식욕이 왕성한 무지는 자신의 재능을 뽐내고 싶어 졌고 고민 끝에 카카오 TV 라이브로 방송을 하기로 마음먹었다.그냥 먹방을 하면 다른 방송과 차별성이 없기 때문에 무지는 아래와 같이 독특한 방식을 생각해냈다.회전판에 먹어야 할 N 개의 음식이 있다.  각 음식에는 1부터 N 까지 번호가 붙어있으며, 각 음식을 섭취하는데 일정 시간이 소요된다.  무지는 다음과 같은 방법으로 음식을 섭취한다.무지가 먹방을 시작한 지 K 초 후에 네트워크 장애로 인해 방송이 잠시 중단되었다. 무지는 네트워크 정상화 후 다시 방송을 이어갈 때, 몇 번 음식부터 섭취해야 하는지를 알고자 한다.  각 음식을 모두 먹는데 필요한 시간이 담겨있는 배열 food_times, 네트워크 장애가 발생한 시간 K 초가 매개변수로 주어질 때 몇 번 음식부터 다시 섭취하면 되는지 return 하도록 solution 함수를 완성하라.입출력 예 #1이 문제를 완전히 해결하려면 효율성 테스트를 통과해야 합니다. 효율성 테스트의 제한 사항은 정확성 테스트보다 까다롭기 때문에 정확성 테스트를 통과한 풀이를 그대로 적용하면 시간 초과가 발생합니다. 따라서, 실행 시간을 줄일 수 있는 아이디어가 필요합니다.시간이 1초 지날 때마다 다음 먹을 음식을 반복문을 이용해 하나하나 찾아가며 시뮬레이션하면 됩니다.먼저 음식별 필요 시간을 오름차순으로 정렬합니다. 시간의 오름차순으로 정렬해두면 음식을 먹는 데 소요되는 시간을 한꺼번에 지울 수 있습니다. 예를 들어 정렬한 시간이 T = [1, 3, 3, 4, 5]라면 처음에 T[0] * 5 = 5만큼의 시간을 한꺼번에 지울 수 있습니다. 다음으로 T[1]부터 남은 시간을 한꺼번에 제거합니다.  즉, (T[1] - T[0]) * 4 = 8 만큼의 시간을 한꺼번에 지웁니다. 마찬가지로 (T[2] - T[1]) * 3 = 0 만큼의 시간을 한꺼번에 지울 수 있습니다.위와 같은 방법으로 시간을 지워가다가, 지운 시간의 합이 K 보다 커지게 되면 남은 시간의 개수로 나눈 나머지를 이용해 K 초 후 다시 먹기 시작해야 될 음식의 번호를 바로 구할 수 있습니다.  이때, 남은 시간을 다시 원래 음식의 번호 순서대로 재정렬해야 합니다.꼭 이 방법이 아니라도 K에 도달하는 시점을 빠르게 구할 수만 있으면 실행 시간을 줄일 수 있습니다.전무로 승진한 라이언은 기분이 너무 좋아 프렌즈를 이끌고 특별 휴가를 가기로 했다.  내친김에 여행 계획까지 구상하던 라이언은 재미있는 게임을 생각해냈고 역시 전무로 승진할만한 인재라고 스스로에게 감탄했다.라이언이 구상한(그리고 아마도 라이언만 즐거울만한) 게임은, 카카오 프렌즈를 두 팀으로 나누고, 각 팀이 같은 곳을 다른 순서로 방문하도록 해서 먼저 순회를 마친 팀이 승리하는 것이다.그냥 지도를 주고 게임을 시작하면 재미가 덜해지므로, 라이언은 방문할 곳의 2차원 좌표 값을 구하고 각 장소를 이진트리의 노드가 되도록 구성한 후, 순회 방법을 힌트로 주어 각 팀이 스스로 경로를 찾도록 할 계획이다.라이언은 아래와 같은 특별한 규칙으로 트리 노드들을 구성한다.아래 예시를 확인해보자.라이언의 규칙에 맞게 이진트리의 노드만 좌표 평면에 그리면 다음과 같다. (이진트리의 각 노드에는 1부터 N까지 순서대로 번호가 붙어있다.)이제, 노드를 잇는 간선(edge)을 모두 그리면 아래와 같은 모양이 된다.위 이진트리에서 전위 순회(preorder), 후위 순회(postorder)를 한 결과는 다음과 같고, 이것은 각 팀이 방문해야 할 순서를 의미한다.다행히 두 팀 모두 머리를 모아 분석한 끝에 라이언의 의도를 간신히 알아차렸다. 그러나 여전히 문제는 남아있다. 노드의 수가 예시처럼 적다면 쉽게 해결할 수 있겠지만, 예상대로 라이언은 그렇게 할 생각이 전혀 없었다.이제 당신이 나설 때가 되었다.곤경에 빠진 카카오 프렌즈를 위해 이진트리를 구성하는 노드들의 좌표가 담긴 배열 nodeinfo가 매개변수로 주어질 때,  노드들로 구성된 이진트리를 전위 순회, 후위 순회한 결과를 2차원 배열에 순서대로 담아 return 하도록 solution 함수를 완성하자.입출력 예 #1문제에 주어진 예시와 같다.트리를 순회하는 방법은 검색을 통해 쉽게 알 수 있으므로 문제가 되지 않습니다. 이 문제의 핵심은 좌표 값으로 주어지는 노드들을 트리로 구성하는 부분입니다.트리를 만들기 위해 y 값을 이용해서 각 노드의 level 을 분리하고, 현재 노드의 자식 노드가 가질 수 있는 x값을 이용하여 현재 노드의 왼쪽, 오른쪽 자식을 정확히 찾는 것이 중요합니다.각 노드의 왼쪽, 오른쪽 자식 노드는 다음과 같이 찾을 수 있습니다.먼저 현재 노드 P의 x값을 Px, 현재 노드의 자식 노드가 가질 수 있는 x 범위를 Lx, Rx (Lx < Px < Rx)라고 하겠습니다. 또 어떤 노드 K의 x값을 Kx 라고 하겠습니다. 만약 현재 노드의 바로 다음 레벨에 Lx ≤ Kx < Px를 만족하는 노드 K가 있다면 K는 노드 P의 왼쪽 자식이 됩니다. 이때, 노드 K의 자식 노드가 가질 수 있는 x값의 범위는 Lx ≤ x ≤ Px - 1 (x ≠ Kx)가 됩니다.마찬가지로 현재 노드의 바로 다음 레벨에 Px < Kx ≤ Rx를 만족하는 노드 K가 있다면 K는 노드 P의 오른쪽 자식이 되며, 노드 K의 자식 노드가 가질 수 있는 x의 범위는 Px + 1 ≤ x ≤ Rx (x ≠ Kx)가 됩니다.위 과정을 재귀적으로 반복하면서 각 노드의 왼쪽, 오른쪽 자식을 찾아주면 트리를 구성할 수 있습니다.노드별 왼쪽, 오른쪽 자식을 찾는 방법은 여러 가지가 있을 수 있습니다.  그중 하나로, 재귀적으로 순회하며 트리를 만들면 같은 level의 노드는 x값이 작은 노드부터 방문하게 되므로,  큐를 트리의 레벨만큼 만들어 두고, x축 기준으로 오름차순 정렬된 노드들을 y축 값이 같은 노드끼리 각 큐에 넣어두면 큐의 front를 확인하는 방법으로 O(1)에 찾을 수 있습니다.이렇게 하면 노드의 수가 N일 때, 트리를 구성하는 데는 O(N) 시간이 소요되며, 시간 복잡도는 전체 노드를 정렬하는데 걸리는 시간인 O(NlogN)이 됩니다.프렌즈 대학교 조교였던 제이지는 허드렛일만 시키는 네오 학과장님의 마수에서 벗어나, 카카오에 입사하게 되었다.  평소에 관심있어하던 검색에 마침 결원이 발생하여, 검색개발팀에 편입될 수 있었고, 대망의 첫 프로젝트를 맡게 되었다. 그 프로젝트는 검색어에 가장 잘 맞는 웹페이지를 보여주기 위해 아래와 같은 규칙으로 검색어에 대한 웹페이지의 매칭점수를 계산 하는 것이었다.예를 들어, 다음과 같이 A, B, C 세 개의 웹페이지가 있고, 검색어가 hi라고 하자.이때 A 웹페이지의 매칭점수는 다음과 같이 계산할 수 있다.검색어 word와 웹페이지의 HTML 목록인 pages가 주어졌을 때, 매칭점수가 가장 높은 웹페이지의 index를 구하라. 만약 그런 웹페이지가 여러 개라면 그중 번호가 가장 작은 것을 구하라.word : blind위의 예를 가지고 각각의 점수를 계산해보자.따라서 매칭점수가 제일 높은 첫번째 웹 페이지의 index인 0을 리턴 하면 된다.word : Muzi기본점수 및 외부 링크수는 아래와 같다.링크점수는 아래와 같다.각 웹 페이지의 매칭 점수는 다음과 같다.따라서 매칭점수가 제일 높은 두번째 웹 페이지의 index인 1을 리턴 하면 된다.점수를 계산하는 로직 자체는 복잡하지 않지만, 점수 계산에 필요한 요소들을 잘 추출해야 하는 문제입니다.정규표현식을 이용하거나 문자열 처리 로직을 구현해서 a 태그와 meta 태그를 찾아 현재 페이지의 URL 과 외부 링크의 URL 을 찾습니다. 또한, 전체 HTML 문서를 대상으로 검색어가 몇 번 등장하는지 찾습니다. 이때, 제시된 조건에 맞게 단어를 찾을 수 있도록 적절히 split 하여 비교합니다.  각 HTML 문서별 기본 점수, 외부 링크 수를 구하고, 해당 웹페이지로 링크가 걸린 다른 웹페이지들을 찾아 링크 점수를 계산합니다.마지막으로 각 페이지의 매칭 점수를 구하고, 최댓값을 갖는 문서의 인덱스를 구하면 됩니다.프렌즈 블록이라는 신규 게임이 출시되었고, 어마어마한 상금이 걸린 이벤트 대회가 개최 되었다.이 대회는 사람을 대신해서 플레이할 프로그램으로 참가해도 된다는 규정이 있어서, 게임 실력이 형편없는 프로도는 프로그램을 만들어서 참가하기로 결심하고 개발을 시작하였다.프로도가 우승할 수 있도록 도와서 빠르고 정확한 프로그램을 작성해 보자.아래 그림과 같이 1×1 크기의 블록을 이어 붙여 만든 3 종류의 블록을 회전해서 총 12가지 모양의 블록을 만들 수 있다.1 x 1 크기의 정사각형으로 이루어진 N x N 크기의 보드 위에 이 블록들이 배치된 채로 게임이 시작된다. (보드 위에 놓인 블록은 회전할 수 없다). 모든 블록은 블록을 구성하는 사각형들이 정확히 보드 위의 사각형에 맞도록 놓여있으며, 선 위에 걸치거나 보드를 벗어나게 놓여있는 경우는 없다.플레이어는 위쪽에서 1 x 1 크기의 검은 블록을 떨어뜨려 쌓을 수 있다. 검은 블록은 항상 맵의 한 칸에 꽉 차게 떨어뜨려야 하며, 줄에 걸치면 안된다.  이때, 검은 블록과 기존에 놓인 블록을 합해 속이 꽉 채워진 직사각형을 만들 수 있다면 그 블록을 없앨 수 있다.예를 들어 검은 블록을 떨어뜨려 아래와 같이 만들 경우 주황색 블록을 없앨 수 있다.빨간 블록을 가로막던 주황색 블록이 없어졌으므로 다음과 같이 빨간 블록도 없앨 수 있다.그러나 다른 블록들은 검은 블록을 떨어뜨려 직사각형으로 만들 수 없기 때문에 없앨 수 없다.따라서 위 예시에서 없앨 수 있는 블록은 최대 2개이다.보드 위에 놓인 블록의 상태가 담긴 2차원 배열 board가 주어질 때, 검은 블록을 떨어뜨려 없앨 수 있는 블록 개수의 최댓값을 구하라.입출력 예 #1 문제에 주어진 예시와 같음문제를 이해하는 것은 어렵지 않지만 제거해야 할 블록을 찾기 위한 아이디어가 필요합니다.문제에서는 검은 블록을 떨어뜨린다고 되어있으나, 실제로 검은 블록을 떨어뜨리지 않고 순서대로 검은 블록으로 채워 나가기만 해도 삭제될 블록을 찾을 수 있습니다.  먼저 게임 보드의 왼쪽 위(혹은 오른쪽 위)부터 가로 방향으로 한 줄씩 순서대로 진행하면서 빈칸에 검은 블록을 채울 수 있는지 확인합니다. 현재 칸이 빈칸이라면 위쪽으로 삭제되지 않은 블록이 있는지 확인합니다.  만약 다른 블록이 없다면 검은 블록으로 채우고, 그렇지 않으면 그대로 빈칸으로 둡니다.칸 하나를 확인한 후에는 해당 칸을 포함하는 칸 중에서 삭제할 수 있는 블록이 있는지 확인합니다.  블록이 사라질 수 있는지 판단은 검은 블록 두 개와 같은 색 블록 4개가 2x3, 3x2의 직사각형 안에 들어있는지 확인하면 됩니다.블록을 지운 경우에 지워진 칸을 그대로 둘지, 혹은 검은 블록으로 채울지 확인하는 과정이 필요합니다. 블록이 삭제된 칸이어도 검은 블록으로 채울 수 없는 경우가 있기 때문입니다.  지워진 칸을 기준으로 위쪽에 삭제되지 않은 블록이 있는지 확인하여 검은 블록을 적절히 채웁니다(삭제되는 블록을 찾는 방향에 따라 조금 다를 수도 있습니다).블록이 삭제되면 카운트를 1 증가시키고, 게임 보드의 모든 칸에 대해 삭제될 블록을 찾은 후 카운트된 값을 반환하면 됩니다.또 다른 방법으로, 문제의 설명대로 위에서 블록을 떨어뜨려서 없앨 수 있는 블록을 차례대로 찾아서 제거하는 것을 생각해 볼 수 있습니다.도형의 모양을 자세히 보면, 제거할 수 있는 도형은 채워야 할 공간이 위쪽으로 열려있는 5가지뿐임을 알 수 있습니다.  최상단 좌측부터 검사를 시작해 도형이 있는 칸(0보다 큰 값)을 만나면, 주변 값들을 확인해서 제거 가능한 도형 중 하나인지를 체크합니다.  만약, 제거 가능한 도형 중 하나라면 도형에서 채워야 하는 공간부터 최상단까지 모든 값이 비어있는지를 체크합니다. 모두 비어있다면 이는 없앨 수 있다는 뜻이므로 이 도형을 0으로 채워 제거합니다.제거 가능한 도형을 모두 찾을 때까지 이 과정을 반복하고, 도형을 제거할 때마다 카운트를 증가시켜주면 됩니다.지금까지 1차 코딩 테스트 문제와 풀이에 대해 살펴봤습니다.아마 문제를 풀어본 분이라면 고개가 끄덕여지는 부분도 있을 것이고, 자신의 풀이와 차이점도 확인할 수 있었을 것 같네요. 모쪼록 이 글이 도움이 되었으면 좋겠습니다.마지막으로, 5시간 동안 테스트에 응해주신 지원자분들께 감사드립니다. 모두 고생 많으셨고 2차 오프라인 테스트에서 만날 수 있길 바라봅니다. : )",http://tech.kakao.com/2018/09/21/kakao-blind-recruitment-for2019-round-1/,0,kakao,"python,react,bootstrap,css,javascript,frontend",NULL,2018-09-21
코드 페스티벌 2018 본선 이야기,"지난 8월 25일 토요일, 카카오 코드 페스티벌 오프라인 본선이 진행됐습니다. 예선에서의 엄청난 경쟁률을 뚫고 당당히 본선에 진출한 64명의 실력자들이 함께 했는데요. 작년과는 다르게 카카오 판교 오피스에서 행사를 개최하여 더 뜻깊은 자리가 되었던 것 같습니다.▶ 행사 후기가 궁금하시다면?그럼 본선에 출제되었던 문제와 해법을 알아보도록 하겠습니다.서로 다른 결과의 경우의 수가 총 36 가지임을 알 수 있습니다. 그러므로 모든 경우를 고려하는 완전 탐색 풀이를 구현하면 됩니다.  특정 경우에서 동점자가 발생하는 경우가 존재하기 때문에, 동점자가 발생하는 모든 경우를 유의할 필요가 있습니다.모순이 없다고 가정하고, M 을 구해 봅시다. 편의상 b0 = 0 으로 둔다면, i (1 ≤ i ≤ n)번째 로그에서 카카오머니 잔고의 변화량은 bi - bi-1 입니다.만약 bi - bi-1 = ai라면, i 번째 로그가 입금인지 출금인지의 여부와 관계없이, 카카오머니 잔고가 ai 만큼 변하여 제대로 기록된 것입니다.하지만, 만약 bi - bi-1 ≠ ai 라면, 카카오머니 잔고가 부족하여 통장에서 돈을 가져왔을 것입니다. (이 외의 방법이 없습니다.)통장에서 가져온 금액은 bi - (bi-1 + ai) 원입니다.  문제의 지문에서, 통장에서 돈을 가져올 때에는 M 원씩을 여러 번 가져오므로, bi - (bi-1 + ai) 이 M 의 배수여야 한다는 조건을 얻을 수 있습니다.  또한, 최종 잔고는 M 원 미만이므로, bi < M 이라는 조건도 얻을 수 있습니다.위의 관찰 중 첫 번째 조건을 종합해 보면, M 으로 가능한 수들은 bi - (bi-1 + ai) 들의 공약수임을 알 수 있습니다.  이들 중 두 번째 조건을 만족하려면, M 이 크면 클수록 좋다는 것을 알 수 있습니다.따라서, bi - (bi-1 + ai) 들의 최대공약수를 구한 뒤, 이것을 M 으로 놓고, 주어진 로그대로 입출금을 해보면서 모순이 없는지 확인하면 됩니다.문제를 잘 관찰해 보면, 인접한 두 격자의 색이 다른 경우 두 격자의 현재 상태는 초기 상태와 같다는 성질을 발견할 수 있습니다.증명) 인접한 두 격자의 현재 상태가 BW 일 때, 원래 WW 거나 BB 였다면, 두 격자는 연결되어 있으므로 현재 상태와 같이 달라지는 경우는 발생하지 않습니다.  원래 WB 였다면 상태가 바뀔 때 BW 로 한 번에 바뀔 수 없고, WW 또는 BB 를 거쳐야 하므로 불가능합니다. 따라서 초기 상태가 BW 였음을 알 수 있습니다.인접한 격자 중 자신과 색이 다른 것이 존재하는 격자들의 경우 위 성질에 의해 색이 정해지고, 그 외의 격자들은 초기 상태에 아무렇게나 칠해져 있어도 현재 상태로 만들 수 있음을 알 수 있습니다.  (연결된 컴포넌트들의 경계선에 있는 부분은 색이 정해 지므로, 내부는 아무렇게나 칠해져 있어도 경계선과 동일하게 만들 수 있습니다.)따라서, 가능한 초기 상태의 수는 2(색이 정해지지 않은 격자의 수) 가 됩니다.튜브는 연료를 구하러 망망대해로 나가고 싶으나, 사냥꾼이 어떠한 섬을 점거했을 때 길이 막힐 것이 두려워 걱정하고 있습니다. 튜브는 현재 위치에서 안전하게 망망대해로 나갈 수 있을까요?이 문제는 풀이의 방향이 크게 두 갈래로 나뉩니다. 하나는 출제진이 의도하였던 풀이이고, 하나는 출제진이 예상하지 못했던 방향의 풀이입니다. 첫 번째 풀이를 중심으로 설명하나, 두 번째 풀이에 대해서도 간단히 짚고 넘어가겠습니다.문제를 다시 요약해 보겠습니다. 우리는 튜브가 도착한 각각의 섬 v 에 대해서, v 와 다른 섬 w 중, w 에 사냥꾼이 있을 때 v 에서 최외곽으로 갈 수 있는 경로가 없어지는 w 가 존재하는가가 궁금한 것입니다.  결국에는 “경로” 와 “섬” 에 대한 이야기니, 그래프에 풀어놓고 생각해보면 편리하게 문제를 해결할 수 있습니다.그래프에 있는 모든 4방향으로 인접한 육지와 바다를 Flood-Fill 로 하나의 정점으로 묶어줍시다. 이제 각각의 정점은 “섬” 이거나 “바다” 로 분류될 수 있습니다. “섬” 과 “바다” 가 맞닿아 있으면 간선을 이어줍시다.  최외곽의 바다를 1번 정점이라고 하면, 우리가 풀고자 하는 문제는 다음과 같습니다.왠지 익숙한 느낌이 들지 않나요? 그래프에서 정점 하나를 제거했을 때 경로가 사라지는 형태의 문제이니, “절점”의 개념을 활용할 수 있다고 생각할 수 있습니다.  그래프에서 어떠한 정점을 제거하였을 때, 컴포넌트의 개수가 증가하는 정점들을 “절점” 이라고 부릅니다. 절점에 대한 자세한 설명은 지면상 생략하겠으나, 어떠한 정점이 절점인지 아닌지를 판별하는 것은 선형 시간에 가능합니다.절점 개념을 도입하면, 문제는 다음과 같이 변합니다.이는 절점을 구하는 알고리즘을 조금만 응용하면 됩니다.  1번 정점에서 DFS 를 시작했을 때, 어떠한 점이 절점이면, 해당 점을 거쳐야만 1번 정점으로 갈 수 있는 점들의 집합이 DFS Tree 상의 서브트리로 표현이 됩니다.  이는 문제가 “서브트리에 있는 정점에 대해서 마킹을 하시오” 의 형태로 환원이 된다는 것을 의미합니다.  서브트리에 있는 정점은 Euler Tour 번호에서 연속된 구간을 이루기 때문에, 구간에 대한 마킹으로 변환할 수 있으며, 이는 변화값 배열을 사용해서 해결할 수 있습니다.입력이 결국에는 평면 상의 격자의 모습임을 상기해 보면, 사냥꾼이 점령하고 있는 섬 안에 “둘러싸인” 섬들은 위험한 섬이 된다는 것을 알 수 있습니다.  즉, 각각의 섬에 대해서 그 섬이 “둘러싸고” 있는 섬들이 무엇인지를 알면 문제를 해결하는 데 조금 더 가까워질 수 있습니다. 둘러싸고 있는 영역을 Flood-Fill 해 주면 되기 때문입니다.다른 풀이는 이 “둘러싸고 있는 영역” 을 효율적으로 구하는 데 초점을 맞춥니다.  각각의 섬에 대해서 Flood-Fill 로 해당 섬의 영역을 구해주고, 영역의 빈자리를 찾아낸 후, 해당 빈자리를 다시 Flood-Fill 로 구해주는 것이죠.직관적으로는 이 부분이 매우 자명하나, 이를 알고리즘으로 옮기는 것은 또 다른 난이도입니다. 여기부터는 출제진도 말을 아끼겠습니다 :D 위 방법은 절점과 같은 고급 개념이 필요하지 않은 알고리즘이지만, 이러한 부분에서의 난이도가 상당히 있었는지, 초반에 이 문제를 빠르게 푼 대부분의 참가자들은 절점 알고리즘을 사용하였습니다.먼저, 초기 상태가 회문인 경우에는 답이 모두 0입니다. 그렇지 않은 경우, 주어진 문자열을 S[1~N] 이라 할 때, S[i] 가 S[N+1-i] 와 다른 최소의 i 를 b 라 하고, e = N-b+1 로 두면 주어진 문자열을 회문으로 만들기 위해서는 b 번째 석판이나 e 번째 석판을 교체해야 한다는 것을 알 수 있습니다.또한 [b, e] 구간 밖에서는 석판을 교체할 이유가 없으므로 시작 위치가 i 일 때 소모해야 하는 체력을 H[i] 라 하면,가 되고 S[b~e] 에 대해서만 문제를 해결하면 됩니다. b 와 e 중 석판 b 를 교체하는 경우를 생각해 보면 시작 위치가 x 번째 석판일 때 가능한 경로를 다음과 같은 2가지로 분류할 수 있습니다.두 경우 모두 [b, r] 의 석판만 교체하여 문자열을 회문으로 만들 수 있어야 가능하고, 또한 [b, r] 에 회문에서 서로 대응되는 두 석판이 모두 포함되는 경우 교체 시 드는 체력이 작은 쪽을 고르는 것이 항상 이득입니다.모든 r 에 대해 [b, r] 구간을 방문할 때 회문을 만들기 위해 석판을 교체하는 데 드는 체력을 배열 P[] 에 미리 저장해 놓을 수 있습니다.  그러면 x 가 주어졌을 때 x <= r 인 모든 r 에 대해 P[r] + (r-x) + (r-b) 의 최솟값이 x->r->b 의 경로 중 최적인 값이고, P[r] + (x-b) + (r-b) 의 최솟값이 x->b->r 의 경로 중 최적인 값입니다.  이는 x 를 e 부터 시작하여 왼쪽으로 한 칸씩 밀면서 계산하면 모든 x 에 대해서 O(N) 시간에 계산할 수 있으므로 석판 b 를 교체하는 경우에 소모해야 하는 최소 체력을 O(N) 시간에 계산할 수 있습니다.  석판 e 를 교체하는 경우도 대칭적으로 생각하면 마찬가지 방법으로 가능합니다.따라서 선형 시간에 문제를 해결할 수 있습니다.먼저, Union 마법을 사용했을 때 사용하기 전보다 더 시끄러워지는 경우는 없습니다.  처음은 directed rooted tree 형태의 그래프이고, 최종 상태는 Union 마법을 더 이상 쓸 수 없는 상태여야 하므로 모든 도로의 끝점은 트리의 leaf 일 것입니다.  이 점에 착안하여 생각해보면 이 문제는 directed rooted tree 의 edge 들을, leaf 를 끝점으로 하는 여러 경로들로 나누어 각 경로의 시작점과 끝점에 있는 건물의 사람 수의 곱을 최소로 만드는 문제입니다.  즉, 건물 i 에 사는 사람의 수를 C[i] 라 할 때, 최종 상태의 모든 경로 u->v 에 대해 C[u]*C[v] 의 합을 최소화하면 됩니다.처음에 주어진 directed rooted tree 에서, root 가 아닌 노드 u 를 생각해봅시다. 또한, u 를 root 로 하는 subtree 를 subtree(u) 라고 합시다.  u 의 부모에서 u 로 들어오는 간선이 있으므로, 최종 상태에는 u 의 조상 중 하나에서 subtree(u)에 포함되는 leaf 로 가는 경로가 하나 있을 것이고, 그 경로에 포함되지 않는 subtree(u)의 edge 들은 subtree(u) 내부의 경로가 될 것입니다.결론적으로, subtree(u) 내부의 edge 들이 최종적으로 어떤 경로에 포함될지 결정된다면, 외부에 영향을 끼치는 요소는 u 의 조상 중 하나와 연결될 leaf 의 건물에 있는 사람 수 뿐입니다.  따라서, 다음과 같은 다이나믹 프로그래밍을 생각할 수 있습니다.점화식은 다음과 같습니다.각 자식 노드 v 에 대해 D[v][l'] + C[u]C[l'] 이 최소가 되는 l' 을 미리 구해놓을 수 있으므로, 시간 복잡도는 각 노드 u 에 대해 subtree(u)의 leaf l 을 선택하는 경우의 수인 O(N2)가 됩니다. 위 다이나믹 프로그래밍은 O(N2)의 시간 복잡도를 가지므로, 시간 초과가 발생하게 됩니다. 이를 줄이기 위해서는 한 가지 관찰이 필요합니다.subtree(u)의 모든 leaf l 에 대해, 좌표평면 상에서 y = C[l] * x + D[u][l] 라는 직선을 그었다고 생각해봅시다. 0 이상의 모든 x 에 대해 그 x 에서 함숫값이 최소가 되는 직선을 구했다고 합시다.  만약 어떤 x 에서도 함숫값이 최소가 되지 않는 직선이 있다면, 그 직선은 최적해를 구하는 데에 있어 쓸모가 없습니다. 그 leaf 가 u 의 어느 조상과 연결되든 간에 더 좋은 방법이 존재하기 때문입니다.  따라서 정점 u 에 대해 subtree(u)의 모든 leaf 에 대한 값을 저장할 필요가 없고, 위에서 설명한 직선들의 아래쪽 convex hull 만을 들고 있으면 충분합니다.앞에서 설명한 DP를 이 convex hull 을 이용해서 할 수 있는데, 먼저 u 의 모든 자식 v 에 대해 D[v][l'] + C[u]C[l'] 의 최솟값은 v 의 아래쪽 convex hull 이 x = C[u] 와 만나는 부분임을 쉽게 알 수 있습니다.  따라서 이를 미리 계산해 놓을 수 있습니다. 또한 u 의 자식 v 에 대해 subtree(v)에 포함되는 leaf 가 u 의 조상과 연결되는 경우는 v 의 convex hull 이 일정 크기만큼(정확히는 v 가 아닌 모든 자식 c 에서 D[c][l'] + C[c]C[l'] 의 최솟값의 합만큼) 위로 올라간 것임을 알 수 있습니다.  따라서, 자식들에 저장된 convex hull 들을 y 축 방향으로 평행 이동시킨 후에 모두 합쳐서 convex hull 을 다시 구할 수 있다면 앞서 설명한 DP 와 정확하게 같은 것을 할 수 있는 것입니다.먼저 set 을 이용해 Dynamic Convex Hull 자료구조를 만들면 O(log N) 시간에 직선을 추가하는 연산을 수행할 수 있고,  어떤 x 좌표가 주어졌을 때 convex hull 에서 해당하는 y 좌표를 이분 탐색을 이용해 O(log2N) 시간에 찾을 수 있습니다.y축 방향으로 얼마만큼 평행이동되었는지는 따로 저장해 놓으면 쉽게 관리할 수 있습니다. x 좌표가 주어졌을 때 convex hull 에서 y 좌표를 찾는 연산은 D[v][l'] + C[u]C[l'] 의 최솟값을 찾을 때 사용하므로 총 O(N)번 쓰게 되어 여기서 시간 복잡도 O(N log2N)가 발생합니다.  자식들의 convex hull 들을 합쳐야 하는데, 자식들 중 가장 직선이 많은 convex hull 에 다른 자식들의 convex hull 의 직선을 삽입하는 small-to-large 방식으로 이를 해결할 수 있습니다.  여기에서 직선 삽입은 Heavy-Light Decomposition 과 같은 원리로 최대 O(N logN)번만 수행됩니다. 따라서, 여기서 발생하는 시간 복잡도는 O(N log2N)입니다.따라서, 총 시간 복잡도 O(N log2N)에 문제를 해결할 수 있습니다.이 문제는 그래프에서 규칙에 따라 모든 노드를 제거할 수 있는지 확인하는 문제입니다. 제거하는 규칙은, 어떤 노드 X 가 제거될 때 그 노드에 연결된 다른 모든 노드 A, B, …, D 가 서로 모두 연결되어 있어야 한다는 것입니다.  이 조건에서 X, A, B, …, D 는 하나의 Clique(모든 노드 쌍이 연결된 부분 그래프)를 이룬다는 것을 알 수 있습니다.  그래프의 한 상태에서 제거될 조건을 만족하는 노드는 어느 것을 먼저 제거하더라도 상관없다는 것을 짐작할 수 있고 증명할 수 있습니다.  하지만, 이렇게 조건을 하나하나 확인하면서 제거할 수 있는 노드를 찾아 나가며 진행하는 것은 매우 느린 방법이 됩니다.빠른 방법 중 하나는 노드를 제거하는 “특정한 순서”를 찾고, 그 순서에 따라서 노드를 제거했을 때 조건을 만족하면서 모든 노드를 제거할 수 있음을 확인하는 것입니다.  이 “특정한 순서”는, 만약 모든 노드를 제거할 수 있는 순서가 하나라도 있다면 반드시 모든 노드를 제거할 수 있는 순서가 된다는 성질을 가집니다.  모든 노드를 제거할 수 있는 그래프는 Clique 들이 서로 노드를 공유하는 모양으로만 구성되어 있어야 한다는 것을 어렵지 않게 짐작할 수 있고 증명할 수 있습니다.비교적 단순하게 두 개의 Clique P 와 Q 가 일부 노드를 공유하고 있는 그래프로 설명해 보겠습니다.  이 그래프는 모든 노드를 제거하는 것이 가능한 그래프임이 당연합니다. 노드들의 집합 P-Q, Q-P, P∩Q 를 생각해 봅시다.  P-Q 나 Q-P 에 있는 노드가 가장 먼저 제거되는 것은 가능하지만, P∩Q 에 있는 노드가 가장 먼저 제거되는 것은 불가능합니다.  P-Q 나 Q-P 중 한 집합이라도 모두 제거되어야 P∩Q 에 있는 노드가 제거될 수 있음을 알 수 있습니다.이제, 아무 노드에서나 시작해서 그래프를 탐색하면서 방문하는 순서대로 노드들을 출력합니다.  노드가 출력되면 노드에 연결된 다른 노드들에 모두 카운터를 1 증가시키는 연산을 합니다. 카운터 값이 큰 노드부터 무조건 다음에 출력합니다.만약 이 탐색이 P-Q(혹은 Q-P) 에 있는 노드에서 시작된다면 P(혹은 Q)가 모두 출력된 다음에야 나머지 노드가 출력될 수 있습니다. 만약 이 탐색이 P∩Q 에 있는 노드에서 시작된다면, 탐색이 최초로 P-Q(혹은 Q-P) 에 들어가는 순간 P-Q(혹은 Q-P) 에 있는 노드가 모두 출력된 다음에야 Q-P(혹은 P-Q) 에 있는 노드가 출력됨을 알 수 있습니다.모든 경우를 증명하는 것은 복잡하지만 이런 방식으로 출력하면, 출력의 반대 순서가 반드시 제거 가능한 순서가 됨을 알 수 있습니다.특정한 하나의 순서를 찾았으면 이 순서가 규칙을 지키는 제거 순서인지를 확인해야 합니다.  제거 과정에서 매번 규칙을 전부 확인하면 시간이 아주 오래 걸리게 됩니다.  하지만, 이 과정을 살펴보면 동일한 노드 쌍의 연결 관계를 반복적으로 확인하고 있음을 알 수 있습니다.  동적 프로그래밍과 비슷한 방법으로 반복적으로 확인하는 것을 한 번만 확인하도록 줄여서 빠른 시간에 규칙을 지키는지 확인하는 것이 가능합니다.이러한 두 가지 과정을 거쳐서 O((N+M)logN) 시간 알고리즘을 구현할 수 있습니다. 대회에서는 O(N sqrt(N)) 정도 알고리즘도 통과할 수 있는 수준으로 채점 데이터가 만들어졌습니다.이 문제는 직교 다각형 형태로 주어진 영역을 왼쪽에서 오른쪽으로 비행할 때 단 한 번의 사선 방향을 제외하고는 모두 수직이나 수평으로만 움직일 수 있다고 가정하고 가장 짧은 거리를 찾는 문제입니다.  이 문제의 답을 구현하는 것은 매우 어렵지만 아이디어를 설명하는 것은 비교적 간단합니다.우선, 사선 방향 없이 수직 수평으로만 움직이는 경로를 생각해 봅시다. 주어진 영역 안에서 그러한 최단 경로는 매우 많습니다.  최단 경로들을 모두 그렸다고 하면 그려진 경로들은 모여서 하나의 영역을 만들게 됩니다. 이 영역을 “새 영역”이라고 부릅시다. 새 영역을 구하는 것은 O(N) 시간에 가능합니다.단 한 번의 사선 방향으로의 움직임(사선 성분)에 대해 다음 세 가지를 확인할 수 있습니다.이 세 가지 성질에서 다음과 같은 알고리즘을 만들 수 있습니다. 새 영역의 각 꼭짓점에서 그 꼭짓점에 걸치면서 그 꼭짓점에서 보이는 영역의 경계 위의 두 점을 잇는 모든 선분을 확인합니다.  각 꼭짓점에서는 O(N)개의 다른 꼭짓점이 보입니다. 선분들 중 적어도 한쪽이 꼭짓점인 것들은 따라서 O(N)개가 됩니다. 이들 중 최적인 것이 있다면 쉽게 확인할 수 있습니다.  이들 중 최적인 것이 없다면 앞에서 확인한 선분들 사이를 회전시켜 가면서 최적인 선분을 찾아볼 수 있습니다.  선분을 회전할 때 사선이 만들어 내는 이익은 증가나 감소를 최대 한 번 바꿀 수 있다는 것을 알아낼 수 있어 삼분 탐색으로 충분한 오차 이내까지 선분을 찾아 내려갈 수 있습니다.이러한 방법으로 O(N2 logN * log109) 시간이 걸리는 알고리즘을 만들 수 있습니다. 대회에서는 O(N3) 정도 되는 알고리즘도 통과할 수 있는 수준으로 채점 데이터가 만들어졌습니다.그럼 이제, 코드 페스티벌 본선 결과를 공개합니다! 본선은 예선과 같은 방식으로 채점이 진행되었으며, 1등은 출제된 8문제 중 6문제를 풀어주셨습니다.▶ 순위표 보러 가기사전에 공지된 대로 우수한 성적을 거둔 상위 31명의 참가자에게 상장 및 상금이 수여되었습니다. 아쉽게 수상권에 들지 못한 분들을 위해 다양한 특별상도 준비했는데요, 수상하신 모든 분들 축하드립니다!마지막으로 작년에 비해 본선 문제의 난이도가 높다는 피드백이 많았는데요, 그럼에도 불구하고 끝까지 코드 페스티벌에 적극적으로 참여해주신 분들께 감사드립니다.앞으로 있을 개발자 행사에도 많은 관심 부탁드립니다 :)",http://tech.kakao.com/2018/09/12/code-festival-2018-round-2/,0,kakao,"typescript,frontend,angular",NULL,2018-09-12
2019 카카오 블라인드 신입 개발자 공채가 시작됩니다!,"카카오는 여전히 같은 생각입니다.  개발자가 자신의 가치를 증명할 수 있는 것은 자소서나 스펙이 아니라 코드라고 말이죠!올해는 카카오를 포함하여 5개 기업이 함께 합니다.  지금 바로 도전하세요! new developer coming!▶ 접수 기간 : 8월 27일 (월) 15:00 ~ 9월 11일 (화) 23:59  ▶ 지원 접수 : www.welcomekakao.com  ▶ 문의 사항 : apply@kakaocorp.com  ▶ 모집 회사 : (주)카카오 / (주)카카오 게임즈 / (주)카카오 모빌리티 / (주)카카오페이지 / (주)카카오 페이  (총 5개 기업 중 1개 기업에 지원 가능)2019 카카오 신입 개발자 공채는 스펙보다는 성장 가능성과 잠재력, 창의성 등이 뛰어난 신입 개발자 분들을 선발하기 위해 학력, 경력 등 스펙이 아닌 코딩 능력으로만 검증하는 ‘블라인드’ 전형으로 실시될 예정입니다.블라인드 전형 취지에 맞게 응시자는 학력, 나이, 성별, 경력 등을 기입하지 않고 이름/메일/ 연락처 등만 입력한 후 본인 계정을 생성하면 코딩 테스트에 응시할 수 있습니다!올해는 (주)카카오, (주)카카오게임즈, (주)카카오모빌리티, (주)카카오페이지, (주)카카오페이 5개의 기업이 신입 공채를 함께 진행합니다.지원자는 서류 전형 없이 9월15일부터 코딩테스트를 볼 수 있으며,  이후 오프라인 코딩 테스트, 1차 및 2차 인터뷰가 순차적으로 진행됩니다. 11월 중 최종 합격 발표 예정이며, 합격자들은 오리엔테이션을 거쳐 내년 1월 정식 입사하게 됩니다. (기업 별로 일자는 상이할 수 있습니다)카카오 블라인드 공개 채용과 관련한 자세한 내용은 www.welcomekakao.com에서 확인, 지원 가능합니다.  개발에 대한 열정과 창의성을 갖춘 많은 분들의 지원을 기다립니다 :)▶카카오 블라인드 신입 개발자 공채 지원하러가기",http://tech.kakao.com/2018/08/28/employeement-2019/,0,kakao,,NULL,2018-08-28
코드 페스티벌 2018 예선전 이야기,"작년에 이어 두 번째로 진행된 카카오 코드 페스티벌, 온라인 예선이 지난 8월 4일 토요일에 진행됐습니다. 작년보다 더욱 많은 6,000여 명의 참가자들이 6시간 동안 뜨거운 열정을 발휘했는데요, 특히 실시간으로 바뀌는 스코어보드를 보면서 치열한 접전을 느낄 수 있었습니다. 여기 예선 문제와 해설, 그리고 결과를 공유합니다. 참가해주신 모든 모든 분들께 감사드립니다!대회에 참가해서 얼마의 상금을 받을 수 있을지를 계산하는 문제로, 주어진 조건대로 구현하면 됩니다. if문을 사용해서, a와 b가 어떤 범위가 있는지에 따라 상금을 구하거나, 크기가 101인 배열 A[0..101]와 65인 배열 B[0..64] 두 개를 만들어서, 각각 1회/2회 대회에서 i등을 하면 얼마의 상금을 받는지를 저장한 뒤 계산하는 방법 등이 있습니다.길이가 N인 수열이 주어졌을 때, 이 중 K개 이상의 연속된 수를 선택하여 표준편차를 최소로 만드는 문제입니다. 범위가 작기 때문에 정의된 대로 직접 계산해도 되고, 이를 좀 더 효율적으로 계산할 수도 있습니다.Naive: O(N3)모든 경우를 다 고려하여 구현해보는 방법입니다. j - i + 1 ≥ K, 1 ≤ i, j ≤ N 을 만족하는 모든 i, j에 대해서 다음과 같은 과정을 수행하면 됩니다.참고로, 여기서 m, v는 각각 (산술) 평균과 분산을 의미하며, 문제에 나와있는 식과 같습니다.  그 후 구한 v 중에서 최솟값을 구하고 이 값의 음이 아닌 제곱근을 출력하면 됩니다.가능한 (i, j)의 가짓수가 O(N2)이므로, 모든 (i, j)에 대하여 평균과 분산을 구하는 프로그램의 시간복잡도는 O(N3)이 됩니다.O(N2)(분산) = (제곱의 평균) - (평균) * (평균) 이라는 성질이 알려져 있습니다. 그러므로 누적 합 배열과 제곱의 누적 합 배열을 만들면, j - i + 1 ≥ K, 1 ≤ i, j ≤ N 을 만족하는 모든 i, j에 대해서 평균과 분산을 O(1)의 시간에 구할 수 있습니다.가능한 (i, j)의 가짓수가 O(N2)이므로, O(N2)의 시간복잡도로 문제를 풀 수 있습니다.그 외에 추가로 고려해야 할 사항은 다음과 같습니다.문제의 조건에 맞게 생성된 논리식이 입력되었을 때, 이 식과 동치인 논리식 중 가장 짧은 논리식을 찾는 문제입니다. ==과 !=를 나누어 생각합니다.위의 과정에서 비교 연산들이 모두 불필요하다고 판단되어 제거되었다면, 조건문은 항상 true를 반환하는 식이 됩니다.  항상 true나 false를 반환하는 가장 짧은 조건문은 길이가 4이며, 각각 T==T와 0!=0의 예시가 있습니다.N개의 체크포인트 사이를 규칙에 맞게 이동하는 방법이 있는지를 찾는 문제입니다. 체크포인트의 수와 질의의 수 모두 최대 25만 개로 매우 많으므로 단순한 방법으로는 시간 안에 답을 구하기가 매우 힘들기 때문에, 다음과 같이 단계별로 알고리즘을 개선시켜볼 수 있습니다.O(QN2)문제를 있는 그대로 해석하면, 각각의 체크포인트에서 HP 재충전 / 부스터 재충전 여부를 모두 저장해야 하는 아주 복잡한 문제가 됩니다. 이 정보들을 최대한 간소화할 수 있을까요?이 관찰을 통해서 문제는 그래프 탐색 문제로 환원됩니다. 각각의 쿼리가 주어졌을 때, min(|Xu - Xv|, |Yu - Yv|)가 주어진 HP 제한 이하인 쌍에 대해서 양방향 간선이 있다고 생각하고, 깊이 우선 / 너비 우선 탐색을 사용해서 문제를 해결할 수 있습니다. 시간 제한을 맞추기에는 너무 느린 알고리즘이지만, 좋은 시작점으로 삼을 수 있겠죠.O(N log N + QN)현재 사용하는 방법의 문제점 중 하나는, 고려해야 할 간선의 개수가 O(N2)개에 육박할 정도로 많다는 것입니다. 이를 줄이기 위해서는 다음과 같은 아이디어가 필요합니다.일단, 간선을 이을 때 min(|Xu - Xv|, |Yu - Yv|) 비용의 간선 하나를 잇는 대신 |Xu - Xv|, |Yu - Yv| 비용의 간선 두개를 잇는다고 생각해 봅시다. 이렇게 해도 둘 중 비용이 적은 간선을 고를 것이기 때문에 답에는 변화가 없고, 식은 단순해 집니다.위 그래프에서 X좌표 차이로 이루어진 간선들만 생각해 봅시다. 그러한 간선들만 놓고 보았을 때 Y좌표는 중요한 요인이 아니기 때문에, 우리는 X축 수직선에 점들을 찍어놓고, 두 점의 거리차로 간선을 이었다고 생각할 수 있습니다. 그렇다면, 수직선 상에 인접하지 않은 두 점 간에 간선을 이을 필요가 있을까요? 인접한 정점을 타고서도 해당 위치로 도달할 수 있기에, 굳이 큰 가중치를 사용해서 수직선 상에 인접하지 않은 두 점을 오갈 필요가 없습니다.같은 이야기는 Y좌표 차이로 이루어진 간선들에 대해서도 똑같이 적용됩니다. 이로써 얻을 수 있는 결론은 다음과 같습니다.“X좌표 순으로 정렬했을 때 인접한 N-1개의 쌍과, Y좌표 순으로 정렬했을 때 인접한 N-1개의 쌍만 고려해도 된다.”이제, 각각의 좌표로 정렬한 후, 인접한 쌍에 대해서만 간선을 이어주면 된다는 결론에 도달합니다. 그래프의 크기가 작아졌으니, 훨씬 더 문제를 해결하기 수월해졌죠. 물론, 여전히 탐색을 일일이 해 주기에는 쿼리의 수가 너무 많습니다.O(N log N + Q log Q)복잡도를 줄이는 전략이 여러 가지가 있으나, 이 중 가장 간단한 전략은 모든 쿼리를 X의 오름차순으로 정렬하는 것입니다. 결국 각각의 쿼리가 의미하는 바는, 가중치 X 이하인 간선들만 사용해서 두 정점을 오갈 수 있나? 라는 형태의 질문과 동일합니다. 이 때 모든 쿼리를 X의 오름차순으로 정렬했다면, 각각의 쿼리에서 보게 되는 간선들의 집합이 갈수록 커지게 됩니다.간선들이 추가되는 상황에서 두 정점을 오가는 경로가 있는지, 즉 두 정점이 연결되어 있는지를 확인하는 좋은 자료구조로는 유니온 파인드(Union-Find, 서로소 집합Disjoint Set이라고도 합니다)가 있습니다. 가중치 순서대로 모든 간선과 쿼리를 보면서, 간선이 나오면 두 정점을 하나의 집합으로 합쳐주고, 쿼리가 나오면 두 정점이 같은 집합에 있는지를 보면 됩니다. 이 방법을 사용하면 O(Q log Q) 정렬 이후 각각의 쿼리를 O(log N) 정도의 속도로 해결할 수 있습니다.쿼리를 정렬하지 않고 그때 그때 결과를 알아내는 방법도 있습니다. 이 방법은 그래프의 최소 스패닝 트리(Minimum Spanning Tree)에 속하는 간선만이 중요하다는 사실에 기반합니다. 해당 사실을 사용하면, 주어진 쿼리는 트리 상의 어떠한 경로에 있는 간선들의 가중치가 모두 X 이하인가? 라는 문제로 변환되며, 이는 트리의 경로에 대한 최댓값을 빠르게 구하는 자료구조를 O(N log N)에 만들어 놓으면, 각각의 쿼리 당 O(log N)에 해결할 수 있습니다. 조금 더 어려운 도전이 필요하다면 시도해 보셔도 좋습니다. :)추천이 여러 번 이루어지고 각각의 추천마다 여러 개의 노드의 값을 갱신하는 과정을 반복할 때, 지정된 값을 넘는 시점이 언제인지를 판단하는 문제입니다. 추천 횟수는 최대 10만 번이고 각각에 대해 값이 갱신되는 노드가 최대 10만 개이므로 단순히 값을 하나씩 갱신하는 방식으로는 시간 안에 답을 구할 수 없습니다.트리 형태로 데이터가 주어지고, 서브트리 내의 모든 값에 일정한 값을 더하는 질의를 처리하기 위해서는 트리를 깊이 우선 탐색으로 방문하는 순서대로 원소를 나열하는 트리 순회 배열(Tree Traversal Array)을 만들고, 구간 트리(Segment Tree)를 사용하여 서브트리에 대응되는 구간의 값을 갱신하는 방식을 일반적으로 사용합니다.특정 시점에 노드에 부여된 가중치를 구하는 과정은 노드마다 O(log N) 시간이 걸리기 때문에, 갱신이 이루어질 때마다 가중치의 합을 구하는 방식은 매우 비효율적입니다. 가중치의 합이 목표 점수를 언제 넘게 되는지만 구하면 되기 때문에, 목표 점수를 넘는 시간에 대한 이분 탐색을 진행할 경우, 특정한 가수의 평균 점수가 목표 점수를 넘는 시간을 O((K log N + N’ log N)log T) 시간에 계산할 수 있습니다. 이 때 N’은 해당 가수가 부른 곡의 수, 즉 노드의 개수이고 T는 시간의 최대 범위인 109입니다.문제에서는 각 가수 별로 목표 점수를 넘게 되는 시점을 구해야 하므로, 위 과정을 모든 가수에 대해 반복할 경우 시간 안에 답을 구하기 힘듭니다. 이때 사용할 수 있는 방법이 병렬 이분 탐색(Parallel Binary Search)입니다. 이분 탐색은 구하는 값의 상한과 하한을 정한 다음 구간의 길이를 반으로 줄여나가는 과정을 반복하는 방법인데요, 구하는 값이 여러 개인 경우 각각에 대해 상한과 하한을 저장하는 배열을 정의한 뒤 한 번 계산할 때마다 모든 구간을 각각의 범위에 맞게 절반씩 줄여나갑니다. 그러면 가수의 평균 점수를 계산하는 과정은 각 가수별로 진행해야 하지만 가중치를 부여하는 과정은 여러 번 반복할 필요가 없기 때문에 모든 가수에 대해 답을 계산하는 데 걸리는 시간이 O((K log N + N log N)log T)가 됩니다. 위 식과 비교하면 값을 갱신하는 과정의 시간 복잡도는 O(K log N log T)로 같으며, 가수별로 부른 곡의 수의 합이 N이 되므로 합을 계산하는 과정의 전체 시간이 O(N log N log T)가 됨을 알 수 있습니다.L-모양 직각다각형은 반드시 └ 또는 ┘ 모양이어야 하며, 밑변이 x축에 붙어 있어야 합니다. 이는 주어진 도형이 히스토그램 모양이기 때문입니다.┌ 또는 ┐ 모양이 가능하다면 넓이가 더 넓은 직사각형도 가능하고, 밑변이 x축보다 위에 있다면 도형을 연장하여 x축에 붙일 수 있습니다. 그러고 나면, L-모양 직각다각형은 밑변이 x축에 붙어 있고, 서로 인접한 두 개의 직사각형이 붙어 있는 형태임을 알 수 있습니다. 이렇게 정의를 하면 정점의 수가 4와 6인 경우를 모두 고려하게 됩니다.가장 넓은 L-모양 직각다각형을 찾기 위하여, 역으로 두 직사각형이 붙어 있는 x좌표 x0을 고정해 봅시다. x ≤ x0인 영역과 x ≥ x0인 영역은 독립적이므로, 각각에 대해 가장 넓은 직사각형을 구한 뒤 넓이를 더하면 됩니다. 즉, x = x0 왼쪽/오른쪽 영역에서, x = x0에 붙어 있으면서 히스토그램에 들어 있는 가장 넓은 직사각형을 구하면 됩니다.이렇게 접근했을 때 첫 번째로 당면하는 문제는 x0이 너무 많다는 것입니다. 다행히도, x0으로 가능한 값들은 입력으로 주어진 x좌표들뿐입니다. 이는 f(x0)을 윗 문단의 상황에서 가장 넓은 L-모양 직각다각형의 넓이로 둔다면, f가 구간별로 선형인 함수(piecewise linear function)이며(연속 함수는 아닙니다), 끊기는 지점들이 입력으로 주어진 x좌표들뿐임을 관찰함으로써 알 수 있습니다.남은 것은 x = x0 왼쪽 영역에서, 오른쪽 변이 x = x0에 붙어 있으면서 히스토그램에 들어 있는 가장 넓은 직사각형의 넓이를 구하는 것입니다. 오른쪽 영역에서 구하는 것은 똑같이 할 수 있습니다. 문제 자체가 히스토그램에서 가장 넓은 직사각형을 구하는 상황과 굉장히 유사합니다. 이 문제는 스택을 활용해 해결할 수 있는 방법이 잘 알려져 있습니다. 이 방법을 “알고리즘 X”라고 부르겠습니다.알고리즘 X는 히스토그램을 왼쪽에서부터 오른쪽으로 훑습니다. 각 x좌표를 고려하는 상황에서, 스택에는 (높이 h, 해당 높이 이상이 유지되는 가장 왼쪽 x좌표 xl)의 쌍들이 들어 있습니다. 이 때, 오른쪽 변이 x = x0인 가장 넓은 직사각형을 구하기 위해 할 수 있는 가장 쉬운 생각은 스택을 모두 순회해 보는 것입니다. 스택의 원소 (h, xl)에 대해, 넓이는 h(x0 - xl)입니다. 하지만 모두 순회하는 것은 굉장히 느립니다.그런데, 식의 꼴을 살펴보면 기울기가 h이고 y절편이 -hxl인 직선임을 알 수 있습니다. 즉, 우리가 원하는 것은 여러 개의 직선들이 있을 때, x = x0에서 최댓값을 구하는 것입니다. 컨벡스 헐 트릭(Convex Hull Trick)을 사용할 수 있을 것이라고 생각할 수 있습니다. 마침, 알고리즘 X를 생각해 보면 스택에 저장된 h는 아래에서 위로 갈수록 순증가하기 때문에, 직선의 기울기가 순증가할 때 사용할 수 있는 컨벡스 헐 트릭에도 알맞아 보입니다.문제는, 알고리즘 X에서 스택의 원소가 빠지기도 한다는 것입니다. 컨벡스 헐 트릭에서 추가된 직선 l에 의해 삭제된 직선들이 있을텐데, 스택에서 원소가 제거되는 과정에서 이 삭제된 직선들이 다시 복구되어야 하는 경우가 발생할 수 있습니다. 이 점을 해결하기 위해 크게 세 가지 방법이 있습니다.예선 참가자 중 우수한 성적을 거둔 64명이 본선에 진출하게 됩니다. 예선 순위표는 홈페이지(https://www.kakaocode.com)에 같이 공지할 예정이니 참고하시기 바랍니다. 본선 진출자들이 즐거운 경험을 가지고 돌아갈 수 있도록, 카카오에서 열심히 준비하고 있으니 많이 기대해주세요!",http://tech.kakao.com/2018/08/09/code-festival-2018-round-1/,0,kakao,,NULL,2018-08-09
MySQL Ascending index vs Descending index,"이 설명에서는 인덱스의 정렬 순서와 데이터 읽기 순서 등 방향에 대한 단어들이 혼재하면서, 여러 가지 혼란을 초래하기 쉬운 설명들이 있을 것으로 보인다. 그래서 우선 표준 용어는 아니지만, 나름대로 몇 개 단어들에 대해서 개념을 정립하고 그 단어를 번역 없이 영어로 그대로 표기하도록 하겠다.MySQL 4.x 버전부터 Feature Request로 등록되어 있던 “Descending index” 기능이 드디어 MySQL 8.0에 도입되었다. MySQL 8.0부터는 이제 아래와 같이 역순으로 정렬되는 인덱스(Descending index)를 생성할 수 있게 되었으며, 필요에 따라서 적절히 정순(ORDER BY ASC)과 역순(ORDER BY DESC)을 혼합해서 정렬하는 작업을 인덱스를 이용할 수 있게 된 것이다.아마도 MySQL 8.0 이전에도 Descending index가 지원되었다고 생각했을 수도 있는데, MySQL 8.0 이전에는 문법만 지원되고 실제 Descending index가 지원되는 것은 아니었다. 또한 Ascending index를 Forward scan하는 것과 Backward scan하는 것만으로 Descending index의 요건을 충분히 만족한다고 생각할 수도 있지만, 실제 그렇지 못한 경우도 많다.MySQL 8.0에 도입된 Descending index가 필요한 가장 큰 이유는 이미 살펴본 예제와 같이 정순(ORDER BY ASC)과 역순(ORDER BY DESC) 정렬을 섞어서 여러 컬럼으로 정렬하는 경우일 것이다. 그런데 Descending index가 필요한 이유가 오직 이것뿐일까?MySQL 8.0 이전 버전을 사용하면서 역순 정렬이 필요한 경우에는, 크게 성능에 대한 고려 없이 지금까지 Ascending index를 생성하고 “ORDER BY index_column DESC” 쿼리로 인덱스를 Backward scan으로 읽는 실행 계획을 사용해왔다. 이제 Ascending index를 Forward scan하는 경우와 Backward scan하는 경우의 성능 비교를 간단히 예제로 한번 살펴보자.우선 아래와 같이 information_schema.COLUMNS 테이블의 레코드를 복사해서 대략 1천2백여만 건의 레코드를 가지는 테이블을 만들어 보자.이제 이 테이블을 풀 스캔 하면서 정렬만 수행하는 쿼리를 아래와 같이 한번 실행해보자. 아래 두 쿼리는 테이블의 프라이머리 키를 Forward scan 또는 Backward scan으로 읽어서 마지막 레코드 1건만 반환하게 된다. 첫번째 쿼리는 tid 컬럼의 값이 가장 큰 레코드 1건을 그리고 두번째 쿼리는 tid 컬럼의 값이 가장 작은 레코드 1건을 반환하게 된다. 하지만 LIMIT .. OFFSET .. 부분의 쿼리로 인해서, 실제 MySQL 서버는 테이블의 모든 레코드를 스캔해야만 한다. (이 쿼리는 모든 레코드를 스캔하는 작업은 하지만, 화면에는 레코드 1건만 출력하려고 LIMIT .. OFFSET .. 옵션을 추가한 것임)위 두 쿼리의 실행 결과는 어떤 차이를 보여줄지 먼저 한번 예측해보자. 지금까지는 많은 사용자들이 두 쿼리가 동일한 실행 시간을 보여줄 것이라 믿어 의심치 않았을 것이다. 당연히 그렇게 작동해야 하니까 고려 대상조차 아니었다.테스트 환경 (CPU Bound 테스트)1천2백여만건을 스캔하는데, “1.2초 정도의 차이쯤이야!!”라고 생각할 수도 있다. 하지만 비율로 따져보면, 역순 정렬 쿼리가 정순 정렬 쿼리보다 28.9% 더 시간이 걸리는 것을 확인할 수 있다. 하나의 인덱스를 정순으로 읽느냐 또는 역순으로 읽느냐에 따라서 이런 차이가 발생한다는 것은 쉽게 이해하기 어렵다.MySQL 서버의 InnoDB 스토리지 엔진에서 (많은 사용자들이 이미 잘 알고 있듯이) Forward & Backward index scan 페이지(블록) 간의 양방향 연결 고리(Double linked list)를 통해서 전진(Forward)하느냐 후진(Backward)하느냐의 차이만 있다. 이것만 보면 Forward와 Backward index scan의 성능 차이는 이해되지 않는다.실제 InnoDB에서 Backward index scan이 Forward index scan에 비해서 느릴 수밖에 없는 2가지 이유를 가지고 있다.InnoDB의 페이지 잠금 방식은 Forward index scan을 중심으로 구현되어 있는데, Forward index scan으로 인덱스 리프 페이지를 읽을 때는, 아래 코드 샘플과 같이 페이지의 잠금을 획득할 때에는 Forward scan 순서대로 잠금을 걸고 다시 잠금을 해제하게 된다.이제 Backward index scan시에 페이지 잠금을 획득하는 코드 샘플을 한번 살펴보자.대략 코드를 읽어보면, (100% 이해는 어렵더라도) 대략 Backward index scan으로 이전 페이지로 넘어가는 과정은 아래와 같은 처리가 발생하는 것을 알 수 있다.InnoDB의 B-Tree 리프 페이지는 Double linked list로 연결되어 있기 때문에, 사실 어느 방향이든지 이동 자체는 차이가 없다. 하지만 InnoDB 스토리지 엔진에서는 페이지 잠금 과정에서 데드락을 방지하기 위해서 B-Tree의 왼쪽에서 오른쪽 순서(Forward)로만 잠금을 획득하도록 하고 있다. 그래서 Forward index scan에서는 다음 페이지 잠금 획득이 매우 간단하지만, Backward index scan에서 이전 페이지 잠금을 획득하는 과정은 상당히 복잡한 과정을 거치게 된다.이런 차이로 인서 많은 페이지를 스캔해야 하는 Index scan에서는 잠금 획득으로 인한 쿼리 처리 지연이 발생하게 된다.InnoDB 스토리지 엔진이 특정 레코드를 검색할 때, B-Tree를 이용해서 검색 대상 레코드(인덱스 엔트리)가 저장된 페이지(Block)까지는 검색할 수 있다. 하지만 그 페이지 내에도 수많은 레코드가 저장되어 있는데, 일반적으로 20바이트 키를 저장하는 인덱스 페이지(16K)라면, 대략 600여개 이상의 레코드가 저장될 수 있다. InnoDB 스토리지 엔진이 600여개 레코드를 하나씩 다 순차적으로 비교한다면 레코드 검색이 상당히 느릴 것이다. 그래서 InnoDB 스토리지 엔진은 하나의 페이지내에서 순차적으로 정렬된 레코드 4~8개 정도씩을 묶어서 대표 키(가장 큰 인덱스 엔트리 키 값)를 선정한다. 그리고 이 대표 키들만 모아서 별도의 리스트를 관리하는데, 이를 페이지 디렉토리(Page directory)라고 한다. 아래 그림은 “Jeremy Cole”이 그린 “InnoDB 자료 구조“중에서 “InnoDB page directory” 그림을 캡처한 것이다. 이미 충분히 이해하기 쉽도록 그려져 있어 그대로 차용하고자 한다.InnoDB 스토리지 엔진은 하나의 페이지에서 특정 키 값을 검색할 때 Page directory를 이용해서 바이너리 서치(Binary search) 방식으로 검색 대상 키를 포함하는 대표 키를 검색한다. 그리고 대표 키를 찾으면 그때부터는 인덱스 키 값 순서대로 연결된 Linked list를 이용해서 대상 레코드를 검색하게 된다.그런데 Double linked list로 연결된 B-Tree의 리프 페이지 구조와는 달리, 페이지 내부의 레코드(인덱스 엔트리)들은 Single linked list 구조로 구성되어 있다. Single linked list는 Ascending index에서는 키 값이 오름차순으로 정렬되어서 Linked list로 구성되는 것이다. 만약 Descending index라면 키 값이 내림차순으로 정렬되어서 Linked list 구성될 것이다. 그래서 Ascending index에서 Forward index scan은 Linked list를 그대로 따라가기만 하면 되지만, Backward index scan은 그렇게 간단하지 않다.아래 코드 샘플은 Forward index scan을 할 때 하나의 페이지에서 Page directory를 이용해서 다음 레코드를 찾아오는 방법을 보여주고 있다.Forward index scan은 단순히 Linked list만 따라가면 되기 때문에 코드 역시 매우 간단하다. 이제 Backward index scan의 코드 샘플을 한번 비교해보자.사실 코드 자체는 많이 복잡하지 않지만, Page directory별로 4~8개 정도의 레코드(인덱스 키 엔트리)가 저장되므로 while loop을 평균적으로 2~4번 정도씩 실행해야 이전 레코드(Backwrad index scan)를 찾을 수 있는 것이다.이로써 Backward index scan이 Forward index scan보다 느린 이유를 알게 되었다. 그렇다면 실제 Backward index scan을 사용하면 서비스가 엄청나게 느려지는 것일까? Forward index scan과 Backward index scan의 실제 서비스 영향도는 일반적으로 그렇게 크지 않았다. 아주 랜덤한 키 값으로 검색해서 Index range scan을 실행하는 경우 대략 아래 그래프와 같이 10% 정도의 쿼리 스루풋 차이를 보였으며, CPU 사용량의 차이는 미미했다 (Test thread를 16개 정도로 안정적인 쿼리 처리가 가능한 상황에서의 테스트 결과). Forward index scanBackward index scan하지만 정렬된 Index의 특정 부분(인덱스의 앞부분 또는 끝부분)을 집중적으로 읽는 경우, 44% 정도의 스루풋 차이를 보이며 CPU 사용량도 큰 차이를 보였다. Forward index scanBackward index scan첫번째 테스트에서는 매번 쿼리가 실행될 때마다 인덱스 스캔 위치를 랜덤하게 선택하도록 해서, 실제 각 쓰레드간의 페이지 잠금 경합이 그다지 심하지 않았던 것이다. 그리고 인덱스를 Backward scan하는 데 추가로 더 걸린 시간은 쿼리의 처리 시간에 그다지 크게 영향을 미치지 않았던 것이다. 그런데 이번 테스트 케이스(두번째 테스트 케이스)에서는 유입되는 모든 쿼리가 동일 페이지에 집중되는 상황인데, 이때에는 쿼리를 실행중인 쓰레드들끼리 경합을 하면서 아주 짧은 페이지 잠금 시간이 더 길어지는 효과를 내게 된 것이다. 그래서 쿼리의 Ascending index scan보다 Descending index scan이 훨씬 더 많은 쿼리 시간이 걸리게 된 것이다.두번째 테스트 케이스에서는 1000건의 레코드를 조회(LIMIT 1000)하도록 했는데, 이 건수가 하나의 페이지에 저장된 레코드 건수보다 크면 Ascending과 Descending index scan의 성능 차이가 커졌으며, 조회 건수가 페이지에 저장된 레코드 건수보다 적으면 Ascending과 Descending index scan의 성능 차이는 줄어들었다. 즉 성능 차이에 영향을 미치는 2가지 구조적 이유 중에서, 페이지 잠금이 Forward index scan에 적합한 구조가 더 크게 영향을 미치는 것으로 보인다.사용자에게 일반적으로 노출되는 잠금(Table & Row lock, …) 이외에도 InnoDB 스토리지 엔진에서는 내부적으로 페이지의 레코드를 접근할 때마다, 페이지에 대해서 잠금을 걸어야 한다. 이때 InnoDB 스토리지 엔진은 RW-lock(Semaphore)이 아닌 Mutex를 사용하기 때문에 읽기 쿼리와 쓰기 쿼리뿐만 아니라 읽기 쿼리들끼리도 페이지 잠금을 점유하기 위해서 경쟁해야 하기 때문에, 동시 쓰레드가 많아지면 많아질수록 성능 영향도는 더 커지게 되는 결과를 만들게 될 것으로 보인다.참고로, 테이블의 데이터 파일을 구성하는 B-Tree의 각 페이지에 저장된 레코드 건수가 성능을 영향을 미치게 되는데, 이 테스트를 위한 테이블의 각 페이지에 저장된 레코드 건수는 아래와 같았다.일반적으로 인덱스를 ORDER BY ... DESC하는 쿼리가 소량의 레코드를 드물게 실행되는 경우라면, Descending index를 굳이 고려할 필요는 없어 보인다.예를 들어서 아래와 같은 쿼리인 경우, 아래 2가지 인덱스 모두 적절한 선택이 될 수 있다.하지만 위 쿼리가 조금 더 많은 레코드를 빈번하게 실행된다면, Ascending index보다는 Descending index가 더 효율적이라고 볼 수 있다. 또한 많은 쿼리가 인덱스의 앞쪽만 또는 뒤쪽만 집중적으로 읽어서 인덱스의 특정 페이지 잠금이 병목 지점이 될 것으로 예상된다면, 적절히 Descending index를 생성하는 것이 경합 감소에 도움이 될 것으로 보인다.물론 ASC와 DESC 정렬을 혼합해서 동시에 사용하는 쿼리라면, 당연히 ASC와 DESC를 섞어서 인덱스를 생성해야 하므로, 고민할 필요 없이 쿼리의 정렬 조건에 맞게 인덱스를 생성하면 될 것으로 보인다.그리고 Ascending index와 Descending index의 선택은 MySQL 서버가 CPU Bound로 쿼리를 처리할 때의 이야기이다. 만약 MySQL 서버가 데이터를 읽기 위해서 매번 Disk를 읽어야 한다면, Ascending index나 Descending index의 구조적 장단점은 Disk 반응 속도(Latency)에 이미 상쇄되어 버리기 때문에 그다지 쿼리 처리상 성능 영향 요소가 아니라고 볼 수 있다.",http://tech.kakao.com/2018/06/19/AscendingAndDescendingIndex/,0,kakao,"docker,spring,php,javascript,java",NULL,2018-06-19
"사용하면서 알게 된 Reactor, 예제 코드로 살펴보기","Reactor는 Pivotal의 오픈소스 프로젝트로, JVM 위에서 동작하는 논블럭킹 애플리케이션을 만들기 위한 리액티브 라이브러리입니다. Reactor는 RxJava 2와 함께 Reactive Stream의 구현체이기도 하고, Spring Framework 5부터 리액티브 프로그래밍을 위해 지원되는 라이브러리입니다. RxJava에 익숙한 필자가 Reactor를 사용하면서 느낀 것은 RxJava와 많은 공통점이 있으며 큰 차이점이 있다면 Reactor는 최소 Java8에서 동작하며 Java8의 피쳐를 잘 지원한다는 점입니다.   본문에서는 필자가 스프링 프레임워크 WebFlux환경에서 개발을 할 때 Reactor에 대해서 알게 된 점을 공유하고자 합니다. 쉬운 이해를 위해 간단한 자바 애플리케이션 예제 코드를 통해 소개하도록 하겠습니다. 본 예제에서 사용된 자바 버전은 Java8이며, Reactor 버전은 3.1.7 임을 알려드립니다.우선 예제에 들어가기 앞서 Mono와 Flux의 차이점을 알 필요가 있습니다. Mono는 0-1개의 결과만을 처리하기 위한 Reactor의 객체이고, Flux는 0-N개인 여러 개의 결과를 처리하는 객체입니다. Reactor를 사용해 일련의 스트림을 코드로 작성하다 보면 보통 여러 스트림을 하나의 결과를 모아줄 때 Mono를 쓰고, 각각의 Mono를 합쳐서 여러 개의 값을 여러 개의 값을 처리하는 Flux로 표현할 수도 있습니다. 자세한 설명은 Reactor의 Mono reference와 Flux reference를 읽어 보시면 됩니다.   Mono와 Flux모두 Reactive Stream의 Publisher 인터페이스를 구현하고 있으며, Reactor에서 제공하는 풍부한 연산자들(operators)의 조합을 통해 스트림을 표현할 수 있습니다. 예를 들어 Flux에서 하나의 결과로 값을 모아주는 reduce연산자는 Mono를 리턴하고, Mono에서 flatMapMany라는 연산자를 사용하면 하나의 값으로부터 여러 개의 값을 취급하는 Flux를 리턴할 수 있습니다. 그리고 Publisher인터페이스에 정의된 subscribe메서드를 호출함으로써 Mono나 Flux가 동작하도록 할 수 있습니다. 자세한 내용은 예제 코드를 통해 다루도록 하겠습니다.여기서는 하나의 스트림에서 여러 개의 스트림으로 갈라질 때 Flux와 Mono를 어떻게 적절히 섞어서 사용했는지 예제를 통해 보도록 하겠습니다.여기서 사용할 예제는 과일바구니 예제입니다. basket1부터 basket3까지 3개의 과일바구니가 있으며, 과일바구니 안에는 과일을 중복해서 넣을 수 있습니다. 그리고 이 바구니를 List로 가지는 baskets가 있습니다. Flux.fromIterable에 Iterable type의 인자를 넘기면 이 Iterable을 Flux로 변환해줍니다. 이러한 예제를 만든 이유는 스프링에서 WebClient를 이용하여 특정 HTTP API를 호출하고 받은 JSON 응답에 여러 배열이 중첩되어 있고, 여기서 또 다른 API를 호출하거나 데이터를 조작하는 경우가 있었습니다.  처음엔 API 호출을 몇 번하고 원하는 데이터로 조작하고자 하는 필요에서 시작하였지만, 받은 데이터를 막상 적절한 연산자의 조합으로 하려고 접근하다 보면 어려워지고, 어떻게 하면 쉽게 풀 수 있을까 생각해보았습니다. 그리고 간단한 예제를 만들어 연습해보는 것이 좋겠다는 생각이 들었습니다. 따라서 이러한 연습을 위해 여기서는 과일바구니를 표현하는 리스트를 만들어 시작을 해보도록 하겠습니다.basketFlux로부터 중복 없이 각 과일 종류를 나열하고, 각 과일이 몇 개씩 들어있는지 각 바구니마다 출력하는 코드를 작성해보도록 하겠습니다. 단순히 Reactor사용 없이 Java에 있는 방법만으로 함수형 프로그래밍도 아닌 절차 지향적으로 생각해보면 어렵지 않습니다. baskets를 for each loop로 돌면서 Set에 담을 수도 있고, 각 과일의 개수는 Set에 처음으로 들어가는 경우 Map에 key값으로 1 값을 갖게 만들고, 그 외의 경우는 1씩 증가시키는 방법으로 과일의 개수를 셀 수 있습니다.  그렇다면 basketFlux에서 연산자들의 조합으로 어떻게 이 2가지 과제를 할 수 있을까요? 우선 이 기능을 추상화한 연산자를 찾아볼 수 있습니다. 중복 없이 값을 처리하는 연산자로 distinct가 있고, 각 key별로 스트림을 관리하기 원한다면 key를 기준으로 Flux로 그룹을 묶을 수 있는 groupBy가 있습니다. 그리고 스트림에서 내려주는 값의 개수를 셀 수 있는 count라는 연산자도 있습니다. 그런데 이것들을 하려면 basketFlux로부터 각각의 바구니들을 꺼내야 합니다. 이렇게 값을 꺼내서 새로운 Publisher로 바꿔줄 수 있는 연산자로는 대표적으로 flatMap, flatMapSequential, concatMap이 있습니다. flatMap은 리턴하는 Publisher가 비동기로 동작할 때 순서를 보장하지 않으므로, 순서 보장을 하려면 flatMapSequential 또는 concatMap을 사용해야 하는데, 여기서는 concatMap을 사용하도록 하겠습니다. flatMapSequential과 concatMap의 차이는 concatMap은 인자로 지정된 함수에서 리턴하는 Publisher의 스트림이 다 끝난 후에 그다음 넘어오는 값의 Publisher스트림을 처리하지만, flatMapSequential은 일단 오는 대로 구독하고 결과는 순서에 맞게 리턴하는 역할을 해서, 비동기 환경에서 동시성을 지원하면서도 순서를 보장할 때 쓰이는 것이 차이점입니다.distinctFruits와 countFruitsMono라는 이름으로 앞서 소개한 연산자들로 조합을 했습니다.   과일의 중복이 없도록 모으는 distinctFruits에서는 List로 변환하기 위해 Flux에서 제공하는 collectList를 이용했습니다. 이렇게 하면 Flux에서 넘어오는 각각의 항목들을 하나의 리스트로 모아주는 Mono로 변환할 수 있습니다. countFruitsMono에서는 각 과일의 개수를 key, value를 갖는 Map (자료구조 interface Map)으로 모으기 위해서 reduce를 이용해서 합쳤습니다. 순서를 보장하기 위해 concatMap과 LinkedHashMap을 사용했습니다. 이렇게 하면 순서대로 넘어온 각 과일의 개수를 순서대로 Map에 순서에 따라 모을 수 있습니다.  이렇게 만들어 놓으니 이제 이 둘을 각각 합쳐서 하나의 스트림으로 리턴을 해줘야 합니다. 리턴 부분은 아직 물음표로 주석처리를 해두었습니다. 이렇게 2개의 스트림을 하나의 객체를 리턴하는 Publisher로 합쳐주는 연산자로는 Flux.zip이 있습니다. 이것을 합쳐줄 객체를 만들기 위해 FruitInfo라는 클래스를 정의하고 zip연산자를 사용해보도록 하겠습니다.FruitInfo 클래스zip연산자로 합친 예제결과distinct 된 리스트와 각 과일의 개수를 묶은 리스트를 하나의 리스트로 묶어서 각각 출력하는 것을 확인할 수 있습니다. 그런데 이런 식의 방식은 너무 비효율적입니다. distinctFruits와 countFruitsMono모두 Flux.fromIterable(basket)로부터 시작해서 각각 basket을 독립적으로 순회합니다. 절차 지향으로 생각하면 하나의 for each loop 안에서 2가지를 한 번에 해결할 수 있는데 여기서는 총 2번 basket을 순회하고, 특별히 스레드를 지정하지 않았기 때문에 동기, 블록킹 방식으로 동작합니다. 논 블록킹 라이브러리의 장점을 전혀 살릴 수 없고, 효율성도 떨어집니다. 단순히 Reactor에서 제공하는 연산자들의 조합의 코드일 뿐입니다.   그래서 비동기 논 블록킹으로 동시성도 살리면서, 순차적으로 basket을 두 번 순회하지 않는 방법을 다음 코드에서 다뤄보고자 합니다.Reactor나 RxJava 모두 동시성 지원을 위해 Scheduler를 제공합니다. 적절한 Scheduler를 적절한 위치에 지정함으로써 동시성과 실행 순서를 적절히 관리할 수 있습니다. 기본적으로 스케줄러를 지정하지 않고 사용하는 연산자가 특정한 스케줄러에서 동작하지 않는다면, Reactor의 Flux나 Mono는 구독할 때 현재 스레드에서 동작합니다. 따라서 위의 코드도 로그를 찍어봄으로써 스레드를 확인해보면 모든 코드가 main thread에서 동기로 실행되는 것을 확인할 수 있습니다. 스프링 프레임워크 5부터 제공하는 WebClient를 사용하면 다른 스레드로 이미 바뀌어서 비동기로 동작하겠지만, 해당 스레드 안에서도 몇몇 스트림은 병렬로 실행시키고자 할 필요가 있을 수 있습니다. 그렇다면 어떻게 스케줄러를 지정하여 1) 과일의 종류를 뽑아내는 것과 2) 과일의 개수를 뽑아내는 이 2가지 작업을 병렬로 실행할 수 있을지 알아보도록 하겠습니다.Reactor의 스케줄러 관련 문서를 보면 기본적으로 제공하는 몇 가지 스케줄러에 대한 설명이 있습니다. 여기서는 병렬로 여러 개를 실행시키기 위해 Schedulers.parallel()을 사용하도록 했는데, 이 스케줄러는 병렬 실행을 위해 CPU 코어 개수만큼 워커를 만들어 병렬로 실행을 지원하는 스케줄러 입니다. RxJava에서는 Schedulers.computation()이 해당 스케줄러에 해당되는 것으로 알고 있습니다. 필자의 머신에서는 쿼드코어에 하이퍼스레딩의 영향으로 최대 8개의 스레드로 해당 스케줄러가 동작하는 것을 확인할 수 있었습니다.subscribeOn연산자는 해당 스트림을 구독할 때 동작하는 스케줄러를 지정할 수 있습니다. 여기서 distinctFruits와 countFruitsMono가 각각 병렬로 동작하길 원하므로 subscribeOn(Schedulers.parallel())을 각각 추가하여 실행시켜 보았습니다. 그런데 이 자바 애플리케이션은 아무 결과도 확인 못하고 끝나 버립니다.왜냐하면 parallel스케줄러는 데몬스레드(Deamon Thread)인데 이 애플리케이션이 처음 동작하는 main thread는 데몬스레드가 아닌 비-데몬스레드(Non-Deamon Thread)이기 때문에 main메서드가 끝나버리며 아무런 비-데몬스레드가 남지 않아 종료되기 때문입니다. 종료되지 않고 계속 동작해야 하는 서버 환경의 애플리케이션에서는 괜찮겠지만, 본 애플리케이션은 main메서드가 끝난 후 비-데몬스레드가 하나도 남아있지 않아 종료됩니다. 이를 방지하기 위해  CountDownLatch를 이용하여 await()으로 애플리케이션이 종료되지 않게 main스레드가 동작이 끝날 때까지 기다리도록 하겠습니다. 위의 스트림이 정상적으로 또는 에러가 나서 종료한 경우에 countDown메서드를 호출하여 더 이상 기다리지 않고 종료되도록 하겠습니다. 혹시 모르게 오랫동안 기다리는 경우를 막기 위해 await(2, TimeUnit.SECONDS)으로 2초 정도의 timeout을 두도록 했습니다.결과결과가 잘 나오는 것을 확인할 수 있습니다. 병렬로 실행되는지 확인하기 위해 distinctFruits와 countFruitsMono의 각각의 시작점 Flux.fromIterable(basket)에 log()라는 메서드를 추가하도록 하겠습니다. 그러면 log()를 호출한 지점 위에서 넘어오는 값을 로그로 확인하며 디버깅하기 좋습니다. Reactor에서 유용한 메서드 중 하나입니다.처음엔 parallel-1과 parallel-2이 같이 동작하고, 그다음 순서로 parallel-3과 parallel-4이 같이 동작하는 것을 로그를 통해 확인할 수 있습니다.지금까지 진행해온 과정에서 아쉬운 점을 좀 더 개선해보고자 합니다. distinctFruits와 countFruitsMono 모두 Flux.fromIterable(basket)에서 출발하기 때문에 병렬로 동작해도 baskets를 각각 순회하여 중복되는 동작이라는 점은 처음의 예제와 다를 게 없습니다. 또한 몇 개 안 되는 데이터를 각각 병렬로 처리하는 것은 스레드를 생성하고 컨텍스트 스위칭을 하는 비용을 생각하면 배보다 배꼽이 클 수도 있습니다. baskets을 순회하는 공통 작업을 하나의 스트림에서 하는 방법은 없을까요? 먼저 관련된 배경지식을 다루고 그 방법을 함께 살펴보도록 하겠습니다.Hot과 Cold 개념은 RxJava에도 있는 개념으로 Reactor의 Hot, Cold 개념은 공식문서 Hot vs Cold를 통해서 확인하실 수 있습니다.   간단히 설명하면 Cold는 각 Flux나 Mono를 subscribe 할 때마다 매번 독립적으로 새로 데이터를 생성해서 동작합니다. 즉, subscribe호출 전까지 아무런 동작도 하지 않고, subscribe를 호출하면 새로운 데이터를 생성합니다. 기본적으로 특별하게 Hot을 취급하는 연산자가 아닌 이상 Flux나 Mono는 Cold로 동작합니다. 따라서 지금까지 예제는 basket으로부터 값을 꺼내어 각각 따로 새로운 데이터를 생성하기 때문에 각각 중복된 작업을 새로 시작하게 동작합니다.   그러나 Hot은 구독하기 전부터 데이터의 스트림이 동작할 수 있습니다. 예를 들어서 마우스 클릭이나 키보드 입력 같은 이벤트 성은 구독여부와 상관없이 발생하고 있다가 이 이벤트를 구독하는 여러 구독자가 붙으면 해당 이벤트가 발생할 때 모두 동일한 값을 전달받을 수 있습니다. 즉, Hot에 해당하는 스트림을 여러 곳에서 구독을 하면 현재 스트림에서 나오는 값을 구독하는 구독자들은 동일하게 받을 수 있습니다.    여기서 주목할 점은 Cold를 Hot으로 바꿀 수 있는 연산자가 있다는 것입니다. 처음 Hot에 대해서 예제를 든 마우스클릭이나 키보드입력같은 이벤트를 떠올리면 쉽게 상상이 안되는데요. Cold는 구독을 하면 값을 생성하기 시작합니다. 그러나 Cold를 Hot으로 바꾸면 구독여부와 상관없이 값을 생성 안 하다가 특정 시점에 값을 생성하도록 제어하여 구독하는 구독자(Subscriber)들이 동일한 값을 받을 수 있도록 할 수 있습니다. 이에 대해 알아보겠습니다.Connectable Flux는 Cold에서 Hot으로 바꾸기 위해서는 Connectable Flux로 변환하는 과정이 필요합니다. 공식문서에 설명되어 있듯 기본적으로 publish라는 연산자를 호출하면 바꿀 수 있습니다. 이렇게 변환된 Flux에서 connect()라는 메서드를 호출할 수 있는데, 이 메서드가 여러 구독자들이 Connectable Flux를 구독한 후 값을 생성하여 각 구독자에게 보내기 시작하게 하는 메서드입니다. 즉, 우리의 예제에서는 distinctFruits와 countFruitsMono가 구독을 모두 완료한 후에 connect()를 호출할 수 있게 해주면 됩니다. 어떻게 할 수 있을까요? 다행히 Reactor에서는 autoConnect나 refCount에 인자 값으로 최소 구독하는 구독자의 개수를 지정해서 이 개수가 충족되면 자동으로 값을 생성할 수 있게 연산자를 제공합니다. 2개의 차이점이 있다면 autoConnect는 이름 그대로 최소 구독 개수를 만족하면 자동으로 connect()를 호출하는 역할만 하고, refCount는 autoConnect가 하는 일에 더해서 구독하고 있는 구독자의 개수를 세다가 하나도 구독하는 곳이 없으면 기존 소스의 스트림도 구독을 해제하는 역할을 합니다. interval처럼 무한히 일정 간격으로 값이 나오는 스트림을 Hot으로 바꾼다면 refCount를 고려해 볼 수 있을 것입니다. 호출되는 소스가 무한으로 값을 생성한다면 더 이상 구독을 안 할 때 해제하게 refCount를 고려해볼 수 있지만, 우리는 제한된 개수의 데이터만 다 다루면 알아서 완료가 되기 때문에 autoConnect로 충분하다고 생각합니다. 참고로 여기서 소개한 2개의 연산자는 인자 값을 없을 경우 최초 구독이 발생할 때 connect()를 호출하도록 동작하고, publish().refCount()를 하나의 연산자로 추상화한 연산자를 share()라고 합니다. 그 밖에 RxJava의 ConnectableFlowable도 동일한 기능을 제공하는 것을 문서를 통해 확인할 수 있었습니다.이제 코드로 공통적으로 사용하는 Flux.fromIterable(basket)을 Hot으로 만들어보도록 하겠습니다.   설명에서 소개한 바와 같이 publish().autoConnect(2)를 사용하도록 하겠습니다. 이렇게 하면 Hot으로 변환된 ConnectableFlux를 최소 2개의 구독자가 구독을 하면 자동으로 구독하는 Flux를 리턴합니다. 이를 소스코드에서는 source라는 변수에 지정하고, distinctFruits와 countFruitsMono모두 source를 공통으로 쓰도록 했습니다. Flux.fromIterable(basket) 뒤에 log()는 그대로 두었습니다.  한 번만 값이 나오나 확인하기 위함입니다. 추가로  distinctFruits와 countFruitsMono에서 subscribeOn은 제거했습니다. 굳이 몇 개 안 되는 데이터를 병렬로 돌릴 필요가 없어 보였고, 하나의 스레드에서 Flux.fromIterable(basket)가 한 번만 동작하면서 2가지 스트림으로 동작할 수 있음을 보여주기 위함입니다.결과이하 결과를 생략했지만 모두 main스레드에서 값이 잘 나오는 것을 확인할 수 있습니다. 여기서는 동일한 스레드이기 때문에 countDownLatch도 필요가 없습니다. 두 군데서 구독할 때만 값이 나오는지 확인하기 위해 zip에서 쓰이는 distinctFruits의 source를 Flux.fromIterable(basket)로 바꿔서 source가 한 번만 구독되도록 해보겠습니다.source를 한 곳 countFruitsMono에서만 구독할 때 예제구독한 후 아무 값도 나오지 않습니다. complete도 불리지 않는 것을 확인할 수 있습니다.위의 예제에서는 몇 개 안 되는 데이터라 같은 스레드에서 동기로 실행시켰지만, 데이터가 많아지거나 현재 스레드가 다른 일을 하게 하기 위해서 distinct나 groupBy count 등의 연산을 하는 지점은 각각 비동기로 처리하고자 하는 필요가 생길 수도 있습니다. 그러나 앞서 소개한 subscribeOn은 이런 경우 적절하지 않습니다.  subscribeOn을 호출한 객체를 구독할 때는 해당 스트림 전체가 해당 스케줄러로 다 바뀌기 때문에, Hot인 source도 2개의 구독자가 구독을 하면 subscribeOn이 지정한 스레드에서 실행되게 되며, 그러면 distinct와 count로 갈라져 나오는 부분도 같은 스레드에서 실행되기 때문입니다. 이를 확인하기 위해 기존의 예제에서 distinctFruits와 countFruitsMono에 각각 subscribeOn(Schedulers.parallel())을 붙여서 실행해보겠습니다. 이때 각각 어느 스레드에서 동작하는지 확인하기 위해 log()를 붙였습니다.결과처음엔 parallel-1과 parallel-2로 동작하는 듯했다가 결국 source는 parallel-1에서 실행됩니다. 2개의 구독자가 구독을 한 후 source가 parallel-1에서 시작되니 그 이후 동작도 다 parallel-1에서 실행되는 것입니다. subscribeOn으로 스케줄러를 지정하여 스위칭이 되면 이후 스트림은 계속 그 스케줄러에 의해 동작되기 때문입니다.이때 필요한 것이 publishOn연산자입니다. 이 연산자가 호출된 위치 이후에 실행되는 연산자들은 publishOn에서 지정된 스케줄러에서 실행되도록 할 수 있습니다. subscribeOn과의 차이점은 마블 다이어그램을 통해 확인하실 수 있습니다. 그렇다면 publishOn을 각각 source 바로 뒤에 호출되도록 붙여 보겠습니다.결과의도한 대로 각각 parallel-1과 parallel-2에서 실행되는 것을 확인할 수 있습니다. 그런데 처음에 source에서 시작할 때는 main스레드에서 시작하다가 publishOn으로 전체 스트림의 스케줄러가 바뀌면서 그다음 source는 parallel-2에서 실행되는 것을 확인할 수 있습니다. 만약 source가 하나의 지정한 스레드에서만 실행되도록 하고 싶다면 source에 subscribeOn을 추가할 수 있습니다. 이렇게 되면 source는 해당 스케줄러에 의해 동작하고 그 이후는 publishOn에 의해 바뀔 수 있습니다. 어떤 스케줄러를 지정할지는 필요에 따라 다를 듯 하지만, Reactor 공식문서 스케줄러를 읽어보고 저의 경우는 Schedulers.single()을 선택했습니다. 호출할 때마다 같은 스레드를 유지할 수 있기 때문에 매번 source를 구독할 때마다 같은 스레드에서 동작할 수 있기 때문입니다.결과 (설명상 필요한 부분만)결과는 필요한 부분만 뽑아 보았습니다. source는 single-1이라는 스레드에서 항상 동작하고, 그 이후에는 각각 parallel-1과parallel-2, parallel-3과parallel-4, parallel-5과parallel-6으로 동작하는 것을 확인할 수 있습니다.Reactor나 RxJava와 같이 스트림을 여러 연산자의 조합으로 체이닝 동작하는 방식의 라이브러리는 디버깅이나 테스트가 쉽지 않은 점이 있습니다. 예를 들어 에러가 났을 때 어떤 연산자에서 오류가 났는지 알기 어려워서 중간에 doOnNext와 같은 연산자로 로그를 찍어야 할 수도 있습니다. 물론 Reactor에는 앞서 소개한 log()라는 연산자도 있어서 편리하게 로그를 찍어볼 수 있습니다. 그러나 이 log()도 직전의 값만 출력해주기 때문에 사이사이에 log()를 넣어주는 것도 번거로워 보였습니다. 그래서 Reactor의 디버깅 관련된 문서를 찾아보았습니다. Flux나 Mono를 구독하기 전 애플리케이션 시작 단계에서 Hooks.onOperatorDebug();를 호출하면 디버깅 모드를 활성화할 수 있으며, 이럴 경우 에러가 발생했을 때 출력되는 스택트레이스에 시작부터 에러가 났을 때까지 연산자의 목록을 모두 볼 수 있습니다. 공식문서에서는 다음과 같이 나온다고 소개되어 있는데, 해보니 실제로 에러가 났을 때 연산자들이 나오는 것을 확인할 수 있었습니다.테스트 코드 작성을 위해 테스트 관련 문서를 참고해 보았습니다. io.projectreactor:reactor-test를 의존성으로 추가하고 StepVerifier를 통해 테스트 코드를 작성할 수 있었습니다. StepVerifier.create로 테스트할 객체를 만들 때 인자로 테스트 대상이 되는 Flux나 Mono를 넘깁니다. 그리고 테스트에 필요한 메서드들을 연달아서 호출해서 기대한 값이 나왔는지 확인할 수 있습니다. 여기서는 expectNext와 verifyComplete를 이용해서 next로 넘어온 값이 기대한 값인지 그리고 complete이 호출되었는지 검증해보도록 하겠습니다. 여기서 getFruitsFlux()는 지금까지 만든 예제와 관련된 Flux를 리턴하는 메서드이며, JUnit4를 이용하여 테스트해보았습니다.테스트는 잘 통과되는 것을 확인할 수 있고, 값을 값을 하나 바꿔서 실패하게 만들면 어떤 값이 스트림에서 넘어왔는데 기대하는 값은 무엇인지도 잘 출력됩니다. 그리고 verifyComplete이 리턴하는 타입은 Duration이란 타입인데, 여기에는 테스트하는 동안 걸린 시간 정보가 들어가게 됩니다.지금까지 간단한 예제를 이용해 Reactor의 연산자들을 어떻게 조합해서 데이터를 변환하는지, Cold에서 Hot으로 변환하는 과정을 이해하고 하나의 스트림에서 여러 스트림으로 나갈 때 어떻게 하는지, 스케줄러를 지정해 어떻게 실행 컨텍스트를 전환시켰는지 살펴보았습니다. 그밖에 log()나 디버깅 모드를 활용해서 에러난 위치나 스트림의 흐름을 쉽게 볼 수 있다는 것도 유용해 보였습니다.  스프링 프레임워크 5부터는 리액티브 프로그래밍을 할 수 있게 Reactor와 RxJava를 사용하도록 지원해주고 있지만, 현재는 실무에서 보편적으로 사용되는 것 같아 보이진 않습니다. RxJava에 익숙하다면 Reactor도 공식문서를 보고 적응하기 어렵지 않아 보였습니다.   사용하면서 어려운 점은 연산자만으로 해결이 가능한 부분이 있음에도 아직 익숙하지 않고 높은 학습곡선과 수많은 연산자들을 다 모르기에, 중간에 Flux나 Mono에서 값을 꺼내서 동기방식과 명령형 프로그래밍으로 조작한 후 다시 넣어야 하나 유혹을 받는 경우가 온다는 것입니다. 이렇게 하면 함수형 프로그래밍과 명령형 프로그래밍이 섞여 있어 코드도 복잡해지고 중간에 block 같은 연산자를 써서 논 블록킹 라이브러리의 장점을 살릴 수 없는 상황이 오게 된다는 것입니다. 따라서 Reactor를 사용하여 리액티브 프로그래밍을 해야 하는 상황을 고려한다면, 1) 필요한 이유, 2) 추후 코드 변경 시 유지보수성, 3)함께 협업하는 사람들의 숙련도나 관심 등을 고려하여 선택해야 한다고 생각합니다. 필자의 경험으로는 여러 스레드를 전환해야 해서 순서가 복잡해져서 그 사이에 순서를 잘 관리하거나, 복잡하게 데이터를 변환해야 하는 경우, 그리고 여러 스트림을 블록킹으로 처리하기보다 논 블록킹으로 처리하기 좋은 경우에 Reactor나 RxJava같은 라이브러리가 유용해 보였습니다.   이번에 Reactor를 사용해보면서 정리했으면 좋겠다는 패턴이 보여서 간단한 예제로 정리를 했습니다. 본문에서 Reactor의 모든 것을 다룰 순 없었어도, 필요한 부분이 참고가 돼서 Reactor 같은 라이브러리로 리액티브 프로그래밍을 하는데 도움이 되었으면 좋겠습니다.",http://tech.kakao.com/2018/05/29/reactor-programming/,0,kakao,"react,java,mysql,backend,frontend,javascript,database",NULL,2018-05-29
NumPy와 C++ Extensions의 성능 비교,"파이썬은 놀라운 생산성을 발휘하는 언어입니다. 하지만 성능 문제는 늘 발목을 잡게 합니다. 이 문제를 극복하는 방법으로 일반적으로 C Extension을 작성하는 방법이 권장되며, 여기서는 표준 편차를 구하는 함수를 작성하여 순수 파이썬의 성능과 NumPy, 각종 C++ Extensions의 성능을 비교해 보도록 합니다.표준 편차를 구하는 파이썬 코드는 아래와 같이 작성할 수 있습니다.NumPy로는 매우 간단하게 한 줄로 처리 가능합니다.NumPy를 사용하면 코드가 간단해지고, 일반적으로 NumPy는 C로 최적화한 매우 효율적인 라이브러리로 알려져 있으나 NumPy는 싱글 코어와 대형 배열에 최적화된 라이브러리라는 한계가 존재합니다. 실제로 배열의 크기가 100개 이내인 경우 NumPy는 순수 파이썬 구현 보다도 오히려 낮은 성능을 보입니다.여기서는 C++로 Extension을 작성하여 성능을 최적화 해보도록 합니다. C++로 표준 편차를 구하는 코드는 아래와 같이 작성했습니다.C++을 파이썬과 연동 하려면 계산 코드 외에도 wrapper 함수를 작성해야 합니다.이 wrapper 함수는 파이썬 리스트를 받아와 값을 하나씩 끄집어 낸 다음 std::vector에 담아 C++ 함수에 전달하는 역할을 합니다. wrapper에는 이외에도 여러가지 처리를 위한 boilerplate 코드가 들어갑니다. 매우 번거로운 작업이고 저 역시도 wrapper 코드를 작성하며 사소한 실수로 무수한 컴파일 오류를 맞이 해야만 했습니다.번거로운 작업입니다.Cython은 CPython과 이름이 비슷하여 혼동될 수 있으나 전혀 다릅니다. 원래의 목적은 Pyrex 기반의 파이썬 코드를 작성하면 이를 C로 변환해 성능을 최적화 해주는 컴파일러입니다. 그러나 외부 C 라이브러리를 랩핑 하는데도 매우 유용합니다. 아울러 C 뿐만 아니라 C++도 네이티브로 지원합니다. 여기서는 C++ 함수를 랩핑하는 용도로 사용했으며, 아래와 같이 코드를 작성했습니다.헤더를 읽어 함수를 정의한 다음 파이썬 스타일의 함수에서 C++ 함수의 리턴값을 전달합니다. C++과 파이썬이 오묘한 형태로 결합되어 있습니다. 이 부분은 장점이자 단점이 될 수 있는데 기존 파이썬의 함수를 그대로 사용할 수 있는 장점이 있는 반면 기존 파이썬 함수의 낮은 성능 또한 그대로 반영됩니다. 상식적으로 파이썬 코드가 단순히 C 코드로 변환되었다고 성능이 개선되진 않습니다. (물론 약간의 효과는 있습니다.) cdef를 이용해 변수를 C/C++ 네이티브로 선언하고 주요 계산 알고리즘은 외부 C/C++ 함수로 따로 작성해서 랩핑해야 진정한 성능 개선 효과를 기대할 수 있습니다.원래 Cython은 파이썬의 리스트를 C++ std::vector로 자동으로 컨버전 하지만 여기서는 조금이나마 성능을 개선하고자 상단에 컨버전을 직접 정의했습니다. 컨버전을 직접 구현할때는 14줄이 필요했으나 여기서는 단 한 줄로 가능했습니다.pybind11는 “Seamless operability between C++11 and Python”라는 모토로 최근에 등장한 C++ 전용 헤더 라이브러리 입니다. ctypes를 사용할 수 있는 C의 잇점이 있다면 pybind11은 C++에서만 사용이 가능합니다. 파이썬 연동을 마치 C++ 코드의 연장선 처럼 부드럽게seamless 할 수 있습니다. cmake도 잘 지원하여 빌드나 IDE 연동도 편리합니다. 앞서 Cython이 파이썬 중심의 라이브러리 였다면 pybind11는 C++ 중심의 라이브러리라 할 수 있습니다.랩핑 코드 또한 파이썬으로 작성했던 Cython과 달리 아래와 같이 C++로 작성합니다.Cython과 마찬가지로 오토 컨버전을 지원하며 헤더를 include 하면 나머지는 자동으로 처리됩니다.C++에 최적화 되어 있으므로 성능이 매우 좋을 것 같지만 아쉽게도 Cython 보다 못한 성능을 보여줍니다. 특히 오토 컨버전은 편리하지만 별도로 제어할 수 없으며, 이로 인한 성능 저하가 뚜렷합니다.최대 1만개까지 배열의 표준 편차를 구하는 성능 테스트 결과는 아래와 같습니다.순수 파이썬 구현의 성능은 따로 언급할 필요가 없을듯 하며, 앞서 잠깐 언급했지만 기대를 모았던 NumPy의 성능이 그다지 높지 않습니다. 이는 대형 배열에 최적화 되어 있기 때문이며 이후에 이어지는 대형 배열의 성능 테스트에선 좋은 성능을 확인할 수 있습니다.C++ 구현은 직접 구현하든 Cython, pybind11을 사용하든 어느쪽이든 좋은 성능을 보여줍니다. 그러나 일반적으로 직접 wrapper를 작성하는 쪽이 가장 성능이 좋으며 오토 컨버전을 지원하는 Cython과 pybind11는 그 만큼의 성능 저하가 있습니다. 특히 pybind11 쪽의 성능 저하가 뚜렷합니다.Cython w/ class는 Cython 구현에 type conversion을 없애기 위해 별도로 구현한 방식입니다. 사실 이 테스트는 NumPy에게 지나치게 유리한데, 왜냐면 파이썬 리스트를 np.array()로 컨버전 하는 것을 벤치마크 바깥에서 별도로 진행했기 때문입니다. 밀리 세컨드 단위로 수행되는 벤치마크에서 NumPy 컨버전은 매우 무거운 편이기도 하고(만약 따로 컨버전 하지 않으면 가장 나쁜 성능이 나옵니다.) 과학 계산에서 NumPy는 사실상 표준 라이브러리의 위치에 있기 때문에 이미 원본 데이터가 NumPy 타입임을 감안하여 어드밴티지를 부여했습니다.그러나, NumPy를 제외한 다른 모든 구현은 type conversion이 포함되며 C++은 직접 컨버전 코드를 작성했고, 나머지는 오토 컨버전이 되도록 처리했습니다. 테스트는 각 100번씩 수행되므로 컨버전이 필요 없는 NumPy에 비해 다른 구현은 모두 100번씩 별도로 컨버전되는 오버헤드가 발생해 공정한 비교가 될 수 없습니다.이를 개선하고자 C++ 클래스를 Cython으로 구현했고 미리 컨버전한 값을 private 변수로 갖고 있다가 벤치마크시 계산만 하는 방식으로 최적화 했습니다. 따라서 계산 코드가 다른 구현과 다릅니다.그 결과 가장 좋은 성능을 확보할 수 있었습니다.5만개까지 대형 배열로 성능 테스트한 결과는 아래와 같습니다.먼저 순수 파이썬으로 계산한 결과는 다른 것과 비교가 불가능 할 정도로 느려 아예 비교에서 제외했습니다. 여기서는 NumPy, C++, Cython, Cython w/ class, pybind11만 비교했는데 앞서 다소 실망스런 모습을 보였던 NumPy가 좋은 모습을 보여줍니다. 일정 갯수를 넘어서면서 부터 가장 좋은 성능을 보이며, 배열의 크기가 늘어나도 전체 계산 속도는 크게 증가하지 않습니다. 대형 배열에 최적화된 C 라이브러리의 진가가 드러나는 순간입니다. 컨버전을 배제한 Cython w/ class 조차도 NumPy에 비해 성능이 낮습니다.참고로 벤치마크는 각 100번씩 수행해 결과를 측정했는데, 실제 프로덕션에서는 같은 계산을 반복하지 않기 때문에 각 1번만 수행하여 NumPy와 Cython w/ class의 비교를 10만개까지 측정해봤습니다.약 3만개 정도 부터 근소한 차이로 NumPy의 성능이 앞서는 것을 확인할 수 있습니다.일반적으로 NumPy만 잘 사용해도 충분한 성능을 얻을 수 있습니다. 그러나 NumPy에는 결정적인 한계가 있는데 싱글 코어에 최적화 되어 있다는 점입니다. 애초에 GIL로 인해 멀티 쓰레드가 유명무실한 파이썬과 마찬가지로 NumPy 또한 싱글 코어에 최적화 되어 있다는 한계가 있으며, 멀티 코어를 제대로 활용하기 위해선 C/C++로 쓰레드 프로그래밍을 해야 합니다. 이 때문에 텐서플로를 포함한 대부분의 딥러닝 프레임워크 또한 C++에서 멀티 코어를 활용하며(이 글에선 언급하지 않았지만 SWIG로 파이썬과 연동하여) 계산을 수행하는 방식으로 구현되어 있습니다.C++11에서 지원하는 std::thread를 이용해 sum, squaredSum을 멀티 쓰레드로 계산해 최적화 해보도록 합니다.각 쓰레드별로 분할하여 시작(start)과 끝(end)으로 지정할 인덱스를 계산하고 전체 배열이 포함된 매우 큰 std::vector를 포인터로 넘깁니다. 만약 포인터가 아닌 밸류로 넘긴다면 성능 저하가 심각해 질 것입니다. 계산 함수에서는 포인터의 밸류를 조회하여 start에서 end까지 값을 끄집어내 연산을 수행합니다.결과를 담을 변수는 C++ 레퍼런스로 넘겼으며, 가장 마지막에 전체 값을 한 번만 업데이트 합니다. 사실 처음 코딩할때는 실수로 레퍼런스 변수를 for loop 사이에 넣고 매 번 업데이트 했는데, 그렇게 할 경우 쓰레드를 4개만 생성해도 변수를 업데이트 하기 위한 atomic lock 경쟁이 생겨 심각한 성능 저하를 가져옵니다. 위 코드 처럼 loop 바깥에서 수행하여 성능을 개선했으며, 컴파일러가 따로 경고하지 않아 실수하기 쉽기 때문에 주의해야 합니다.성능 최적화를 위해 포인터와 레퍼런스를 번갈아 사용해봤는데 이에 따른 성능 이슈는 없었습니다. 둘 중 선호하는 쪽을 사용하면 되며, 일반적으로 C++에서는 안전하고 편리한 레퍼런스를 사용하는 편이 권장됩니다.기존에 NumPy와 근사할 정도로 성능이 좋았던 Cython w/ class와 쓰레드로 구현한 Cython w/ threads의 성능을 비교해보도록 합니다. 성능 향상을 극대화 하기 위해 대형 배열로 정했으며 2억개의 엘리먼트로 비교를 진행했습니다.랜덤을 생성하는데만 해도 약 30초가 걸리는 대형 배열이고, Cython w/ class로 2.49초 정도 소요됩니다.Cython w/ threads로는 1.84초에 완료되어 25% 정도 성능 개선 효과가 있습니다. 맥북 프로에서 진행하여 맥북의 코어 갯수인 8개만큼 쓰레드를 돌렸으며, 쓰레드를 8개나 풀 가동 했음에도 불구하고 성능 개선 효과가 그리 크진 않습니다. 이유는 벡터 로딩에 1.6초나 걸렸기 때문이며, 이처럼 정작 연산이 아닌 엉뚱한 곳에 병목이 있을 수 있으므로 주의깊게 디버깅하는 것이 매우 중요합니다.8개의 쓰레드가 데이터를 나눠 각 쓰레드별 최대 76ms 이내에 모든 연산을 완료 했습니다. 만약 쓰레드를 하나만 사용했다면 600ms가 걸렸을 텐데 이처럼 멀티 쓰레드 프로그래밍으로 524ms를 단축시킬 수 있었습니다.참고로 두 테스트를 동시에 실행하면 대형 변수의 메모리 복사로 인해 서로간의 성능에 영향을 끼치므로 각각 따로 테스트하여 비교했습니다.앞서 성능 비교에서 벡터 로딩에만 1.6초가 걸리는걸 확인할 수 있었습니다. 또한 type conversion에만 14초가 걸렸습니다. 이 처럼 대형 배열에서 파이썬과 C/C++ 네이티브 타입(여기서는 C++의 std::vector)의 type conversion, 변수의 메모리 복사는 상당한 오버헤드를 발생시키며, 이를 최소화 하는 것이 무엇보다 중요합니다. 포인터나 레퍼런스를 잘 활용하여 줄일 수 있는 부분은 가능한 줄이는 편이 좋으며, 여기서도 처음부터 벡터를 포인터로 가져오면 시간을 획기적으로 줄일 수 있으나 NumPy와 비교를 위해 일부러 복사하는 방식을 택했습니다. 프로덕션에는 당연히 포인터를 사용해야 합니다.아울러 직접 모든 wrapper를 작성하는 일은 많은 고난이 뒤따르기 때문에 성능을 약간 타협하여 Cython 또는 pybind11를 택하는 편이 최적의 선택입니다. 그 중에서도 Cython의 성능이 돋보이며, C++ 연동 방식은 pybind11가 좀 더 우아한 편이지만 오토 컨버전의 성능 이슈는 하루빨리 해결되어야 할 과제입니다.이 문서에서 사용한 표준 편차를 구하는 함수와 최초 C++ 구현은 Speeding up Python and NumPy: C++ing the Way를 참조했으며 이를 fork 하여 C++ wrapper를 개선하고 Cython, pybind11 바인딩을 추가했습니다. 전체 코드는 아래 깃헙에 올려 두었습니다.likejazz/PythonCExtensions - GitHub",http://tech.kakao.com/2018/05/15/python-numpy-extensions/,0,kakao,"json,python,react,numpy,webpack,java,backend,frontend,css,database,mongodb",NULL,2018-05-15
카카오 신입 공채 3차 코딩 테스트 문제 해설,"블라인드 채용으로 관심을 모은 카카오 신입 공채의 세 번째 테스트가 지난 10월 29일(일), 오후 2시부터 6시까지 네 시간에 걸쳐 오프라인으로 치러졌습니다. 두 차례의 온라인 테스트를 통과한 지원자들이 한 자리에 모여 다시 한번 실력을 검증하는 자리를 가졌습니다.오프라인 코딩 테스트는 온라인 코딩 테스트와는 사뭇 달랐습니다. 1차와 2차 코딩 테스트에서 상위권의 우수한 성적을 거뒀던 지원자가 3차 코딩 테스트의 관문을 통과하지 못한 경우도 있었습니다. 현장에 와서 다른 지원자와 함께 경쟁한다는 긴장감도 있을 테고요. 자신이 쓰던 집이나 학교의 컴퓨터가 아니어 불편했을 겁니다. OS나 IDE 등의 개발 환경도 평소 자신이 쓰던 것과 달랐을 겁니다. 특히나 문제를 풀다가 막혔을 때 애용하던 “검색 찬스”도 쓸 수 없을 테고요.1차 코딩 테스트에서 Java 언어 사용자들이 고전했다면, 2차와 3차 코딩 테스트에서는 C++ 사용자들이 힘들어했습니다. 1차 응시자들은 대부분 3차 코딩 테스트에서도 같은 언어로 시험을 봤습니다. 다만, 1차에서 여러 언어를 사용하던 지원자들은 3차에서는 절반 가량이 Python을 주 언어로 코딩 테스트에 참가했습니다.이번 3차 테스트에서는 코딩 테스트와 함께 지원자들의 컴퓨팅 관련 기본 지식을 묻는 필기 시험도 함께 치러졌습니다. 사전에 알리지 않고 현장에 와서 필기 시험이 치러진다는 안내를 받고 조금은 놀라셨을 텐데요. 평소 실력이 있는 지원자들인지라 대부분 잘 답하셨더군요.합격 기준은 코딩 문제 5 문제 중 3 문제 이상, 필기 시험 40점 이상을 기준으로 삼았습니다. 필기 시험은 준비없이 치렀다는 점을 고려하여 기준을 낮게 잡았습니다.이번 3차 테스트에서는 코딩 테스트로 다섯 문제를 준비했습니다. 1차 테스트처럼 기초적인 구현 능력을 검증하는 문제들입니다. 1차 테스트와 난이도 면에서 크게 차이는 없지만, 조금은 더 복합적으로 생각하고 구현해야 하는 문제들이 많았습니다.튜브가 활동하는 코딩 동아리에서는 전통적으로 해오는 게임이 있다. 이 게임은 여러 사람이 둥글게 앉아서 숫자를 하나씩 차례대로 말하는 게임인데, 규칙은 다음과 같다.이렇게 게임을 진행할 경우, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 0, 1, 1, 1, 2, 1, 3, 1, 4, … 순으로 숫자를 말하면 된다.한편 코딩 동아리 일원들은 컴퓨터를 다루는 사람답게 이진수로 이 게임을 진행하기도 하는데, 이 경우에는 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, … 순으로 숫자를 말하면 된다.이진수로 진행하는 게임에 익숙해져 질려가던 사람들은 좀 더 난이도를 높이기 위해 이진법에서 십육진법까지 모든 진법으로 게임을 진행해보기로 했다. 숫자 게임이 익숙하지 않은 튜브는 게임에 져서 벌칙을 받는 굴욕을 피하기 위해, 자신이 말해야 하는 숫자를 스마트폰에 미리 출력해주는 프로그램을 만들려고 한다. 튜브의 프로그램을 구현하라.진법 n,  미리 구할 숫자의 갯수 t, 게임에 참가하는 인원 m, 튜브의 순서 p 가 주어진다.튜브가 말해야 하는 숫자 t개를 공백 없이 차례대로 나타낸 문자열. 단, 10~15는 각각 대문자 A~F로 출력한다.반복문과 진법 변환을 할 수 있다면 어렵지 않게 풀 수 있는 문제입니다. 진법 변환은 프로그래밍 언어를 처음 배울 때 연습 문제로 많이 풀어봤을 문제일 텐데요. 오래간만에 풀어보려니 쉽지만은 않았던 듯 싶습니다.참고로 이 문제는 챔퍼나운 수라는 수학 상수를 이용한 문제입니다.이 문제의 정답률은 91.85%였습니다. 대부분 잘 풀어주셨으나, 언어별로는 C++ 사용자들이 약간 어려워했습니다.신입사원 어피치는 카카오톡으로 전송되는 메시지를 압축하여 전송 효율을 높이는 업무를 맡게 되었다. 메시지를 압축하더라도 전달되는 정보가 바뀌어서는 안 되므로, 압축 전의 정보를 완벽하게 복원 가능한 무손실 압축 알고리즘을 구현하기로 했다.어피치는 여러 압축 알고리즘 중에서 성능이 좋고 구현이 간단한 LZW(Lempel–Ziv–Welch) 압축을 구현하기로 했다. LZW 압축은 1983년 발표된 알고리즘으로, 이미지 파일 포맷인 GIF 등 다양한 응용에서 사용되었다.LZW 압축은 다음 과정을 거친다.압축 알고리즘이 영문 대문자만 처리한다고 할 때, 사전은 다음과 같이 초기화된다. 사전의 색인 번호는 정수값으로 주어지며, 1부터 시작한다고 하자.예를 들어 입력으로 KAKAO가 들어온다고 하자.이 과정을 거쳐 다섯 글자의 문장 KAKAO가 4개의 색인 번호 [11, 1, 27, 15]로 압축된다.입력으로 TOBEORNOTTOBEORTOBEORNOT가 들어오면 다음과 같이 압축이 진행된다.입력으로 영문 대문자로만 이뤄진 문자열 msg가 주어진다. msg의 길이는 1 글자 이상, 1000 글자 이하이다.주어진 문자열을 압축한 후의 사전 색인 번호를 배열로 출력하라.GIF 파일 등에서 실제로 쓰이는 LZW 알고리즘을 설명해주고, 구현하는 문제입니다. 실제로 쓰이는 알고리즘을 구현해보는 것이 어떠셨나요? 압축이라는 말만으로 얼핏 어려워 보이지만, 설명에 나온 의사코드Pseudocode를 그대로 따라서 구현만 하면 되는 문제로, 기초적인 문자열과 배열을 다룰 수 있다면 풀 수 있는 문제입니다.이 문제의 정답률은 95.80%입니다. 가장 많은 지원자가 잘 풀어주셨습니다. 언어별로는 Java 언어 사용자들이 조금 어려워했습니다.세 차례의 코딩 테스트와 두 차례의 면접이라는 기나긴 블라인드 공채를 무사히 통과해 카카오에 입사한 무지는 파일 저장소 서버 관리를 맡게 되었다.저장소 서버에는 프로그램의 과거 버전을 모두 담고 있어, 이름 순으로 정렬된 파일 목록은 보기가 불편했다. 파일을 이름 순으로 정렬하면 나중에 만들어진 ver-10.zip이 ver-9.zip보다 먼저 표시되기 때문이다.버전 번호 외에도 숫자가 포함된 파일 목록은 여러 면에서 관리하기 불편했다. 예컨대 파일 목록이 [“img12.png”, “img10.png”, “img2.png”, “img1.png”]일 경우, 일반적인 정렬은 [“img1.png”, “img10.png”, “img12.png”, “img2.png”] 순이 되지만, 숫자 순으로 정렬된 [“img1.png”, “img2.png”, “img10.png”, img12.png”] 순이 훨씬 자연스럽다.무지는 단순한 문자 코드 순이 아닌, 파일명에 포함된 숫자를 반영한 정렬 기능을 저장소 관리 프로그램에 구현하기로 했다.소스 파일 저장소에 저장된 파일명은 100 글자 이내로, 영문 대소문자, 숫자, 공백(“ “), 마침표(“.”), 빼기 부호(“-“)만으로 이루어져 있다. 파일명은 영문자로 시작하며, 숫자를 하나 이상 포함하고 있다.파일명은 크게 HEAD, NUMBER, TAIL의 세 부분으로 구성된다.파일명을 세 부분으로 나눈 후, 다음 기준에 따라 파일명을 정렬한다.무지를 도와 파일명 정렬 프로그램을 구현하라.입력으로 배열 files가 주어진다.위 기준에 따라 정렬된 배열을 출력한다.입력: [“img12.png”, “img10.png”, “img02.png”, “img1.png”, “IMG01.GIF”, “img2.JPG”] 출력: [“img1.png”, “IMG01.GIF”, “img02.png”, “img2.JPG”, “img10.png”, “img12.png”]입력: [“F-5 Freedom Fighter”, “B-50 Superfortress”, “A-10 Thunderbolt II”, “F-14 Tomcat”] 출력: [“A-10 Thunderbolt II”, “B-50 Superfortress”, “F-5 Freedom Fighter”, “F-14 Tomcat”]코딩의 기초 문제라고 할 수 있는 정렬 문제입니다. 하지만 조건은 꽤나 복합적입니다. 파일명을 세 부분으로 나눠, 첫 부분은 대소문자 구분 없이Case Insensitive, 다음 부분은 숫자 값에 따라Numerical 정렬해야 합니다. 또한 정렬 기준에 따라 차이가 없다면 원래 입력에서 주어진 순서를 유지하는 안정 정렬Stable Sort을 사용해야 합니다. 정렬 문제를 풀 때 한 번씩은 다 해보셨죠? 그런데 이걸 어떻게 꿰어서 하나의 프로그램으로 만들어야 할지 어려워하시더군요.여러 정렬 알고리즘을 배우셨을 텐데요. 이 중에 안정 정렬이 어떤 건지 알고 계신가요? 빠른 정렬 알고리즘으로 가장 유명한 퀵 정렬Quick Sort는 아쉽게도 안정 정렬이 아닙니다. 효율이 좋은 O(n log n) 복잡도의 정렬 알고리즘 중에는 병합 정렬Merge Sort 등 일부 알고리즘은 안정 정렬이고요. 효율이 떨어지는 O(n2) 복잡도의 알고리즘 중 버블 정렬Bubble Sort과 삽입 정렬Insertion Sort은 모두 안정 정렬입니다. 여러분이 아는 다른 알고리즘도 안정 정렬인지 아닌지 확인해보세요. 알고리즘의 구현 방법에 따라 같은 알고리즘이라도 안정 정렬이거나 아닐 수도 있습니다.정렬 문제가 워낙 많이 쓰이므로 많은 프로그래밍 언어에서 정렬 알고리즘을 기본 함수로 제공하고 있습니다. 자신이 사용하는 프로그래밍 언어에서 안정 정렬 알고리즘을 제공해주는지 알아두시는 게 좋습니다. 코딩 테스트에서 사용된 프로그래밍 언어 중 C++과 Python에는 안정 정렬이 있고, Java와 JavaScript, Swift에는 안정 정렬이 없습니다. PHP 언어는 숫자 값을 고려해 정렬하는 natsort()를 기본 함수로 제공하기도 합니다. (아쉽게도 문제 3과 조건이 달라 그대로는 쓸 수 없지만요.)기본 정렬 함수가 안정 정렬을 지원하지 않거나, 이 문제처럼 비교 조건이 까다로운 경우에는 decorate-sort-undecorate 패턴을 이용해서 쉽게 해결할 수도 있답니다.이 문제의 정답률은 66.95%였습니다. 언어별로는 C++과 Python 사용자들이 힘들어했습니다. 안정 정렬을 지원해주는 언어인데 도움이 안 되었나 봅니다.라디오를 자주 듣는 네오는 라디오에서 방금 나왔던 음악이 무슨 음악인지 궁금해질 때가 많다. 그럴 때 네오는 다음 포털의 ‘방금그곡’ 서비스를 이용하곤 한다. 방금그곡에서는 TV, 라디오 등에서 나온 음악에 관해 제목 등의 정보를 제공하는 서비스이다.네오는 자신이 기억한 멜로디를 가지고 방금그곡을 이용해 음악을 찾는다. 그런데 라디오 방송에서는 한 음악을 반복해서 재생할 때도 있어서 네오가 기억하고 있는 멜로디는 음악 끝부분과 처음 부분이 이어서 재생된 멜로디일 수도 있다. 반대로, 한 음악을 중간에 끊을 경우 원본 음악에는 네오가 기억한 멜로디가 들어있다 해도 그 곡이 네오가 들은 곡이 아닐 수도 있다. 그렇기 때문에 네오는 기억한 멜로디를 재생 시간과 제공된 악보를 직접 보면서 비교하려고 한다. 다음과 같은 가정을 할 때 네오가 찾으려는 음악의 제목을 구하여라.입력으로 네오가 기억한 멜로디를 담은 문자열 m과 방송된 곡의 정보를 담고 있는 배열 musicinfos가 주어진다.조건과 일치하는 음악 제목을 출력한다.부분 문자열 비교를 묻는 문제입니다. 하지만 멜로디의 각 음을 나타내는 글자가 한 글자일 수도 있고, 두 글자일 수도 있습니다. “ABC”라는 멜로디는 “ABCD”라는 악보에는 들어있지만, “ABC#”라는 악보에는 들어있지 않습니다. C#이 하나의 음을 이루고 있기 때문이죠.문자열 비교에서 이런 문제를 처리해야 할 일이 있습니다.  1차 코딩 테스트에서 설명했던 토큰화Tokenizing를 통해 “ABC#”을 [“A”, “B”, “C#”] 식의 배열로 변환한 후에 비교를 수행할 수도 있고요. 아니면 두 글자로 된 “C#”, “D#”, “F#” 등을 악보에서 사용되지 않는 문자인 “c”, “d”, “e” 등으로 치환Substitution한 후에 문자열 비교 함수를 이용할 수도 있습니다.이 문제의 정답률은 47.50%였습니다. Python 사용자들이 가장 잘 풀었습니다.포털 다음에서 검색어 자동완성 기능을 넣고 싶은 라이언은 한 번 입력된 문자열을 학습해서 다음 입력 때 활용하고 싶어 졌다. 예를 들어, go 가 한 번 입력되었다면, 다음 사용자는 g 만 입력해도 go를 추천해주므로 o를 입력할 필요가 없어진다! 단, 학습에 사용된 단어들 중 앞부분이 같은 경우에는 어쩔 수 없이 다른 문자가 나올 때까지 입력을 해야 한다. 효과가 얼마나 좋을지 알고 싶은 라이언은 학습된 단어들을 찾을 때 몇 글자를 입력해야 하는지 궁금해졌다.예를 들어, 학습된 단어들이 아래와 같을 때이 경우 총 입력해야 할 문자의 수는 7이다.라이언을 도와 위와 같이 문자열이 입력으로 주어지면 학습을 시킨 후, 학습된 단어들을 순서대로 찾을 때 몇 개의 문자를 입력하면 되는지 계산하는 프로그램을 만들어보자.학습과 검색에 사용될 중복 없는 단어 N개가 주어진다.  모든 단어는 알파벳 소문자로 구성되며 단어의 수 N과 단어들의 길이의 총합 L의 범위는 다음과 같다.단어를 찾을 때 입력해야 할 총 문자수를 리턴한다.3차 코딩 테스트에서 가장 어려운 문제였습니다. 열심히 코딩한 후에 제출하면 시간 제한에 걸려 좌절하는 지원자가 많았습니다. 두 단어 “world”와 “word”가 앞 세 글자가 겹친다는 걸 찾는 건 어렵지 않지만, 모든 단어 쌍을 비교하는 방식으로는 제한 시간 내에 풀 수 없습니다.이 문제 해결에 적합한 자료 구조로 트라이Trie가 있습니다. 입력으로 주어진 단어로 트라이를 구성하면, 같은 접두어Prefix를 갖는 단어가 얼마나 있는지를 효과적으로 찾을 수 있습니다.또 다른 방법이 하나 더 있는데요. 전체 단어를 사전 순으로 정렬한다면, 어떤 단어와 앞부분이 가장 많이 일치하는 단어는 정렬 후 인접한 두 단어 중 하나가 됩니다. 이 방법을 이용하면 모든 단어 쌍이 아닌, 정렬 후에 인접한 단어 쌍만 비교하면 되므로 빠르게 문제를 해결할 수 있습니다.이 문제의 정답률은 34.07%였습니다. Java 사용자들이 가장 잘 풀었습니다.아마, 많은 지원자 분들이 필기 시험이 등장하여 적잖이 당황스러우셨을 겁니다. 알고리즘을 묻는 코딩 테스트 만으로는 자칫 채용 시험이 코딩 대회의 장이 될 수 있어 이를 보완하고자 기본 지식을 묻는 필기 시험을 추가하기로 했습니다. 필기 시험이 있다는 사실은 당일까지도 공지하지 않고 대외비로 준비했는데요. 대신 사전 학습 없이도 평소에 컴퓨터 과학을 공부했다면 누구나 쉽게 풀 수 있는, 상식 수준에 준하는 문제들로 출제하였습니다.필기 시험 PDF 다운로드문제는 총 20문제로 구성하였습니다.이 중 10번까지는 빈칸을 채우는 문제였습니다. 컴퓨팅 및 컴퓨터 과학, 인터넷 등의 기본적인 개념에 대한 영어 위키백과의 설명을 제시하고 각각 무엇을 설명하는 지를 맞추는 문제였습니다.현업에서 일을 하려면 평소에도 영어로 된 문서를 많이 접하게 될 텐데요. 따라서 문제 또한 모두 영어로 제시하여 독해 능력도 함께 보고자 했고, 각각의 문항 앞뒤로 충분한 부연 설명을 제시하여 최소한 이 정도 용어는 알고 있으면 좋겠다는 출제 의도를 포함했습니다.사실 이 문제들은 문장을 검색해보면 금방 정답을 찾을 수 있습니다. 그러나, 검색 없이도 이 정도 용어들은 바로 대답할 수 있길 바랬고, 인터넷이 제한된 오프라인 테스트여서 가능한 문제들이었습니다.11번은 조금 어려운 문제였던 거 같습니다. TCP의 커넥션 종료 과정의 순서를 묻는 문제였는데요.  순서보다 좀 더 정확히는 active close와 passive close를 숙지하고 있는지를 묻고 싶었습니다. 실무에서 TIME_WAIT으로 인한 문제는 여전히 간간히 발생하고 있으므로 이 개념은 꼭 숙지했으면 하는 의도로 출제하였습니다. 더 깊은 이야기는 카카오 기술 블로그에 올라왔던 CLOSE_WAIT & TIME_WAIT 최종 분석 글을 읽어보세요.12번은 제록스 팔로알토 연구소에서 1979년에 소개한, 소프트웨어 구조를 설명한 사실상 최초의 방법론이자 여전히 중요하게 쓰이고 있는 MVC 소프트웨어 디자인 패턴에 대한 문제입니다.13, 14, 15번 문제는 시간 복잡도, 빅오를 구하는 문제였는데요. 13번의 경우 실행 순서를 손으로 그려본다면 2n이 됨을 알 수 있습니다. 14, 15번은 상수항이 있는데요. 빅오에서는 일반적으로 상수항을 제거하기 때문에 각각 n이 됩니다. 특히 14번의 경우 ½ n이 되는데, 이는 log n과 혼동할 수 있으나 엄연히 전혀 다릅니다. 따라서 상수항 ½ 이 제거되어 n이 됩니다.16번은 재밌는 문제인데요. 약간의 함정이 숨어 있는데 각각의 시간 복잡도를 계산해보면, len(A) = N, len(B) = M 이라 할 때, A를 정렬할 경우 정렬과 이진 검색을 합하면 N log N + M log N = (N+M) log N, B를 정렬할 경우 M log M + N log M = (N+M) log M 이 됩니다. 길이가 짧은 A를 정렬하는 쪽이 좀 더 빠르게 동작하겠죠?17, 18, 19번은 적합한 자료 구조를 묻는 문제였고 어렵지 않게 풀 수 있었으리라 생각합니다. 18번의 경우 위키백과에도 인덱스 구현에 대한 설명참고이 등장합니다. 인기 있는 인덱스 구현  자료구조는 균형 트리, B+ 트리, 해시라고 나오네요.20번은 트리 순회를 직접 계산해보는 문제입니다. 알고리즘을 설명에 상세히 제시하였기 때문에 기존에 트리 순회 알고리즘을 몰랐던 분들도 충분히 쉽게 풀 수 있었으리라 생각합니다.코딩 테스트 참가자들의 메일이나 후기로 블라인드 테스트에 대한 많은 의견들을 들을 수 있었습니다. 1차 코딩 테스트 후기에서 언급되었던 것처럼 채용을 위한 시험이기에  이번 세 차례의 블라인드 테스트는 어려운 문제보다는 기본기를 확인하기 위한 기본적인 문제 중심으로 출제했으며, 실무에서 접할 수 있을법한 문제 중심으로 구성했습니다.세 차례의 코딩 테스트를 통과한 지원자들은 이제 또다시 두 차례의 면접이 기다리고 있습니다. 코딩 테스트를 통해 다양한 방식으로 개발 역량을 검증했다면, 면접은 카카오에서 함께 일할 수 있는 사람인지를 확인하는 과정입니다. 카카오 크루로 함께 일할 수 있게 되길 기대해보겠습니다.함께 보기:",http://tech.kakao.com/2017/11/14/kakao-blind-recruitment-round-3/,0,kakao,"sass,python3,python,java,mysql,docker,backend,frontend,javascript,database,html,objective-c",NULL,2017-11-14
카카오 신입 공채 2차 코딩 테스트 문제 해설,"지난 10월 14일(토) 오후 2시부터 10시까지 8시간 동안 온라인 2차 코딩 테스트가 있었습니다. 1차 코딩 테스트와도 사뭇 다른 형식이라 신선했다는 의견도 있고, 당황한 지원자도 있었을 텐데요. 2차 문제에는 어떤 의도가 숨어있는지 살펴보겠습니다.1차 코딩 테스트는 어려운 알고리즘 문제가 아닌 자료구조, 알고리즘 등의 전산학 기초에 대해 충분히 학습하였다면 누구나 풀 수 있을만한 “구현” 위주의 문제들로 구성을 하였고, 총 7문제 중 4문제 이상 푼 지원자들에게 2차 기회가 주어졌습니다. 즉, 기본적인 구현 역량은 보유하고 있다고 할 수 있습니다. 그렇다면 추가적으로 테스트 해야하는 것은 무엇일까요?온라인 2차 코딩 테스트 문제 출제 위원회에서는,문제에 어떤 장치들이 있었는지 살펴볼까요?2차 테스트 문제는 우선 토큰을 발급받고, 웰컴 서버로부터 5개 카테고리의 Seed URL을 받아온 후 각 카테고리의 문서를 읽어 그 안에 있는 이미지들을 가져와 특징값을 추출하여 서버에 저장/삭제하는 문제입니다.쉽게 구현할 수 있는 수준의 요구사항을 주되, 자주 접해보지 않았을 (것으로 추정되는) REST API와 JSON Parsing을 포함시켜 단 시간에 학습하여 풀도록 하였습니다. 이 두가지 키워드는 언어별 편차가 심한 점을 감안하여 사전에 미리 제공하였습니다.토큰의 유효기간은 10분으로 설정하고, 점수 현황판을 제공했습니다. 8시간 동안 스스로 최적화를 하고 한 번만 결과를 제출하도록 하면 일부 지원자는 반복 과정을 통해 최적화를 하지 않을 것 같았습니다. 그래서 다른 사람의 점수를 보고 계속해서 최적화를 수행할 수 있도록 토큰을 10분으로 제한하였습니다. 수행하는 도중에 문제점이나 병목을 찾으려면 적절히 로그도 남겨야 하고 모니터링도 자연스럽게 하게 될 것이라 생각했습니다.최종점수는 아래 공식으로 산출합니다.평가 메트릭은 최대한 현실적인 부분을 반영하려고 노력했습니다.누락되거나 삭제되지 않은 이미지에는 페널티를 부여하였는데, 누락보다는 삭제되지 않은 경우에 더 큰 페널티를 주었습니다. 이는 실 상황을 더 반영한 것인데, 누락된 것보다는 삭제되지 않은 이미지가 더 치명적이기 때문입니다. 사용자에게 노출되지 말아야 할 이미지가 삭제되지 않고 노출된 것이, 노출되었으면 좋았을 이미지가 누락되어 노출되지 않은 것보다는 더 치명적일테니까요. 마찬가지로 잘못된 데이터의 경우 페널티가 가장 큽니다. 데이터가 잘못된 경우 시스템을 서서히 망가뜨리는 데다가, 이를 알아차리기가 쉽지 않기 때문입니다.총 쿼리 수에 마이너스 페널티를 준 것은 적절히 요청하지 않아도 되는 것들을 필터링하라는 의도가 반영되었습니다.가장 빈번하게 호출해야 하는 API는 /image/feature입니다. 해당 API의 웰컴 서버에서의 처리 속도는 요청하는 개수에 따라 약 최소 16ms ~ 최대 120ms 까지 걸리도록 디자인하였습니다. 네트워크 지연 시간을 포함하면 싱글 스레드로는 초당 요청 제한인 50건을 채우지 못할 수 있습니다. 따라서 스레드 혹은 프로세스를 최소 2개 이상 생성해야 초당 요청 수 제한을 상회할 수 있습니다.참고로 웰컴 서버 처리 속도는 배치 처리 개수에 따라 exp 그래프 형태를 취하고 있습니다. 최대 배치 처리 사이즈인 50개씩 보내는 것보다 30~40개 정도가 가장 효율이 좋도록 설계되어 있습니다. 대다수의 지원자가 단건, 혹은 50개씩 요청을 보냈는데, 30개씩 보낸 지원자도 있어 놀랐습니다.실제 이미지 크롤링을 한다고 생각해봅시다. 크롤링하려고 URL을 큐에 넣어두었는데 그 사이 사용자가 이미지를 삭제했을 수도 있고, 해당 서버가 잠시 내려갔을 수도 있습니다. 웰컴 서버도 이를 시뮬레이션했습니다. 모든 API는 특정 확률 값에 따라 실패하도록 되어 있습니다. 그리고 특정 이미지는 특징값 추출이 매번 실패하도록 고안되었습니다. 재시도 예외처리를 하지 않았다면 해당 요청은 누락되어 감점이 될 것이고, 반복적으로 특징값 추출에 실패하는 이미지를 블록처리하지 않았다면 무의미한 요청이 쌓여 페널티를 받게 됩니다.문서 내 이미지들의 추가/삭제 간에는 다양한 시나리오가 존재합니다.모두 현실에 있을 법한 유형들입니다. 보통 인터넷에는 아주 많은 중복 이미지가 존재하고, 이 모든 이미지를 색인하다면 공간 낭비가 크기 때문에, 기존에 이미 추가된 이미지인지 확인하는 단계가 필요합니다. 우리의 온라인 테스트에서는 간단한 메모리 캐시로도 충분합니다. 한 문서 내에 추가/삭제 명령이 연달아 오는 경우도 있습니다. 이 경우에는 웰컴 서버에 추가했다가 삭제할 것이 아니라 서로 상쇄시키면 불필요한 API 요청을 줄일 수 있습니다. 추가된 적 없는 이미지를 삭제하라고 오는 경우도 있습니다. 이 경우도 메모리 캐시를 사용하고 있다면 쉽게 걸러낼 수 있습니다. 마지막 경우는 추가/삭제를 상쇄하는 연산을 할 때 단순히 set을 사용하면 안 되도록 넣어두었습니다. Add A, Del A, Add A 가 올 경우 최종적으로 Add A 만 요청해야 하는데, set으로 합쳐버리면 Add A, Del A 만 남아서 서로 상쇄되어 누락될 것 입니다.여기서 한 가지 더, 이미지 추가/삭제는 문서 전 영역에 걸쳐 일어납니다. 즉 첫 번째 문서에서 추가한 이미지를 50번째 문서에서 삭제할 수 있습니다. 따라서 50건이 쌓일 때마다 추가/삭제 연산을 요청한 지원자의 경우 이미지 누락을 피할 수 없습니다. 그렇다고 계속 쌓아두다가 막판에 넣으려 하다보면 제한 시간 10분을 초과하여 이미지를 다 넣지 못하는 사태가 생길 수도 있지요. 적절한 선에서 의사결정을 해야 합니다. (트레이드오프)이 곳에도 장치가 마련되어 있습니다. 카테고리별로 이미지의 추가/삭제 비율과 next_url 이 갱신되는 시간에 차등이 있습니다. 시시각각 업데이트되는 news 카테고리 같은 경우 next_url 이 매우 빈번하게 갱신이 됩니다. 반면 art 카테고리는 상대적으로 next_url 이 업데이트 안 될 확률이 7~8배 높습니다. 이미지 데이터량 자체는 blog 카테고리가 가장 풍부합니다. 다만 유저가 올리는 만큼 삭제되는 이미지도 많고, 추가했다가 삭제하는 등의 변동도 가장 크도록 설계되었습니다. 반면 정제된 news는 추가/삭제는 큰 반면 변동은 적습니다.실제 내부 베타 테스트 진행 시 30만 점을 획득한 한 카카오 개발자는 5개의 카테고리 중 2개는 제외하고 3개 카테고리만 수집하여 30만점 이상의 고득점을 올렸습니다. 이번 온라인 2차 테스트에서도 일부 지원자가 카테고리 1개씩만 시도하는 경우가 발견되었습니다. 단, 여기에도 물론 트레이드오프가 존재합니다. 1개 카테고리만 수집한다고 할 경우 병렬 처리를 하게 되면 문서 간 순서를 보장하는 것이 어려워집니다. 추가적인 구현이 필요하거나 혹은 순서가 뒤틀림에 따라 받게 되는 누락 페널티를 무시하고 양으로 승부할 수도 있겠지요. 다시 한 번, 모든 것이 다 트레이드오프입니다.여러분은 어느 정도까지 파악하여 진행하셨나요?합격선은 8만 점으로 병렬 처리를 하지 않았더라도 예외처리를 하고, 배치 처리를 했다면 충분히 받을 수 있는 점수이지만, 문제출제위원회는 이렇게 다양하게 장치를 마련해두었고, 또 이런 장치들이 실무에서도 흔하게 발생하는, 그래서 여러분들이 앞으로 고민할 수도 있는 트레이드오프였다는 것을 이야기하고 싶습니다.오랜 시간 고생하셨습니다!2차 합격자들의 언어 분포입니다. 1차 테스트에서는 C++가 25%로 가장 높았으나 2차 테스트에서는 파이썬이 42.1%로 압도적으로 높은 비율을 보였고, 자바가 35.1% 로 뒤를 이었습니다. 1차에서는 테스트 플랫폼의 제약 때문에 보이지 않던 C#, Objective-C도 보이고요. 차트에는 보이지 않지만, Go로 푼 지원자도 1명 있었습니다.최고점은 235,969점이며 응시자 전체 평균은 47,705점입니다.대략적인 코드 분석 결과는 아래와 같습니다.2차 온라인 코딩테스트를 준비하면서 가장 심혈을 기울인 부분은 “트래픽 테스트” 입니다. 서버와 통신을 주고받는 형태이다 보니 서버의 응답이 느려지거나 자칫 서버가 죽기라도 한다면 테스트에 치명적이기 때문입니다.우선 일차적으로 토큰별 요청량은 초당 50개로 제한하였습니다. 첫 번째 그래프가 같은 토큰으로 초당 50개 이상씩 던지는 사용자의 요청을 Drop 한 결과입니다. 한 개의 토큰으로 최고 800개/초 요청을 보낸 지원자도 있습니다.스트레스 테스트는, 예상 트래픽을 산출(700여 명의 지원자 * 초당 50건 = 35,000건/초)한 후 약 2~3배의 트래픽에도 문제 없을 정도로 준비하였습니다. 다행스럽게도, 초당 트래픽의 최고치는 약 6000건으로 문제 없이 테스트를 치를 수 있었습니다.2차 코딩테스트 진행 도중 두 가지 이슈가 있었습니다.매끄럽게 진행하지 못하여 불편을 겪으신 일부 지원자분들께 양해 말씀드립니다.",http://tech.kakao.com/2017/10/24/kakao-blind-recruitment-round-2/,0,kakao,"python,react,backend,frontend,angular,javascript,xml,php",NULL,2017-10-24
분산 웹 캐시 (Wcache)의 개선과정 - Part 2,"Part 1: 분산 웹 캐시에서는 카카오의 트래픽을 처리하고 있는 Wcache에 대한 간략한 소개를 하였습니다. 이전 버전의 Wcache는 기본적으로 준수한 응답속도를 보이고 있었지만, metadata를 집중된 DB에 저장하는 방식 및 기타 구조상의 문제로 인한 성능 안정성 문제, 그리고 기능상의 문제들이 잠재되어 있었습니다. 본 포스트에서는 이전 버전의 Wcache에서 어떠한 구조적 문제가 있었는지, 또한 이를 어떻게 해결하였는지를 다룹니다.이전 포스트에 나와있듯이 Wcache는 metadata 정보를 컨텐츠와는 별도로 DB에 저장해 두고 있었습니다. 메모리에 올라와 있는 LRU hashtable에 원하는 컨텐츠가 캐싱되어 있지 않다면, SQLite DB에 컨텐츠 키를 가지고 어떤 BigFile에 있는지, 헤더의 길이는 얼마나 되는지 등의 정보들을 조회를 해야 하는 것이죠.위 과정은 평상시 읽는 과정에서는 문제가 없었지만, block 단위로 컨텐츠를 디스크에 저장할 때와 BigFile이 가득 차 오래된 BigFile block들을 replace 할 때 문제가 발생합니다. n개의 컨텐츠가 하나의 block에 있을 경우 BigFile에서의 디스크 write operation은 한 번만 발생하지만 SQLite DB에서의 metadata 관련 정보 업데이트는 n번 발생하게 됩니다.  특히, 주기적으로 용량 확보를 위해 오래된 블록 또는 BigFile 전체를 비워야 하는 경우, DB 전체를 스캔해 관련 항목을 삭제하는 작업(ex: “DELETE FROM table WHERE BigFileNo = 1”)으로 인한 부하가 증가하게 되고, 결국 이러한 작업이 있을 때마다 Wcache의 성능은 일시적으로 평상시에 비해 최대 80%까지 하락하는 모습을 보이게 됩니다. DB 부하를 줄이기 위해 block 크기를 줄이는 방법을 고려해 보았으나 그만큼 디스크 write operation 횟수가 증가합니다. 게다가 구조상 block 크기보다 큰 컨텐츠를 저장할 수 없기 때문에 그만큼 캐시 효율이 감소하게 됩니다.이러한 중앙 집중적인 SQLite구조에는 한계가 있다고 파악하였고, 근본적으로 저장 구조를 개선해야 된다고 결론 내렸습니다.중앙 집중적인 SQLite대신 각 BigFile에 metadata를 함께 저장하는 방식을 취하기로 하였습니다. 이를 위해 SQLite처럼 journaling이 가능하면서 안정적으로 metadata와 컨텐츠를 저장하기 위해 자체적으로 Journaling BigFile, 일명 JBF를 개발해 적용하였습니다.JBF는 위 그림과 같이 BigFile 내부에 block-level journal(write-ahead log), space map, B-Tree 등을 가지고 있어 BigFile 개별로 복구, 조회, 포맷이 가능합니다. 또한, Metadata 정보를 JBF 내부 B-Tree에 적재하고, 컨텐츠 body는 JBF의 일반 영역에 저장합니다. JBF는 BigFile별 포맷이 매우 빠르게 이루어 지기 때문에 기존 버전과는 다르게 가득 찬 BigFile을 비울 때 발생하는 성능 하락 이슈가 없습니다. 컨텐츠를 여러 block에 걸쳐 쓰는것이 가능하기 때문에 저장 가능한 컨텐츠의 최대 크기 제한 역시 BigFile 전체 크기로 늘어나게 됩니다.기존 SQLite에 의존했던 탐색 로직을 개편하기 위해서는 어떠한 JBF에 컨텐츠가 존재하는지를 캐시 key 만으로 알아내야 합니다. 이를 위해 JBF들을 몇 개의 그룹으로 나누고, 캐시 key를 그룹 개수로 modular 연산하여 특정 그룹을 정하고, 해당 그룹 내부의 있는 JBF들에서 순차적으로 탐색하도록 구성하였습니다.전체 JBF들을 동시에 사용하지 않고 그룹으로 묶어 사용하는 이유는 효율적인 디스크 용량 활용이 가능해지기 때문입니다.  JBF는 BigFile 단위로 포맷을 하게 되는데, 그룹을 만들지 않고 모든 JBF에 골고루 저장하게 되면 JBF들이 가득 차게 되는 시점이 비슷해지고,  이후 오래된 캐시를 비우는 작업 시 전체 JBF들을 비슷한 시기에 비워야 하는 이슈가 생깁니다.  그렇게 되면 순간적으로 hit율이 낮아짐은 물론 새롭게 컨텐츠를 캐싱하는 양도 많아져 소스 서버의 부하까지 발생하게 됩니다.  반면 그룹을 묶어서 사용하게 되면 그룹 별로 하나씩만 비울 수 있게 되어 순간적인 캐시 hit율 하락을 완화시킬 수 있습니다.또한 각 그룹별로 write가 이루어지는 JBF들의 순번이 정해져 있고 컨텐츠가 쌓이는 속도도 일정하기 때문에 이점을 활용해 디스크 locality도 증가시킬 수 있습니다. Wcache 초기 세팅 시 각 그룹에서 같은 순번에 있는 JBF들을 물리적 디스크상에서 인접하게 생성시키면(group 1의 1번 JBF, group 2의 1번 JBF, … group 1의 2번 JBF, …) 컨텐츠를 디스크에 캐싱할 때 인접한 구역을 쓰기 때문에 HDD를 사용하는 경우 디스크의 seek time을 줄일 수 있는 중요한 요인이 됩니다.JBF들의 그룹을 만드는 구조는 한 가지 치명적인 단점이 있습니다. 바로 중복된 JBF 탐색입니다. 위 그림에서 볼 수 있듯이 캐싱된지 오래된 컨텐츠를 읽기 위해서는 쓸모없는 JBF 탐색이 들어가야 하는데, 이는 개편 후 초기 테스트 시 Wcache에 쌓이는 컨텐츠가 많아질수록 성능을 저하시키는 주요 원인이 되었습니다.이를 해결하기 위해 각 JBF 앞단에 bloom filter1를 적용하게 됩니다. Bloom filter는 어떤 원소가 집합에 속하였는지 확률적으로 알 수 있게 하는 함수입니다. 약간의 false positive만 가지고 있고 false negative는 없기 때문에 해당 필터를 통과하는 경우에만 JBF 조회를 하도록 변경을 함으로써 기존 대비 2 ~ 5배의 응답속도를 향상시켰습니다.HTTP 헤더 중에는 ‘Vary’라는 항목이 있습니다. 동일한 URL에 대해 요청을 하더라도 요청한 사용자의 특징(User Agent, Accept Encoding, Origin 등등)에 따라 서로 다른 응답을 해 주기 위해서 존재하는 헤더입니다. 따라서 웹 캐시에서는 vary 헤더를 확인하고 해당 헤더에서 명시하는 조건에 따라 동일 URL이라 하더라도 다른 종류의 컨텐츠를 캐싱하고, 제공해야 합니다.기존 Wcache에서는 이런 vary object에 대한 고려가 충분하지 않았습니다. 아래 그림처럼 vary object 저장은 가능했지만, 리스트 형식으로 원하는 vary object가 나올 때까지 탐색해야 했고 그마저도 vary 헤더가 없는 normal object와 동시에 캐싱을 할 수 없는 이슈가 있었습니다.이를 해결하기 위해 저장 구조 설계 시 처음부터 vary object의 존재를 고려하였습니다. Metadata를 두 개의 타입 (Meta / Info)으로 나누어, Meta에는 현재 Wcache에 캐싱되어있는 vary object의 종류와 info의 포인터를, Info에는 실제 컨텐츠의 정보 (offset, header 등)를 담도록 설계하였습니다. 이 구조를 통해 여러 개의 vary object가 있어도, normal object와 공존해도 문제없이 사용자가 원하는 컨텐츠를 제공할 수 있게 됩니다.Wcache는 느슨한 구조의 actor model2을 가지고 있습니다. 사용자의 요청이 들어오면 다수의 actor(HTTP 요청 수신 / 응답 / 컨텐츠 처리 / 소스 서버 통신)를 돌아다니며 처리됩니다.  각 actor는 I/O multiplexing 형식으로 동시에 여러 개의 요청을 다룰 수 있게 하여 최대한의 성능을 낼 수 있도록 설계되었습니다. 그러나 디스크 I/O를 하는 actor는 내부적으로 blocking read / write를 수행하게 되어 단일 thread로는 원활한 성능을 얻을 수 없기에 내부적으로 multi thread 모델을 채택하였습니다.그러다보니 해당 구조에서는 캐싱된 컨텐츠를 처리하는 actor에서 컨텐츠를 조회하고 검증하는 동안 불가피하게 캐시 key에 대해 광범위한 lock 처리를 해야 했습니다.  이 lock은 컨텐츠가 새로 갱신되거나 삭제(Purge)될 때를 위해 필요하지만, 이전 구조에서는 read / write lock 구분이 없었습니다.  이는 동일 컨텐츠를 집중적으로 요청할 때 해당 컨텐츠의 초당 처리수가 제한되는 문제를 야기합니다. 일반적으로 특정 이벤트3로 인해 트래픽이 증가하는 경우, 소수의 인기 있는 컨텐츠들이 집중적으로 요청되는 경우가 많으므로 이러한 성능 제한은 급작스런 트래픽 대응 시 잠재적인 문제가 될 수 있습니다.이를 해결하기 위해 먼저 read / write lock을 분리하여 평시에 컨텐츠가 집중적으로 요청되는 경우 동시에 접근이 가능할 수 있도록 하였습니다.  더 나아가 lock의 범위를 줄이고 추후 유지보수를 쉽게 하기 위해 순수하게 디스크 I/O 부분과 캐시 컨텐츠를 검증하는 부분을 별도의 actor로 분리해 조금 더 효율적인 처리를 할 수 있도록 변경하였습니다. 이 조치는 동일 컨텐츠 요청에 대해 기존 대비 약 3배의 성능 향상을 이루어냅니다.이번 개편은 개발부터 성능 안정화까지 약 1년에 걸쳐 진행되었습니다. 기존 Wcache 구조의 핵심 부분들을 전부 뜯어고치는 대 작업이었습니다. 이번 개편을 통해 더 안정적인 성능을 이끌어 낼 수 있었고, 기능적인 측면들 - vary object 저장 유연화, 컨텐츠 크기 제한 해제, regular expression 기반 대량 캐시 퍼지 등 - 에서 큰 발전을 이룰 수 있게 되었습니다.Bloom Filter ↩Actor Model ↩다음 앱에서의 뉴스속보 및 날씨알림 등의 푸시, 카카오톡 채널탭 뱃지 등.. ↩",http://tech.kakao.com/2017/10/23/wcache-2/,0,kakao,"backend,json,java,python",NULL,2017-10-23
분산 웹 캐시 (Wcache)의 개선과정 - Part 1,"웹 서비스의 규모가 커지고 이용자의 수가 늘어날수록 서비스 제공자는 scalability 이슈에 직면합니다.  그중에서도 실제 ‘로딩 속도’의 차이를 느끼게 해 주고 트래픽의 대부분을 차지하는 정적 컨텐츠의 신속한 제공은 서비스 품질을 좌우하는 중요한 요소가 되곤 합니다.이런 수많은 컨텐츠들(Javascript, css, image 등)을 빠르게 제공하기 위해 클라이언트와 서버 사이에 위치하며 컨텐츠를 임시로 저장하는 Middlebox를 웹 캐시(web cache)라고 합니다. 웹 캐시의 기능은 Apache Traffic Server, Nginx, Squid와 같은 어플리케이션에서 지원하고 있으며, 대량의 컨텐츠를 처리하기 위한 전용 하드웨어 형태의 상용 솔루션도 있습니다.본 포스트에서는 카카오에서 자체적으로 개발하여 운영 중인 웹 캐시, Wcache에 대한 간략한 소개를 진행하고 올해 상반기에 진행되었던 대대적인 구조 개편 내역을 다음 포스트에 설명하고자 합니다.기존에 웹 캐시로 사용되던 상용 솔루션의 문제점은 아래와 같았습니다.이런 문제점은 점점 늘어나는 서비스들을 위한 기능을 추가하거나 장애 대응 및 트래픽 확장 시 걸림돌이 되었고, 자체적인 솔루션을 개발하는 계기가 되었습니다. C 언어로 구현된 Wcache는 범용 하드웨어(x86)의 자원을 최대한 활용하면서도 안정적인 성능을 낼 수 있도록 하였으며(multi-thread, I/O multiplexing, Direct Memory Access),  HTTP 표준을 준수하는 캐시 정책, 컨텐츠 퍼지 및  Reverse / Forward HTTP Proxy의 기본적인 기능(HTTP message control, access log, access control, DNS caching 등)을 지원합니다.웹 캐시의 성능은 보통 저장장치의 I/O 속도에 의해 좌우됩니다.1 특히 일정 수준의 캐시 hit율을 보장하기 위해 수십~수백 GB의 캐시 용량이 필요한 경우에는 디스크에 얼마만큼 안정적이고 효율적으로 컨텐츠를 저장하고 읽어오는가에 따라 성능이 크게 차이 날 수 있습니다.컨텐츠 별로 파일을 만들어 저장하는 방식은 다수의 컨텐츠를 저장할 때 일반적인 범용 파일 시스템(ext3, ext4 등)상에서 많은 문제를 일으킵니다. 하나의 디렉토리에 많은 파일을 저장하기 힘들뿐더러, 다수의 디렉토리를 만들면 디스크 및 커널 메모리의 inode 캐시 낭비를 일으킵니다. 또한, 파일 개수가 많아질수록 접근 속도도 느려지고 용량 확보를 위해 오래된 컨텐츠를 삭제할 때에도 수많은 I/O가 발생하게 됩니다. 용량 활용 측면에서도 기본 파일 시스템 블럭 단위가 4KB이기 때문에 4KB 미만의 컨텐츠가 다수 존재할 경우 심한 용량 낭비를 유발합니다.이러한 문제 때문에 Wcache에서는 독자적인 저장 구조를 만들어 컨텐츠 저장에 활용하였습니다. 먼저 컨텐츠 데이터가 저장되는 디스크에는 미리 일정한 크기(디스크 크기에 따라 64MB ~ 10GB)의 BigFile들을 여러 개 생성해 두어 컨텐츠를 저장할 공간을 확보해 둡니다. 이는 디스크가 연속된 영역에 순차적으로 데이터를 쓸 수 있도록 해줍니다. 추가로, 디스크 쓰기 작업 횟수를 줄이기 위해 BigFile 내부를 ‘block’이라는 세부 구조로 나누어 캐시가 되는 컨텐츠를 바로 저장하지 않고 메모리에 적재 후 block 단위로만 디스크에 쓰는 방식을 취하여 성능 향상을 이끌었습니다.Metadata에는 URL을 기반으로 한 캐시 key와 컨텐츠가 저장되어 있는 위치(BigFile 정보 및 offset)등의 정보를 담고 있으며, 이 정보는 컨텐츠가 저장되는 BigFile과는 별개로 SQLite DB에 저장합니다.디스크와 메모리의 효율적인 사용을 위해 Wcache는 HTTP 헤더와 일부 metadata 정보를 메모리상에 구성해둔 LRU hash table에 캐싱합니다. 메모리에 캐싱되어 있는 컨텐츠에 대해서는 DB 접근 없이 바로 응답이 가능하며, 캐싱되어 있지 않은 컨텐츠에 접근할 때는 DB에서 컨텐츠가 저장되어 있는 BigFile 정보를 읽어 컨텐츠에 대한 정보를 읽어오게 됩니다.초기 Wcache는 위 그림처럼 load balancer (LB) 밑에 여러 개의 Wcache 노드를 병렬로 구성하였습니다. 트래픽 대응을 위해서는 괜찮은 구조였지만, LB가 사용자 요청을 단순히 round robin 방식으로 분산하고 있어 모든 Wcache에 중복된 컨텐츠들이 캐싱되어 이 구조로는 높은 캐시 hit율을 얻기 힘들었습니다.이를 해결하기 위해 Wcache는 분산 구조를 지원하였습니다. 위 그림처럼 여러 대의 Wcache 노드로 구성된 클러스터를 구성하여 consistent hashing 기법을 이용해 컨텐츠를 고르게 분포시키고, 클라이언트 요청이 들어왔을 때 알맞은 노드에 요청을 라우팅 해주도록 설계하였습니다. 이 방법은 각 Wcache가 고유한 컨텐츠를 저장함으로써 캐시 효율을 증가시킬 수는 있었습니다. 그러나 특정 컨텐츠가 인기가 많은 hot item이 되는 경우, (예: 위 그림의 Wcache-A에 존재하는 (a)컨텐츠) 수많은 요청이 하나의 Wcache로 몰리는 현상이 일어나게 되고, 결국 트래픽을 감당할 수 없게 됩니다.이러한 문제를 해결하기 위해, 저희는 해당 클러스터 구조를 조금 더 발전시키기로 하였습니다. 위 그림처럼 Wcache를 두 개의 layer로 나눈 후, 1차 layer에 해당하는 Wcache들이 자신만의 분산 클러스터를 2차 layer로 가지도록 구성을 합니다. 이렇게 구성하면 1차 layer에서는 트래픽을 받고, 캐시 miss가 발생했을 경우 2차 layer 중 적절한 Wcache 노드에 요청합니다. 위 구조의 효과를 배가시키기 위해 1차 layer에 I/O 속도가 빠른 SSD를 탑재한 장비를, 2차 layer에는 상대적으로 속도는 느리지만 큰 저장공간을 가진 HDD 장비를 탑재하여 빠른 응답속도와 높은 캐시 hit율, 두 마리 토끼를 전부 잡을 수 있었습니다. 특히 소수의 유명한 컨텐츠가 매우 많이 요청되고, 나머지 컨텐츠의 사용 빈도가 기하급수적으로 낮아지는 long tail2 분포를 나타내는 서비스에 대해 높은 캐시 효율과 성능을 보여 주었습니다.이렇게 구성한 Wcache는 현재 카카오 서비스에서 수십만 TPS 상당의 트래픽을 95% 이상의 높은 캐시 hit율을 가지며 안정적으로 처리하고 있습니다. 다음 포스트에서는 Wcache에 잠재되어 있는 문제점이 무엇이 있었는지, 또 어떤 방법으로 해결하였는지에 대해 알아보도록 하겠습니다.Reducing the Disk I/O of Web Proxy Server Caches ↩Long tail distribution ↩",http://tech.kakao.com/2017/10/23/wcache-1/,0,kakao,"json,python,react,java,docker,backend,frontend,angular,php",NULL,2017-10-23
카카오 신입 공채 1차 코딩 테스트 문제 해설,"‘블라인드’ 전형으로 실시되어 시작부터 엄청난 화제를 몰고 온 카카오 개발 신입 공채. 그 첫 번째 관문인 1차 코딩 테스트가 지난 9월 16일(토) 오후 2시부터 7시까지 장장 5시간 동안 온라인으로 치러졌습니다. 지원자들의 개발 능력을 잘 검증하기 위해 출제 위원들이 한 땀 한 땀 독창적이고 다양한 문제들을 만들어 냈고 문제에 이상은 없는지, 테스트케이스는 정확한지 풀어보고 또 풀어보며 만반의 준비를 기했습니다.먼저, 가장 궁금해하실 1차 합격 기준부터 알려드립니다. 1차 합격 기준은 총 7 문제 중 4 문제 이상을 풀이한 분들입니다. 참고로 각 문제는 배점이 동일하므로 어떤 문제를 풀었던지 간에 관계는 없습니다.문제는 쉬운 난이도에서 어려운 난이도 순으로 풀 수 있도록 차례대로 배치했는데요. 앞서 얘기했듯 모든 문제는 배점이 동일하며 부분 점수는 없습니다. 즉, 채점 테스트케이스를 하나만 틀려도 오답으로 처리가 됩니다. 하지만 입출력 예제에 대부분의 예외 사항을 포함했고 따라서 입출력 테스트를 정상적으로 통과했다면 채점도 무리 없이 통과할 수 있도록 구성했습니다. 아울러 이번 코딩 테스트는 대회가 아니라 채용을 위한 시험인 만큼 ACM-ICPC 같은 어려운 알고리즘 설계 능력을 겨루는 문제가 아닌 업무에서 있을만한 상황을 가정하여 독창적이고 다양한 분야의 문제를 출제했고, 난이도 또한 비교적 쉬운 수준으로 조정하였습니다. 일반적으로 자료구조, 알고리즘 등의 전산학 기초에 대해 충분히 학습하였다면 누구나 풀 수 있을만한 문제들로 구성했습니다.참가 언어별로는 자바가 전체의 43%로 가장 많았습니다. 그다음이 C++ 36%, 파이썬 11%, 자바스크립트 8% 순이었는데요. 스위프트는 0.7%의 참가자만이 선택하여 아직 스위프트가 주류로 성장하기엔 좀 더 시간이 필요해 보였습니다.4문제 이상을 풀이한 합격자의 비율은 C++이 25%로 가장 높았습니다. 그다음으로 파이썬이 24%로 근소한 차이로 뒤를 쫓고 있고, 참가자가 매우 적었던 스위프트도 20%로 합격률은 비교적 높았습니다. 그러나, 참가자가 가장 많았던 자바는 11%의 합격률 밖에 보여주지 못했으며 아쉽게도 자바스크립트의 경우 합격률이 9%에 불과했습니다.풀이한 언어의 평균 코드 라인 수를 알아볼까요? C++이 평균적으로 가장 긴 라인 수를 자랑했습니다. 4번과 6번 문제는 78라인이나 필요했네요. 그다음은 근소한 차이로 자바입니다. 크게 차이가 나진 않지만 C++에 비해 평균적으로 5 ~ 6라인 정도가 짧았습니다. 그런데 재밌게도 가장 긴 코드는 자바가 차지했네요. 6번 문제의 경우 자바는 무려 80라인을 기록했습니다!그다음은 자바스크립트입니다. 자바에 비해 10라인 이상이 짧습니다. 역시나 파이썬이 가장 짧은 라인 수를 기록했는데요. 1번 문제는 고작 22라인 밖에 필요하지 않았습니다. 게다가 가장 긴 코드가 필요했던 6번 문제도 48라인으로 자바의 60% 수준에 불과합니다.이외에도 여러 언어를 섞어서 풀이한 분들이 전체의 5%나 되었으며, ‘C++ + 자바 + 자바스크립트 + 파이썬’ 이 4가지 언어를 동시에 섞어서 풀이한 분도 계셨네요.긴 시간 동안 시험을 치르고, 문제를 풀이하느라 다들 고생 많이 하셨습니다. 자, 그렇다면 많은 분들이 궁금해하실 코딩 테스트 문제를 하나씩 짚어보도록 할까요?네오는 평소 프로도가 비상금을 숨겨놓는 장소를 알려줄 비밀지도를 손에 넣었다. 그런데 이 비밀지도는 숫자로 암호화되어 있어 위치를 확인하기 위해서는 암호를 해독해야 한다. 다행히 지도 암호를 해독할 방법을 적어놓은 메모도 함께 발견했다.네오가 프로도의 비상금을 손에 넣을 수 있도록, 비밀지도의 암호를 해독하는 작업을 도와줄 프로그램을 작성하라.입력으로 지도의 한 변 크기 n 과 2개의 정수 배열 arr1, arr2가 들어온다.원래의 비밀지도를 해독하여 ""#"", 공백으로 구성된 문자열 배열로 출력하라.이 문제는 비트 연산Bitwise Operation을 묻는 문제입니다. 이미 문제 예시에 2진수로 처리하는 힌트가 포함되어 있고, 둘 중 하나가 1일 경우에 벽 #이 생기기  때문에 OR로 처리하면 간단히 풀 수 있습니다. 아주 쉬운 문제였던 만큼 if else로 풀이한 분들도 많이 발견되었는데요. 정답으로는 간주되지만 이 문제는 비트 연산을 잘 다룰 수 있는지를 묻고자 하는 의도였던 만큼 앞으로 이런 유형의 문제를 풀 때는 비트 연산을 꼭 기억하시기 바랍니다.이 문제의 정답률은 81.78%입니다. 첫 번째 문제이고 가장 쉬운 문제였던 만큼 많은 분들이 잘 풀어주셨습니다.카카오톡에 뜬 네 번째 별! 심심할 땐? 카카오톡 게임별~카카오톡 게임별의 하반기 신규 서비스로 다트 게임을 출시하기로 했다. 다트 게임은 다트판에 다트를 세 차례 던져 그 점수의 합계로 실력을 겨루는 게임으로, 모두가 간단히 즐길 수 있다. 갓 입사한 무지는 코딩 실력을 인정받아 게임의 핵심 부분인 점수 계산 로직을 맡게 되었다. 다트 게임의 점수 계산 로직은 아래와 같다.0~10의 정수와 문자 S, D, T, *, #로 구성된 문자열이 입력될 시 총점수를 반환하는 함수를 작성하라.“점수|보너스|[옵션]”으로 이루어진 문자열 3세트. 예) 1S2D*3T3번의 기회에서 얻은 점수 합계에 해당하는 정수값을 출력한다. 예) 37문자열 처리String Manipulation를 묻는 문제입니다. 앞에서부터 한 글자씩 잘라서 처리할 수 있고, 또는 간단한 컴파일러를 만들듯이 토큰화Tokenizing와 의미 분석Semantic Analysis을 통해 어렵지 않게 계산할 수 있습니다.점수 중에는 한 자리뿐만 아니라 두 자리인 10점도 포함되어 있기 때문에 한 글자씩 잘라서 처리할때는 그 부분에 유의해야겠네요. 토큰화로 처리할 때는 정규식을 사용하면 비교적 쉽게 잘라낼 수 있습니다. S, D, T는 각각 원점수, 제곱, 세제곱으로 처리하고 스타상은 두 배로 계산하면 됩니다. 참, 아차상은 마이너스 점수라는 점에 유의하세요.이 문제의 정답률은 73.47%입니다. 앞서 비밀지도 보다는 낮지만 그래도 많은 분들이 잘 풀어주셨습니다.지도개발팀에서 근무하는 제이지는 지도에서 도시 이름을 검색하면 해당 도시와 관련된 맛집 게시물들을 데이터베이스에서 읽어 보여주는 서비스를 개발하고 있다. 이 프로그램의 테스팅 업무를 담당하고 있는 어피치는 서비스를 오픈하기 전 각 로직에 대한 성능 측정을 수행하였는데, 제이지가 작성한 부분 중 데이터베이스에서 게시물을 가져오는 부분의 실행시간이 너무 오래 걸린다는 것을 알게 되었다. 어피치는 제이지에게 해당 로직을 개선하라고 닦달하기 시작하였고, 제이지는 DB 캐시를 적용하여 성능 개선을 시도하고 있지만 캐시 크기를 얼마로 해야 효율적인지 몰라 난감한 상황이다.어피치에게 시달리는 제이지를 도와, DB 캐시를 적용할 때 캐시 크기에 따른 실행시간 측정 프로그램을 작성하시오.여기서부터 문제가 좀 어려워졌던 거 같습니다. 정답률이 많이 낮은데요. 이 문제는 ‘조건’에도 나와있지만 LRU 캐시 교체 알고리즘을 구현하는 문제이고, 이미 잘 알고 있다면 또는 검색해봤다면 잘 구현된 LRU 알고리즘 코드는 많이 찾을 수 있습니다.단, 이 문제에는 입출력 예제에 캐시 사이즈 0이 포함되어 있습니다. 공개된 대부분의 LRU 구현 코드는 0일 때의 비정상적인 상황은 가정하지 않고 있기 때문에 생각 없이 그냥 가져와 붙인다면 에러가 나서 많이 고생했을 거 같네요. 하지만 사이즈 0을 처리하는 예외 처리 자체는 어렵지 않게 구현할 수 있으므로 입출력 예제가 왜 자꾸 틀리는지를 유심히 살펴봤다면 쉽게 풀 수 있는 문제입니다.아울러 검색해서 가져온 코드는 반드시 사용 가능한지 라이선스를 확인하고, 가져올 때는 꼭 출처를 명시해야 한다는 점 잊지 마세요.이 문제의 정답률은 45.26%입니다.카카오에서는 무료 셔틀버스를 운행하기 때문에 판교역에서 편하게 사무실로 올 수 있다. 카카오의 직원은 서로를 ‘크루’라고 부르는데, 아침마다 많은 크루들이 이 셔틀을 이용하여 출근한다.이 문제에서는 편의를 위해 셔틀은 다음과 같은 규칙으로 운행한다고 가정하자.일찍 나와서 셔틀을 기다리는 것이 귀찮았던 콘은, 일주일간의 집요한 관찰 끝에 어떤 크루가 몇 시에 셔틀 대기열에 도착하는지 알아냈다. 콘이 셔틀을 타고 사무실로 갈 수 있는 도착 시각 중 제일 늦은 시각을 구하여라.단, 콘은 게으르기 때문에 같은 시각에 도착한 크루 중 대기열에서 제일 뒤에 선다. 또한, 모든 크루는 잠을 자야 하므로 23:59에 집에 돌아간다. 따라서 어떤 크루도 다음날 셔틀을 타는 일은 없다.셔틀 운행 횟수 n, 셔틀 운행 간격 t, 한 셔틀에 탈 수 있는 최대 크루 수 m, 크루가 대기열에 도착하는 시각을 모은 배열 timetable이 입력으로 주어진다.콘이 무사히 셔틀을 타고 사무실로 갈 수 있는 제일 늦은 도착 시각을 출력한다. 도착 시각은 HH:MM 형식이며, 00:00에서 23:59 사이의 값이 될 수 있다.쉬워 보이는데 어려운 문제가 바로 이 문제였던 거 같네요. 당초 난이도를 ‘중’으로 두고 문제를 중간 즈음에 배치하였는데, 시간을 계산하는 부분에서 많은 분들이 어려워하셨던 거 같습니다.예를 들어 2번 입출력 예제의 경우 [""09:10"", ""09:09"", ""08:00""]인데 이 경우 두 번째 버스는 9:10분에 출발하기 때문에 9:10분에 오면 되지 않느냐 많이들 혼동하셨을 거 같아요. 하지만 9:00에 오는 버스는 8:00에 대기하는 크루 1명만 탑승할 수 있고, 따라서 9:10 버스에는 남아 있는 두 명이 모두 타게 됩니다. 따라서 좀 더 이른 9:09에 와야 탑승할 수 있습니다.전체 계산은 어렵지 않지만 이처럼 정확하게 시간 계산을 해야 하는 부분이 많고 마지막 버스 시간까지 빈틈없이 계산해야 해서 많은 분들이 실수를 한 거 같습니다. 이 문제는 정답률이 두 번째로 낮은 26.79%입니다.여러 언론사에서 쏟아지는 뉴스, 특히 속보성 뉴스를 보면 비슷비슷한 제목의 기사가 많아 정작 필요한 기사를 찾기가 어렵다. Daum 뉴스의 개발 업무를 맡게 된 신입사원 튜브는 사용자들이 편리하게 다양한 뉴스를 찾아볼 수 있도록 문제점을 개선하는 업무를 맡게 되었다.개발의 방향을 잡기 위해 튜브는 우선 최근 화제가 되고 있는 “카카오 신입 개발자 공채” 관련 기사를 검색해보았다.기사의 제목을 기준으로 “블라인드 전형”에 주목하는 기사와 “코딩 테스트”에 주목하는 기사로 나뉘는 걸 발견했다. 튜브는 이들을 각각 묶어서 보여주면 카카오 공채 관련 기사를 찾아보는 사용자에게 유용할 듯싶었다.유사한 기사를 묶는 기준을 정하기 위해서 논문과 자료를 조사하던 튜브는 “자카드 유사도”라는 방법을 찾아냈다.자카드 유사도는 집합 간의 유사도를 검사하는 여러 방법 중의 하나로 알려져 있다. 두 집합 A, B 사이의 자카드 유사도 J(A, B)는 두 집합의 교집합 크기를 두 집합의 합집합 크기로 나눈 값으로 정의된다.예를 들어 집합 A = {1, 2, 3}, 집합 B = {2, 3, 4}라고 할 때, 교집합 A ∩ B = {2, 3}, 합집합 A ∪ B = {1, 2, 3, 4}이 되므로, 집합 A, B 사이의 자카드 유사도 J(A, B) = 2/4 = 0.5가 된다. 집합 A와 집합 B가 모두 공집합일 경우에는 나눗셈이 정의되지 않으니 따로 J(A, B) = 1로 정의한다.자카드 유사도는 원소의 중복을 허용하는 다중집합에 대해서 확장할 수 있다. 다중집합 A는 원소 “1”을 3개 가지고 있고, 다중집합 B는 원소 “1”을 5개 가지고 있다고 하자. 이 다중집합의 교집합 A ∩ B는 원소 “1”을 min(3, 5)인 3개, 합집합 A ∪ B는 원소 “1”을 max(3, 5)인 5개 가지게 된다. 다중집합 A = {1, 1, 2, 2, 3}, 다중집합 B = {1, 2, 2, 4, 5}라고 하면, 교집합 A ∩ B = {1, 2, 2}, 합집합 A ∪ B = {1, 1, 2, 2, 3, 4, 5}가 되므로, 자카드 유사도 J(A, B) = 3/7, 약 0.42가 된다.이를 이용하여 문자열 사이의 유사도를 계산하는데 이용할 수 있다. 문자열 “FRANCE”와 “FRENCH”가 주어졌을 때, 이를 두 글자씩 끊어서 다중집합을 만들 수 있다. 각각 {FR, RA, AN, NC, CE}, {FR, RE, EN, NC, CH}가 되며, 교집합은 {FR, NC}, 합집합은 {FR, RA, AN, NC, CE, RE, EN, CH}가 되므로, 두 문자열 사이의 자카드 유사도 J(""FRANCE"", ""FRENCH"") = 2/8 = 0.25가 된다.입력으로 들어온 두 문자열의 자카드 유사도를 출력한다. 유사도 값은 0에서 1 사이의 실수이므로, 이를 다루기 쉽도록 65536을 곱한 후에 소수점 아래를 버리고 정수부만 출력한다.이 문제는 자카드 유사도를 설명해주고 자카드 유사도를 직접 계산하는 프로그램을 작성하는 문제입니다. 자카드 유사도는 실무에서도 유사한 문서를 판별할 때 주로 쓰이는데요, 몰랐더라도 문제에서 자세히 설명해주기 때문에 이해하는데 어려움은 없었을 거 같습니다. 공식은 매우 간단한데요, 교집합을 합집합으로 나눈 수입니다. 다만, 이 값은 0에서 1 사이의 실수가 되는데, 여기서는 이를 다루기 쉽도록 65536을 곱한 후 소수점 아래를 버리고 정수부만 취하도록 합니다.문제 설명은 원소의 중복을 허용하는 다중집합multiset으로 되어 있는데, 자주 접하는 자료구조가 아니고, 일부 언어에서는 기본으로 제공하는 자료구조가 아니라 어려워하는 분들이 있었습니다. 하지만 다중집합 자료구조를 쓰지 않더라도, 각 원소를 정렬된 배열에 넣은 후 병합 정렬Merge sort에서 배웠던 코드를 응용, 어렵지 않게 합집합과 교집합 함수를 직접 구현할 수도 있습니다.다중집합의 교집합, 합집합만 잘 구해낸다면 이 문제는 어렵지 않게 풀 수 있으며, 다만 집합 A와 B가 모두 공집합일 경우에는 나눗셈이 정의되지 않으므로division by zero 따로 J(A,B) = 1로 정의합니다. 즉, 65536을 곱하면 이 경우 1 * 65536 = 65536이 정답이 됩니다. 예제 입출력에도 합집합이 공집합인 경우가 포함되어 있으므로 이 경우만 주의한다면 쉽게 풀 수 있는 문제입니다.이 문제의 정답률은 41.84%입니다.블라인드 공채를 통과한 신입 사원 라이언은 신규 게임 개발 업무를 맡게 되었다. 이번에 출시할 게임 제목은 “프렌즈4블록”. 같은 모양의 카카오프렌즈 블록이 2×2 형태로 4개가 붙어있을 경우 사라지면서 점수를 얻는 게임이다.만약 판이 위와 같이 주어질 경우, 라이언이 2×2로 배치된 7개 블록과 콘이 2×2로 배치된 4개 블록이 지워진다. 같은 블록은 여러 2×2에 포함될 수 있으며, 지워지는 조건에 만족하는 2×2 모양이 여러 개 있다면 한꺼번에 지워진다.블록이 지워진 후에 위에 있는 블록이 아래로 떨어져 빈 공간을 채우게 된다.만약 빈 공간을 채운 후에 다시 2×2 형태로 같은 모양의 블록이 모이면 다시 지워지고 떨어지고를 반복하게 된다.위 초기 배치를 문자로 표시하면 아래와 같다.각 문자는 라이언(R), 무지(M), 어피치(A), 프로도(F), 네오(N), 튜브(T), 제이지(J), 콘(C)을 의미한다입력으로 블록의 첫 배치가 주어졌을 때, 지워지는 블록은 모두 몇 개인지 판단하는 프로그램을 제작하라.입력으로 주어진 판 정보를 가지고 몇 개의 블록이 지워질지 출력하라.게임 요구 사항을 구현해보는 문제입니다. 같은 모양의 카카오프렌즈 블록이 2x2 형태로 4개가 붙어있을 경우 사라지면서 점수를 얻는 게임인데요. 인접한 모든 블록이 사라지는 실제 게임들과 달리 계산을 쉽게 하기 위해 2x2로 제한하고, 사라진 블록 자리에는 새로운 블록이 채워지지 않습니다. 그럼에도 불구하고 인접한 블록을 모두 스캔해야 하는 문제라 짧지 않은 코드가 필요했을 것 같네요. 이번 시험에서 가장 긴 코드가 필요한 문제였습니다. 자바의 경우 무려 80라인이나 필요했네요. 블록 매트릭스를 생성하여 스캔하고 제거해 나가는 작업을 반복하면서 더 이상 제거되지 않을 때 사라진 블록 자리의 수를 계산하면 됩니다.이 문제의 정답률은 48.01%입니다.이번 추석에도 시스템 장애가 없는 명절을 보내고 싶은 어피치는 서버를 증설해야 할지 고민이다. 장애 대비용 서버 증설 여부를 결정하기 위해 작년 추석 기간인 9월 15일 로그 데이터를 분석한 후 초당 최대 처리량을 계산해보기로 했다. 초당 최대 처리량은 요청의 응답 완료 여부에 관계없이 임의 시간부터 1초(=1,000밀리초)간 처리하는 요청의 최대 개수를 의미한다.이번 테스트의 마지막 문제이고, 가장 어려운 문제입니다. 초당 최대 처리량이 되는 구간 윈도우를 찾아야 하는 문제인데요. 당연히 처음부터 끝까지 스캔하기에는 범위가 너무 크고, 게다가 ms 단위로 되어 있기 때문에 첫 로그 시각부터 마지막 로그 시각까지 1ms씩 증가시키면서 1000ms 단위의 슬라이딩 윈도우로 풀면 24 * 3600 * 1000 * n * 1000ms 만큼의 연산이 필요하기 때문에 이렇게는 풀 수가 없습니다.그렇다고 각 로그의 시작 시각부터 마지막 시각까지 1ms 씩 움직이면 time(ms) * n^2 이 되며, time(ms)의 값은 대부분 천 단위 이상이기 때문에 마찬가지로 타임아웃이 발생하여 풀 수가 없습니다. 그런데 자세히 살펴보면 요청량이 변하는 순간은 각 로그의 시작과 끝뿐임을 알 수 있습니다. 따라서, 각 로그 별 2번의 비교 연산만 수행하면 되며 2 * n^2, 빅오로 정리하면 O(n^2)에 풀 수가 있습니다. 빅오에서 제거된 상수항도 매우 작기 때문에 이 경우 무리 없이 문제를 풀 수 있게 되며 C++ 기준으로 10ms를 넘지 않습니다.물론, 이 문제는 윈도우를 사용하지 않고도 풀 수 있는 방법이 있습니다. 효율적인 알고리즘을 쓴다면, O(n log n)으로 풀 수 있는 방법도 있으니 한 번 고민해보세요. 이 문제는 가장 어려운 문제였던 만큼 정답률은 가장 낮은 17.99%입니다.이렇게 모든 문제를 돌아보고 간략한 해설을 곁들여 봤습니다. 어떠신가요?참여하신 분들 중 미처 풀지 못한 문제가 있었다면 문제 해설을 보면서 ‘조금만 더 시간이 있었더라면…‘라며 안타까움을 느끼는 분들이 많으실 거라 생각합니다. 여타의 코딩 대회와 달리 채용을 위한 시험인 만큼 재밌게 즐기기는 힘들었을 것입니다. 하지만, “천재는 노력하는 사람을 이길 수 없고, 노력하는 사람은 즐기는 사람을 이길 수 없다.”는 말이 있듯이, 끝까지 즐기는 마음 잊지 않고 코딩을 즐긴다면 언젠가 좋은 결과 있으리라 확신합니다. 마지막까지 잘 마무리하여 꼭 카카오에서 여러분들을 만나 뵙게 되길 기대하겠습니다.그럼, 2차 시험에서 다시 만나도록 할게요. 마지막까지 파이팅!",http://tech.kakao.com/2017/09/27/kakao-blind-recruitment-round-1/,0,kakao,"javascript,frontend,java,python",NULL,2017-09-27
kakao의 오픈소스 Ep8 - hbase-packet-inspector,"이번에 카카오에서 오픈소스로 공개한 hbase-packet-inspector (이하 HPI) 는 HBase 리젼서버의 네트워크 패킷을 분석해 요청과 응답 정보를 추출하는 툴입니다. 기존의 모니터링 툴을 통해서는 알 수 없었던 보다 상세한 정보들을 확인할 수 있습니다.먼저 왜 이런 툴이 필요했는지 이야기해봐야 할 것 같습니다.카카오와 다음의 많은 서비스들은 HBase 를 중요한 데이터 저장소로 사용하고 있습니다. 서비스 간의 간섭을 피하기 위해 개별 서비스는 각각 독립적인 HBase 클러스터를 사용하는 것이 원칙이며, 그러다 보니 실제 운영 중인 HBase 클러스터는 수십 개에 이릅니다. 각 클러스터의 데이터 스키마와 액세스 패턴, 워크로드는 모두 상이하지요.그리고 이 모든 클러스터를 5명의 인원이 시간을 나누어 운영하고 있습니다. 때문에 각 클러스터의 서비스적 특성을 모두 세밀하게 파악하고 있지 못한 것이 현실입니다. 물론 최초 클러스터 투입 시점에 전반적인 리뷰 프로세스를 거치지만 시간이 지나며 초기와는 다른 양상으로 흘러가기도 하니까요.이러한 상황에서 서비스 장애는 발생하고, 우리는 최대한 빨리 이에 대응해야 합니다. 긴급한 서비스 장애 상황에서 빠르게 문제 원인을 파악할 수 있는 방법들이 필요합니다.많은 경우 기본적인 모니터링만으로도 문제 파악이 가능합니다. 각 서버의 시스템 리소스 사용량이나 HBase 가 제공하는 서버 별, 리젼 별 메트릭을 확인하면 대부분의 경우는 어떠한 부분이 문제가 되고 있는지 바로 알 수 있고, 그에 대한 대응 프로세스는 이미 마련되어 있죠.하지만 예측 범위를 벗어난 예외적인 경우들이 문제입니다. 평상시와 다른 비정상적 클라이언트 동작, 비정상적인 액세스 패턴, 또는 비정상적 데이터로 인한 문제가 발생할 경우 서버 단위의, 혹은 리젼 단위의 coarse-grained 지표만 가지고는 빠른 문제 파악이 어렵습니다.정확히 어떤 데이터가, 어떤 클라이언트의 어떤 오퍼레이션에 의해, 어떤 빈도로 조회되고 갱신되고 있는지 정확히 진단할 수 있는 방법이 필요했습니다. 1구체적으로 예를 들어 어떤 로우키 (row key) 2 로 액세스가 집중되고 있는지 파악이 필요한 경우가 있었습니다. 특정 레코드로 쓰기가 집중될 경우 경합이 발생하게 되고 시스템 리소스에 여유가 있음에도 불구하고 애플리케이션 성능은 낮게 나타날 수 있습니다. 일반적인 모니터링 지표 (CPU 사용량, HBase 리퀘스트 처리량 등) 로는 감지하기 어려운 상황입니다. 이런 상황을 파악하고, 문제가 되는 레코드를 정확히 확인할 수 있다면 효과적인 대응이 가능하겠죠.기존의 모니터링 도구로는 대응이 불가능한 부분이었고, 담당 서비스 팀에서도 정확한 추적이 어려운 상황이었습니다. 마지막 수단으로 ngrep 을 이용해 네트워크 패킷의 바이트 스트림을 눈으로 따라가 보았습니다.테이블명, 오퍼레이션 타입, 접근하는 로우키 정보들을 어렴풋이 확인할 수 있습니다. 여기서 많이, 자주 보이는 로우키들을 기억해서 서비스 담당팀에 전달하는 것이 당시 우리가 할 수 있는 최선이었죠. 프로세스는 비효율적이고 부정확했습니다.흔히 발생하는 상황은 아니었지만, 그 후로도 이러한 경우들이 여러 번 반복되었고, 보다 체계적으로 대응해야 할 필요성을 느끼게 됩니다.“이럴 거면 제대로 까 봅시다.”HBase 프로토콜을 이해하는 패킷 분석 도구를 만들기로 했습니다. 명칭은 이미 오픈소스로 공개한 hbase-region-inspector 와 유사하게 hbase-packet-inspector 로 정했습니다.개발을 위해선 HBase RPC 에 대한 이해가 필요합니다. 다행히 HBase 의 RPC 프로토콜은 단순한 편으로 문서화가 잘되어 있고, Protocol Buffer 기반이므로 관련 .proto 파일들을 들여다보면 메시지 구조를 모두 알 수 있습니다. 3HBase 의 RPC 는 간단하게 다음 그림으로 요약할 수 있습니다.RequestHeader 와 ResponseHeader 의 Protocol Buffer message 정의는 다음과 같습니다.요청의 경우 RequestHeader 를 보면 어떤 타입의 요청인지 (method_name), 어떤 파라미터로 요청되었는지 모두 알 수 있지만, 응답의 경우 그러한 정보가 직접적으로 주어져 있지 않아 매칭 되는 요청을 call_id 기준으로 찾아봐야 합니다. 따라서 HPI 는 패킷 스트림을 분석하면서 call_id 에 해당하는 원래의 요청을 내부 상태로 기억하고 관리합니다.커넥션의 단절, 또는 pcap 의 패킷 드랍으로 인해, 요청에 대한 응답을 HPI 가 보지 못하는 경우들이 발생할 수 있습니다. 이러한 경우들이 장기간 누적되면 내부 상태 관리에 필요한 메모리 사이즈가 지속적으로 증가하므로 이를 시간 기준, 사용 메모리 기준으로 정리하는 로직도 구현해야 합니다.RequestHeader 의 method_name 에 따라 해당 요청 타입에 맞는 메시지가 파라미터로 따라오게 되는데요, 간단한 예로 Get 요청의 경우 다음과 같은 메시지를 사용합니다.우리가 원하는 정보 – 어떤 리젼을 향하는 요청인지, 어떤 로우키에 대한 요청인지 등 – 를 모두 추출할 수 있죠.Scan 의 경우는 조금 복잡한데요, 하나의 scan 작업은 최초의 open scanner, 1번 이상의 next rows, 최종 close scanner 의 세 번 이상의 RPC 로 구성되고 4, 이들은 개별적인 RPC 로서 서로 다른 call_id 를 갖습니다. 이들을 이어주는 것은 open scanner 응답에 포함된 scanner_id 로 이를 내부 상태로 관리하고 연관된 RPC 를 묶어주는 작업이 필요합니다.추가적으로 패킷 분석 시 신경 써야 했던 부분들은 다음과 같습니다.원하는 정보를 추출했다면, 이를 어떻게 보여줄 것인가의 고민이 이어집니다. 최초에는 hbase-region-inspector 와 유사하게 웹을 통한 시각화를 고려했지만, 요구 사항을 나열해보니 난감했어요.생각해보면 끝이 없습니다. 이토록 다양한 형태의 요구를 모두 수용할 수 있을 만큼 강력하고 유연한 사용자 인터페이스는 무엇이 있을까, 우리의 오랜 친구 SQL 이 떠올랐습니다. 위의 요구 사항은 다음과 같이 표현해볼 수 있겠네요.미려한 시각화는 없지만 유연하고 강력합니다. SQL 인터페이스를 제공하기로 결정합니다.빠르고 간단하게 실행할 수 있는 툴을 만드는 것이 목표였기 때문에 외부 데이터베이스 연동을 고려하지는 않았고 5, H2 데이터베이스를 내장해 메모리 데이터베이스에 적재하기로 했습니다.H2 가 제공하는 큰 장점은 커맨드 라인과 웹 기반의 SQL 인터페이스를 내장하고 있다는 점이었는데요, 덕분에 사용자 인터페이스를 개발하는데 시간을 전혀 들이지 않고 빠른 프로토타이핑이 가능했습니다.HPI 를 실행하면 지정한 네트워크 인터페이스에 대한 패킷 캡처를 시작합니다. 분석한 내용을 메모리 데이터베이스에 적재하므로, 마냥 계속 유지할 수는 없고 heap 영역 부족이 발생하기 전에 중단해야 합니다. 지정된 시간 동안 (--duration) 혹은 지정된 개수의 패킷을 처리할 때까지 (--count) 유지하도록 할 수도 있고, 사용자의 키 입력 시점까지 유지할 수도 있습니다.아래 보시는 내용은 50만 개의 패킷을 처리한 시점에서 처리를 중단한 후, H2 가 제공하는 SQL 인터페이스로 데이터를 조회해보는 모습입니다.그리고 앞서 언급한 것처럼 웹 기반의 SQL 인터페이스가 공짜로 따라오지요. 화려하진 않지만 원하는 기능은 모두 수행할 수 있습니다.이 정도로도 그럭저럭 쓸만한 상태가 되었고, 한동안 잘 활용했지만 한계는 뚜렷했습니다.다수의 서버에서 HPI 를 중단 없이 장기간 실행하고 수집된 결과를 취합해 실시간으로 분석해보고 싶었습니다. 이에 Apache Kafka 로의 전송 기능을 도입하게 되었습니다.Kafka 로 전송할 경우, 복수개의 consumer 를 이용해 다양한 방식으로 데이터를 가공해 유연하게 활용할 수 있다는 장점이 있습니다. 카카오에서 Kafka 가 데이터 연동 시 “사실상 표준” 도구로서 활용되고 있다는 점도 선택에 영향을 주었죠.패킷 캡처 방식은 서버의 최대 성능에 영향을 주는 것으로 알려져 있고, HPI 도 예외는 아닙니다. 리젼서버의 부하가 높은 상황이라면 HPI 를 리젼서버가 아닌 애플리케이션 서버 쪽에서 실행하는 것이 안전하겠죠 6. HPI 는 포트 번호를 기준으로 서버 여부를 판단하므로 반드시 리젼서버 상에서 실행할 필요가 없습니다. 다음과 같은 형태가 됩니다.Kafka 로 전송된 데이터는 위의 그림에 표현한 것처럼 다양한 방식으로 활용이 가능한데요, 카카오에서는 Spark streaming 으로 데이터를 가공해 OLAP 엔진인 Druid 으로 실시간 전송하고 Pivot 으로 시각화하여 확인하고 있습니다.여기서 한걸음 더 나아가 Druid API 를 이용해 주기적으로 클러스터 핫스팟 분석을 수행하고, 이에 따른 적절한 대응을 자동으로 수행하는 고도화 작업을 진행하고 있습니다.아직 부족한 점들이 있지만 HPI 는 HBase 클러스터의 모니터링과 운영 프로세스를 개선하는데 적지 않은 도움을 주고 있습니다. 오픈소스 공개 이후에도 지속적으로 개선해 나갈 예정이며 비슷한 고민(과 고생)을 하신 분들께 도움이 되길 바랍니다.원칙적으로 이러한 액세스 패턴에 대한 지표는 개별 서비스 담당팀에 의해   추적/모니터링이 되는 것이 맞겠습니다. 하지만 여러 현실적인 이유로 그에   대한 대비가 충분히 되지 않은 경우들이 있을 수 있고, 서비스 장애 상황에   급하게 이에 대한 추가 개발/배포를 요구하는 것은 어렵죠. ↩HBase 데이터 테이블의 primary key ↩HPI 는 JVM 에서 동작하는 Clojure 로 개발했으므로   proto 파일에 대한 별도의 전처리 없이 HBase 서버와 클라이언트가 사용하는   Java API 를 그대로 사용할 수 있습니다. ↩Small scan 인 경우는 예외로 한 번의 RPC 로 이루어집니다. HPI 는 small   scan 여부를 구분합니다. ↩JDBC 드라이버, 유저명, 패스워드, 접속 권한, 테이블 생성 권한 … ↩단순히 tcpdump 를 실행하는 것만으로도 서버의   최대 성능이 10 ~ 15% 가량 저하되는 것을 확인할 수 있습니다 (이는 최대   성능의 관점이며 서버의 처리량이 높지 않은 상태라면 그 정도의 차이가   관찰되지는 않습니다). HPI 의 경우도 유사하나 HPI 는 단순한 tcpdump 보다   더 많은 CPU 자원을 사용하므로 추가적인 주의가 필요합니다. 카카오에서는   서비스의 안정적 운영을 위해 시스템 리소스에 어느 정도 여유가 있는   수준으로 클러스터의 규모를 산정하기 때문에 HPI 를 추가적으로 실행하는데   큰 무리가 없습니다. ↩",http://tech.kakao.com/2017/09/22/opensource-8-hbase-packet-inspector/,0,kakao,"tcp,python,swift,java,mysql,backend,database,php",NULL,2017-09-22
카카오 코드 페스티벌 본선 이야기,"지난 9월 9일 토요일, 카카오 코드 페스티벌의 오프라인 본선이 진행됐습니다. 예선에서의 엄청난 경쟁률을 뚫고 당당히 본선에 진출한 100여명의 실력자들이 함께 했는데요. 합병 후 카카오의 첫 개발자 행사인 만큼, 처음이라는 설렘을 담아 구석구석 정성스러움을 가득 담아 대회를 준비했습니다.▶ 행사 후기가 궁금하시다면?코드 페스티벌의 핵심인 문제도 정말 열심히 준비했습니다! 참가자들도 “문제 모티브가 재미있어 다른 대회보다 더 즐기는 마음으로 참여할 수 있었다”는 긍정적인 피드백을 주셨는데요, (이런 피드백 무한 감사, 정말 힘이 납니다!) 본선에 출제되었던 문제에 대한 설명과 해설을 이제부터 진행하고자 합니다.코드 페스티벌 본선에는 총 8문제가 출제되었습니다. 3시간이라는 짧은 시간동안 진행되었지만 참가자들의 대단한 실력을 증명하듯 모든 문제에 정답자가 있었습니다. 그럼 이제 문제를 하나하나 함께 살펴보실까요?8명의 프렌즈가 나란히 서서 단체사진을 찍는데, 각자가 다른 프렌즈와 어느 정도 거리를 두고 서고 싶은지를 입력으로 받고 이 조건을 모두 만족하는 경우의 수를 구하는 문제입니다. 8명이 나란히 서는 모든 경우의 수가 8! = 40,320으로 많지 않기 때문에, 모든 가능한 방법에 대해 조건을 모두 만족하는지를 확인하면 됩니다. C++의 경우 next_permutation 함수를 이용하면 빠르게 코드를 작성할 수 있으며, 이를 사용하지 않고 직접 가능한 경우의 수를 모두 생성하거나 8중 반복문으로 조건을 확인해도 개수가 많지 않아 제한 시간 안에 답을 구할 수 있습니다.택시가 다니는 거점과 도로의 정보, 그리고 택시가 시간대 별로 보낸 현재 위치가 입력으로 주어집니다. 단 현재 위치와 다음 위치를 연결하는 도로가 없을 경우 이동이 불가능하며, 이와 같은 오류를 최소한으로 수정하여 이동 가능한 경로로 만드는 것이 목표인 문제입니다.동적 계획법(Dynamic Programming)으로 풀 수 있습니다. 다음과 같은 2차원 배열을 정의하고 순서대로 값을 채워나가면 됩니다.승차 위치는 오류가 없기 때문에 S[0][j]의 값은 j가 입력된 승차 위치인 경우 0, 그렇지 않은 경우 INF입니다. 그리고 i>0인 경우의 값은 i-1번째의 값을 참조하여 계산할 수 있습니다. 이때 택시가 특정 위치에 계속 머무르는 것이 가능하기 때문에 계산할 때 이를 고려해야 합니다. 모든 값을 구한 뒤 입력된 하차 위치 j에 대해 S[k-1][j]를 구하면 됩니다. O(k(n+m))의 시간복잡도로 답을 구할 수 있습니다.2차원 배열이 주어지고, 사천성 게임의 규칙에 따라 블록을 제거하는 방법을 구하는 문제입니다. 단 원래의 사천성 규칙에 비해 경로의 꺾는 횟수가 한 번으로 줄어들었고 모든 블록이 항상 두 개씩만 존재한다는 조건이 추가되었습니다. 그리고 블록은 알파벳 대문자로 표시되기 때문에 최대 26개만 존재할 수 있습니다. 가능한 방법이 여러 가지인 경우 알파벳 순으로 가장 먼저인 문자열을 리턴하는 조건이 있기 때문에, 입력된 초기 상태부터 A부터 Z까지 확인하며 같은 글자의 두 블록이 제거 가능한지 확인하는 과정을 반복하면 됩니다. 게임판의 크기가 크지 않기 때문에 단순한 방법으로도 경로 확인이 가능한데, 그중 한 가지는 각 블록에서 상/하/좌/우로 다른 블록이나 장애물에 막히지 않고 갈 수 있는 위치의 집합을 구한 뒤 두 집합의 공통 원소가 있는지를 확인하는 방법이 있습니다.2차원 배열이 입력으로 주어질 때, 왼쪽 위에서 오른쪽 아래로 이동하면서 길이가 최소인 경로, 길이가 같다면 대화 시간의 합이 가장 작은 경로를 구하는 문제입니다. 단 총 대화 시간의 합은 입력된 s를 넘지 않아야 합니다. 먼저 다음과 같은 3차원 배열을 정의합니다.이를 채우는 방법은 Dijkstra 알고리즘 등을 이용하면 됩니다. 모든 값을 계산한 뒤 S[m-1][n-1][k] <= s인 최소의 k가 최소 경로의 길이, 배열에 저장된 값이 대화 시간의 합이 됩니다.헬스장의 예약 내역이 입력으로 주어질 때, 예약한 회원들 간의 락커의 거리를 최대로 하는 배치를 구하는 문제입니다. 단 영업시간을 통틀어 할당된 락커 간 최소거리를 최대화하는 것이 목적이기 때문에 손님이 입장한 순간 거리를 최대로 하는 위치에 배정해주는 것보다 앞으로 입장할 손님을 고려하여 배치하는 것이 최적입니다. 결국 회원의 수가 최대인 시간대의 최적 배치를 구하면 기타 시간대에는 그 배치의 부분집합을 사용하면 되므로, 락커의 크기와 락커를 사용하는 최대 인원에 의해 답이 결정됩니다.문제를 살짝 바꾸어, 락커의 크기와 최소 거리가 입력으로 주어졌을 때 최대 락커의 수를 구하는 문제를 생각해봅시다. 이 문제를 풀 수 있으면 원래의 문제인 락커를 사용하는 최대 인원에 대해 최소 거리를 구하는 문제도 풀 수 있습니다. 선택된 모든 락커의 거리가 d 이상이 되도록 최대의 개수로 락커를 선택하기 위해, 각각의 락커를 그래프의 정점으로 두고, 거리가 d 이상인 락커를 간선으로 잇는 그래프를 만듭니다. 이렇게 만들어진 그래프에서 최대 완전 부분 그래프를 구하면 그 크기가 답이 됩니다. 최대 완전 부분 그래프를 구하는 효율적인 방법은 알려져 있지 않지만, 이 문제의 경우 그래프의 크기가 크지 않고, 자명한 경우에 대해서는 그래프를 찾지 않고도 답을 구할 수 있기 때문에 문제의 크기를 더 줄일 수 있습니다. 가령 거리가 1인 경우는 모든 락커를 사용하는 경우이고, 거리가 2인 경우는 락커를 한 칸씩 건너 사용하는 경우(체크무늬 형태)입니다. 이와 같이 오래 걸리는 경우를 제외하고, 탐색 과정에서 적절한 가지치기(pruning)를 하면 됩니다. 단 이 경우에도 제한 시간 안에 모든 경우에 대한 답을 구하기 힘들 수 있는데, 답을 구해야 하는 경우의 수가 많지 않기 때문에 (락커의 크기가 최대 10이고 락커를 사용하는 최대 인원은 100명으로, 가능한 모든 조합에 대해 답을 구한다고 해도 그 수가 많지 않습니다.) 모든 가능한 경우에 대해 답을 구해놓고 이를 리턴하는 식으로 코드를 작성하는 것도 가능합니다.주어진 점에 대해, 서로 꼭짓점이 연결되는 직사각형의 형태로 구성된 ‘기하학적으로 아름다운 귀걸이’를 만들 수 있는 경우의 수를, 점이 추가 혹은 삭제되는 각각의 경우에 대해 계산하는 문제입니다. 점의 개수 및 점을 추가하거나 삭제하는 변화의 수가 최대 100,000이기 때문에 O(n log n)의 시간복잡도로 해결해야 합니다.각각의 점 (x_i, y_i)에 대해 z_i = y_i - x_i를 정의합니다. 즉, z_i는 (x_i, y_i)를 지나는 기울기가 1인 직선의 y절편이 됩니다. 이를 기준으로 내림차순 정렬을 한 뒤 다음과 같은 배열을 정의하여 채웁니다.이 배열의 값은 왼쪽 위에서 오른쪽 아래의 순서대로 계산하고, 값을 계산할 때에 해당 위치의 점이 가지는 특성값 k를 z에 더하여 참조해야 할 절편의 값을 알 수 있으며, 해당 직선 내에서 x좌표가 [x-k, x]인 구간을 참조하여 Dp_1값을 모두 더하면 됩니다. 즉, 다음과 같이 Dp_1의 누적합 배열을 만들면 이분탐색을 통해 Dp_1[i][j]를 O(log n)에 계산할 수 있습니다.위와 비슷하게 오른쪽 아래에서부터 올라오는 경우에 대해서도 배열을 정의합니다.이 배열의 값은 오른쪽 아래에서 왼쪽 위의 순서대로 계산합니다. Dp_1을 계산할 때와 다르게 해당 점과 직사각형으로 연결될 오른쪽 아래 꼭짓점의 특성값이 여러 가지가 될 수 있음을 주의해야 합니다. 특정한 점에 대해 값을 계산하면서 뒤에 계산할 점에 대한 전처리를 진행하는 방식으로 계산을 진행하면 됩니다. 해당 점을 오른쪽 아래 점으로 두면서 직사각형으로 연결될 수 있는 점은 특성값의 성질에 의해 z값이 같은 직선 상의 연속된 점이므로, 세그먼트 트리 등을 이용하여 각각의 점을 왼쪽 위 점으로 하는 경우의 수를 차례로 더해가면 됩니다. 그래서 이 배열을 계산하는 과정도 마찬가지로 O(n log n)에 완료될 수 있으며, 이후의 연산을 위해 위의 경우와 같이 Dp_2sum 배열을 계산합니다.그러면 초기 상태에 대해 가능한 귀걸이의 경우의 수는 점 E에 대해 Dp_1의 값을 계산하면 됩니다. 점이 추가되는 경우에는 추가되는 점에 대해 유효한 Dp_1의 값과 Dp_2의 값을 이분탐색으로 찾은 뒤, 필요한 값을 곱하여 계산할 수 있고, 점이 삭제되는 경우에는 삭제되는 점에 대한 Dp_1과 Dp_2 값을 가져와 그 점을 지나는 경우의 수를 구하고, 전체 경우의 수에서 이 값을 빼면 됩니다.그래프에서 연결하는 정점이 같은 두 간선을 인접한 간선으로 부르고, 서로 인접한 간선이 없는 간선의 집합을 매칭이라고 부릅니다. 주어진 그래프에 대해 초기 매칭과 최종 매칭이 입력으로 주어지고, 이를 매칭의 조건을 항상 만족하면서 간선을 추가하거나 삭제하여 변환하는 방법을 구하는 문제입니다. 초기 매칭 M_0와 최종 매칭 M_t에 대해, 다음과 같이 집합 H를 정의합니다. H = (M_0 - M_t) U (M_t - M_0) 즉, 두 매칭에 공통으로 속한 간선을 제외한 간선의 집합이 됩니다. 이 집합에 속한 간선을 인접한 간선끼리 부분집합으로 묶으면 모두 다음의 경우 중 하나에 속하게 되며, 이는 M_0과 M_t가 모두 매칭의 조건을 만족한다는 점을 이용하여 보일 수 있습니다.첫 번째와 두 번째에 속하는 경우는 단순히 간선을 삭제하거나 추가하면 됩니다. 세 번째의 경우는 M_0 - M_t에 속한 간선을 삭제하면 다섯 번째 경우가 되며, 네 번째의 경우는 한쪽 끝을 삭제하면 다섯 번째 경우가 됩니다. 다섯 번째 경우에 해당하는 간선에 대해서는 M_t - M_0에 속하는 끝 간선을 추가한 뒤, 번갈아가며 삭제 또는 추가 연산을 적용합니다. 이상의 과정에서 간선의 수는 k-2 이하로 내려가지 않아야 한다는 조건이 있는데, 각 부분집합에 대해 적용되는 연산은 독립적으로 적용이 가능하므로 부분집합에서 |M_t - M_0| - |M_0 - M_t|가 큰 순서대로 연산을 적용함으로써 간선의 수를 항상 k-2 이상으로 유지하는 것이 가능합니다.삼각형의 세 변을 이루는 고무줄을 규칙에 따라 움직여 만들 수 있는 새로운 모양의 수를 구하는 문제입니다. 고무줄의 모양은 오목해야 한다는 조건이 있는데, 이 조건을 만족하도록 B와 C를 잇는 고무줄을 이동시켜 위 그림과 같은 모양을 만든 상황을 생각해봅시다. B와 C를 잇는 고무줄이 거치는 점을 순서대로 P_1, …, P_k라고 할 때, B에서 P_1로 그은 연장선과 C에서 P_k로 그은 연장선, 그리고 선분 BC로 만들어지는 삼각형이 있을 때, P_2, …, P_k-1은 모두 삼각형 안에 들어가게 되며, 삼각형 영역 중 고무줄 위쪽에 속하는 부분에는 점이 없어야 합니다. 그리고 모든 고무줄은 오목한 모양으로만 이동이 가능하므로 A와 B를 잇는 고무줄, 혹은 A와 C를 잇는 고무줄은 삼각형 내부의 점을 지날 수 없습니다. 삼각형 안에 있는 점을 지날 수 있는 고무줄은 B와 C를 잇는 고무줄이 유일하고 이들 점이 오목한 형태로 이어져야 하므로, P_1과 P_k가 정해지면 B와 C를 잇는 고무줄의 모양은 유일하게 정해지게 됩니다. 즉, 각 고무줄에 대해 양 끝 점을 정한 뒤 만들어지는 모양이 규칙을 만족하는지 보면 됩니다. 단 이 경우 살펴봐야 하는 모양의 수가 O(n^6)이 되어 제한시간 안에 모두 살펴볼 수 없습니다.더 생각을 발전시켜 보면, 각 고무줄의 왼쪽 끝점만 정해지면 그에 따라 오른쪽 끝점이 유일하게 결정됨을 알 수 있습니다. 그렇게 각 고무줄에 대응되는 왼쪽 끝점을 정하고, 만들어지는 모양이 문제에서 제시된 조건을 만족하는지를 보면 됩니다. 삼각형의 꼭짓점에서 각 고무줄의 왼쪽 끝점을 지나는 연장선을 그었을 때 만들어지는 삼각형의 내부에 점이 없으면 조건이 성립하는 경우임을 알 수 있습니다. 그래서 총 O(n^3)의 경우의 수를 살펴보면 됩니다.그럼 이제, 코드 페스티벌 본선의 결과를 공개합니다! 예선과 같은 방식으로 채점이 진행되었으며, 1등은 출제된 8문제 중 6문제를 풀어주셨습니다.▶ 순위표 보러 가기사전에 공지된 대로 우수한 성적을 거둔 상위 21명의 참가자에게 상장 및 상금이 수여되었습니다. 아쉽게 수상권에 들지 못한 분들을 위해 다양한 특별상도 준비했는데요, 수상하신 모든 분들 모두 축하드립니다!카카오의 첫 개발자 행사를 즐겨주신 분들께 감사드리며, 앞으로 있을 개발자 행사에도 많은 관심 부탁드립니다 :)",http://tech.kakao.com/2017/09/14/code-festival-round-2/,0,kakao,,NULL,2017-09-14
Parallel Programming and Applicative in Scala,"Monolithic 아키텍쳐로 개발시에는 일반적으로 하나의 저장소만 고려해야 하는 경우가 많았습니다.Monolithic 아키텍쳐를 사용하면 편리한점이 많습니다. 코드가 한곳에 모여 있고 데이터가 한곳에 집중이 되어 있다는 것입니다. 일반적인 정규화 된 테이블에서 상품과 관련된 정보를 가져온다고 가정해보겠습니다. 데이터는 여러개의 테이블로 쪼개져 있기 때문에 필요한 데이터를 조합이 필요하다면 아래와 같이 SQL을 이용해서 여러개의 테이블을 join해서 데이터를 조합하여  가져올 수 있습니다.단순함을 가지고 있는 Monolithic은 장점도 많이 있지만 단점이 많은 개발 방법론입니다. 하나의 코드 베이스안에서 모든것이 관리 되기 때문에 경계선이 애매하고 많은 컴포넌트가 서로 의존을 가지고 강결합을 이루고 있게 됩니다. 코드가 늘어남에 따라 시스템은 무거워지고 조금만 고쳐도 여러곳에서 side effect가 생기며 외부 변화에 빠르게 대처하지 못하게 됩니다.이런 단점을 극복하기 위해서 마이크로 서비스란 개념이 2011년도에 나오고 그 이후 패러다임이 바뀌게 되었습니다. 특히 Netflix와 같은 실리콘 밸리의 유명한 IT기업에 이를 전폭적으로 사용하고 이에 대한 성공 사례를 보여주며 많은 기업과 소프트웨어 개발자들이 이 아키텍쳐를 채택 해야하는 근거를 제시해주었습니다. 이제 마이크로 서비스는 많은 관심을 가지고 엔터프라이즈 시장에서 인기를 가지고 있는 아키텍쳐 입니다. 아래 통계자료를 보면 75% 이상이 마이크로 서비스를 일부 혹은 전면적으로 사용하며 개발하고 있습니다.마이크로 서비스로 개발하는 것은 무조건 좋고 장점만 있는 것은 아닙니다. 마이크로 서비스로 개발 방법론 을 한다는 것은 과거의 Monolithic 아키텍쳐로 하나의 저장소만 관리하는것과 완전 다른 개발 방식을 가져오게 되었습니다. 각각의 마이크로 서비스는 독립적으로 동작하기 때문에 자신만의 고유한 데이터를 가지고 있습니다. 즉 많은 데이터는 각각의 마이크로 서비스로 분산 됩니다.Monolithic으로 개발시에는 메인의 DB에 ER Diagram만 잘알면 되었지만 다른 마이크로 서비스의 데이터는 어디에 어떤 테이블로 저장되어었는지 알 필요가 없습니다. 도메인이 분리 되었기 때문에 다른 마이크로 서비스의 API의 스펙 관리 하고 이를 쉽게 호출 할수 있어야 해야 합니다. 이를 위해 Rest API는 documentation을 잘 보여주는 Swagger, RPC의 Thrift 그리고 GRPC와 같은 도구로 API Spec을 주로 표현합니다. 물론 API Spec을 관리하는 다른 방법도 많이 있습니다.분리된 데이터를 합치고 구성하기 위해서 API Gateway에서 여러곳에 마이크로 서비스의 정의된 API를 호출하여 분산되어 있는 다양한 정보를 가져와서 조합을 해야합니다.예를 들어 마이크로 서비스에서 정보를 얻기 위해서 10개의 API에서 정보를 가져와야 할 경우가 있다고 해보겠습니다. 이를 동기화 방식으로 처리를 한다면 각각의 API가 100 ms의 응답을 준다면 1초의 딜레이가 생기게 됩니다. 마이크로 서비스가 좋다고 했는데 SQL 한번 호출하고 200ms이면 되던 API가 5배나 느려졌습니다.혹자는 과거(Monolithic)가 더 좋다며 이런걸 왜 쓰냐고 하는 경우도 있습니다. 하지만 마이크로 서비스의 느슨한 결합의 장점은 쉽게 뿌리 칠수가 없습니다. 코드에 한번 들어간 SQL 조인 쿼리는 시스템과 강결합 되어서 쉽게 고칠수 없고 리팩토링및 시스템을 유지보수 하기 여간 어려운것이 아닙니다.문제를 해결하기 위해 블로킹 연산 말고 Future의 비동기 연산을 사용하면 상황이 달라지지 않을까요?이전 글(Asynchronous Programming and Monad Transformers in Scala)은 Monad를 이용한 비동기 연동방식 Future Monad의 flatMap을 이용하여서 비동기 프로그래밍을 실행할 수 있는 방법을 알려드렸습니다.이것을 간단하게 코드로 표현하면 아래와 같습니다.위의 for comprehension 코드는 flatMap과 map으로 변경이 됩니다. 아래와 같은 룰을 통해 변환 하게 됩니다.중간 <- 는 flatMap으로 마지막 <- 는 map 함수를 이용해 아래 코드로 변하게 됩니다.Future의 flatMap은 앞의 행위가 완료 되었을때, 특정 API를 호출 했다면 그 API가 완료 되어야만 다음 API가 callback으로 수행하기 됩니다.그렇기 때문에 이 코드는 아래 순서대로 데이터를 가져오게 됩니다.flatMap 의 아용한 비동기 프로그램은 되지만 병렬 프로그램은 아닙니다.async != parallel 입니다. 비동기가 된다고 병렬 프로그래밍은 아닙니다.서로 의존성이 없은 데이터라면 순차적으로 가져올 필요가 없습니다.동시에, 병렬로 가져오면 됩니다.병렬 프로그래밍은 간단한 수식을 통해 성능을 예측할수 있습니다. 특정 테스크를 실행하기 위해서 순차적으로 실행되야 하는 부분과 병렬로 실행 될수 있는 부분은 구분함으로서 가능합니다.전체 테스크 중에 병렬로 처리 가능한 부분의 비율이 성능의 향상을 결정짓습니다. 병렬 프로그래밍, map-reduce와 같은 내용에 자주 나오는 Amdahl의 법칙에 맞추어 보면여기서 S(latency) 는 전체 테스크 실행의 이론적인 속도 향상이다.s 는 병렬로 처리가능했을때 성능이 일어날수 있는 부분이다.p 는 전체 테스크중에 성능 개선(병렬처리)이 가능한 부분의 원래 시간이다.각각의 데이터를 가져오는걸을 1초라 하면 각각의 연산의 단순합으 1초 * 7 = 7초가 걸리게 됩니다. 이중 병렬로 가져올수 있는것이 6초입니다.먼저 동시에 2개씩 병렬로 처리하는 경우에는 그 성능이1.75배가 증가합니다. 7초가 걸리던 응답 속도는 약 4초로 줄어들게 됩니다.6개를 동시에 병렬로 처리가 가능하다면이번엔 기존 속도에 약 3.5배 정도 증가하게 됩니다. 예상 되는 응답시간은 7초에서 2초로 줄어들게 됩니다. 이는 기존에 monolithic 아키텍처와 같은 수준을 유지 할수가 있습니다.물론 방금 말한 수치는 단순한 가정입니다. 복잡한 엔터프라이즈 환경에서 성능의 변수는 다양하고 많기 때문에 꼭 이렇다 말할수는 없습니다. 하지만 동시에 실행할 수 있다면 순차 프로그래밍보다 병렬 프로그래밍을 통해서 응답속도를 획기적으로 줄일 수 있습니다.scala.concurrent.Future의 특성을 고려해서 구현해보겠습니다. scala에서 기본으로 제공해주는 Future는 eager evaluation 방식으로 동작합니다. lazy(사용하는 시점) evaluation이 아니라 선언되는 시점에 바로 동작하기 합니다. 간단하게 테스트 해보면 변수 future를 따로 실행을 하지 않아도 1초 후에 ‘hello world’가 화면에 출력됩니다.Eager evaluation 특성을 이용해서 먼저 future를 실행하고 나중에 for comprehension으로 조합하는 코드를 만들수 있습니다.이제 위의 코드는 병렬도 동작합니다. 하지만 코드가 2배로 늘어났다 한번만 쓰고 필요없는 local variable이 왕창 늘어 났습니다. 그리고 중대한 문제점이 하나 더 들어있습니다. 자바에도 Future에 대한 다양한 구현체, thrird party 라이브러리가 존재를 하듯이 이와 마찬가지로 스칼라에도 monix - Task, scalaz - Task, twitter future등 다양한 비동기 구현체가 존재합니다.이 구현체들은 scala.concurrent.Future 처럼 eager evaluation을 한다는 보장은 없습니다. Twitter가 만든 Future 구현체의 경우 eager evaluation을 하지만 monix와 scalaz의 Task는 lazy evaluation을 합니다.같은 로직을 monix.task를 활용해서 구현할수 있습니다.아래 수치는 같은 로직을 scala future와 monix task를 활용하여 수치를 비교한것입니다. 테스트에 대한 전체 소스코드는 github에 올려 놓았습니다.우리의 코드는 더이상 병렬로 동작하지 않습니다. monix task는 7초 걸리고 scala future는 2.7초 걸렸습니다. Eager evaluation의 효과를 이용해보려 했지만 여러개의 scala future를 합친결과는 monix의 task를 합친 결과는 다릅니다.비동기 연산의 구현체가 바뀌었다고 병렬로 진행되것이 순차로 진행되는것을 누구도 원하지 않을 것입니다. 이를 해결하고 명확하게 프로그램에게 나는 이걸 병렬도 돌리고 싶다고 말할 수 있는 방법이 있습니다.병렬 프로그래밍을 하기 위해서 Monad와 eager evaluation 활용해서 만드는것 보다 Monad의 친구 또다른 typeclass인 Applicative를 활용하는 방법이 있습니다.Applicative 단어를 듣는 순간 이건 무엇인가 당황할수 있습니다. Monad도 잘 모르는데 뭔 Applicative인가?하지만 포기하지 마세요! 어렵지 않습니다. 다만 용어가 아직 익숙하지 않을 뿐입니다!Applicative는 겨우, 단지, 고작 함수 2개로 정의 됩니다.먼저 Applicative의 인터페이스 정의를 살며보면생각보다 복잡하진 않습니다. 단순히 pure와 ap함수로 구성되어 있습니다.Applicative의 ap함수는 형태는 Functor의 map 모양과 유사합니다.ap함수의 map에서 받는 함수의 모양 A => B의 형태가 F로 감싼 F[A => B]로 감싸졌습니다. 이게 끝입니다.그리고 주된 특징은 아래 그림에서 처럼 두개의 container를 열어서 함수를 적용하고 닫는것입니다. 두개를 연다는것은 두개를 동시에 열수(parallel)도 있다는 뜻입니다.오픈소스 함수형 프로그래밍 라이브러리인 cats의 Applicative trait와 Apply trait를 통해서 ap함수와 pure함수를 확인할수 있습니다.함수형 언어에서 에서 F[A]를 F[B]로 바꾸는 여러가지 방법이 있습니다. 잠깐 정리하고 넘어가보겠습니다.그외에도 F[A]를 F[B]를 변화 시키는 여러 typeclass가 존재합니다. 또한 F[A] ~> G[A]로 변환 시키는 것도 존재합니다. 이 글에서는 Applicative에만 집중하겠습니다.언제나 그렇듯 의문이 들고 많은 질문을 받는습니다. Applicative란 함수는 도대체 언제 사용해야하는가? Applicative란 개념이 왜 필요한가?Applicative 안에 있는 ap 함수는 future를 활용한 병렬 프로그래밍을 할때 효과적으로 사용될수 있습니다. ap함수는 바로 사용하는 경우는 많이 없지만 활용한 보조함수 product, mapN 같은 함수를 많이 사용하게 됩니다.Future의 기준으로 ap 함수를 생각해보겠습니다.두개의 future fa, fb가 있고 두개의 future안에 들어 있는 값을 동시에 완료되는 연산하고 싶다고 하고 싶다면이제 ap함수를 활용해서 fab를 도출해보겠습니다. 즉 fa와 fb의 값을 합쳐 보겠습니다.ap함수는 두번째 인자가 함수를 감싼 F[A => B]입니다.입력이 F[A => B]인데 우리가 가지고 있는 값은 F[B]입니다. 입력값의 타입을 맞추어 주기 위해 우리는 fb를 변환해야 합니다. 아래와 같이 바꿀수 있습니다.우리가 최종적으로 원하는건 A와 B값의 쌍이기 때문에 Future[B]의 B값에 A의 값이 들어오면 A와 B의 값의 쌍으로 변환 시키는 faab: Future[A => (A, B)]의 형태로 바꾸어 보겠습니다.이제 하나가 함수가 되었기 때문에 ap함수에 적용시킬수 있습니다. 타입도 정확합니다. (F[A])(F[A => (A, B)]) => F[(A, B)] 그다음에 ap(fa)(faab)를 적용시키면 F[(A, B)]의 형태가 됩니다.어떻게 사용할지 몰랐던 ap 함수는 두개의 Future를 합치는데 탁월한 역할을 합니다.간단하게 두개의 future를 합치는 함수를 만들었습니다. 이를 일반화하고 이 함수 이름을 product라 하겠습니다.이 product를 활용하면 간단하게 두개의 future를 병렬 연산하고 그 완료된 값을 합쳐 보겠습니다.아직 우리는 ap 구현하지 않았습니다. ap 인터페이스를 정의만 하고 이를 이용해서 product함수를 만드는것만 구현했습니다.ap를 두개의 future를 동시에 완료되게 구현하면 동시에 fa, fb가 실행되고 Future[(A, B)]를 만들수 있습니다 . 즉 병렬로 A와 B를 가져오는 연산을 ap함수에 구현하면 product함수도 병렬로 실행되게 됩니다.실제 많이 사용되는 오픈소스 라이브러리도 이와 같은 방식을 이용해서 구현하였습니다.스칼라의 함수형 프로그래밍을 도와주는 scalaz의 future instance, free monad를 쉽게 사용할수 있게 도와주는 freestyle에 구현되어 있는 future instance는 future의 zip 연산을 활용해서 동시성을 구현하였습니다.하지만 cats의 future instance는 별도의 구현없이 flatMap을 이용하여 구현하였습니다.flatMap을 이용해서 ap를 구현할수는 있습니다. 하지만 이 ap함수는 flatMap의 순차 연산 특성을 가지게 되기 때문에 병렬연산의 특성을 가지 있지 않다는것에 주의해야합니다.앞에서 말했듯이 cats의 future instance가 실제 병렬로 잘 동작하는 이유는 scala의 future가 eager evaluation이기 때문입니다. product 함수를 호출하는 시점에 이미 두개의 future가 이미 실행되었기 때문입니다.cats에서 기본 제공해주는 future instance를 사용하지 않고 별도로 future.zip을 이용해서 구현해서 사용하는 사례 1, 2가 있습니다.그리고 scalaz와 monix에서는 nondeterminism이라는 기능을 제공해서 Applicative를 병렬로 연산하거나 순차연산 할것인지를 명시적으로 선택할수 있습니다.scalaz의 task는 아래 예를 참고하면 됩니다. parallel로 동작하기 위해서는 Nondeterminism를 활용하면 됩니다.monix의 task 경우에도 아래 코드처럼 nondeterminism을 이용하면 applicative에서 병렬 프로그래밍이 가능합니다.위의 코드의 전체 코드는 github에 올려놓았습니다.이제 이를 활용하여 원래 처음 만들었던 프로그램에 적용을 하면 Applicative의 mapN 연산자를 활용하여서 병렬 연산을 하고 빠른 응답을 얻을수 있습니다.함수형 언어에는 다양한 특징이 있는데 이 특징들은 마이크로 서비스를 하기에 좋은 언어라고 생각합니다. 특히 비동기 프로그래밍(Monad), 병렬프로그래밍(Applicative)에는 장점이 부각이 됩니다.꼭 함수형 언어가 아니더라도 마이크로 서비스를 적용하고 있거나 적용하려고 한다면 코드의 많은 부분을 병렬 프로그래밍으로 바꿀수 있는지 보고 적극적으로 병렬로 처리하면 더욱더 빠른 응답을 주고 마이크로 서비스의 장점을 최대화 할 수 있을 것이라 생각합니다. :-)",http://tech.kakao.com/2017/09/02/parallel-programming-and-applicative-in-scala/,0,kakao,"python,react,java,mysql,docker,backend,frontend,scala,database,php",NULL,2017-09-02
카카오 블라인드 신입 개발자 공채를 실시합니다!,"2014년 합병 이후, 카카오의 첫 신입 개발자 공채가 시작됩니다.학력, 전공무관! 웹, 모바일 서비스에 열정이 있다면 누구나 지원 가능한 카카오의 첫 ‘블라인드 신입 개발자 공채’!▶모집 분야 : 웹/모바일/서버개발 ▶접수 기간 : 8월 28일 (월) 15:00 ~ 9월 14일 (목) 15:00 ▶선발 인원 : OO명 ▶지원 접수 : www.welcomekakao.com ▶문의 사항 : apply@kakaocorp.com스펙보다는 성장 가능성과 잠재력, 창의성 등이 뛰어난 신입 개발자 분들을 선발하기 위해 학력, 경력 등 스펙이 아닌 코딩 능력으로만 검증하는 ‘블라인드’ 전형으로 실시될 예정인데요,블라인드 전형의 취지에 맞게 응시자는 학력, 나이, 성별, 경력 등을 기입하지 않고 성명 e메일, 휴대전화 등만 입력한 후 본인 계정을 생성하면 코딩테스트에 응시할 수 있습니다!모든 지원자를 대상으로 실시되는 코딩테스트는 9/16부터 진행되며, 온라인 2차례와 오프라인 1차례, 총 3차례에 걸쳐 실시됩니다.코딩테스트를 통과한 합격자를 대상으로 1,2차 인터뷰를 진행한 후 오는 12월 최종합격자를 선발할 예정이며 합격자들은 오리엔테이션을 거쳐 내년 1월 정식 입사하게 됩니다카카오 블라인드 공개 채용과 관련한 자세한 내용은 www.welcomekakao.com 에서 확인, 지원 가능합니다. 모바일 서비스에 대한 열정과 창의성을 갖춘 많은 분들의 지원을 기다립니다 :)▶카카오 블라인드 신입 개발자 공채 지원하러가기",http://tech.kakao.com/2017/08/30/employment/,0,kakao,,NULL,2017-08-30
카카오 코드 페스티벌 예선전 이야기,"지난 8월 5일 토요일, 카카오 코드 페스티벌의 온라인 예선이 개최되었습니다. 합병 후 카카오라는 이름으로 처음 열리는 개발자 행사인 만큼, 여러 카카오 크루들이 긴장되지만 신나는 마음으로 대회를 준비했습니다.이번 예선전에는 총 6개의 문제가 출제되었습니다. 다양한 난이도의 문제를 출제하여 최대한 많은 참가자들이 즐길 수 있도록 하는 데 초점을 맞췄습니다. 출제진이 생각했던 것보다 빠르게 문제를 풀어나가는 참가자를 보면서 뛰어난 실력에 감탄했고, 여러 번 제출했지만 정답 판정을 받지 못하는 분들을 보며 안타까움을 느꼈습니다. 그리고 대회가 끝난 뒤 후기를 통해 어려운 문제였지만 즐거운 경험이었다는 이야기, 특히 문제 안에서 만날 수 있었던 아이유와 카카오프렌즈에 대한 관심을 보면서 뿌듯함을 느낄 수 있었습니다.이 글을 통해 온라인 예선에 출제되었던 문제와 해설, 그리고 결과를 공유드리고자 합니다. 카카오 코드 페스티벌 예선에 참가해주신 모든 분들께 감사드리며, 향후 카카오와 카카오 개발자 행사에도 꾸준한 관심 부탁드립니다.2차원 배열이 입력으로 주어졌을 때, 상하좌우로 연결된 같은 색깔의 영역이 몇 개인지, 그리고 영역의 최대 크기가 몇인지 구하는 문제입니다. 특정 지점에서부터 시작하여 상하좌우의 칸과 현재 칸의 색깔을 비교하여, 색깔이 같은 인접한 칸이 있을 경우 그 지점에서 같은 과정을 반복하는 식으로 영역의 크기를 구할 수 있습니다. (Flood fill을 검색해보세요.)출제된 문제 중 가장 많은 분들이 푼 문제인데, 경계지점(상하좌우 중 일부가 없는 경우)에 대한 처리를 하지 않은 코드를 제출하여 정답을 받지 못한 분들이 많았습니다.왼쪽 위부터 오른쪽 아래까지 도달할 수 있는 경우의 수를 세는 문제로, 동적 계획법(Dynamic programming)으로 풀 수 있습니다. 먼저 다음과 같이 두 개의 배열을 정의합니다.그리고 각 칸의 조건에 따라 배열의 값을 채워갑니다. H 배열을 계산하는 것을 예로 들면, 자유롭게 지나갈 수 있는 칸의 경우 H[i][j] = H[i][j-1] + V[i-1][j], 회전이 불가능한 칸의 경우 H[i][j] = H[i][j-1]입니다. 자동차가 지나갈 수 없는 칸의 경우에는 H[i][j] = 0이 됩니다. V 배열도 비슷하게 채울 수 있습니다.왼쪽 위부터 오른쪽 아래로 H와 V 배열을 채워나가면 문제에서 원하는 경우의 수를 빠짐없이 효율적으로 셀 수 있게 됩니다.문제의 조건에 의해, 삽입되는 기호는 총 26가지(알파벳 소문자의 수)이며 각각은 한 번씩만 적용될 수 있습니다. 즉, 각 알파벳의 개수와 위치를 세면 어떤 단어에 어떤 규칙으로 적용되었는지 알 수 있습니다.기호의 개수가 1개 혹은 3개 이상인 경우, 이 기호는 규칙 1에 의해 추가된 기호임을 알 수 있습니다. 기호의 개수가 2개이면서 사이에 들어간 글자(대문자)의 수가 2개 이상인 경우, 이 기호는 규칙 2에 의해 추가된 기호임을 알 수 있습니다. 기호의 개수가 2개이면서 사이에 들어간 글자의 수가 1개일 때는 규칙 1 혹은 규칙 2가 모두 적용될 수 있는데, 이 경우에도 다음의 유일한 예외를 제외하고는 규칙 2가 적용된 기호로 간주할 수 있습니다. aAbBbCa 즉, 다른 기호의 구간 안에 있는 경우입니다.즉, 각 기호 별로 개수를 세어, 기호의 개수가 2개가 아닌 경우 규칙 1, 2개인 경우 규칙 2(위에서 설명한 경우 제외)로 적용된 기호로 간주하고 그에 맞게 규칙이 올바르게 적용되었는지를 판단하면 됩니다.이상의 내용이 출제자가 생각한 풀이인데요, 문제의 복잡도에 걸맞게 다양한 방법으로 푸신 분들이 많았습니다. 2차원 배열을 정의하여 각 부분 문자열 별로 올바르게 해석될 수 있는지를 계산하는 다이나믹 프로그래밍 코드가 인상적이었습니다.규칙에 따라 생성된 문자열은 다음의 성질을 가지고 있습니다.그리고 문제를 풀 때 다음의 성질을 사용합니다.그러면 특정 문자열의 값은 같은 길이의 문자열 중 값이 최소인 경우를 계산하고, 그 문자열과 구하려는 문자열의 차이를 더하면 됩니다. *++*+*+++의 경우를 예로 들면, ***++++++의 값은 33이고, 이 문자열에서 세 번째 *를 세 칸 뒤로, 두 번째 *를 두 칸 뒤로 차례로 옮기면 구하려는 문자열이 되므로 그 값은 33 + 3 * 2 + 2 * (2 * 3) = 51입니다.특정한 값이 주어졌을 때 그 값을 나타내는 문자열의 수를 구하는 원래 문제로 돌아와서, 입력된 값에 대해 그 값을 나타내는 문자열은 모두 길이가 같음을 보일 수 있습니다. 그러면 입력된 값과 해당 길이 문자열로 얻을 수 있는 최소값의 차를 구하고, *를 옮겨서 그 값만큼의 차이를 얻을 수 있는 경우의 수를 구하면 됩니다. 위의 예제에서는 [2, 3]이 되겠네요 (*를 뒤로 옮기는 횟수) 입력되는 값의 범위가 크지 않기 때문에 가능한 경우를 적절한 가지치기와 함께 전체 탐색해도 시간 안에 답을 구할 수 있습니다.금방 떠올릴 수 있는 해법으로 모든 가능한 쐐기 조합에 대해 문제의 조건(영역 내에 다른 쐐기가 없음)을 만족하는지를 일일이 계산하는 O(n^3) 해법이 있습니다만, n이 최대 5,000이므로 시간 안에 답을 구할 수 없습니다. (그럼에도 일부 참가자 분들은 최적화를 잘 해서 O(n^3) 코드로 정답을 받으셨습니다..)먼저 다음과 같은 2차원 배열을 만듭니다.위와 같이 부분합 배열을 구하면 특정 영역 내에 있는 쐐기의 개수를 O(1)에 구할 수 있습니다. 모든 쐐기 조합에 대해 영역 내의 쐐기의 개수가 0인지를 확인하면 됩니다. 부분합 배열을 계산하는 과정, 모든 쐐기 조합에 대해 계산하는 과정 모두 O(n^2)에 실행됩니다.※ 대회 중 채점 데이터가 문제의 설명과 다른 경우가 있었습니다. 여기에서 공개되는 최종 순위는 해당 오류를 수정하여 문제에서 설명된 조건에 맞는 데이터로만 채점이 진행된 결과입니다.두 트리의 최대 공통부분을 찾는 문제입니다. 루트가 지정되어 있기 때문에 차례로 내려가면서 두 트리의 자식을 비교하여 노드 간 대응되는 조합을 찾으면 됩니다.다음과 같은 함수를 정의합니다.a를 루트로 하는 서브트리, b를 루트로 하는 서브트리의 최대 공통부분의 크기를 구하기 위해서는 먼저 각 서브트리의 자식 간 모든 조합에 대해 공통부분의 크기를 구합니다. 즉, a1, a2, a3가 a 노드의 자식, b1, b2가 b 노드의 자식인 경우, f(a1, b1), …, f(a3, b2)의 6가지 경우의 값을 모두 구합니다. 그리고 여기에서 최대값을 얻을 수 있는 조합을 찾으면 됩니다.이 때 이 문제를 Minimum-cost flow 문제로 접근하여 정답을 구할 수 있습니다. Flow graph를 아래 그림과 같이 구성하고, 각각의 capacity를 모두 1로 하되 cost로 각 조합에 대한 결과를 할당합니다. 원래 Minimum-cost flow 문제는 최소 비용의 경우를 구하는 문제이지만 이 문제에서는 공통부분의 크기가 최대가 되도록 조합을 구해야 하므로, cost를 음수로 할당하여 해결할 수 있습니다.그러면 a 노드와 b 노드를 루트로 하는 서브트리의 최대 공통부분의 크기는 여기에서 구한 최소 비용에 다시 음수를 취하고 1을 더하면 됩니다.플로우 문제이기 때문에 외부 코드를 사용해서 푼 참가자가 많았고, 서브트리의 자식 간 대응 관계를 구할 때 Hungarian method를 이용하여 푼 분들도 있었습니다.그러면 엄청난 경쟁률을 뚫고 본선에 진출할 참가자를 발표합니다! 본선 참가자를 발표하기 전에, 채점 기준에 대해 다시 한번 설명드리겠습니다.예선에 출제된 6문제에 대해, 모든 문제를 맞힌 참가자가 12명, 5문제를 맞힌 참가자가 19명, 4문제를 맞힌 참가자가 40명입니다. 이상의 71명은 9월 9일에 열리는 카카오 코드 페스티벌의 본선에 진출하시게 됩니다! 추가로, 3문제를 맞힌 82명 중 공지된 순위 결정 기준에 따라 상위 29명의 참가자 역시 본선 진출자가 되셨습니다. 본선 참가 대상자 여러분께 참가 등록에 대한 이메일을 발송했으니 확인해주세요! :)예선에서 3문제 이상을 맞힌 상위 153명의 참가자에 대한 순위표를 공개합니다. 본선에 참가하시는 분들께는 축하의 말씀을, 아쉽게 참가 대상자가 되지 못하신 분들께는 위로의 말씀을 드립니다.순위표 보러 가기그럼 다시 한번 카카오 코드 페스티벌에 관심을 가지고 참가해주신 여러분들께 감사의 말씀을 드리며, 9월 9일에 있을 본선 및 이후에 카카오에서 개최할 개발자 행사에도 많은 관심 부탁드립니다!",http://tech.kakao.com/2017/08/11/code-festival-round-1/,0,kakao,python,NULL,2017-08-11
kakao의 오픈소스 Ep7 - CMUX: CLI에 날개를 달자!,"“카카오의 오픈소스를 소개합니다” 일곱 번째는 jon.kwon과 동료들이 개발한 CMUX입니다.CMUX는 Cloudera Manager 기반의 하둡 클러스터를 관리하는데 필요한 대화형 커맨드라인 인터페이스 도구들을 제공합니다.CMUX의 아이디어를 참고해 보세요. 여러분의 커맨드라인에 날개를 달 수 있을 것입니다.수천 대의 하둡 클러스터의 정보를 빠르게 검색하여 필요한 정보를 조회하기도 하고,특정 조건으로 검색한 노드에 SSH 로그인하여 병렬 작업을 하거나,특정 조건으로 검색한 관리자 웹페이지를 열어보기도 합니다.특정 조건으로 검색한 노드에만 명령어를 실행할 수도 있습니다.필요하면 외부 툴을 실행할 수도 있죠.조금만 여유가 있다면 Rolling restart role처럼 아주 복잡한 유지 보수 작업이나 배치 작업을 만들어서 사용할 수도 있습니다.지금부터 이런 것들을 가능하게 한 CMUX의 아이디어를 소개해 드리겠습니다.CMUX는 크게 4단계의 작업 흐름으로 구성된 명령어 집합입니다.입력 소스는 파일, 파이프라인, API 등 여러분이 상상할 수 있는 다양한 형태가 될 수 있습니다. CMUX에서는 Cloudera Manager의 REST API와 카카오의 인프라 자원을 조회하는 API를 주로 사용합니다.CMUX의 꽃에 해당되는 부분입니다. 빔(Vim)신이라고 불리는 카카오의 jg.choi이 만드신 FZF라는 커맨드라인 검색 도구를 사용하여, 원하는 조건으로 입력을 검색하고 결과를 걸러냅니다.걸러진 결과를 바탕으로 명령어 또는 명령어 집합을 생성합니다. CMUX는 Ruby로 작성되어 있기 때문에 당연히 Ruby 코드로 생성하겠죠.생성한 명령어 또는 명령어 집합을 실행합니다. 이때 명령어 집합을 병렬로 실행할 수 있는 인터페이스가 필요할 수 있는데, CMUX는 이를 위해 TMUX를 사용합니다.그럼, 이해를 돕기 위해 간단한 예제 코드를 통해 이 과정을 구현해 보겠습니다.CMUX의 아이디어를 구현하기 위해 필요한 두 가지 도구인 FZF, TMUX를 설치합니다. OS X 유저라면 homebrew로 간단하게 설치할 수 있습니다.CMUX는 Ruby로 작성되어 있지만, 이 예제에서는 쉘 스크립트로 간단하게 구현해 보겠습니다. 그리고 쉘에서 JSON 포맷으로 제공되는 Cloudera Manager REST API를 편하게 활용할 수 있도록 jq를 설치하겠습니다.자 이제 준비가 되었으니, 데이터 입력 부분부터 구현해 볼까요?Cloudera Manager REST API를 활용하여, Cloudera Manager에 생성되어 있는 클러스터 정보를 취득하겠습니다.대략 이런 모습의 결과를 확인할 수 있을 것입니다. Cloudera Manager가 없는 환경이라고 낙담하지 않으셔도 됩니다. 다음 단계부터는 아래의 내용을 clusters.txt로 저장했다고 가정하고 진행하겠습니다.호출된 결과를 jq 명령어를 이용해서 특정 필드만 가져오도록 하겠습니다.  우리는 “클러스터 이름(name)”, “클러스터 표시 명(displayName)”, “클러스터 관리자 페이지 URL(clusterUrl)”에만 관심이 있습니다.잘 걸러졌습니다.이제, 특정 클러스터를 검색하고 필터링할 수 있도록 하겠습니다.먼저, 위 결과를 클러스터별로 선택 가능하도록 jq의 join문으로 열을 결합합니다.참고CMUX에서는 결과물을 잘 정렬된 테이블 형태로 출력할 수 있도록, 이 부분을 별도의 모듈로 구현하였습니다.내가 원하는 결과를 검색하고 선택할 수 있도록 해 볼까요?fzf 명령어를 파이프에 연결하겠습니다.위 스크립트를 실행하면 아래와 같이 선택 가능한 상태로 FZF가 활성화됩니다.“Ryan”이라는 클러스터 이름을 검색하겠습니다. “Fuzzy Finder”라는 이름에 걸맞게 아래와 같이 느슨한 검색이 가능합니다. 다양한 검색 옵션이 있으니, fzf의 man 페이지를 읽어보시기 바랍니다.이번엔 “Neo”와 “Apeach” 클러스터를 선택하겠습니다. 기본적으로 tab 키로 선택할 수 있습니다. 전체 선택, 전체 선택 해제 등 다양한 옵션이 있으니, 마찬가지로 man 페이지를 읽어보시기 바랍니다.최종 선택한 결과는 아래와 같이 문자열로 반환됩니다.결과의 마지막 열인 “Cluster URL”을 기본 브라우저로 열 수 있도록 명령어를 만들겠습니다. OS X 환경이라는 가정하에 open 명령어를 사용합니다.위에서 생성한 명령어를 실행할 수 있도록 스크립트를 변경하겠습니다.이 코드를 실행하면 여러분이 선택한 클러스터의 URL이 기본 웹브라우저에서 열릴 것입니다. 이 예제에서는 이해를 돕기 위해 각 카카오 프렌즈의 상품페이지로 이동하도록 URL을 편집해 두었습니다. ^^;이번엔 조금 더 복잡한 구현을 도전해 볼까요?웹 브라우저로 각 URL을 열기 전에 TMUX로 선택한 URL의 수만큼 윈도우를 분할한 후 URL 정보를 화면에 출력하도록 스크립트를 보강하겠습니다.위와 같이 실행하면 여러분의 터미널 윈도우가 아래와 같이 분할된 후 URL에 출력되는 것을 확인할 수 있을 것입니다.참고CMUX에서는 이 부분이 tws 라는 별도의 명령어로 보다 정밀한 화면 제어가 가능하도록 구현되어 있습니다.CMUX를 개발한 후, 지난 1년여 동안 내부적으로 사용하면서 버그를 수정하고 기능을 보강하고 있지만 부끄러울 정도로 부족한 면이 많습니다.  하지만, CLI에서도 이런 것도 할 수 있다는 아이디어를 공유하고 싶었으며, 더 기발한 아이디어로 CLI가 풍부해지길 기대하면서 오픈 소스로 공개하게 되었습니다.마지막으로 CMUX를 위해 FZF에 여러가지 기능을 탑재해 주신 jg.choi님께 감사의 말씀을 드립니다.",http://tech.kakao.com/2017/07/12/opensource-7-cmux/,0,kakao,"python,react,docker,backend,frontend,javascript,angular,xml,ruby",NULL,2017-07-12
"오픈소스 간단 리뷰 - nomad : 가벼운 스케쥴러, 강력한 성능","서비스 스케줄러는 클러스터 내의 컴퓨팅 리소스를 관리하고 사용자 애플리케이션을 어느 호스트에서 서비스할지 결정하는 시스템 소프트웨어입니다. 컨테이너 스케줄러로는 kubernetes나 docker swarm등이 있으며, 하둡 스케줄러로는 YARN이 많이 사용됩니다.이 글에서는 이러한 스케줄러 중 하나인 nomad를 소개합니다. nomad는 vagrant, consul, packer등의 시스템 소프트웨어로 유명한 hashicorp사의 오픈소스 소프트웨어로, 자사의 consul과 vault를 각각 service discovery와 secure storage에 사용합니다. hashicorp사는 자사의 웹페이지에서 nomad를 통해 5000개 호스트에 100만 개 컨테이너를 5분 만에 배포한 사례를 소개하고 있습니다.(Nomad Million Container Challenge)Kubernetes는 CNCF(Cloud Native Computing Foundation)에서 개발을 주도하고 있으며, 현재 가장 인기있는 container orchestrator로서 안정성과 성능이 뛰어납니다. (최근 오픈소스화된 cite도 Kubernetes를 사용합니다.) 하지만 설계의 특성상 몇가지 단점들이 있습니다.Kubernetes의 특징 중 하나는 전체 시스템을 “직접” 관리하는 것입니다. 이러한 설계로 인해 Kubernetes에서 pluggable하게 설계하지 않은 기능은 재컴파일하지 않는 이상 구현하기 어려운데요, 예를 들면 cloud provider 추가, volume type 추가 등이 있습니다. 최근에는 FlexVolume(https://kubernetes.io/docs/user-guide/volumes/#flexvolume)등의 재컴파일 없이 확장 가능한 모델도 추가되고 있습니다.또한, Kubernetes는 기반 인프라가 갖춰져 있어야만 사용할 수 있습니다. Kubernetes 설치에서 가장 난해한 부분 중 하나는 네트워킹으로, Kubernetes는 모든 Pod이 서로 중복되지 않고 routable한 IP를 가져야만 서비스할 수 있습니다. 이러한 요구사항을 따르기 위한 여러 플러그인들이 개발되어 있지만 대부분 각 호스트에 설치된 docker daemon의 구동 옵션을 조절(flannel)하거나 컨테이너 구동 후 nsenter를 통해 직접 network stack을 수정(calico)하는 등의 저수준 해킹에 가까운 방식을 사용합니다.반면 nomad는 가벼운 리소스 관리자와 스케줄러로만 이루어져 있기 때문에 구조적으로 단순하고 성능이 빠르며 이해하기 쉽습니다. 또한, docker나 rkt 등의 컨테이너 드라이버 외에 fork/exec, qemu, java, LXC 등의 드라이버도 활용할 수 있습니다.java로 만든 서비스는 JAR나 WAR형태로 패키징 되어 JVM위에서 구동되며, 맞는 버전의 JVM만 있으면 어디에서나 구동된다는 점에서 컨테이너와 유사합니다.(JNI가 필요한 경우는 논외로 합니다.) 이러한 JVM기반 서비스는 nomad를 통해 컨테이너화 하지 않고도 orchestration을 할 수 있습니다.이 글에서는 Java 드라이버의 활용에 대해 다루며, nomad와 다른 클러스터 관리자/스케줄러와의 차이점은 Nomad vs. Other Software 에서 자세하게 살펴보실 수 있습니다.이 절에서는 nomad에서 JVM기반 프로세스를 구동하는 방법에 대해 간단한  웹서비스 예제를 통해 살펴보겠습니다.nomad의 Java Driver는 주어진 Job Spec에 따라 JAVA_HOME을 선택하고 cgroups, namespaces, chroot 등으로 job을 isolation시켜서 구동합니다.nomad의 Java Driver 스펙에는 jar_path, args, jvm_options등을 지정하며, 부가적으로 구동될 JVM의 버전을 선택할 수 있습니다.아래 Job Spec은 가상의 fatJAR 배포 서버 https://internal.file.server에서 다운로드할 수 있는 java-sample-all.jar에 대해 명시하고 있습니다. 실제 운영 시에는 jenkins의 artifact를 사용하여 손쉽게 CI서버/배포서버를 구축할 수 있습니다.nomad는 서비스 실행 시 호스트에서 사용되지 않는 임의의 포트번호를 서비스에 할당한 후 런타임에 환경변수로 NOMAD_PORT_[포트이름]를 전달합니다. 각 서비스는 실행 시 전달받은 포트를 사용하여 구동됩니다.아래는 sparkjava를 이용한 간단한 예제입니다. 코드에서 listening port의 기본값으로 4567을 지정한 후 NOMAD_PORT_http가 있는 경우 해당 환경변수의 값으로 변경하였습니다.빌드 스크립트에서는 fatJAR로 만들기 위해 shadowjar plugin을 사용하였습니다.작업을 구동하려면 nomad run명령을 사용합니다.실행결과를 보려면 nomad status 명령을 사용합니다.서비스가 클러스터 내에 할당된 정보를 보려면 nomad alloc-status명령을 사용합니다.서비스 로그는 nomad logs명령으로 볼 수 있습니다. 아래에서는 slf4j-simple이 stderr로 로그를 출력하기 때문에 -stderr옵션을 추가하였습니다.배포나 롤백 등의 서비스 수정은 plan과 run 두 단계를 거칩니다. plan은 변경된 내역이 클러스터에 어떻게 적용될지 보여주며, run은 실제로 변경을 수행합니다.Job Spec에서 hello서비스의 인스턴스를 3개로 늘려 보겠습니다.변경된 Job Spec을 plan명령으로 확인합니다.변경내역을 run명령으로 적용합니다.변경된 서비스를 status명령으로 확인합니다.구동된 서비스는 consul에 등록됩니다.nomad의 web frontend는 hashicorp에서 공식적으로 지원하는 atlas와 오픈소스인 hashi-ui가 있습니다. 여기서는 hashi-ui에 대해 알아보겠습니다.hashi-ui는 consul과 nomad의 오픈소스 web frontend입니다. consul에 내장된 ui와 가장 큰 차이점은 websocket을 이용한 실시간 업데이트입니다.nomad는 클러스터를 구성하는 각각의 역할을 분리하고 스케줄링에만 집중함으로써 간결하고 빠른 아키텍처를 만들었습니다. 단순하기 때문에 비록 구현된 기능의 수는 Kubernetes보다 적지만 성능 측면에서는 Kubernetes보다 더 뛰어나며, 필요한 기능을 추가하기도 더 쉽습니다.이 글이 서비스 오케스트레이션 솔루션 선택에 도움이 되었으면 합니다. 감사합니다.",http://tech.kakao.com/2017/01/25/nomad/,0,kakao,"docker,swift,ruby",NULL,2017-01-25
대규모 분산 스토리지(Kage)의 발전과정,"대부분의 초기 스타트업은 컨텐츠를 저장할 저장소에 대한 별다른 고민을 하지 않습니다. 여유가 있다면 NAS 장비를 구매해서 사용하고, 아니라면 NFS와 RAID를 구성해서 사용하게 됩니다. 하지만 서비스가 점점 커짐에 따라 하루 동안 저장되는 컨텐츠의 용량이 커지고, 네트워크 트래픽과 디스크 I/O가 증가하면서 NFS, NAS로는 유지가 불가능한 상황에 처하게 됩니다.구글(GFS, 2003)1과 페이스북(Haystack, 2011)2도 비슷한 상황을 겪었고 자체적으로 스토리지 시스템을 만들어 서비스를 유지시키는 데 성공하였습니다. 카카오 역시 초창기엔 카카오톡에서 주고받는 이미지와 동영상들을 모두 NAS에 저장하는 방식을 채택하였지만 이용자 수와 트래픽이 늘어남에 따라 더 이상 감당할 수 없게 되었고, 이에 확장이 용이하고 빠른 응답속도와 높은 신뢰성을 가지는 대규모 분산 스토리지 시스템을 구축하게 되었습니다.그리하여 탄생하게 된 것이 바로 KAGE(KAkao storaGE)입니다.현재 카카오톡, 카카오스토리를 포함해 카카오의 다양한 서비스를 지탱하고 있는 Kage의 주요 특징은 아래와 같습니다.Haystack와 같은 분산 스토리지의 아키텍쳐를 알고 계신 분이라면 위 특징만 보고도 어느 정도 구조가 파악되셨을 것 같습니다만, Kage 역시 보통의 분산 시스템처럼 파일을 저장할 때 복제본을 생성하여 물리적으로 다른 위치에 있는 3개의 저장소에 각각 저장합니다. 즉 원본 파일 외에도 2개의 복제본을 더 생성하여 총 3개의 파일을 저장하는 것인데, 이러한 정책을 통해 파일 읽기에 대한 트래픽을 분산시킬 수 있으며, 장애에 대한 유연한 처리도 가능해집니다. 만약 3개의 저장소 중 2개의 저장소에 장애가 발생하더라도, 나머지 하나의 저장소를 통해서 읽기 요청을 처리할 수 있습니다.Kage는 크게 다수의 데이터노드(Datanode) 서버와 네임노드(Namenode) 서버로 구성되는데, 이 중 데이터노드는 실제 파일을 저장하고, 저장된 파일을 읽어서 전송하는 역할을 합니다. 데이터노드에 있는 파일 저장소는 청크(Chunk)라는 일정한 크기를 가진 저장공간으로 이루어져 있으며, 물리적으로 다른 서버에 있지만 논리적으로는 같은 데이터를 가지고 있는 3개의 청크를 청크셋(ChunkSet)이라고 부릅니다.위에서 Kage가 파일을 저장할 때 서로 다른 3개의 저장소에 복제본들을 저장한다고 하였는데, 파일을 저장할 청크셋을 결정해주기만 하면 자연스럽게 3개의 서로 다른 저장소(= 청크)에 복제본을 저장할 수 있게 됩니다. 이 중 가장 먼저 데이터 쓰기를 받는 저장소를 마스터(Master), 나머지 두 노드를 슬레이브(Slave)라 부릅니다. 그렇다면 파일을 어느 청크셋에 저장할지는 누가 결정할까요? 바로 네임노드입니다.네임노드는 실제 파일이 저장되어있는 데이터노드, 청크 그리고 청크셋들의 정보를 관리하는 역할을 합니다. 클라이언트는 데이터를 쓰기 위해서 먼저 네임노드에게 쓰기 가능한 청크셋의 정보를 요청합니다. 이후 전달받은 정보를 통해 해당 청크셋의 마스터 데이터노드에 쓰기를 요청하게 되고, 마스터는 먼저 자신의 하드디스크에 쓰기를 완료한 후에, 나머지 슬레이브 노드에 데이터를 전달합니다. 모든 쓰기 과정이 성공적으로 완료되면 Kage-Key를 받게 되는데, Kage-Key에는 청크셋ID와 오프셋 등 파일을 찾을 수 있는 정보가 담겨있습니다. 클라이언트는 이후에 이 Key를 이용해 데이터노드에 읽기 혹은 삭제 요청을 진행할 수 있습니다.읽다 보니 일반적인 파일 쓰기와 조금 다른 점을 느끼신 분들도 있을 텐데요, 일반적인 쓰기의 경우 파일 이름, 내용, 그리고 저장 위치로 쓰기를 요청하는 반면, Kage의 경우 파일 이름과 내용만으로 쓰기를 요청하고 파일이 저장된 위치(KAGE_KEY)를 돌려받습니다.전통적인 파일 시스템을 이용하는 NAS에서 파일을 읽게 되면 하나의 파일 읽기 요청에 대해서도 여러 번의 IO 오퍼레이션이 발생하게 됩니다. 파일 이름을 inode번호로 변환하고, inode를 디스크에서 읽고, 실제 파일내용을 디스크로 읽는 등의 과정을 거쳐야 합니다. 파일 시스템은 파일마다 메타정보(이름, 디렉토리 등)를 가지고 있고, 파일 개수가 많아질 수록 이러한 메타정보가 큰 병목이 됩니다.2 Kage는 커다란 파일(Chunk)에 순차적으로 데이터를 쓰고, Kage-Key를 통해 데이터의 논리적 위치를 구해내어 바로 접근하게 함으로써 이러한 병목 문제를 해결하였습니다.발급받은 Kage-Key는 모두 서비스쪽에서 관리를 하여야 하는데, 혹시나 서비스쪽에서 Key를 분실한다면 영영 데이터를 찾을 수 없는 문제도 있습니다. 하지만 동시에 해당 서비스 담당자 외에는 (Kage 개발자 조차) 특정 파일이 어디에 저장되어있는지 전혀 유추할 수 없다는 보안적 장점도 가지고 있습니다.Kage의 또 다른 재미있는 특징은 일정 시간이 지나면 파일이 자동으로 삭제되도록 설정할 수 있다는 것입니다. 카카오톡의 이미지, 비디오 전송을 위해서 개발이 시작되었기 때문에 일정 시간이 지나면 청크를 삭제하며 디스크를 끝없이 재활용할 수 있게 설계되었습니다.이 특성 때문에 청크들이 시간에 따라 삭제되고 다시 생성되는 과정이 끊임없이 반복되는데, 이 과정에서 갑자기 청크가 부족하거나, 특정 데이터노드에 트래픽이 몰리거나, 한꺼번에 많은 청크가 삭제되는 등의 현상이 발생하곤 했습니다.자칫하면 큰 장애로 이어질 수 있는 이러한 문제들을 해결하기 위해, 청크를 할당하는 스케쥴링 방법을 다양하게 세워 최대한 노드에 트래픽이 골고루 분산될 수 있도록 하였습니다. 현재 주로 사용하고 있는 스케쥴링 방법은 아래와 같습니다.Kage는 안정적인 서비스를 위해서 모든 노드들을 빠짐없이 이중화 혹은 삼중화하여 운영하고 있습니다. 또한 특정 IDC에서 문제가 생겼을 때에 발생하는 장애를 최소화하기 위해, IDC 이중화도 함께 진행하고 있습니다.청크셋을 구성하는 대부분의 청크들 역시 두 IDC에 포함하도록 구성하고 있는데 여기에 재미있는 정책이 있습니다. Kage의 데이터는 Master->Slave->Slave 순으로 쓰이게 되는데, Master와 두 Slave의 IDC를 다르게 선택하는 정책을 사용하고 있습니다.예를 들어 Master가 IDC-A에 있는 데이터노드라면, 나머지 두 Slave는 IDC-B에 있는 데이터노드에서 선택하는 것입니다. 이는 특정 IDC의 장애나 IDC 간의 단절이 발생했을 때 쓰기 실패를 좀 더 빨리 감지하기 위해서입니다.하지만 모든 청크셋이 여러 IDC에 걸쳐 있다면 IDC 단절 시 쓰기가 무조건 실패하는 문제가 발생하게 됩니다. 따라서 같은 IDC에 있는 데이터노드들로만 구성된 청크셋도 유지하여 하나의 IDC로도 서비스가 가능하게 운영하고 있습니다.네임노드 역시 인터링크를 거치지 않고 데이터를 전달하기 위해 각 IDC 별로 하나 이상 존재합니다. 빠른 데이터 전달과 장애 극복을 위해 네임노드는 다음과 같은 우선순위를 이용해 쓰기 가능한 청크셋을 고릅니다.사내에 다양한 서비스들이 생기고 다양한 종류의 미디어 파일이 업로드됨에 따라, 이에 대한 전처리 혹은 후처리까지 지원하는 API서버의 필요성이 높아지게 되었습니다. 특히 비디오 파일은 모든 기기에서 원활하게 재생 가능하기 위해 트랜스코딩을 하는 과정이 필요합니다. 이 과정을 클라이언트에서 진행할 경우 너무 시간이 오래 걸려 사용자에게 좋지 않은 경험을 주게 때문에, Kage에 업로드되는 동영상의 경우 모두 서버단에서 트랜스코딩을 거쳐서 저장되고 사용자들에게 제공되게 됩니다. 현재 컨테이너 기반의 Worker 서버들이 FFMPEG을 이용해 분산 트랜스코딩을 진행하고 있습니다. 트랜스코딩의 대략적인 흐름은 아래와 같습니다.이미지의 썸네일 생성이나 서비스마다 필요한 다양한 이미지 효과 처리를 위해서 업로드 혹은 다운로드 시에 이미지를 변환하는 기능도 제공하고 있습니다.  API 서버는 HTTP 프로토콜로 Kage로 업로드 및 다운로드가 가능하고 설정에 따라 한 번의 업로드로 다양한 종류의 이미지를 얻어 낼 수 있기 때문에, 모든 서비스 개발자들은 이 API 서버를 통해 Kage를 이용하고 있습니다.새로운 SNS 서비스를 만들어서 프로필 사진을 업로드한다고 가정해봅시다. 혹시 모르니 원본도 저장하여야 하고, 빠른 이미지 서빙을 위해 JPEG이나 WEBP로 압축된 파일도 필요하고, 썸네일도 필요하고, 어쩌면 얼굴 부분만 자른 사진도 필요할 것입니다. 큰 작업이 아니라고 생각될 수도 있으나 매 서비스마다 비슷한 개발을 진행하여야 한다면, 전사 차원에선 큰 리소스 낭비가 아닐 수 없습니다. 따라서 서비스 개발 시에 필요한 이미지 관련 처리들은 Kage API 서버에서 전담하여 처리하고 있습니다.카카오의 클라우드 서비스(Krane)가 개발되면서 오브젝트 스토리지(Object Storage)에 대한 필요성이 생겼고, 이 때문에 파일의 메타정보까지 저장하는 Meta-Kage라는 시스템이 탄생하게 되었습니다. 오브젝트 스토리지는 실제 데이터와 메타 데이터를 분리하여 저장하며, 주로 사용자 계정마다 고유 식별자를 통해 파일에 접근하는 형태의 스토리지입니다. 기존의 블록 스토리지보다 성능은 떨어지지만 훨씬 많은 양의 데이터를 효율적으로 저장할 수 있다는 장점을 가지고 있습니다. 대표적인 오브젝트 스토리지 서비스로는 Amazon의 S3가 있습니다.Meta-Kage를 단순하게 풀어보자면 실제 파일을 저장하는 Kage와 파일의 메타 정보를 저장할 Key-Value Store를 조합한 형태로 볼 수 있습니다. 만약 사용자가 “loen/image/iu.jpg”라는 파일을 Meta-Kage에 저장하기를 요청한다면 API 서버는 Kage에 파일을 써서 Kage-Key를 얻은 후에, Key-Value Store에 (“loen/image/iu.jpg”, Kage-Key)를 기록합니다. 이후에 읽기가 요청된다면 Key-Value Store에서 “loen/image/iu.jpg”에 해당하는 Kage-Key를 찾은 후에 Kage에서 해당 데이터를 읽어 요청자에게 전달하게 됩니다.Meta-Kage는 OpenStack의 Swift API를 지원하도록 개발되었으며 현재 사내의 오브젝트 스토리지, Docker Hub 등을 포함해 비교적 업로드가 적은 서비스에서 주로 이용하고 있습니다.SNS에 업로드되는 이미지나 비디오는 시간이 흐를수록 접근 빈도가 크게 떨어지는 특징을 가지고 있습니다. 업로드 한지 얼마 되지 않아 많은 인기를 끌고 있는 (= 많은 읽기 요청을 받는) Data를 Hot Data라고 부르고, 반면 시간이 많이 흘러 인기가 식어버린 데이터를 Cold Data라고 부릅니다.Hot Data는 많은 읽기 요청 트래픽 및 장애에 버티기 위해 보통 2벌 정도 더 복제해서 저장하는데, 모든 데이터를 원본 크기에 3배가 되는 용량으로 유지하는 것은 기업 입장에서 큰 비용입니다. 카카오톡에서 업로드된 데이터들은 일정 시간이 지나면 지워지기 때문에 상관이 없지만, 카카오스토리와 같은 서비스에 업로드 된 데이터는 영구적으로 고객들에게 제공되어야 하니 부담이 아닐 수 없습니다. 그렇다고 원본만 남기고 나머지를 지워버리기엔 하드디스크의 장애의 위험이 있기 때문에, ‘비교적 적은 용량으로 데이터를 신뢰성 있게 유지 보관하는’  Cold Storage의 필요성이 높아졌습니다. 그래서 기존 Kage 시스템을 바탕으로 Replication Factor 1.5로 데이터를 저장하는 Cave(고대 문서는 꼭 동굴에서 나오니깐…)가 탄생하게 되었습니다.Cave 역시 기존 Kage 시스템을 바탕으로 개발되었습니다. 다만 기존 Kage에서 데이터를 저장할 땐 Replication Factor가 3이었는데 (2벌을 복제하여 총 3벌을 저장), Cave는 Replication가 1.5입니다. ‘1.5라고 하면 원본을 제외하고 반쪽만 더 저장하는 거 아닌가?’라고 생각할 수 있겠지만 1/3 정도 맞는(?) 이야기입니다. Cave는 데이터를 6개의 블럭으로 나눈 후, Reed-Solomon Coding3을 이용하여 3개의 블럭(Parity Block)을 더 만들어 냅니다. 그리고 만들어진 9개의 블럭을 9개의 Datanode에 나누어 저장합니다이렇게 만들어진 9개의 블럭 중에 6개의 블럭만 있으면 Reed-Solomon decoding을 이용해 원본 데이터를 만들어 낼 수 있기 때문에, (Replication Factor = 9/6 = 1.5) 읽기 요청 시에 6개의 블럭만 읽어들여 원본 데이터를 만들어낸 후 유저들에게 제공하게 됩니다. 3개의 디스크에 장애가 발생하는 경우에도 문제없이 데이터를 제공하는 게 가능하며, 에러가 발생한 블럭들을 복구해 낼 수 있습니다.카카오스토리처럼 영구 저장되는 데이터는 시간이 지나면 Cave로 마이그레이션 된 후, 데이터에 접근할 수 있는 새로운 키(Cave-Key) 새로 발급받게 됩니다. 하지만 서비스 개발자나 유저들은 기존의 Kage-key로도 Cave로 이동한 데이터를 읽을 수 있어야 하므로, 마이그레이션 시 (Kage-key, Cave-key) 쌍을 Key-value Store에 기록해둡니다. Cave가 구축된 이후부터 API 서버는 아래와 같은 방식으로 데이터를 읽고 있습니다.지금까지 카카오의 여러 서비스들이 사용하고 있는 분산 스토리지 시스템의 발전 과정에 대해 알아보았습니다. 처음에는 NAS를 대체하기 위해 만든 단순한 형태의 스토리지 시스템이었지만 다양한 니즈에 의해 멀티미디어 지원, 오브젝트 스토리지, 콜드 스토리지 등의 형태로 발전하게 되었습니다. 전반적인 컨셉과 발전과정을 설명하는 것이 목적이었던 글이었기 때문에, 이론적 배경이나 설명이 다소 부족한 감이 있습니다. 나중에 기회가 된다면 한번 자세히 다뤄보도록 하겠습니다. ^^The Google File System ↩Finding a needle in Haystack: Facebook’s photo storage ↩ ↩2Reed-Solomon error correlation ↩",http://tech.kakao.com/2017/01/12/kage/,0,kakao,"docker,css,frontend,python",NULL,2017-01-12
RxJS - Daum영화에 적용하다,"2016년 개편된 Daum영화 프론트엔드 개발에는 ReactiveX의 JavaScript 라이브러리 RxJS 4를 사용했습니다. ReactiveX는 ReactiveX Introduction에서 callback의 문제점에 도움을 주는 것으로 소개가 되어 있습니다. 웹에서는 Angular 2에 RxJS 5가 쓰이며 관심을 받았고, Android app개발에서도 RxJava가 여러 곳에 쓰이며 관심을 받고 있습니다. 적용 당시 IE 브라우저 버전 대응 문제와 RxJS 5가 Beta 였던 이유로 RxJS 4를 적용했습니다. RxJS는 프론트엔드의 여러 이벤트들에 대한 비동기 처리에 도움을 주지만, 수많은 operator들과 함수형 프로그래밍 패러다임에 대한 이해를 해야 해서 어려움이 있었는데요. 예를 들어 함수형 프로그래밍 패러다임에 맞게 외부 변수를 참조하지 않고 적절한 함수의 합성을 생각해야 하는 점이었습니다. 그렇다면 ReactiveX가 무엇인지 간략히 먼저 소개하고, RxJS를 Daum영화에는 어떻게 적용했는지 각 기능별 코드를 중심으로 소개하겠습니다. 이해를 돕기 위해 코드를 간소화 한 점이 있으며, 실제 적용 코드와 큰 흐름에서는 같도록 했음을 알려드립니다.http://reactivex.io/intro.htmlReactiveX의 Introduction을 보면 여러 item들을 비동기로 받기 위한 방식이고 Observer pattern을 사용한다고 나와 있습니다. Single item의 비동기는 JavaScript에서는 Promises를 생각하실 수 있습니다.    onNext, onError, onCompleted 의 3가지 callback이 소개되어 있어, error처리를 onError에서 한 번에 할 수 있다는 점과 onNext로 각각의 item을 받다가 정상적으로 끝나면 onCompleted가 호출되는 내용이 나와 있습니다. subscribe는 onError가 발생하든 onCompleted가 발생하든 끝나며, onError 발생 시 onCompleted는 호출되지 않습니다. 추가로 ReactiveX는 다양한 operator를 제공합니다. 잘 활용하기에 따라서 장점이 될 수도 있고, operator가 너무 많아서 진입장벽이 커지는 단점이 될 수 있다고 생각합니다.  Rx의 operator들은 operators(http://reactivex.io/documentation/operators.html)에 자세히 소개되어 있으며, operator를 선택하면 자세한 설명이 marble diagram이라 불리는 다이어그램과 함께 나와 있습니다. Marble diagram은 Observable(http://reactivex.io/documentation/observable.html)에 소개되어 있고, Marble diagram 중심으로 operator가 소개된 사이트 RxMarbles(http://rxmarbles.com/)도 있습니다.서제스트 검색 자동완성은 서제스트 검색창에 검색어를 입력하면 이를 서버에 보내 결과를 그려주는 기능입니다.자동완성에 적절한 operator를 찾다가 RxJS autocomplete example code에서 사용된 operator들을 참고했고, 아래에는 참고한 operator들을 사용한 이유와 그 외 operator들을 사용한 이유를 소개합니다. 먼저 검색 자동완성의 유효한 입력을 거르기 위해 서버에 요청하는 flatMapLatest 직전까지 사용한 operator들이 있습니다. keyup event가 발생할 때 입력된 텍스트 값을 map으로 넘겨주고 300ms미만의 간격의 키 입력을 제외하기 위해 300ms의 debounce를 주었습니다. 특수키 등을 입력 시에는 같은 값이 중복 요청될 소지가 있어 distinctUntilChanged을 적용했습니다. scan을 이용하여 텍스트 박스에 default로 입력된 originalValue가 있을 시 이 값과 다른 값이 입력될 때까지 null을 return하여 그 아래 filter에서 걸러지게 하였습니다.  이런 경우는 첫 입력이라 distinctUntilChanged 에서 걸리지 않기 때문입니다.원래 내용에서는 scan과 filter조합으로 distinctUntilChanged 이후에 첫 originalValue 걸러지게 하였는데, 복잡하여 다른 방법을 찾아 소개 합니다. startWith와 skip의 조합입니다. originalValue로 시작하여 distinctUntilChanged 이후에는 skip(1)을 하여 첫 originalValue 1개는 skip하도록 하는 것 입니다. 이렇게 하면 default로 입력된 originalValue는 최초 distinctUntilChanged에 영향을 주게 되면서 skip할 수 있습니다.여기까지 찾은 유효한 입력은 flatMapLatest를 통해 server에 요청하게 됩니다. 비동기 방식으로 결과가 오기 때문에, 서버로부터 응답이 오는 순서가 섞이면 flatMapLatest를 사용하여 요청에 대한 응답이 이미 온 응답보다 앞선 요청일 경우 무시하게 했습니다. 현재는 mobile환경에서만 서제스트 검색에서 닫기 버튼이 있어 PC환경과 반응형 웹 대응으로 인해 takeUntil이 없지만, 두 환경에 닫기 버튼이 있을 당시에는 takeUntil을 적용하여 닫기 버튼을 누를 때까지 키보드 입력에 대한 event를 처리한 코드도 있어 함께 소개합니다.이렇게 하면 닫기 버튼을 눌렀을 때 unsubscribe를 처리하는 쪽과 subscribe를 하는 쪽을 나눌 필요 없이, 한 코드에서 시작부터 끝까지 흐름을 볼 수 있습니다. 마지막으로 error 발생 시 3번 retry하도록 했습니다. 혹시라도 일시적인 장애로 서버에 오류가 난다면 3번까지는 재시도하기 위함입니다.유효한 입력이 발생하여 자동완성 결과로 적절하게 DOM을 update하면, PC환경에서 위/아래 방향키를 누르면 해당 방향으로 선택이 되고 enter입력 시 선택된 링크로 이동이 되도록 해야 합니다. scan을 이용해서 방향키나 엔터가 입력될 때마다 이전에 넘어온 위치 값을 받아서 적절한 위치로 선택이 이동되거나, enter를 입력 시 해당 위치로 이동이 되도록 구현한 코드입니다.개편 프로젝트에 새로 들어간 기능입니다. 사이드 메뉴 프로필을 통해 들어가면 본인이 평점을 주지 않은 영화들의 목록이 나와 평점과 리뷰를 남길 수 있게 하는 ‘평점 늘리기’ 기능이 있습니다. 적용된 shareReplay operator는 parameter로 넘겨준 숫자만큼의 item들은 최초 subscribe에서만 처리하여 가지고 있다가, 이후의 subscribe에서는 최초에 가지고 있던 item들을 replay하기 위한 operator입니다. 평점 늘리기에 보여줄 전체 movieId들을 미리 한 번만 받아놓고, 이후 다른 operator들을 붙여 subscribe하게 될 때 불필요하게 모든 id들을 다시 받아오는 일이 없도록 하기 위함입니다. 이렇게 하면 여러 id들을 저장할 array를 준비하고 그 array로 가져올 값을 요청하되 중복 요청했는지 체크하는 로직을 별도로 구현할 필요 없이, Rx에서 제공하는 operator들로 한 곳에서 처리할 수 있는 장점이 있습니다.shareReplay에 대해서 자세히 알고 싶으시다면 배경지식으로 Hot Observables, Cold Observables, Hot Observables replied에 대해 설명된 https://github.com/Reactive-Extensions/RxJS/blob/master/doc/gettingstarted/creating.md를 참고하세요.shareReplay 이후의 operator들에 대한 더 자세한 설명을 위해 이어서 아래의 코드를 예제로 보실 수 있습니다. 아래의 코드는 더보기를 눌렀을 때 현재 위치의 offset을 받아, 그 offset으로 부터 pageSize만큼 영화 정보(포스터, 제목 등등)를 받아와 그려주는 코드입니다.문뜩 위 코드가 flatMap함수 안에서 if문으로 분기하고 data가 없을 때 flatMap에서 끝내는 방식이 함수형 프로그래밍이나 Rx의 개념과 맞지 않는 듯하여, 아래와 같이 바꿔볼 수도 있다는 생각이 듭니다. 아래와 같이 if operator와 throw operator의 조합으로 data가 없을 시 onError에서 처리하는 방법도 남겨 둡니다.적용과 별개로 RxJS에서 알게 된 그 밖의 내용을 소개해드리고자 합니다. RxJS 4 Read Me에 따르면 RxJS = Observables + Operators + Schedulers로 소개되어 있습니다. 본 사례에서는 Observable과 Operator만 소개되었지만, item을 처리하는 순서를 이해하고 디테일하게 컨트롤하기 위해서는 scheduler에 대한 이해가 필요합니다. Rx.Scheduler class 에는 scheduler와 scheduling에 대한 자세한 설명이 소개되어 있습니다. 크게 3가지 scheduler가 있는데, 즉시 처리하는 immediate, 내부적으로 queue에 작업을 넣어 trampoline을 이용하는 currentThread, 비동기 방식의 default가 있습니다. 사용할 scheduler를 바꾸고자 할 때는 subscribeOn 과 observeOn operator를 적절히 사용하시면 됩니다. Virtual DOM과 연계하여 RxJS가 필요하다면 Cycle.js나, React redux 환경에서는 redux-observable을 함께 고려하실 수 있을 것 같습니다.여러 곳에서 발생하는 이벤트, AJAX 호출로 인해 callback이 많아져 callback hell이 생기면서 이벤트의 흐름을 찾기 어려워지는 경우가 있습니다. 여기서 적용사례의 모든 것을 다 다루진 못했지만, RxJS는 여러 AJAX 비동기 응답을 한 곳에 모아야 하는 경우나 어떤 AJAX의 응답이 다른 AJAX의 input값이 되는 경우에도 유용했습니다. 그러나 어려운 점으로는 함수형 프로그래밍보다 명령형 프로그래밍에 더 익숙한 개발자로서 이벤트의 흐름을 함수의 합성으로 생각해야 하고, 많은 operator들 중 적합한 operator를 알고 있지 않으면 찾아봐야 하는 점이었습니다. RxJS를 Daum영화에 적용한 코드가 Rx,함수형 프로그래밍 관점에서 볼 때 아직 부족한 부분이 있을 수 있겠으나, callback hell로 인한 어려움에 대응할 수 있음을 확인한 사례였습니다.",http://tech.kakao.com/2017/01/09/daummovie-rxjs/,0,kakao,"json,react,webpack,java,backend,vue,frontend,javascript,css,angular,typescript,html",NULL,2017-01-09
kakao의 오픈소스 Ep6 - Cite,"“카카오의 오픈소스를 소개합니다” 여섯번째는 niko.bellic이 개발한 Cite입니다.Cite는 Container as a Service(CaaS)로서 소스코드를 빌드하고 배포하며 운영하는 일련의 과정을 자동화하는 웹 서비스입니다.Cite는 google kubernetes기반 CaaS(Container as a Service)입니다.Kubernetes는 최근 Container Orchestrator로 각광받고 있지만 설치와 운영이 복잡하기 때문에 익혀서 사용하기 위해서는 많은 시간과 노력을 필요로 합니다.Cite는 이러한 어려움을 줄이기 위해 Kubernetes Cluster를 사전에 생성하고 실제 서비스 담당 개발자가 Kubernetes Cluster로 서비스 배포/롤백 등을 할 수 있도록 Kubernetes와 GitHub을 연동하였습니다.Cite에서의 서비스 배포는 아래의 흐름을 따릅니다.빌드, 배포, 롤백 등 각 서비스의 상태는 github commit status와 deployment status 이벤트를 통해 처리하며, LoadBalancer는 Kubernetes를 watch하여 각 서비스의 상태가 변경될 때 loadbalancer의 upstream을 변경합니다.Cite에서는 Kubernetes에 내장된 rolling-upgrade 베포 방식이 아닌 A-B switching방식을 선택하였습니다. A-B switching은 배포시 새 컨테이너를 모두 구동한 후 loadbalancer에서 새 서비스의 upstream을 사용하도록 변경하는 방식인데요, 이 방식은 rolling-upgrade에 비해 배포시 리소스 사용량은 많지만 배포 이후에도 일정 기간 기존 컨테이너가 구동중이기 때문에 롤백이 빠르다는 장점이 있습니다. Cite는 주기적으로 1시간 이상 사용되지 않는 - service selector에 등록되지 않은 - 컨테이너를 종료하고 있습니다.skraper는 카카오톡, 스토리 등 서비스에서 URL을 입력받고 해당 URL을 방문하여 대표 이미지를 추출한 후 반환하는 서비스입니다. skraper는 최초의 cite를 이용한 퍼블릭 서비스로 현재 cite에서 컨테이너 5 + 10개로 구동중입니다.",http://tech.kakao.com/2016/12/26/opensource-6-cite/,0,kakao,docker,NULL,2016-12-26
카카오의 전사 리소스 모니터링 시스템 - KEMI(Kakao Event Metering & monItoring),"KEMI(Kakao Event Metering & monItoring)는 카카오의 전사 리소스 모니터링 시스템 입니다. 서버, 컨테이너와 같은 리소스의 메트릭 데이터를 수집해서 보여주고 설정한 임계치에 따라 알림을 보내주는 KEMI-STATS과 ETL을 통해 수집한 log를 대시보드 형태로 보여주거나 실시간 알림을 할 수 있는 KEMI-LOG로 구성되어 있습니다. KEMI-STATS는 수만대에 이르는 카카오의 전체 서버와 컨테이너 서비스를 모니터링하는데 이용되고 있으며 polling방식과 push방식 두가지를 사용합니다.  리소스 중 서버(physical machine, virtual machine, amazon ec2)의 경우 polling방식으로 SNMP를 이용하여 시스템 메트릭을 수집합니다.  데이터를 수집하는데 여러가지 방식이 있을 수 있지만 SNMP를 기본으로 선택한 이유는 서버의 운영체제와(linux/windows/nw switch) 상관없이 모니터링하기 위해서 입니다.polling 방식의 수집은 젠킨스 배치 job을 이용해서 1분마다 아래와 같은 순서로 실행됩니다.push 방식의 수집은 컨테이너 리소스 모니터링과 SNMP가 지원되지 않는 서버에서 사용되고 있으며 아래와 같은 순서로 실행됩니다.polling 또는 push방식으로 수집된 데이터는 아래와 같은 순서로 View를 위해 Time Series DB에 저장되고 룰에 따라 알람이 수행됩니다.이게 KEMI-STATS의 기본적인 구성입니다.그리고 위의 실시간 스트리밍 데이터를 이용한 알람 외에 수집된 데이터를 이용한 리소스 효율화 서비스도 제공하고 있고 그 순서는 아래와 같습니다.이 외에도  SNMP의 oid를 확장하여 SNMP에서 제공해주는 기본 메트릭 외에 다양한 커스텀 메트릭을 수집할 수 있고, push방식으로 메트릭 데이터를 넣을 때 사용자가 만든 메트릭을 넣을 수 있습니다. 현재 KEMI-STATS의 이러한 확장성을 이용해서 시스템의 보드의 온도, haproxy, nginx, memcached, redis 등의 stats 정보, 컨테이너 등의 상태를 모니터링하기 위해 필요한 커스텀 메트릭이 수집되고 있습니다. KEMI-LOG는 각 서비스에서 발생한 로그를 모아서 저장하고 보여주는 기능과 로그 별로 설정된 룰에 따라 알람을 발생시켜 줍니다. 인프라운영에 필요한 기본적인 syslog나 네트워크 관련 로그들을 받고 있으며, 필요에 따라 각 서비스들에서 KEMI-LOG쪽으로 로그 데이터를 보내서 이용하고 있으며 그 규모는 하루 수백기가 정도입니다. KEMI-LOG의 데이터 흐름은 아래와 같습니다.위 데이터 흐름에서 선택하거나 개발된 몇가지 기술들과 방법은 아래와 같은 장점을 가집니다.KEMI 개발은 issac.lim, hardy.jung, jenny.ssong, joanne.hwang, andrew.kong 이  함께하고 있으며 카카오 인프라&데이플랫폼팀의 많은 지원을 받아 운영되고 있습니다. 끝으로… 위 내용이 모니터링 서비스를 개발하고 계신 분들께 조금이라도 도움이 되면 좋을 것 같습니다.",http://tech.kakao.com/2016/08/25/kemi/,0,kakao,"docker,django,python",NULL,2016-08-25
CODING BATTLE 가위바위보! - 못다한 이야기,"지난 8월 13일(토)부터 이틀간 코엑스 그랜드에서 열렸던 PyCon 2016 APAC에서  카카오 부스를 지켰던 iolo.fitzowen 입니다.키스톤 스폰서 자격으로 행사장에서 가장 큰 부스를 운영하게되었는데, 거대한 부스를 어떻게 활용할 것인가를 오랫동안 고민했습니다.부스 이벤트로 코딩 퀴즈를 하기로 하고 사내 그룹웨어인 아지트를 통해 문제를 추천 받았는데, bryan.j가 제안한 가위바위보 AI 대전 아이디어을 다듬어 CODING BATTLE 가위바위보!라는 이름의 행사를 진행했습니다. (이 자리를 빌어, 멋진 아이디어를 주신 bryan.j, 그리고 채택되지 않았지만 다양한 의견을 주신 여러분께 감사드립니다.)자세한 내용은 이벤트 페이지 CODING BATTLE 가위바위보! in 파이콘 2016 APAC를 참고하시고, 이 글에서는 파이썬 초보(!)가 코딩 이벤트를 진행하면서 겪었던 에피소드를 인상적인 소스 코드와 함께 전해드리겠습니다.최초의 아이디어는 서버-to-서버 HTTP 통신을 이용하는 방식이었습니다.방식이었습니다.보신 분들은 없겠지만, 이 방식으로 구현된 버전이 행사 이틀 전에 카카오의 깃헙에 잠깐 올라가 있었습니다^^;행사 전날 오후, 회사 카페에서 clark.kang과 henry.ha를 우연히 만나 (그렇습니다! 카카오에 입사하시면… 이런 연예인(?)들은 매일 우연히 마주칠 수 있습니다!) 파이콘 이벤트에 대해 얘기를 나누다가… 코엑스의 열악한 네트웍 환경에서 클라우드 서버에 올리는 삽질의 무의미함에 대한 날카로운 지적(!)을 받고, 로컬 환경에서 개발하고 테스트하고 대결할 수 있는 방식으로 변경하기로 전격 결정!!!그날 밤을 꼴딱 새서 새로운 게임 진행 서버를 만들었습니다.흠흠… 그러니까 여러분들이 보신… (웹브라우저와 터미널을 번갈아 보여주면서 생목으로 고함을 지르는) 바로 그 방식입니다^^;;방식을 급히 바꾸면서 사건사고도 많았습니다.카카오 부스를 방문한 JetBrains 직원이 콧방귀를 뀔 정도로 전근대적인 방법이지만, 그만큼 확실하다고 믿었던 메일이 백본네트웍 장애라는 전대미문의 장애로 첨부파일이 손상되는 초유의 사태가 발생했습니다. 오후 4시가 되서야 참가자 9명의 첨부 파일이 모두 복구됐고… 9명을 추가해서 예선전을 다시 치렀죠. 덕분에 결과 발표도 5시로 연기.(옆에 앉아었던 violet.blue가) 웹을 뒤져서 받은 음성 파일과 손바닥 이미지 파일을,  (바로 옆에서 스마트스터디 부스를 지키고 있던) outsider님에게 넘겨주고 30분 남짓 개발한 것을, (제가) 대충 갖다 붙여서 (수동으로 버튼을 누르면 나타나고/사라지는) 안내면술래 가위바위보! 보! 보! 보! 애니메이션도 준비했습니다.첫 날은 참가 신청자가 100명을 넘지 않아, 메일만 제 때 도착했다면 라이언 캐릭터 목베개를 받을 수 있었습니다. 무더운 날씨에도 불구하고 목배게를 목에 걸고 다니시던 모습을 보며… 참 뿌듯(?) 했었죠.시험적으로 몇판 돌려보니, 라이브로 해도 되겠다고 판단하고, 예정보다 한시간 늦은 오후 5시, 랩탑을 TV에 연결하고 라이브로 대본없이 진행했습니다.결과는 아시다시피(예상대로) random의 완승이었습니다.진지하게(?) 접근했던 참가자들은 그 결과에 분노(?)했고, 저도 마찬가지였습니다. 이벤트를 준비하면서 수억번의 가위바위보를 했지만, 랜덤을 이길 방법은 쉽게 보이지 않았습니다. 정말 없을까요?그래서!2일차는 규칙을 바꿔보기로 했습니다. 파이썬 기본으로 제공하는 random과 외부 모듈을 사용하지 않고, 코드로 정면 승부!!다음 날 아침, 행사장에 도착하니, 이미 참가 접수 메일이 들어오고 있었습니다.(순진한 개발자들, 이제야 선착순의 의미를 깨달았어…) 점심때 쯤엔 참가 신청 메일이 100통을 넘었습니다.(어랏 장난이 아닌데…) 접수를 중단해야 할지를 고민하다가, 경품(라이언 목베개)은 줄 수 없지만, 게임에는 참가할 수 있는 것으로 결정했습니다.오후 2시, 참가 접수를 마감하고 시험삼아 몇 게임씩 돌리던 중, 몇몇 플레이어들의 특이한 결과를 확인하고, 코드들 뜯어보니 파이썬 마법의 열쇠 더블언더스코어(__)가 여기저기 흩어져 있더군요. 파이썬 초보인 저로써는 의도 조차 파악하기 힘들어, 파이썬 고수들을 찾아갔습니다. 자원봉사자로 참여하고 있던 ganadist님, 정지오님, 서승효님을 비롯한 몇몇 분들의 도움을 받아 적들의(?) 의도와 막을 수 있는 방법을 급히 확보했습니다.게임 결과 발표 시간이 임박해서 일부 참가자들의 코드는 확인하지 못한채 발표를 시작했는데…. 아니나 다를까… 확인하지 못한 코드들이 말썽을 부렸습니다.  175명이 풀리그를 치르려면 15,225 게임(1,522,500 번의 가위바위보)를 해야 하는데… 매번 sleep(.1)을 하면… ㅠㅠ 가위바위보 한 번 결정하는데 1초 이상이 걸리는 플레이어도 있었습니다. 이 플레이어도 공평하게 174 게임(17,400 번의 가위바위보)를 해야 했죠.그래도 기다려보자!라고 버텼지만, 저의 오기를 비웃 듯 행사장의 전원이 꺼졌습니다. CPU 사용량 100%의 상태에서 랩탑의 배터리는 2시간도 못버틸테고, 그때까지 결과가 나올 가능성은 없었습니다. 결국, 2일차 결과 발표를 연기할 수 밖에 없었습니다. 부피를 최소화하기 위해 래핑된 라이언의 표정이 슬프…참가자들의 의욕을 과소평가한… 저의 불찰입니다. 이 자리를 빌어서 기다려주신 많은 참가자 분들께 사과드리고, 또 감사드립니다.마무리를 짓지 못하고 찝찝한 마음과 지친 몸을 끌고 섬으로 돌아오면서, 제시한 룰을 깨트리지 않고 어뷰징을 막을 수 있는 방법을 고민했는데, ganadist님께서 선물을 보내왔습니다.우여곡절 끝에, 오늘에야 2일차 게임 결과를 발표합니다(두둥!):2일차 오후 2시까지 접수된 188명 중에서, 예제를 복사해서 낸 5명, random을 사용한 8명을 뺀 175명(1일차 참가자 32명 포함)의 코드가 접수되었고, input 함수를 사용하거나(키보드 입력 대기) show_me_the_hand 함수가 없는 11명을 제외한 164명이 예선에 참가했습니다.예선은 풀리그 방식으로 164명의 플레이어가 다른 163명과 게임을 진행합니다. 총 13,366(164*163/2) 게임, 1,336,60 번의 가위바위보를 하는 거죠. 이 글을 쓰고 있는 시점에 6시간째 돌아가고 있군요. 12,452 번째 게임이니까 끝이 보입니다.예선전 시작 동영상(용량이 큽니다. 데이터 요금에 주의하세요)혼자 회의실에 앉아 대사를 읊으려니 여간 쑥스러운게 아닙니다.본선 32강전 동영상(용량이 큽니다. 데이터 요금에 주의하세요)본선 16강전 동영상(용량이 큽니다. 데이터 요금에 주의하세요)본선 8강전 & 준결승 동영상(용량이 큽니다. 데이터 요금에 주의하세요)결승전 동영상(용량이 큽니다. 데이터 요금에 주의하세요)이제부터 본론입니다.참가하신(구경하신) 분들은 아시다시피 random의 완승이었습니다. 그게 가위바위보 게임의 본질이니까 이상할 건 없죠. 그래도…차암 쉽죠? 가위, 바위만 내는 전략입니다. 그런데 이 전략이 (수학적인 설명은 못하지만) 대회 전에 제가 알고 있던 (상대방의 대전 기록을 분석하지 않고) 랜덤을 이기는 유일한 전략이었습니다.크게 다르지 않습니다. 가위를 낼 확률이 좀 더 높아졌네요.역시 크게 다르지 않습니다. 가위, 바위를 낼 확률이 좀 더 높아졌네요.아! 이번엔 뭔가 조금 다르죠? 상품을 전달할때도 참가자의 아쉬움과 분노(랜덤에 지다니!)가 느껴져서 저도 같이 분노(랜덤에 지다니!)했었죠.대부분 예제 코드와 동일하거나 약간 수정한 전략이었습니다만, 몇몇 참가자들은 참신한 시도를 했습니다. 그러나, 이런 참신한 시도들은 순수한 랜덤에 허무하게 무너졌는데요, 상대의 전략을 파악했다(패턴을 읽었다)고 생각하고 대응 전략을 결정한 순간… 진거죠. 있지도 않은 패턴을 읽은… 오해영!1일차 참가자들의 코드는 대충봐도 대부분 의도를 파악할 수 있었는데, 2일차 참가자들의 코드는 저같은 파이썬 초보에겐 어림도 없었습니다. 단 하루만에 완전히 다른 게임이 되었습니다. 개발자들이 독한 마음을 먹으면 이렇게 무섭습니다.상대방이 직전에 냈던 손에 맞춰서 내는 전략인데요, 단순해 보이지만, 결과는 우승!!CODING BATTLE 가위바위보는 - 이 분의 아이디처럼 -  바부겜이었을까요?상대방이 직전에 냈던 손과 같은 손을 내면 이기는 손을 내는 전략입니다. 역시나, 이유를 설명할 순 없지만, 결과는 결과는 매우 성공적!상대방이 낸 손에 따라 승리에 4, 무승부에 2, 패배에 1의 가중치를 계산하고, 가중치가 가장 높은 - 가장 승률이 높은 손을 내는 전략입니다.(맞나요?) 안정적인 전략이지만, 이런 식의 전략이 아무생각없는 단순 랜덤에게 허무하게 패하는 경우가 많았습니다. 그래도 결과가 좋습니다.대전 중에서 가장 많은 시간을 사용한 코드입니다. 동영상 녹화를 힘들게 만든 분이죠^^; 제 수준으로 의도 파악이 불가능하네요. 뭔가 어렵구나… 정도? 개인적으로는 우승하지 않을까… 기대를 했었는데… 의외로 단순한 전략에 허무하게 무너졌습니다.ㅠㅠ본선 토너먼트에 오른 64명 중에서 승률 TOP 5을 보면:가위바위보처럼 운에 의존하는 게임에서 60% 이상의 승률을 보였다는 것이 놀랍네요. 이 분들은 대진운이 안좋았거나 카운터 전략을 만났을 뿐… 너무 서운해 하지 않으셨으면…첫째날처럼 단순한 랜덤보다는 약간의 전략이 가미된 랜덤들이 많았고, 성적도 좋았습니다. 또한 상대방의 플레이를 교묘하게 따라 하는 전략들도 많았고, 성적도 좋았습니다. 복잡한 계산을 통해 상대방의 전략을 분석하고, 그에 따라 전략을 바꾸는 플레이어도 있었는데, 32강, 16강, 8강을 거치면서 의외로 단순한 전략을 오해해서(랜덤에서 패턴을 읽었다면… 오해영) 맥없이 무너지는 결과가 종종 있었습니다. 아직은 파악된 전략의 종류가 많지 않아서 효과적이지 않지만, 이런 대회를 계속 개최하면 어떻게 될까요?이걸로 끝내기엔 아쉬우니, 재미있는 코드를 몇가지 살펴보겠습니다:아… gawi, bawi, bo를 사용한 제 자신이 부끄러워지네요. rock, scissors, paper도 아니고 말이죠 ㅠㅠ== 연산자를 오버로딩해서 상대의 손을 확인하고, __str__(문자열 형변환) 연산자를 오버로딩해서 항상 이기는 손을 내는 객체를 리턴하는 어뷰징(?)입니다. 이벤트 소개 페이지의 pseudo code에서는 효과가 있었겠지만, 실제 게임 진행 서버에서는 (상대방이 정상이라면) 항상 부전패입니다^^; 이 방식의 또 다른 문제점은 내가 항상 == 연산자의 앞에 온다는(left-hand operand) 보장이 없다는 거죠.심사 초반에 이 코드를 보지 않았다면, 어뷰징에 대해서 생각도 못했을텐데… 덕분에 다른 어뷰징들도 찾아보는 계기가 된 코드입니다.파이썬 모듈 로더를 활용해서, 로딩된 모듈 중에 show_me_the_hand 함수가 있으면 항상 bo만 내는 함수로 바꿔치기 합니다. 물론 플레이어 자신은 항상 gawi만 내죠^^;처음 계획한 서버-to-서버 HTTP 통신 방식이었으면 효과가 없었겠지만, 바뀐 로컬에서 실행하는 방식에서는 쉽게 막을 방법이 없었습니다. 그렇다고 약속한 게임 규칙을 임의로 바꿀 수도 없어서 고민했는데, ganadist님이 급히 만들어주신 플레이어 자신의 모듈만 로딩된 격리된 프로세스에서 함수를 실행하고 파이프로 결과를 주고 받는 방식으로 게임 규칙 변경없이 무력화할 수 있었습니다.현재 디렉토리의 모든 모듈을 .py 파일을 미리 로딩해서 각각 1000번의 결과를 학습하고, 학습된 결과에 기반해 자신의 손을 결정하는 방식입니다.기발한 아이디어 였지만, 허무하게도… random 사용 금지 규칙에 따라… 서류 전형에서 탈락!! 참가상도 못받아가셨네요 ㅠㅠ 그냥 time() % 3이라도 하시지…이 외에도, 수알못 파알못 - 수학을 전혀 모르는 파이썬 초보인 제 수준으로는 의도 파악조차 힘든 멋진 코드들이 많았지만, 깃헙에 올려둔 게임 진행 서버의 소스 코드로 대신하며, 코드 리뷰(구경?)를 마칩니다.예능으로 시작했다가 다큐로 끝난다더니, 이번 가위바위보 이벤트가 바로 그랬습니다.부족한 이벤트에 큰 호응을 보여주신 많은 참가자 분들과 이벤트 진행과 준비에 고생한 운영자 분들께 감사드립니다. 통큰 스폰서로 개발자들에게 꿈과 희망, 그리고 좌절(?)을 선물해주신 회사 측에도 감사드립니다. 특히, 급하게 요청드렸음에도 기꺼이 코드를 만들어주신 outsider님과 ganadist님께 감사드립니다.긴 글, 끝까지 읽어주셔서 감사합니다. 이 한마디를 전하며 긴 글을 마칩니다.may the PYTHON be with you…",http://tech.kakao.com/2016/08/19/gawibawibo/,0,kakao,"python3,python",NULL,2016-08-19
개발자를 위한 SSD (Coding for SSD) - Part 6 : A Summary – What every programmer should know about solid-state drives,"이번 챕터에서는 지금까지 언급했던 내용들을 간략히 요약해서 정리해 보았다. 조금 더 상세한 내용을 쉽게 찾아갈 수 있도록, 각 내용들은 다른 파티의 한두개 이상의 섹션을 나열해 두었다.SSD (Solid state drive)는 플래시 메모리를 기반으로 하는 저장 장치이이다. 각 비트들은 셀에 저장되는데, SSD의 셀은 1 비트(SLC), 2 비트(MLC) 그리고 3 비트(TLC) 셀 타입이 있다.See also: 섹션 1.1각 셀은 최대 가능한 P/E(Program/Erase) cycle을 가지며, 최대 가능한 P/E cycle을 초과하면 결함 셀(Defective cell)로 간주된다. 이는 NAND 플래시 메모리는 언젠가는 Wear-off되고 수명이 제한적이라는 것을 의미한다.See also: 섹션 1.1테스트도 결국 사람이 수행하는 것이기 때문에, 모든 벤치마크는 오류나 실수를 담고 있다. 그래서 제조사나 제 삼자에 의한 벤치 마킹 결과를 참조할 때는 주의해야 한다. SSD를 이용한 벤치마킹을 진행할 경우에는, 실제 사용할 SSD 드라이브와 최대한 응용 프로그램의 워크로드와 비슷한 인하우스 벤치마킹 도구를 이용할 것을 권장한다. 마지막으로 응용 프로그램의 요건(SLA)에 맞는 메트릭에 집중해서 벤치마킹을 할 것을 권장한다.See also: 섹션 2.2, 2.3SSD의 셀(Cell)은 블록(Block)으로 그룹핑되어 있으며, 블록(Block)은 다시 플레인(Plane)으로 그룹핑된다. SSD에서 읽고 쓰기의 가장 작은 단위는 페이지(Page)이며, 페이지는 단독으로 삭제(Erase)되지 못하고 블록(Block) 단위로만 삭제될 수 있다. NAND 플래시 페이지 사이즈는 제품이나 제조사별로 다양한데, 대 부분의 SSD는 2KB와 4KB 그리고 8KB와 16KB를 페이지 사이즈로 사용하고 있다. 또한 대부분의 SSD에서는 하나의 블록은 128개 또는 256개의 페이지를 가지므로, 블록의 사이즈는 256KB에서 4MB까지 다양한 사이즈를 가지게 되는 것이다. 예를 들어서 삼성 SSD 840 EVO는 2048KB의 블록 크기를 가지며, 각 블록은 256개의 8KB 크기 페이지를 가지고 있다.See also: 섹션 3.2SSD 드라아브에서는 페이지 하나의 크기보다 작은 사이즈의 데이터를 읽을 수는 없다. 물론 응용 프로그램이나 운영 체제에서는 단 1개의 바이트도 읽을 수는 있지만, 실제 SSD 내부적으로는 하나의 페이지 전체를 읽어서 불필요한 데이터는 모두 버리고 사용자가 원하는 하나의 바이트만 리턴해주는 것일 뿐이다.See also: 섹션 3.2SSD에 쓰기를 할 때에는 SSD의 페이지 크기의 배수로 처리된다. 그래서 단지 1 바이트만 SSD에 기록하는 경우에는 최소 하나의 페이지 크기의 데이터가 기록되어야 한다. 필요 이상으로 데이터를 기록해야 하는 것을 “Write amplication”이라고 하며, SSD 드라이브에 쓰기를 하는 것을 “program”이라고도 한다.See also: 섹션 3.2NAND 플래시 페이지는 “free” 상태일때에만 데이터를 저장(program)할 수 있다. 데이터가 변경되면 이전 버전의 페이지는 SSD의 내부 레지스터로 복사된 후 데이터가 변경되고 그리고 새로운 버전의 데이터는 새로운 “free” 상태의 페이지에 기록되는데 이를 “read-modify-update”라고 한다. 또한 SSD에서 변경된 데이터는 기존 위치에 업데이트되지 못하고, 항상 새로운 “free” 상태의 페이지에만 저장될 수 있다. 일단 데이터가 SSD 드라이브에 영구히 저장되면, 이전 버전의 데이터를 가지고 있는 페이지는 “stale” 상태로 마킹되고 Garbage-collection에 의해서 삭제(Erase)될때까지 그 상태로 남아있게 된다.See also: 섹션 3.2SSD의 페이지는 덮어쓰기할 수 없다. 일단 페이지가 “stale” 상태로 바뀌면, 그 페이지를 다시 사용하기 위해서는 반드시 삭제(Erase) 과정을 거쳐야 한다. 그러나 페이지는 단독으로 삭제될 수 없으며, 그 페이지를 포함한 블록이 통째로 삭제(Erase)될때에만 “free” 상태로 바뀔 수 있다.See also: 섹션 3.2FTL(Flash translation layer)는 호스트의 논리 블록 주소를 SSD의 물리 블록 주소로 맵핑해주는 SSD 컨트롤러의 컴포넌트이다. 최근의 SSD 드라이브는 대 부분 Log structured 파일 시스템과 비슷한 작동 방식을 가진 “hybrid log-block mapping”나 그로부터 파생된 블록 맵핑 알고리즘을 사용하고 있다. “hybrid log-block mapping” 맵핑 알고리즘은 랜덤 쓰기를 시퀀셜하게 변환해주는 장점을 가지고 있다.See also: 섹션 4.2SSD 드라이브는 내부적인 병렬 처리 기능을 가지고 있는데, 이 병렬 처리 기능은 NAND 플래시 칩 단위로 여러 블록들에 동시에 쓰기할 수 있도록 해준다. 이렇게 한번에 병렬로 액세스할 수 있는 블록들의 그룹을 “Clustered block”이라고 한다.See also: 섹션 6NAND 플래시 셀은 데이터 쓰기를 할 수 있는 회수 제한이 있어서, 이 제한을 넘어서면 해당 셀은 더 이상 사용할 수 없게 된다. 이런 현상을 “Wear-off”라고 하는데, FTL은 최대한 SSD의 셀들이 최대한 골고루 사용될 수 있도록 쓰기 작업을 분산해준다. 이상적으로는 SSD의 모든 셀들이 동시에 그들의 P/E cycle 한계에 도달하도록 하는 것이 FTL의 중요한 목표인 것이다.See also: 섹션 3.4SSD 컨트롤러의 Garbage-collection은 “stale” 상태의 페이지를 삭제하여 다시 사용 가능한 “free” 상태로 만들어준다. “stale” 상태의 페이지는 “free” 상태로 전환되지 않고서는 재사용될 수 없다.See also: 섹션 4.4Garbage-collection과 같은 백그라운드 오퍼레이션은 호스트로부터 유입되는 사용자 요청(포그라운드 오퍼레이션)에 좋지 않은 영향을 미치게 된다. 대표적으로 지속적인 작은 랜덤 쓰기가 발생하는 상황에서는 더욱 더 성능상 나쁜 영향을 미치게 된다.See also: 섹션 4.4“Read-modify-write” 오퍼레이션으로 인한 “Write amplication”을 최소화하기 위해서, 가능하다면 NAND 플래시의 페이지 크기로 SSD 드라이브에 쓰기를 하는 것이 좋다. 현재까지 출시된 SSD 제품들중에서 가장 큰 페이지 사이즈는 16KB이므로, 가능하면 16KB 정도를 기본 쓰기 데이터 사이즈로 선택하는 것이 좋다. SSD의 페이지 사이즈는 SSD 제조사나 모델별로 상이하며, 또한 SSD 기술 발전으로 더 크게 증가할 수도 있다.See also: 섹션 3.2, 3.3SSD 드라이브에 쓰기를 할 때에는 페이지 사이즈에 맞춰서(Align) 호출하는 것이 좋으며, 페이지 사이즈의 배수로 데이터를 기록하는 것은 더더욱 권장한다.See also: 섹션 3.2, 3.3최대의 스루풋을 위해서, 가능한 작은 사이즈의 데이터 쓰기는 메모리에 모아서 버퍼링했다가 버퍼가 가득 차면 SSD 드라이브로 기록하는 것이 좋다. 작은 데이터 쓰기들을 모아서 배치로 한번의 쓰기 요청으로 처리하는 것이 좋다.See also: 섹션 3.2, 3.3읽기 성능은 쓰기 패턴의 결과라고 볼 수 있다. 만약 대용량의 데이터가 한번에 SSD 드라이브에 쓰여진다면, 그 데이터들은 NAND 플래시 칩의 여러 위치로 분산 저장된다. 그래서 연관된 데이터는 동일 페이지와 블록 그리고 Clustered block에 기록하는 것이 좋다. 그래야지만 나중에 (SSD의 내부 병렬 처리의 도움을 받아서) 한번의 I/O 요청으로 데이터를 빠르게 읽을 수 있기 때문이다.See also: 섹션 5.3읽기와 쓰기가 동시에 실행되는 워크로드에서는 SSD 내부적인 캐싱과 Readahead 메커니즘의 효과를 얻기 어려우며, 이로 인해서 스루풋이 떨어질 수도 있다. 이렇게 읽고 쓰기가 혼합된 형태의 워크로드는 가능하다면 읽기와 쓰기를 대용량(가능하다면 Clustered block 크기에 맞춰서)으로 순차적으로 실행할 수 있도록 유도하는 것이 좋다. 예를 들어서 1000개의 파일을 읽고 변경해야 한다면, 하나씩 파일을 읽어서 변경하는 형태보다 한번에 1000개의 파일을 읽어서 처리한 후 1000개의 파일을 변경하는 형태가 더 SSD의 처리 효울성에는 도움이 된다.See also: 섹션 5.4SSD 드라이버의 데이터가 더이상 필요치 않아서 삭제하고자 할 때에는, 삭제 요청을 일정량 모아서 한번의 오퍼레이션으로 삭제하는 것이 좋다. 이는 SSD 컨트롤러의 Garbage-collection이 한번에 더 큰 영역을 처리할 수 있도록 해주며, 그로 인해서 SSD의 내부적인 프레그멘테이션을 최소화할 수 있다.See also: 섹션 4.4SSD 드라이브에 기록하고자 하는 데이터가 작다면(SSD의 Clustered block 보다 작은 경우), 랜덤 쓰기는 시퀀셜 쓰기보다 느리게 처리될 것이다. 만약 쓰기가 Clustered block 크기와 일치하거나 Clustered block의 크기의 N배수(정확하게)인 경우에는, 랜덤 쓰기라 하더라도 SSD의 내부 병렬 처리 능력을 활용할 수 있게 된다. 랜덤 쓰기라 하더라도 SSD의 병렬 처리 능력을 활용할 수 있다면 시퀀셜 쓰기만큼의 스루풋을 얻을 수 있다. 대 부분의 SSD 드라이브에서 Clustered block의 사이즈는 16MB에서 32MB 정도이므로, 32MB 정도의 데이터를 한번에 쓰기할 수 있으면 최적의 쓰기 성능을 얻을 수 있다.See also: 섹션 5.2동시에 여러 쓰레드로 실행되는 읽기 요청은 SSD 드라이브의 Readahead 메커니즘을 100% 활용하기 어렵다. 게다가 한번에 여러 논리 블록 주소를 액세스하는 것은 결국 하나의 NAND 플래시 칩으로 집중될 수 있고, 이런 경우에는 SSD의 내부 병렬 처리 능력을 활용하지 못하게 된다. 연속된 블록을 대용량으로 읽는 오퍼레이션은 SSD 드라이브의 Readahead 버퍼를 활용(SSD 드라이브가 Readahead cache를 가지고 있는 경우)할 수 있으며, 또한 내부적인 병렬 처리 기능까지 활용할 수 있다. 결과적으로 가능하다면 요청을 버퍼링했다가 한번에 큰 데이터를 읽는 형태가 스루풋 향상에 도움이 된다.See also: 섹션 5.3단일 쓰레드로 대용량의 데이터를 쓰는 것은 많은 쓰레드로 동시에 작은 데이터를 쓰는 것 만큼의 스루풋을 얻을 수 있다. 하지만 단일 쓰레드로 대용량의 데이터를 기록하는 것이 레이턴시(응답 속도) 측면에서는 여러 쓰레드로 동시에 쓰기를 하는 것보다 빠르게 처리된다. 그래서 가능하다면, 단일 쓰레드로 대량의 데이터를 한꺼번에 기록하는 것이 좋다.See also: 섹션 5.2멀티 쓰레드로 작은 데이터를 아주 빈번하게 쓰기 요청을 실행하는 것은 단일 쓰레드로 작은 쓰기를 실행하는 것보다는 더 나은 스루풋을 낼 것이다. 그래서 작은 데이터 쓰기가 배치 형태로 묶어서 처리될 수 없다면, 멀티 쓰레드로 쓰기를 실행하는 것이 좋다.See also: 섹션 5.2핫(Hot) 데이터는 빈번하게 읽고 변경되는 데이터를 의미하며, 반대로 콜드(Cold) 데이터는 그렇지 않은 데이터를 말한다. 만약 핫 데이터가 콜드 데이터와 함께 동일 페이지에 저장되어 있다면, 콜드 데이터는 핫 데이터가 Read-modify-write 형태로 변경될 때마다 항상 같이 복사되어야하며 또한 Wear-leveling을 위해서 Garbage-collection이 해당 페이지를 이동시킬 때에도 동일하게 콜드 데이터가 항상 같이 다른 페이지로 이동되어야 한다. 콜드 데이터와 핫 데이터를 분리하는 것은 Garbage-collection이 좀 더 빠르고 효율적으로 처리될 수 있도록 도와줄 것이다.See also: 섹션 4.4매우 빈번하게 변경되는 핫 데이터나 메타 데이터는 최대한 시스템의 메모리에 캐시되거나 버퍼링될 수 있도록 유지하고, SSD 드라이브에 변경되는 빈도를 최소화해주는 것이 좋다.See also: 섹션 4.4최근의 SSD 드라이버는 일반적으로  SATA 3.0(550MB/s)과 PCI Express 3.0(채널당 1GB/s, 모델별 차이는 있지만 일반적으로는 다중 채널 채택)을 지원하고 있다. SAS(Serial Attached SCSI) 인터페이스는 일부 엔터프라이즈 SSD 모델에 장착되긴 하지만, 일반적이지는 않다. 최근 버전에서는 PCI Express와 SAS 인터페이스가 SATA 보다는 훨씬 뛰어난 전송 속도를 보이지만, 조금 비싼 편이다.See also: 섹션 2.1SSD 드라이브는 최대 물리 용량보다 더 작은 용량으로 파티션을 생성함으로써 Over-provisioning 공간을 할당할 수 있다. 남은 공간은 사용자나 호스트에게는 보이지 않지만 SSD 컨트롤러는 여전히 남은 물리 공간을 활용할 수 있다. Over-provisioning 공간은 NAND 플래시 셀의 제한된 수명을 극복하기 위한 Wear-leveling이 좀 더 원활하게 처리될 수 있도록 도와준다. 데이터 쓰기가 아주 빈번한 경우에는 성능 향상을 위해서 전체 용량의 25% 정도의 공간을 Over-provisioning 공간을 할당하는 것이 좋으며, 그렇게 쓰기 부하가 심하지 않은 경우에는 10%~15% 정도의 공간을 Over-provisioning 공간으로 할당해주는 것이 좋다. Over-provisioning 공간은 NAND 플래시 블록의 버퍼처럼 작동하기도 하는데, 이는 일시적으로 평상시보다 높은 쓰기 부하가 발생하더라도 Garbage-collection이 충분한 “free” 상태 페이지를 만들어 낼수 있도록 완충 역할을 해준다.See also: 섹션 5.2운영 체제의 커널과 파일 시스템이 TRIM 명령을 지원하는지 확인하도록 하자. TRIM 명령은 운영 체제나 파일 시스템 레벨에서 삭제된 블록의 정보를 SSD 컨트롤러에게 알려주는 역할을 한다. SSD 컨트롤러는 새로운 쓰기 요청들을 위해서, 시스템이 한가한 시간에 Garbage-collection을 실행하는데, TRIM 명령으로 삭제된 블록 정보를 SSD 컨트롤러가 받을 수 있으면 Garbage-collection의 삭제(Erase) 작업이 훨씬 효율적으로 처리될 수 있다.See also: 섹션 5.1쓰기 요청이 NAND 플래시의 물리 메모리와 맞춰지려면(Alignment), SSD 드라이브를 파티셔닝하고 포맷할때 NAND 플래시의 페이지 크기와 일치(Align)시켜야 한다.See also: 섹션 5.1지금까지 “Coding for SSDs” 시리즈의 내용을 간단히 요약했다. SSD에 대한 개인적인 연구를 통해 배운 것들을 누구나 쉽게 이해할 수 있도록 전달되었기를 희망한다. 이 시리즈를 읽고 더 상세히 SSD에 대해서 공부하기를 원한다면, 챕터 2부터 5까지의 게시물 하단에 냐열된 레퍼런스 문서들은 아마도 훌륭한 가이드가 될 수 있을 것으로 생각한다. USENIX에서도 매년 SSD에 관련된 놀라운 연구들이 진행되고 있으므로, USENIX FAST 컨퍼런스(파일시스템과 스토리지 기술에 관련된 USENIX 컨퍼런스) 웹 사이트도 많은 도움이 될 것을 생각된다.This articles are translated to Korean with original author’s(Emmanuel Goossaert) permission. Really appreciate his effort and sharing.Original articles :",http://tech.kakao.com/2016/07/18/coding-for-ssd-part-6/,0,kakao,,NULL,2016-07-18
개발자를 위한 SSD (Coding for SSD) - Part 5 : 접근 방법과 시스템 최적화,"지금까지 SSD 드라이브의 내부적인 작동 방식에 대해서 살펴 보았다. 또한 SSD를 접근할 때 어떤 방식이 사용되어야 하며, 그리고 그 접근 방법이 다른 방법보다 왜 나은지 등의 이해를 돕는 자료들도 제공했다. 이번 챕터에서는 읽기와 쓰기는 어떻게 처리되어야 하는지, 그리고 읽고 쓰기가 동시에 발생할 때 서로 어떤 간섭 효과를 내게 되는지를 살펴보도록 하겠다. 그리고 성능 향상을 위해서 파일 시스템 레벨에서 가능한 최적화에 대해서도 조금 언급하도록 하겠다이번 섹션에서 사용되는 시퀀셜(“sequential”)과 랜덤(“random”)이라는 단어로 SSD 액세스를 의미한다. 이전 I/O 오퍼레이션의 마지막 논리 블록 주소(LBA) 직후의 논리 블록 주소(LBA)를 시작 지점으로 SSD를 접근하는 경우 시퀀셜이며, 그렇지 않은 경우를 랜덤이라고 한다. 그리고 FTL에 의해서 동적으로 블록 맵핑이 실행되기 때문에, 논리 주소가 연속적이라고 해서 실제 물리적인 데이터의 위치가 연속적인 것은 아닐 수도 있다는 것도 기억해두자.벤치마킹과 제조사의 데이터 시트를 보면, 랜덤 쓰기는 시퀀셜 쓰기보다 느리다는 것을 알 수 있다. 물론 이건 정확하게 랜덤 쓰기의 워크로드가 어떠냐에 따라서 틀린 이야기일 수도 있다. 하지만 쓰기 데이터가 작다면(여기에서 작은 데이터의 기준은 Clustered block의 크기보다 작은 것을 의미하며, 예를 들어서 32MB 미만 정도로 생각할 수 있다), 데이터 시트나 벤치마킹의 결과에서와 같이 랜덤 쓰기는 시퀀셜 쓰기보다 느리다. 그러나 Clustered block의 크기 또는 그 배수의 데이터를 랜덤으로 쓰기한다면, 시퀀셜 쓰기와 거의 비슷한 수준의 성능을 내게 된다. 섹션 6에서 본 것과 같이 SSD의 내부 병렬 처리는 최소 하나의 Clustered block이 처리될 때 최대 처리 능력을 보여주기 때문이다. 그래서 이렇게 대량의 데이터를 기록하는 경우에는 시퀀셜이든지 랜덤이든지, 내부적으로 여러 채널과 여러 칩을 사용하는 내부 병렬 처리 방식은 동일하게 사용된다(데이터가 여러 채널과 여러 칩으로 스트라이핑되는 것이다). 또한 이 경우 SSD가 지원하는 내부적인 병렬 처리 능력들을 모두 활용하게 되는 것이다. Clustered block의 쓰기 오퍼레이션은 섹션 7.3에서 다시 살펴보도록 하겠다. 지금은 성능적인 측면에서 (그림 8과 9) 쓰기 버퍼의 크기가 Clustered block(일반적인 SSD에서는 16MB 또는 32MB)에 가까워지거나 더 커지면서 랜덤 쓰기의 스루풋이 시퀀셜 쓰기와 비슷해지는 것을 확인할 수 있다. (출처: 2012년 김 재홍 외 1) (출처: 2012년 민 창우 외 2)하지만 쓰기가 작다면(여기에서 작다는 것은 NAND 플래시 페이지의 크기보다 작은 16KB 미만을 의미), 컨트롤러는 블록 맵핑을 위한 메타 데이터 관리를 위해서 더 많은 일을 해야 한다. 일부 SSD 드라이브는 논리 블록 주소와 물리 블록 주소의 맵핑을 위해서 트리 형태의 데이터 구조체를 사용한다3. 그리고 작고 빈번한 랜덤 쓰기는 SSD 드라이브의 메모리(RAM)의 맵핑 테이블을 매우 빈번하게 업데이트해야 함을 의미한다. 그리고 메모리의 맵핑 테이블은 플래시 메모리로 동기화되어야 하는데3 4, 메모리의 모든 업데이트는 플래시 메모리의 많은 쓰기를 발생시킨다. 하지만 시퀀셜 쓰기는 메타 데이터의 변경을 덜 필요로 하기 때문에 플래시 메모리에 동기화하는 회수도 줄어들게 된다.만약 쓰기가 Clustered block의 크기보다 작다면, 랜덤 쓰기는 시퀀셜 쓰기보다 느릴 것이다. 하지만 쓰기가 Clustered block과 동일하거나 배수 크기의 데이터를 기록한다면, 랜덤 쓰기도 SSD의 모든 병렬 처리 능력을 활용하게 되며 그로 인해서 시퀀셜 쓰기와 비슷한 스루풋을 낼 수 있게 된다.랜덤 쓰기의 데이터 크기가 작으면 시퀀셜보다 스루풋이 떨어지는 또 다른 이유로는 블록의 “copy-erase-write” 오퍼레이션이 많이 발생하기 때문이다. 반면 최소 블록 크기의 데이터를 저장하는 시퀀셜 쓰기는 빠른 “switch-merge” 최적화가 사용될 수 있다. 게다가 작은 랜덤 쓰기는 데이터를 랜덤하게 무효화하기 때문에, 최악의 경우 많은 블록들이 단 하나의 무효화된 페이지를 가지게 된다. 이는 “stale” 페이지들이 일부 영역에 집중화(localizing)되는 것이 아니라, 전체 물리 공간에 골고루 퍼뜨리는 효과를 내게 되는데 이를 “내부 프레그멘테이션(internal fragmentation)”이라고 한다. 내부 프레그멘테이션은 Garbage-collection이 “free” 페이지를 만들어내기 위해서 많은 블록 삭제(Erase)를 실행하게 만드는 “Cleaning efficiency”를 유발하게 된다.마지막으로 동시성 측면에서 보면, 하나의 쓰레드에서 대량의 버퍼를 기록하는 것은 많은 쓰레드가 동시에 작은 데이터를 쓰기하는 것만큼 빠르다. 단일 쓰레드로 대량 데이터 쓰기시에는 SSD의 내부 병렬 처리 능력을 모두 활용할 수 있기 때문이다. 그래서 여러 쓰레드로 동시에 병렬로 데이터 쓰기를 실행하는 것은 SSD 드라이브의 스루풋을 향상시키지 못한다3 4. 역으로 많은 동시 쓰레드가 데이터를 쓰기하는 것은 단일 쓰레드 쓰기보다 레이턴시를 증가시키는 역 효과만 낳게 될 것이다5 6 7.하나의 큰 쓰기 요청은 병렬로 실행되는 많은 작은 쓰기 요청만큼의 스루풋을 낼 수 있다. 하지만 레이턴시 측면에서 보면, 하나의 큰 쓰기 요청은 많은 쓰기 요청보다 더 나은 응답 속도를 보장받을 수 있다. 그래서 가능하다면 큰 데이터를 한번에 기록하는 것이 좋다.많은 동시 쓰레드로 작은 쓰기 요청은 하나의 작은 쓰기 요청보다 나은 스루풋을 제공한다. 만약 I/O 데이터가 작고 버퍼링 또는 배치로 묶을 수 없다면 멀티 쓰레드로 쓰기를 수행하는 것이 좋다.읽기는 쓰기보다 빠른다. 시퀀셜 읽기와 랜덤 읽기의 성능은 워크로드에 의존적이다. FTL은 논리 블록과 물리 블록을 동적으로 맵핑하며, 쓰기를 여러 채널로 스트라이핑해준다. 이 방법을 때로는 “Write-order-based” 맵핑이라고도 한다5. 만약 처음 데이터가 기록되던 순서와는 무관하게 완전히 랜덤하게 데이터 읽기 요청이 발생한다면, 설령 읽기 요청이 연속적이라 하더라도 여러 채널로 분산되어 처리된다는 것을 보장할 수 없다. 연속적인 랜덤 읽기가 하나의 채널에 연결된 다른 블록들을 액세스할 수도 있으며, 이런 경우에는 SSD의 내부적인 병렬 처리 능력을 활용하지 못하게 되는 것이다. Acunu는 그의 블로그8에서, 읽기 성능은 데이터의 읽기 패턴이 얼마나 쓰기 패턴과 일치하느냐에 직접적으로 연결된다고 언급하고 있다.읽기 성능은 쓰기 패턴의 결과이다. 대량의 데이터가 한번에 기록된다면, 그 데이터는 NAND 플래시 칩에 골고루 분산되어서 저장될 것이다. 그래서 연관된 데이터들은 최대한 동일 페이지와 블록 그리고 클러스터링 블록에 기록되도록 하는 것이 좋다. 그래야지만 SSD의 병렬 처리 능력을 이용해서 나중에 한번의 I/O로 빠르게 읽을 수 있다.아래의 그림 10은 하나의 플레인을 가진 칩이 4개 그리고 2개의 채널을 가진 SSD를 보여주고 있다. 참고로 대 부분의 SSD는 항상 하나의 칩당 2개 또는 그 이상의 플레인을 가지고 있는데, 여기에서는 설명의 단순화를 위해서 칩당 하나의 플레인만 있는 그림을 그렸다. 대문자는 NAND 플래시 블록 크기의 데이터를 의미한다. 그림 10의 최 상단에 표시된 오퍼레이션은 [A B C D] 데이터를 시퀀셜하게 쓰는 것을 의미하는데, 여기에서는 Clustered block의 사이즈이다. 쓰기 오퍼레이션은 빠른 처리를 위해서 병렬 처리와 인터리빙 모드를 이용해서 4개의 플레인으로 스트라이핑된다. 4개의 블록은 논리 블록 주소상으로는 연속되게 시퀀셜하지만, 실제 내부적으로는 각각의 플레인에 저장된다. “Write-order-based” FTL에서는, 플레인의 모든 블록은 동등하게 유입된 쓰기를 처리하게 된다. 그래서 Clustered block은 플레인의 동일한 PBN을 가질 필요가 없다. 예를 들어서 그림 10에서는, 첫 Clustered block은 4개의 서로 다른 플레인에 속한 블록에 저장되며, 각 플레인에서의 PBN은 1, 23, 11 그리고 51을 갖게 된다.그림 10의 하단에는 2번의 읽기 오퍼레이션을 보여주고 있는데, [A B E F]와 [A B G H] 데이터를 읽고 있다. [A B E F] 읽기를 위해서, A와 E는 동일 플레인에 속해 있으며, B와 F는 다른 플레인에 속해 있다. 그래서 [A B E F]는 하나의 채널을 통해서 2개의 플레인으로부터 읽게 된다. [A B G H] 읽기에서, A와 B 그리고 G와 H는 모두 각각 다른 플레인에 저장되어 있기 때문에 [A B G H]는 2개의 채널을 이용해서 4개의 플레인으로부터 동시에 읽을 수 있다. 데이터를 읽을 때, 더 많은 채널과 플레인을 이용할 수 있다는 것은 좀 더 내부 동시성 처리 기능을 활용할 수 있음을 의미하며 더 나은 읽기 성능을 보장받을 수 있게 된다.내부적인 병렬 처리로 인해서, 성능 향상을 위해서 멀티 쓰레드를 이용하여 동시에 데이터를 읽지 않아도 된다. 쓰레드는 읽고자 하는 데이터의 내부적인 맵핑 정보를 알지 못하기 때문에 내부적인 병렬 처리의 효과를 활용할 수가 없고 결국 동일 채널의 데이터를 이용하게 될 가능성도 있다. 또한 멀티 쓰레드로 동시에 데이터를 읽게 되면, SSD의 Read ahead (Prefetching buffer) 효과를 저해할 수도 있다는 게시물도 있다5.동시 랜덤 읽기는 SSD의 Read ahead 메커니즘을 제대로 활용하지 못할 수도 있다. 또한 다중으로 논리 블록 주소를 액세스하는 것은 내부적인 병렬 처리 기능을 활용하지 못하고 결국 동일 칩으로 집중되어 버릴 수도 있다. 게다가 대량 데이터 읽기 오퍼레이션은 연속된 주소를 액세스함으로써 Read ahead 버퍼(Read ahead 버퍼가 있다면)를 활용할 수 있다. 결과적으로 한번에 대량의 데이터를 읽는 방법이 추천된다.SSD 제조사는 일반적으로 페이지나 블록 그리고 Clustered block의 크기에 대해서는 공개하지 않는다. 그러나 단순한 테스트1 5를 통해서 SSD의 기본적인 특성을 상당한 확률로 알아낼 수 있다. 이러한 정보는 데이터를 읽고 쓸 때 버퍼의 크기를 최적화하는데 활용할 수 있으며, 해당 SSD의 특성에 맞게 포맷시에 파티션을 얼라인(Align)할 수도 있다. 이런 내용은 섹션 8.4를 참조하도록 하자.작은 데이터를 읽고 쓰기는 작업이 동시에 발생하게 되면 성능 저하를 유발할 수 있다3 5. 동일 내부 자원을 위해서 읽고 쓰기가 경합을 할 수 있기 때문이다. 또한 읽기와 쓰기를 혼합하면 Read ahead와 같은 내부 최적화 메커니즘을 활용하지 못하게 만들기도 한다.작은 읽기와 쓰기가 혼합되어 동시에 실행되는 워크로드는 내부적인 캐싱이나 Read ahead 메커니즘이 제대로 활용되지 못하게 만들어서 전체적인 스루풋을 떨어뜨리게 된다. 동시에 읽고 쓰기 요청을 실행하는 것은 피하고 하나씩 큰 용량의 청크(Clsutered block 크기)를 읽고 쓰도록 하는 것이 좋다. 예를 들어서 1000개의 파일이 업데이트 되어야 한다면, 파일을 한 개씩 루프로 읽고 쓰는 형태로 처리할 수도 있다. 하지만 이런 방법은 느리게 처리될 것이다. 가능하다면 한번에 1000개의 파일을 한번에 읽고 그 다음에 1000개의 파일을 한번에 업데이트하도록 하는 것이 좋다.섹션 3.1에서 설명된 바와 같이, 쓰기는 페이지의 크기에 맞춰서 실행된다. 페이지의 크기에 맞춰서 쓰기 요청된 데이터는 NAND 플래시의 물리 페이지에 바로(Read-modify-write 과정 없이) 기록될 수 있다. 기록하는 데이터가 SSD 페이지 크기라 하더라도, 물리 페이지와 맞춰지지(Alignment) 않은 쓰기는 2개의 NAND 플래시 물리 페이지에 기록되어야 한다. 이런 현상이 생기면, SSD 드라이브는 두번의 “Read-modify-write” 오퍼레이션을 수행해야 한다9. 그래서 SSD 드라이브의 쓰기에서 사용되는 파티션이 NAND 플래시 페이지 사이즈와 물리적으로 맞춰졌는지(Align)는 매우 중요한 요소이다. 여러 가이드 문서와 튜토리얼에서 SSD 드라이브를 포맷할 때 어떻게 파티션 파라미터를 설정하는지 소개되고 있다10 11. 구글에서 검색해보면 특정 SSD 드라이브 모델의 페이지와 블록 사이즈 그리고 Clustered block의 크기를 확인할 수 있다. 만약 이런 정보들이 구글 검색으로 확인이 안될 경우에는, 리버스 엔지니어링을 통해서 이런 파라미터 값들을 확인할 수 있다1 5. 파티션 얼라인먼트를 통해서 성능을 상당히 끌어올릴 수 있다는12 것은 이미 여러 문서12에서 확인되었다. 또한 크진 않지만, 파일 시스템을 건너뛰어서 SSD 드라이브에 직접 쓰기를 실행하는 경우에도 성능 향상을 기대할 수 있다13.SSD 플래시 메모리와 논리적인 쓰기가 정확하게 맞춰지도록 하기 위해서, 반드시 파티션이 NAND 플래시 메모리의 페이지와 맞춰지도록(Align) 포맷해야 한다.섹션 5.1에서 소개되었듯이, 모든 파일 시스템이 TRIM 명령14을 지원하는 것은 아니다. 리눅스 2.6.33 또는 그 이상의 버전에서 ext4와 XFS 파일 시스템만 TRIM 명령을 지원하는데, 이때에도 discard 마운트 옵션이 활성화되어야 한다. 또한 파티션을 마운트할 때, noatimer,nodiratime 그리고 relatime 마운트 옵션을 활성화하여 파일의 메타 정보 업데이트를 하지 않도록 해서 성능 향상을 기대할 수도 있다 (물론 메타 정보 업데이트가 불필요한 경우에만) 15 11 16 17.파일 시스템과 리눅스 커널이 TRIM 명령을 지원하는지 확인하도록 하자. TRIM 명령은 호스트에서 블록이 삭제되는 경우에, 그 삭제 블록 정보를 SSD 드라이브로 전달해주는 역할을 하며, 이렇게 삭제 블록 정보를 SSD 컨트롤러가 알게 되면 Garbage-collection에서는 삭제된 블록에 대해서 불필요한 복사 작업을 피할 수 있게 된다.리눅스의 기본 I/O 스케줄러는 CFQ(Completely Fair Queuing)이다. CFQ는 요청된 I/O를 모아서 배치로 기록하기 때문에 스피닝 HDD(Spinning hard disk)의 seek-time을 최소화 해준다. SSD 드라이브는 기계적인 장치가 아니기 때문에, 이런 형태의 I/O 요청의 재 정렬(Re-ordering)은 필요치 않다. 많은 가이드 문서와 토론 사이트에서는 I/O 스케줄러를 CFG에서 NOOP이나 Deadline으로 변경하는 것이 SSD의 레이턴시를 줄여줄 것이라고 말하고 있다.16 18. 하지만 리눅스 버전 3.1부터, CFQ는 SSD 드라이브를 위한 어느 정도의 최적화 알고리즘을 가지고 있다19. SSD로 주어지는 워크로드에 따라서 I/O 스케줄러별 성능 차이를 보여주는 벤치마크 자료들도 있다15 20 21 22. 개인적인 생각으로는 워크로드가 아주 특별하지 않고 실제 응용 프로그램 벤치마킹 테스트에서 다른 I/O 스케줄러가 더 나은 성능을 보여주는 것이 아니라면, 굳이 CFQ 스케줄러에서 NOOP이나 Deadline으로 바꿀 필요는 없어 보인다.Swap이 자주 사용되는 경우에는 많은 I/O 요청이 발생하기 때문에, SSD 드라이브에 스왑 파티션이 있는 경우 SSD의 랜덤 쓰기가 자주 발생하며 그로 인해서 수명이 훨씬 더 빨리 줄어들 수 있다. 리눅스 커널에서는 vm.swappiness 커널 파라미터를 기준으로 얼마나 자주 페이지들을 디스크로 스왑할지를 결정한다. vm.swappiness 값으 0부터 100까지 설정할 수 있는데, 0은 커널이 최대한 스왑을 하지 않도록 하며 100은 최대한 커널이 디스크의 스왑 영역을 사용하도록 유도한다. 예를 들어 Ubuntu에서는 vm.swappiness 기본 값이 60이다. SSD 드라이브를 사용하는 경우에는 vm.swappiness 값을 최대한 낮은 값으로 설정하여 SSD로 기록되는 데이터를 최소화하여 SSD 드라이브의 수명을 늘리는 것이 좋다16 23. 어떤 가이드에서는 vm.swappiness 값으로 1을 추천하는데, 실질적으로 1은 0과 동일한 효과를 낸다17 18.굳이 디스크에 기록되지 않아도 되는 모든 임시 파일들과 로그 파일들은 SSD 드라이브의 P/E cycle을 낭비하는 것이다. 그러한 파일들은 가능하다면 RAM을 이용한 tmpfs 파일 시스템으로 유도하도록 하자16 17 18.This articles are translated to Korean with original author’s(Emmanuel Goossaert) permission. Really appreciate his effort and sharing.Original articles : Parameter-Aware I/O Management for Solid State Disks (SSDs), Kim et al., 2012 ↩ ↩2 ↩3 SFS: Random Write Considered Harmful in Solid State Drives, Min et al., 2012 ↩ Understanding Intrinsic Characteristics and System Implications of Flash Memory based Solid State Drives, Chen et al., 2009 ↩ ↩2 ↩3 ↩4 Design Tradeoffs for SSD Performance, Agrawal et al., 2008 ↩ ↩2 Essential roles of exploiting internal parallelism of flash memory based solid state drives in high-speed data processing, Chen et al, 2011 ↩ ↩2 ↩3 ↩4 ↩5 ↩6 http://www.storagereview.com/samsung_ssd_840_pro_review ↩ http://www.storagereview.com/micron_p420m_enterprise_pcie_ssd_review ↩ http://www.acunu.com/2/post/2011/08/why-theory-fails-for-ssds.html ↩ http://blog.nuclex-games.com/2009/12/aligning-an-ssd-on-linux/ ↩ http://www.linux-mag.com/id/8397/ ↩ http://tytso.livejournal.com/2009/02/20/ ↩ ↩2 http://rethinkdb.com/blog/page-alignment-on-ssds/ ↩ ↩2 http://rethinkdb.com/blog/more-on-alignment-ext2-and-partitioning-on-ssds/ ↩ http://en.wikipedia.org/wiki/Trim_(computing) ↩ http://superuser.com/questions/228657/which-linux-filesystem-works-best-with-ssd/ ↩ ↩2 https://wiki.debian.org/SSDOptimization ↩ ↩2 ↩3 ↩4 http://wiki.gentoo.org/wiki/SSD ↩ ↩2 ↩3 https://wiki.archlinux.org/index.php/Solid_State_Drives ↩ ↩2 ↩3 https://www.kernel.org/doc/Documentation/block/cfq-iosched.txt ↩ http://www.danielscottlawrence.com/blog/should_i_change_my_disk_scheduler_to_use_NOOP.html ↩ http://www.phoronix.com/scan.php?page=article&item=linux_iosched_2012 ↩ http://www.velobit.com/storage-performance-blog/bid/126135/Effects-Of-Linux-IO-Scheduler-On-SSD-Performance ↩ http://www.axpad.com/blog/301 ↩",http://tech.kakao.com/2016/07/17/coding-for-ssd-part-5/,0,kakao,,NULL,2016-07-17
개발자를 위한 SSD (Coding for SSD) - Part 4 : 고급 기능과 내부 병렬 처리,"이번 챕터에서는 SSD의 주요 기능인 TRIM과 Over-provisioning에 대해서 간단히 살펴보도록 하겠다. 또한 SSD의 내부 병렬 처리와 클러스터링 블록에 대해서도 같이 살펴보도록 하겠다.용응 프로그램이 SSD의 모든 논리 블록 주소에 파일을 기록했다고 가정해보자. 그러면 SSD는 풀(full)로 사용되었다고 생각될 수 있다. 이제 이 모든 파일들이 지워졌다고 가정해보자. 파일 시스템은 SSD가 100% 비어 있다고 보지만, SSD 컨트롤러는 호스트로부터 삭제된 논리 블록의 주소를 알지 못하기 때문에 실제 SSD 드라이브는 여전히 100% 사용중이라고 생각하게 된다. SSD 컨트롤러는 호스트의 파일 시스템으로부터 덮어 쓰기 명령이 전달될 때에만 그 영역이 빈 공간이라고 판단할 수 있게 되는 것이다.이때 Garbage-collection 프로세스는 삭제된 파일과 연관된 블록들을 지울(Erase) 것이다. 결과적으로 블록이 “stale” 데이터를 가지고 있다는 것을 알아내는 순간 삭제(Erase)하는 대신 지연 처리되는 것인데, 이는 성능을 심각하게 떨어뜨리게 된다. 또 다른 우려 사항은 삭제된 파일들을 SSD 컨트롤러는 모르기 때문에, Garbage-collection은 Wear leveling을 위해서 매번 삭제된 파일들의 데이터도 계속 복사해서 새로운 페이지로 저장해야 한다. 이는 SSD의 Write Amplication을 더 높이게 되고, 호스트의 포그라운드 워크로드의 처리를 방해하게 된다.지연된 삭제(Erase)로 인한 문제점을 해결하기 위한 방법이 TRIM 명령이다. TRIM 명령은 운영 체제에서 의해서 해당 논리 공간이 더 이상 필요치 않다는 메시지를 SSD 컨트롤러로 전달해 주는 것이다. 이렇게 SSD 컨트롤러가 불필요한 블록들에 대한 정보를 가지고 있다면, Garbage-collection 프로세스는 더 이상 불필요한 페이지들을 복사해서 이동하지 않아도 되며 언제든지 필요할 때 삭제(Erase)할 수 있게 되는 것이다. TRIM 명령은 SSD 컨트롤러와 운영 체제 그리고 파일 시스템 3가지 컴포넌트가 모두 TRIM을 지원할 때에만 사용 가능하다.TRIM 명령의 위키피디아 페이지1에는 TRIM 명령을 지원하는 운영 체제와 파일 시스템의 목록을 나열하고 있다. ATA TRIM 명령은 리눅스 커널 2.6.33 버전부터 지원되기 시작했다. 하지만 ext2와 ext3 파일 시스템은 여전히 TRIM 명령을 지원하지 않으며, ext4와 XFS 파일 시스템은 TRIM 명령을 지원한다. Mac OS 10.6.8 그리고 HFS+ 파일 시스템은 TRIM 명령을 지원하며, 윈도우 7에서는 SATA 인터페이스를 사용하는 SSD에서만 TRIM 명령을 지원하며 PCI Express 인터페이스에서는 지원하지 않는다.대 부분의 SSD 드라이브는 TRIM 명령을 지원하며, 앞으로의 쓰기 성능 향상을 위해서 Garbage-collection이 최대한 빨리 처리되도록 해줄 것이다. 그래서 가능하다면 TRIM이 지원되는 SSD를 사용할 것을 권장하며, 또한 운영 체제와 파일 시스템 레벨에서 TRIM이 가능하도록 준비하는 것이 좋다.Over-provisioning은 단순히 논리적인 블록보다 물리적인 블록의 수가 더 많도록 해주는 것인데, 일정 비율의 물리 블록을 SSD 컨트롤러는 볼 수 있지만 운영 체제나 파일 시스템은 보지 못하도록 예약해두는 것이다. 전문 SSD 제조사는 이미 7 ~ 25% 정도의 Over-provisioning 공간을 보유하고 있으며2, 사용자는 단순히 가능한 물리 공간의 크기보다 작은 크기로 파티셔닝함으로써 더 많은 Over-provisioning 공간을 생성할 수 있다. 예를 들어서, 100GB SSD 드라이브에 90GB 파티션을 생성하면 나머지 10GB는 자동으로 Over-provisioning 공간으로 남겨지는 것이다. Over-provisioning 공간은 운영 체제 레벨에서는 보이지 않더라도, SSD 컨트롤러는 여전히 그 공간을 볼 수 있고 사용할 수 있다. SSD 제조사가 Over-provisioning 공간을 제공하는 주된 이유는 NAND 플래시 셀의 제한된 수명 주기를 극복하는 것이다. 보이지 않는 Over-provisioning 블록은 운영 체제에 보여지는 공간의 블록들이 수명이 다 되는 경우에 자동으로 대체되어서 사용된다.AnandTech는 Over-provisioning 공간이 SSD의 성능과 수명에 미치는 영향을 보여주는 재미있는 게시물3을 공개했다. 그들의 연구에 따르면 드라이브 공간의 25%를 Over-provisioning 공간으로 예약해 두면 엄청난 성능 향상을 얻을 수 있다는 것이다. 또 다른 재미있는 게시물을 Percona에서도 공개했는데, Intel 320 SSD로 테스트한 결과 SSD의 공간 사용률이 높아질수록 쓰기 스루풋은 점점 떨어진다는 것4이다.왜 이런 현상이 발생하는 것일까? Garbage-collection은 “stale” 페이지를 삭제(Erase)하기 위해서 백그라운드로 SSD 드라이브가 한가한 시간을 이용한다. 삭제(Erase) 오퍼레이션은 일반적인 데이터 쓰기보다 느리게 실행되므로 SSD가 지속적으로 과도한 랜덤 쓰기 부하가 있는 시스템에서는 Garbage-collection이 “stale” 페이지를 삭제(Erase)하기도 전에 “free” 페이지를 모두 소진해버리게 되는 것이다. 이때 FTL은 포그라운드의 랜덤 쓰기를 따라가지 못하고, Garbage-collection 프로세스는 호스트로부터 포그라운드 쓰기 요청이 들어오면 그때 동시에 삭제(Erase) 작업을 같이 하게 된다. 아래 그림 7에서 보여지는 바와 같이 벤치마킹의 결과에서 성능이 급격하게 떨어지는 것을 확인할 수 있다. 그래서 Over-provisioning 공간은 많은 쓰기 워크로드를 흡수해주는 버퍼 공간으로 작동하게 되는 것이다. 그리고 이 버퍼가 Garbage-collection이 워크로드를 따라잡을 수 있도록 충분한 시간을 만들어주는 것이다. 충분한 크기의 Over-provisioning 공간은 SSD가 사용되는 시스템의 워크로드에 따라 다른데, 일반적으로 지속적인 랜덤 쓰기 워크로드 환경에서는 25% 정도의 Over-provisioning 공간이 권장3된다. 만약 워크로드가 그렇게 무겁지 않다면, 10 ~ 15% 정도의 Over-provisioning 공간으로도 충분할 수 있다.SSD 드라이브는 단순히 물리적인 공간보다 더 적은 크기로 논리적인 공간을 설정(포맷)하면 Over-provisioning 공간을 만들 수 있다. 남은 공간은 사용자에게는 보이지 않지만, SSD 컨트롤러는 여전히 그 공간을 사용할 수 있다. Over-provisioning은 NAND 플래시 셀의 제한된 수명을 극복하기 위한 Wear-leveling 메커니즘에도 도움이 된다. 쓰기 부하가 그렇게 심하지 않은 경우에는 10 ~ 15% 정도의 Over-provisioning 공간으로도 충분하다. 하지만 지속적인 랜덤 쓰기가 과도하게 발생하는 경우에는 25% 정도의 Over-provisioning 공간이 성능을 향상시켜 줄 것이다. Over-provisioning 공간은 NAND 플래시 블록의 버퍼처럼 작동하기 때문에, 쓰기가 포화(Write saturation)되는 시점에도 Garbage-collection이 과도한 쓰기를 견딜 수 있도록 해준다.Over-provisioning은 TRIM 명령이 지원되지 않는 경우에도 성능 향상을 제공할 것으로 예상(이는 단순히 나의 추측이며, 이를 증명할만한 문서는 찾지 못했다)할 수 있다. 75%의 공간만 운영 체제가 사용하며 나머지 25%의 공간이 Over-provisioning으로 설정된 시스템을 가정해보자. SSD 컨트롤러는 전체 공간을 모두 사용할 수 있기 때문에 돌아가면서 이 100%의 공간이 사용되었다가 삭제될 것이다. 하지만 어느 한 순간에는 75%의 NAND 플래시 메모리 공간만 사용될 것이다. 이는 나머지 25%의 물리 메모리 공간은 실제 논리 블록 주소와 맵핑되어 있지 않기 때문에, SSD 컨트롤러는 안전하게 해당 영역이 데이터를 가지고 있지 않다고 판단할 수 있게 되는 것이다. 그래서 Over-provisioning 공간에 대해서는 미리 Garbage-collection을 처리할 수 있으며, 이는 TRIM 명령이 지원되지 않는다 하더라도 TRIM의 효과를 낼 수 있게 되는 것이다.일부 SSD 컨트롤러는 ATA Secure Erase 기능을 제공하는데, 이는 사용자가 기록했던 모든 데이터를 삭제하고 FTL 맵핑 테이블을 초기화함으로써 SSD 드라이브를 초기 상태로 만들어서 성능을 회복(초기 상태로)시키는 것이 주요 목적이다. 하지만 ATA Secure Erase 기능이 NAND 플래시 메모리 셀의 P/E Cycle 한계를 초기화 시켜주는 것은 아니다. 이 기능은 스펙상으로는 상당히 기대되는 기능이지만, 이는 제조사의 기능 구현이 얼마나 정확한지에 따라 다르다. 2011년 Wei(외 여러 연구원)은 12개 모델의 SSD에 대한 조사 결과, 단지 8개 모델만 ATA Secure Erase 기능을 제공했으며 이중에서 3개 모델은 잘못된 방식(Buggy implementation)으로 구현되어 있었다5.성능과 관련된 사항은 중요하다. 하지만 보안과 관련된 문제는 더 중요하다. 그렇지만 보안과 관련된 사항은 이 문서의 주제와는 거리가 있다. SSD의 데이터를 좀 더 신뢰성 있게 삭제(Erase)하는 방법에 대한 Stack Overflow 토의6 7들이 있으니, 더 자세한 내용은 이 게시물들을 참조하도록 하자.NCQ(Native Command Queueing)는 SSD 드라이브가 내부적인 병렬 처리 능력을 이용해서 동시에 여러 호스트 명령을 처리할 수 있도록 해주는 Serial ATA의 기능이다8. SSD 드라이브의 낮은 레이턴시에 더불어 최신의 SSD 드라이브는 호스트로부터의 레이턴시를 극복하기 위해서 NCQ를 사용한다. 예를 들어서 NCQ는 호스트 CPU가 바쁠때에는 드라이버가 항상 명령을 처리할 수 있도록 유입되는 명령의 우선순위를 높여줄 수 있다9. 빠른 응답 속도를 위해서 새로운 드라이브는 NCQ를 사용하는데, NCQ는 호스트의 명령을 큐잉하여 우선순위를 재설정하고 때로는 지연처리를 하기도 한다9.SSD 드라이브가 설치된 컴퓨터가 집에 있든지 데이터센터에 있든지 전원 실패(Power Failure, 정전)은 피할 수 없다. 일부 제조사는 SSD 드라이버에 수퍼 커패시터(Super capacity)를 포함해서, 컴퓨터의 전원 공급이 차단되었을 때 요청된 I/O를 처리할 수 있을 정도의 충분한 전원을 내장하여 항상 SSD 드라이버가 일관된 상태를 유지하도록 해준다. 하지만 문제는 모든 SSD 드라이버가 수퍼 커패시터나 전원 차단에 대한 보호 장치를 내장하고 있는 것은 아니며, SSD 드라이브의 제품 소개서에 항상 명시하는 것도 아니다. Secure Erase 기능과 같이 전원 보호 장치가 제대로 구현되었는지 명확하지 않다.2013년 Zheng(외 여러 연구원)은 15개 제품의 SSD 드라이브를 테스트10했다. 다양한 전원 실패 상황으로 테스트를 진행한 결과, 15개 제품 중 13개 제품에서는 데이터 손실이 발생했으며 데이터 손상도 발생했다. Luke Kenneth Casson Leighton의 전원 실패(Power Fault) 테스트에서는 4개 제품중 3개 SSD 드라이브의 데이터가 손상되었으며, 나머지 1개(Intel SSD 드라이브)만 일관된 상태를 유지했다11.SSD는 아직은 상당히 젊은 기술이기 때문에, 전원 실패에 대한 데이터 손상 문제는 머지않아 해결될 것으로 생각된다. 하지만 현재 시점에서는 무정전 전원 장치(UPS, uninterruptible power supply)에 대한 투자는 충분히 필요할 것으로 보인다. 또한 다른 데이터 저장 솔루션과 마찬가지로 SSD도 정기적인 백업이 필요할 것으로 보인다.물리적인 한계로 인해서, 비동기 방식의 NAND 플래시 I/O 버스는 32~40MB/s의 대역폭 이상을 서비스할 수 없다12. SSD 제조사의 입장에서 성능을 향상시킬 수 있는 유일한 방법은 다수의 패키지가 병렬로 처리되거나 인터리빙(interleave) 모드로 작동하도록 설계를 변경하는 것이다. 인터리빙 모드의 자세한 설명은 Kim et al. 의 2013년 문서인 “Parameter-Aware I/O Management for Solid State Disks (SSDs)”의 2.2를 참조하도록 하자.SSD아키텍처에서 여러 레벨의 내부적인 병렬 처리 능력을 묶어서, 여러 칩에 걸쳐서 동시에 2개 이상의 블록을 액세스할 수 있다. 이렇게 동시 접근 가능한 블록을 묶어서 “Clustered block”이라고 한다. SSD 드라이버의 내부적인 병렬 처리에 관련된 상세한 내용은 이 문서의 방향은 아니지만, Clustered block과 병렬 처리의 레벨에 대해서는 간략하게 살펴보도록 하겠다. 이 주제에 관련된 더 상세한 내용에 대해서 살펴보고자 한다면, 이 두개13 8의 문서를 살펴보도록 하자. 더불어 copyback 명령 및 Plane간 데이터 전송등 고급 기능에 대한 내용은 이 문서[5]를 더 참조해보자.내부적으로 여러 레벨의 병렬 처리 능력이 NAND 플래시 칩의 다른 위치에서 2개 이상의 블록을 동시에 읽을 수 있도록 해주는데, 이를 “Clustered block”이라고 한다.그림 6은 NAND 플래시 패키지들이 계층형으로 구성되어 있는 SSD 드라이브의 내부를 보여주고 있다. SSD 드라이브는 채널(Channel), 패키지(Package), 칩(Chip), 플레인(Plane), 그리고 블록(Block)과 페이지(Page)등의 다양한 레벨로 구성되어 있다. 문서 8에 설명된 것처럼, 아래와 같은 병렬 처리 능력을 제공한다.여러 칩에 걸쳐서 한번에 액세스될 수 있는 여러 개의 블록을 “Clustered block”13이라고 하는데, RAID 시스템14 12에서 사용되는 스트라이핑(striping)과 비슷한 아이디어이다.한번에 접근 가능한 논리 블록 주소들은 개별 플래시 패키지에서 서로 다른 SSD 칩들에 걸쳐서 스트라이핑된다. 이는 FTL의 맵핑 알고리즘 덕분에 가능하며, 이는 Clustered block에 포함되는 블록들이 서로 연속된 주소이든지 관계없이 독립적이다. 스트라이핑 블록들은 여러 채널을 동시에 사용할 수 있으며, 그 채널들의 대역폭을 묶어서 생각할 수 있다. 또한 읽기와 쓰기 그리고 삭제(Erase) 오퍼레이션을 병렬로 처리할 수 있다. 이는 Clustered block 사이즈 또는 그 배수 크기의 I/O 오퍼레이션은 SSD의 다양한 내부 병렬 처리 능력을 최대한 활용할 수 있다는 것을 보장한다. Clustered block에 대한 자세한 내용은 섹션 8.2와 8.3을 참조하도록 하자.This articles are translated to Korean with original author’s(Emmanuel Goossaert) permission. Really appreciate his effort and sharing.Original articles : http://en.wikipedia.org/wiki/Trim_(computing) ↩ http://en.wikipedia.org/wiki/Write_amplification ↩ http://www.anandtech.com/show/6489 ↩ ↩2 http://www.ssdperformanceblog.com/2011/06/intel-320-ssd-random-write-performance/ ↩ Reliably Erasing Data From Flash-Based Solid State Drives, Wei et al., 2011 ↩ http://security.stackexchange.com/questions/12503/can-wiped-ssd-data-be-recovered ↩ http://security.stackexchange.com/questions/5662/is-it-enough-to-only-wipe-a-flash-drive-once ↩ Essential roles of exploiting internal parallelism of flash memory based solid state drives in high-speed data processing, Chen et al, 2011 ↩ ↩2 ↩3 http://en.wikipedia.org/wiki/Native_Command_Queuing ↩ ↩2 Understanding the Robustness of SSDs under Power Fault, Zheng et al., 2013 — discussion on HN ↩ http://lkcl.net/reports/ssd_analysis.html - discussion on HN ↩ Design Tradeoffs for SSD Performance, Agrawal et al., 2008 ↩ ↩2 Parameter-Aware I/O Management for Solid State Disks (SSDs), Kim et al., 2012 ↩ ↩2 Understanding Intrinsic Characteristics and System Implications of Flash Memory based Solid State Drives, Chen et al., 2009 ↩",http://tech.kakao.com/2016/07/16/coding-for-ssd-part-4/,0,kakao,,NULL,2016-07-16
개발자를 위한 SSD (Coding for SSD) - Part 3 : 페이지 & 블록 & FTL(Flash Translation Layer),"이번 챕터에서는 데이터 쓰기가 Block과 Page 레벨에서 어떻게 처리되는지, 그리고 쓰기 시에 발생하는 “Write Amplication”과 “Wear Leveling”의 기본적인 개념을 살펴보도록 하겠다. 추가로 FTL(Flash Translation Layer)이 무엇인지, 그리고 FTL의 2가지 목적인 논리적 블록 맵핑(Logical Block Mapping, 여기에서는 Hybrid Log Block Mapping 위주로)과 Garbage-collection도 같이 살펴볼 것이다.NAND 플래시 메모리의 구성 특성상, 특정 셀을 단독으로 읽고 쓰는 작업은 불가능하다. 메모리는 그룹핑되어 있으며, 아주 특별한 방법으로만 접근할 수 있다. 그래서 NAND 플래시 메모리의 특별한 방법을 숙지하는 것은 SSD의 데이터 구조를 최적화하고 작동 방식을 이해하는데 있어서 꼭 필요한 부분이다. 이번 섹션에서는 SSD의 읽고 쓰기 그리고 삭제(Erase) 오퍼레이션이 실행되는 방법들을 살펴 보도록 하겠다.한번에 하나의 페이지보다 작은 크기의 데이터를 읽을 수는 없다. 물론 사용자는 운영 체제에게 단 하나의 바이트만 읽기를 요청할 수는 있지만, 실제 SSD는 하나의 페이지를 통째로 읽은 다음 불 필요한 데이터는 모두 버리고 사용자가 요청한 한 바이트만 반환하는 것이다. 즉 불필요한 데이터를 많이 읽게 되는 것이다.쓰기를 실행할 때에도 SSD는 페이지 단위로, 하나의 페이지 또는 여러 개의 페이지로 실행된다. 그래서 단 하나의 바이트만 기록하는 경우에도 반드시 전체 페이지가 기록되어야 한다. 이렇게 필요 이상으로 쓰기가 발생하는 것(Write Overhead)을 “Write Amplication”이라고 하는데, 이는 섹션 3.3에서 자세히 설명하고 있다. SSD의 페이지에 데이터를 쓰는 것을 “프로그램 (program)”한다 라고도 하며, 많은 SSD 관련 문서에서 쓰기(Write)와 프로그램(Program)은 자주 혼용되기도 한다.NAND 플레시 메모리의 페이지는 반드시 “free” 상태일때에만 쓰기를 할 수 있다. 데이터가 변경되면, 페이지의 내용은 내부 레지스터로 복사된 후 레지스터에서 변경되어 새로운 “free” 상태의 페이지로 기록되는 것이다. 이를 “Read-Modify-Write”라고 한다. SSD에서 데이터는 다른 페이지로 이동하지 않고 변경될 수 없다(in-place update가 불가능). 이렇게 변경된 데이터가 새로운 페이지에 완전히 기록되면, 원본 페이지는 “stale”로 마킹되고 삭제(Erase)되기 전까지 그 상태로 남게 된다.페이지는 덮어 쓰기가 불가능하기 때문에 한번 “stale” 상태로 된 페이지는 반드시 삭제(Erase)하는 작업을 거쳐서 “free” 상태로 전이할 수 있다. 그러나 삭제는 단일 페이지 단위로 처리될 수 없고, 그 페이지가 포함된 블록을 통째로 삭제해야 한다. 사용자는 읽기와 쓰기 명령만 데이터 액세스를 위해서 사용할 수 있으며, 삭제 명령은 SSD 컨트롤러가 “free” 공간이 필요할 때 자동적으로 내부 명령을 실행해서 Garbage-collection을 실행할 때 사용된다.아래의 그림 4는 SSD에 데이터가 기록되는 과정을 보여주고 있다. 설명을 단순화하기 위해서, 이 그림에서는 단 2개의 블록과 각 블록의 4개의 페이지만을 가지고 있도록 그려졌지만 여전히 NAND 플래시 패키지의 전체 구성을 표현하고 있다. 그림의 각 단계에서 오른쪽의 텍스트는 어떤 일이 발생하고 있는지를 설명하고 있다.처음 상태로, 2000번 블록은 “free” 상태이며, 1000번 블록은 3개의 이미 사용된 “used” 페이지(PPN=0,1,2)와 1개의 “free” 페이지(PPN=3)를 가지고 있다. 여기에서 PPN은 물리 페이지 번호(Physical Page Number)를 의미한다.1000번 블록의 PPN=0 페이지가 “x’“로 업데이트되었다. 페이지는 덮어 쓰기될 수 없으므로 기존 “x” 데이터를 가진 PPN=0 페이지는 “stale” 상태로 바뀌고 새로운 버전의 데이터가 “free” 페이지였던 PPN=3 페이지로 기록되었다.Garbage-collection은 1000번 블록의 모든 유효한 데이터(“stale” 상태의 PPN=0는 남기고)를 2000번 블록으로 복사한다. 새로운 쓰기를 받아들이기 위해서 1000번 블록은 삭제된다. 블록은 지정된 횟수(P/E cycles)만큼만 삭제 될 수 있다.쓰기는 페이지 사이즈에 맞춰서(Aligned) 실행되므로, 페이지 사이즈에 일치하지 않는 모든 쓰기는 필요 이상의 부가적인 쓰기(Write amplification 1)를 필요로 한다. 한 바이트 쓰기는 결국 하나의 페이지를 통째로 쓰기해야 하므로, 페이지 사이즈가 16KB인 SSD에서는 16KB를 기록해야 하고 이는 상당히 비효율적이다.그러나 이것만 SSD의 문제점은 아니다. 필요 이상의 데이터를 쓰게 되면, 필요 이상의 내부 오퍼레이션을 유발하게 된다. 페이지 크기에 맞춰지지 않은 쓰기는 먼저 해당 페이지의 데이터를 캐시로 읽어야 하며, 다시 페이지에 기록되어야 하기 때문에 즉시 페이지에 기록하는 것보다 느리게 작동한다. 이런 현상을 “read-modify-write”라고 하는데, 가능하다면 이런 현상은 피하는 것이 좋다 2 3.“Write Amplication”과 “Read-Modify-Write” 현상을 최소화하기 위해서, NAND 플래시 페이지의 크기보다 작은 데이터의 쓰기는 가능하면 피하도록 하자. 현재 최대 페이지 사이즈가 16KB이므로, 16KB 이상의 데이터 쓰기를 권장한다. 이 크기는 SSD 모델에 따라서 가변적인데, 앞으로 SSD가 발전하면서 페이지의 크기가 더 증가할 수도 있고 그때에는 데이터 쓰기의 단위를 더 늘려야 할 필요도 있다.데이터의 쓰기는 단일 페이지의 크기에 맞추거나, 여러 페이지의 크기에 맞춰서 실행하도록 하자.스루풋을 최대화하기 위해서, 가능하면 작은 쓰기는 메모리에 버퍼링했다가 버퍼가 가득 차면 단일 쓰기로 최대한 많은 데이터를 기록하도록 하자.섹션 1.1에서 살펴보았듯이, 프로그램-삭제(P/E Cycles) 회수가 제한되어 있으므로 NAND 플래시 셀은 제한된 수명을 가지게 된다. 예를 들어서 하나의 블록에만 데이터를 읽고 쓰는 가상의 SSD를 가정해보면, 이 블록은 아주 빨리 P/E 사이클 제한을 넘어서게 되어서 사용하지 못하게 될 것이다. 그러면 SSD컨트롤러는 이 블록을 “사용 불가능”으로 마킹하게 된다. 결과적으로 SSD의 전체 사용 가능한 공간이 줄어들게 된다. 500GB 용량의 SSD 드라이브를 구매했는데 2년 후에는 250GB 공간만 남게 된다면, 얼마나 짜증나겠는가?이러한 이유로 SSD 컨트롤러의 중요한 역할 중 하나는, SSD의 전체 블록에 대해서 P/E cycle이 골고루 분산되도록 쓰기(“Wear leveling”)를 실행하는 것이다. 이상적으로는 모든 블록이 P/E Cycle 한계에 동시에 도달하여 한번에 모든 블록이 사용 불가능 상태로 만드는 것이다 4 5.최고의 “Wear leveling”을 위해서, SSD는 쓰기가 발생하면 현명하게 블록을 선택해야 하며 때로는 특정 블록을 주위로 옮겨야 할 수도 있다. 이 과정에서 또 다른 “Write Amplication”이 발생하는 것이다. 그래서 블록 관리는 “Write Amplication”과 “Wear Leveling”의 사이에서 적절히 타협점을 찾아야 하는 것이다. 그래서 SSD 제조사들은 Garbage-collection과 같은 “Wear Leveling”을 위한 기능들을 가진 제품을 출시하고 있는 것이다.NAND 플래시 셀은 너무 빈번하게 쓰기 삭제 과정을 거치면 사용 불가능 상태(wearing off)가 되기 때문에, 셀 간의 작업을 분산하여 각 블록들이 P/E Cycle 한계에 동시에 도달하도록 하는 것이 FTL(Flash Translation Layer)의 중요한 목표 중 하나이다.업계에 SSD가 이렇게 쉽게 받아들여지게 만든 중요한 요소 중 하나는 SSD가 HDD와 동일한 호스트 인터페이스를 이용한다는 것이다. 물론 현재의 LBA(Logical Block Address) 어레이는 덮어쓰기가 가능한 HDD에서만 적합한 요소이며, SSD에는 적합하진 않지만 말이다. 이 때문에 NAND 플래시 메모리는 내부적인 특성을 숨기고 LBA 어레이를 호스트로 노출하기 위해서 부가적인 컴포넌트를 필요로 한다. 이 컴포넌트를 FTL(Flash Translation Layer)하고 하며, SSD 컨터롤러 내부에 위치하고 있다. FTL은 아주 중요한 역할을 담당하며, 논리적 블록 맵핑(Logical Block Mapping)과 Garbage-collection 2개의 중요한 부분을 담당한다.논리적인 블록 맵핑은 호스트 영역의 논리 주소(LBA, Logical Block Address)를 NAND 플래시 메모리의 물리적 주소(PBA, Physical Block Address)로 변환해주는 역할을 담당한다. 블록 맵핑은 LBA와 PBA로 구성된 테이블을 가지며, 이 맵핑 테이블은 빠른 액세스를 위해서 SSD의 메모리(RAM)에 저장되며, 전원이 꺼지거나 만약의 경우를 대비해서 SSD의 플래시 메모리에도 저장된다. SSD의 전원이 켜지면 플래시 메모리에 저장된 맵핑 테이블을 읽어서 메모리(RAM)에 로딩된다 6 3.블록 맵핑을 구현하는 단순한 방법은 페이지 단위로 맵핑 테이블을 구성하는 것이다. 이 방법은 아주 유연하지만, 맵핑 테이블 자체가 아주 많은 메모리를 사용하게 된다는 큰 단점이 있다. 필요한 메모리가 커지면 SSD의 생산 단가가 상당히 높아지게 된다. 이를 해결하기 위한 방법으로는 페이지 단위가 아니라 블록 단위의 맵핑을 이용할 수도 있다. SSD 드라이브가 256개의 페이지를 가지고 있다고 가정해보면, 블록 단위의 맵핑은 페이지 단위의 맵핑보다는 256배 적은 메모리를 필요로 하게 되므로 그만큼 적은 메모리가 필요하게 되는 것이다. 그러나 페이지 하나만 기록되어도 될 정도의 작은 데이터를 자주 업데이트하는 경우에는 불필요하게 블록을 통째로 기록해야 하기 때문에 불필요한 쓰기가 많이 발생하게 된다. 이는 SSD의 “Write Amplication”을 증가시키기 때문에 블록 단위의 맵핑은 상당히 비효율적이라고 볼 수 있다 6 2.블록 레벨과 페이지 레벨 맵핑의 트레이드 오프(Trade-off)는 성능과 용량의 문제라고 볼 수 있다. 그래서 일부 연구원들에 의해서 “Hybrid” 한 방법7들이 제시되었는데, 이 중에서 가장 일반적인 방법이 Log Structrued 파일 시스템과 비슷한 형태의 Log-block 맵핑이다. 유입되는 쓰기 오퍼레이션은 시퀀셜하게 로그 블록에 기록되고, 로그 블록이 꽉 채워지면 동일한 LBN(Logical block Number)을 가지는 블록의 데이터와 병합하여 새로운 “free” 블록으로 기록하는 방법이다. 이 방법에서 로그 블록은 몇 개(a few)만 유지되기 때문에, 페이지 단위의 맵핑은 아주 소량만 관리되면 된다 8 7.아래의 그림 5는 단순화한 Hybrid log block FTL을 보여주고 있는데, 각 블록은 4개의 페이지만을 가지고 있다. 4번의 쓰기가 FTL에 의해서 처리되고 모든 페이지들이 가득 데이터를 가지게 될 것이다. 논리적인 페이지 번호 5와 9는 LBN=1과 연결되며, LBN=1은 물리 주소 1000번과 연결되어 있다. 초기 LBN=1이 로그 블록 맵핑 테이블에 있을 때는, 모든 물리 페이지의 옵셋은 NULL이며 1000번 로그 블록은 비어 있는 상태이다.처음 b’가 LPN=5에 기록되고 로그 블록 맵핑 테이블(PBN=1000, log block #1000)에 의해서 LBN=1로 연결된다. 즉 페이지 b’는 1000번 블록의 옵셋 0 위치에 기록된 것이다. 맵핑의 메타 데이터가 업데이트되어야 하는데, 이를 위해서 물리 옵셋이 논리 옵셋 1(예를 들어서)의 위치에 NULL에서 0으로 저장된다.쓰기 오퍼레이션은 계속 유입되고 그에 맞게 맵핑 메타 데이터도 변경된다. 1000번 로그 블록이 가득 채워지면, 3000번 논리 데이터 블록과 병합된다. 이 정보는 데이터 블록 맵핑 테이블을 통해서 확인할 수 있다. 병합 작업의 결과는 “free” 상태였던 9000번 블록에 기록되는데, 이 작업이 끝나면 1000번과 3000번 블록은 삭제(Erase)되어 “free” 블록이 되고 9000번 블록은 데이터 블록이 된다. 데이터 블록 맵핑 테이블의 LBN=1을 위한 메타 데이터는 처음 3000번 데이터 블록에서 9000번 데이터 블록으로 업데이트된다.여기에서 중요한 것은 4번의 쓰기가 2개의 LPN에만 집중되어 있다는 것이다. 로그 블록 맵핑 방법은 병합이 진행되는 동안 “Write Amplication”을 줄이기 위해서, b’와 d’는 무시하고 더 최신의 b”와 d”만 데이터 블록에 저장한다는 것이다. 마지막으로 로그 블록이 병합되기 전에 최근 업데이트된 데이터를 읽으려고 하면, 그 데이터는 로그 블록에서 읽어야 한다. 물론 이미 병합된 데이터라면 데이터 블록을 읽어야 할 것이다. 이 때문에 읽기 요청은 로그 블록 맵핑 테이블과 데이터 블록 맵핑 테이블을 모두 읽어야 하는 이유인데, 이는 그림 5에 보여지고 있다.로그 블록 FTL은 더 나은 최적화를 할 수 있도록 해주는데, 그 중에서도 중요한 것은 “switch-merge”(“swap-merge”이라고도 함)이다. 논리 블록의 주소가 한번에 기록된다고 가정해보자. 이는 그 논리 주소의 새로운 데이터들이 동일한 로그 블록에 기록된다는 것을 의미한다. 이 로그 블록은 전체 논리 블록의 데이터를 모두 가지기 때문에, 이 로그 블록을 별도의 병합하여 새로운 블록으로 옮기는 과정은 불필요한 작업(병합전과 병합후의 블록이 동일한 데이터를 가지게 될 것이므로)이 될 것이다. 이런 경우에는 단순히 로그 블록 맵핑을 거치지 않고 데이터 블록 맵핑을 바로 변경할 수 있으면(데이터 블록 맵핑의 메타 데이터만 변경하면 되므로) 더 빠를 것이다. 이렇게 데이터 블록 맵핑 테이블에서 데이터 블록과 로그 블록을 바꾸는(switch) 것을 “switch-merge”라고 한다.로그 블록 맵핑 스키마는 많은 논문의 주제가 되곤 했으며, FAST (Fully Associative Sector Translation), 수퍼 블록 맵핑 그리고 Flexible Group Mapping7 등과 같은 발전을 이루어 왔다. Mitsubishi 알고리즘과 SSR8 등의 맵핑 스키마도 있다. 아래는 FTL과 맵핑 스키마를 배우기 위한 좋은 자료들이다.FTL(Flash Translation Layer)은 호스트의 LBA(Logical Block Address)와 드라이브의 PBA(Physical Block Address)를 맵핑해주는 SSD 컨트롤러의 컴포넌트이다. 가장 최근의 드라이브는 Log Structure 파일 시스템과 같이 작동하는 “hybrid log-block mapping” 또는 그 파생 알고리즘을 구현하고 있다. 이 알고리즘은 랜덤 쓰기를 시퀀셜 쓰기처럼 핸들링할 수 있도록 해준다.2014년 2월 2일 현재 위키피디아9에는 70여개의 SSD 제조사가 나열되어 있는데, 재미있는 것은 단 11개의 제조사만 SSD 컨트롤러를 생산하고 있다. 제조사는 단 11개10만 있다. 그리고 11개의 제조사중에서 삼성과 인텔을 포함한 단 4개의 제조사만 자사를 위한 SSD 컨트롤러를 생산하고 있으며, 나머지 7개사는 SSD 컨트롤러를 생산하여 다른 SSD 제조사로 판매하고 있는 것이다. 이는 단지 7개 회사가 SSD 마켓의 90% 정도의 SSD 컨트롤러를 제공하고 있다는 것을 의미한다.이 90%의 수치중에서 어떤 SSD 컨트롤러 회사가 어떤 SSD 드라이브 제조사로 공급하고 있는지는 모르겠지만, 파레토 법칙으로 고려해보면, 단지 2~3개의 컨트롤러 제조사가 대 부분의 시장을 점유하고 있을 것으로 보인다. 이런 이유로 삼성이나 인텔등 전용 SSD 컨틀롤러를 사용하는 4개 회사를 제외하면, 나머지 회사들의 SSD 드라이브는 거의 모두 동일한 SSD 컨트롤러를 사용중이며 매우 비슷하게 작동할 것이라는 것이다.SSD 컨트롤러의 일부인 맵핑 스키마는 SSD 드라이브의 전체적인 성능을 결정하기 때문에 SSD의 크리티컬한 컴포넌트라고 할 수 있다. 경쟁이 심한 SSD 시장에서 서로 자사의 FTL 구현 알고리즘을 상세한 내용을 전혀 공개하지 않는 이유가 이 때문인 것이다. 그래서 FTL 알고리즘에 대한 내용들이 많이 공유되어 있지만, 얼마나 많은 제조사들이 그 FTL 알고리즘을 구현하고 있는지는 어떤 모델이나 브랜드에 적용하고 있는지 알려지지 않는다“11 Essential roles of exploiting internal parallelism of flash memory based solid state drives in high-speed data processing, Chen et al, 2011”의 저자는 워크로드를 분석해서 SSD 드라이브가 사용중인 맵핑 알고리즘을 리버스 엔지니어링(Reverse Engineering)할 수 있다고 주장한다. 개인적으로 나는 칩으로부터 바이너리 코드 자체를 리버스 엔지니어링하지 않는 이상, 특정 드라이버에서 어떤 맵핑 정책이 사용되는지 정확히 판단하기는 어렵다고 생각한다. 또한 특정 워크로드에서는 어떤 맵핑 알고리즘이 사용되는지 예측하기는 더 어렵다.세상에는 수많은 맵핑 알고리즘이 있으며, 그 수많은 제품들의 펌웨어를 리버스 엔지니어링한다는 것은 엄청난 시간이 소모될 것이다. 그럼에도 불구하고 맵핑 방법의 모든 소스 코드를 구했다고 한들 무슨 이점이 있을까? 종종 새로운 프로젝트를 위한 시스템의 요건은 일반적으로 교체될 수 있는 하드웨어를 이용해서 조금 더 나은 결과를 내는 것이다. 그래서 하나의 맵핑 알고리즘을 위해서 서비스를 최적화하는 것이 다른 맵핑 알고리즘에서도 좋은 성능을 보장하는 것이 아니기 때문에, 그다지 가치 있는 최적화는 아닌 것으로 볼 수 있다. 하나의 맵핑 알고리즘에만 적합한 최적화가 필요한 경우는 그 하드웨어만 지속적으로 사용해야 하는 임베디드 시스템과 같은 경우이다.이러한 이유들로 인해서, SSD가 사용중인 맵핑 알고리즘을 알아내는 것은 큰 이점이 없다고 생각된다. 맵핑 스키마에서 한가지 알아야 할 중요한 것은 LBA와 PBA 사이의 주소 변환이며, 이를 위해서 Hybrid Log Block 맵핑 또는 그로부터 파생된 맵핑 알고리즘이다. 결과적으로 맵핑 테이블과 메타 데이터를 변경하는 오버헤드를 최소화해주기 때문에, NAND 플래시 블록의 크기보다 큰 데이터 청크를 쓰기하는 것은 효율적이다.섹션 4.1과 4.2에서 소개되었듯이, SSD 드라이브의 페이지는 덮어쓰기 될 수 없다. 만약 페이지의 데이터가 업데이트되어야 한다면, 새로운 버전의 데이터는 “free” 페이지에 기록되어야 하고 예전 버전의 데이터가 기록된 페이지는 “stale”로 삭제 마킹되어야 한다. 블록이 “stale” 상태의 페이지들을 가지고 있다면, 그들은 재사용되기 위해서는 먼저 삭제(Erase)되어야 한다.SSD 컨트롤러의 Garbage-collection 프로세스는 “stale” 상태의 페이지들이 삭제(Erase)되어 새로운 쓰기 데이터를 저장할 수 있도록 해주는 과정이다.단순히 데이터 쓰기 오퍼레이션(250 ~ 1500 마이크로 초)에 비해서 블록을 삭제(Erase)하는 과정(1500 ~ 3500 마이크로 초)은 많은 시간이 소요되므로, 이런 부차적인 삭제(Erase) 작업은 쓰기 속도를 느리게 만든다. 그래서 일부 컨트롤러는 백그라운드 Garbage-collection을 도입하고 있다. 백그라운드 Garbage-collection은 Idle Collection이라고도 알려져 있는데, 이는 SSD 컨트롤러가 한가한 시간에 주기적으로 “stale” 페이지를 “free” 상태로 만들어 준다. 이렇게 충분한 “free” 상태의 페이지가 준비되어 있으면 유저 쓰기는 느려지지 않고 충분히 빠른 쓰기 속도를 보장할 수 있게 되는 것이다6. 다른 SSD 컨트롤러는 Parallel Garbage-collection 방식을 구현하고 있는데, 이는 호스트의 쓰기 요청과 동시에 Garbage-collection을 실행하는 방식이다1.호스트로부터 쓰기 요청이 올 때 동시에 Garbage-collection이 필요할 정도의 과도한 쓰기 부하를 필요로 하는 워크로드는 흔하지 않다. 이런 때에는 Garbage-collection이 백그라운드로 실행되는 것은 호스트로부터 전달되는 포그라운드(Foreground) 명령 실행을 방해할 수 있다 6. TRIM 명령과 Over-provisioning은 이런 현상을 줄여줄 수 있는 좋은 솔루션인데, 이는 섹션 6.1과 6.2에서 살펴보도록 하겠다.백그라운드 오퍼레이션은 포그라운드 오퍼레이션에 악영향을 미칠 수 있다. Garbage-collection과 같은 백그라운드 오퍼레이션은 호스트로부터 오는 포그라운드 명령에 나쁜 영향을 미칠 수 있다. 특히 이런 현상은 작은 데이터의 랜덤 쓰기가 지속적으로 발생하는 시스템에서는 더욱 더 나쁜 영향을 미치게 될 것이다.블록이 이동되어야 하는 조금 덜 중요한 이유중 하나는 읽기 방해(Read disturb)이다. 읽기는 주의 셀들의 상태를 변경할 수도 있다. 그래서 블록은 일정 회수 이상의 읽기가 수행된 이후 다른 위치로 옮겨져야 한다5. 데이터가 변경되는 비율은 중요한 요소이다. 어떤 데이터는 아주 뜸하게 변경되는데, 이런 데이터를 콜드(cold) 또는 정적(static) 데이터라고 한다. 반면 아주 빈번하게 변경되는 데이터들도 있는데, 이를 핫(hot) 또는 동적(dynamic) 데이터라고 한다. 만약 페이지가 일부는 콜드 그리고 나머지 일부는 핫 데이터를 가진다면, Wear Leveling을 위해서 핫 데이터가 Garbage-collection될 때마다 콜드 데이터도 같이 옮겨 다녀야 할 것이다. 하지만 이렇게 핫 데이터와 함께 콜드 데이터들이 따라 다녀야 한다면, “Write Amplication”은 더 심해질 것이다. 이런 현상은 콜드 데이터와 핫 데이터를 서로 다른 페이지로 분리함으로써 피할 수 있다. 이 방법의 단점은 콜드 데이터를 가진 페이지들은 덜 자주 삭제(Erase)될 것이고, 이로 인해서 SSD 컨트롤러는 콜드 데이터와 핫 데이터를 가진 페이지들을 Wear Leveling을 위해서 주기적으로 스왑(swap) 해줘야 한다. 데이터의 변경 빈도는 응용 프로그램 레벨에서 결정되기 때문에, FTL은 하나의 페이지에 얼마나 핫 데이터와 콜드 데이터가 저장될지 예측할 수 있는 방법이 없다. SSD에서 성능을 향상시키기 위한 방법으로는 핫 데이터와 콜드 데이터를 최대한 다른 페이지로 분리하는 것이며, 이는 Garbage-collection이 좀 더 효율적으로 작동하도록 해준다12.빈번하게 변경되는 데이터를 핫 데이터라고 하며, 그렇지 않은 데이터를 콜드 데이터라고 한다. 만약 핫 데이터와 콜드 데이터가 동일 페이지에 저장된다면, 핫 데이터가 변경될 때마다 콜드 데이터는 핫 데이터와 함께 Read-Modify-Write 오퍼레이션에 같이 포함되어 복사되어야 한다. 또한 Wear-leveling을 위해서 콜드 데이터도 같이 계속 다른 페이지로 이동되어야 한다. 콜드 데이터와 핫 데이터는 최대한 분리해야 Garbage-collection을 효율적으로 처리될 수 있다.매우 빈번하게 변경되는 핫 데이터는 최대한 버퍼링되었다가 SSD에 덜 자주 업데이트되도록 하는 것이 좋다.데이터가 더 이상 필요치 않거나 삭제해야 할 때에는 최대한 모아서 한번(단일 오퍼레이션)에 삭제하는 것이 좋다. 이렇게 단일 오퍼레이션으로 삭제하는 것이 Garbage-collection 처리가 한번에 큰 영역을 처리하도록 해주며 그와 동시에 내부 프레그멘테이션을 최소화시켜 줄 것이다.This articles are translated to Korean with original author’s(Emmanuel Goossaert) permission. Really appreciate his effort and sharing.Original articles : http://en.wikipedia.org/wiki/Write_amplification ↩ ↩2 Parameter-Aware I/O Management for Solid State Disks (SSDs), Kim et al., 2012 ↩ ↩2 Design Tradeoffs for SSD Performance, Agrawal et al., 2008 ↩ ↩2 http://en.wikipedia.org/wiki/Solid-state_drive ↩ http://en.wikipedia.org/wiki/Flash_memory ↩ ↩2 Understanding Intrinsic Characteristics and System Implications of Flash Memory based Solid State Drives, Chen et al., 2009 ↩ ↩2 ↩3 ↩4 A Reconfigurable FTL (Flash Translation Layer) Architecture for NAND Flash-Based Applications, Park et al., 2008 ↩ ↩2 ↩3 ↩4 A Survey of Flash Translation Layer, Chung et al., 2009 ↩ ↩2 ↩3 http://en.wikipedia.org/wiki/List_of_solid-state_drive_manufacturers ↩ http://en.wikipedia.org/wiki/List_of_flash_memory_controller_manufacturers ↩ Essential roles of exploiting internal parallelism of flash memory based solid state drives in high-speed data processing, Chen et al, 2011 ↩ SFS: Random Write Considered Harmful in Solid State Drives, Min et al., 2012 ↩",http://tech.kakao.com/2016/07/15/coding-for-ssd-part-3/,0,kakao,,NULL,2016-07-15
개발자를 위한 SSD (Coding for SSD) - Part 2 : SSD의 아키텍처와 벤치마킹,"이 챕터에서는 NAND 플래시 메모리의 기본적인 내용과 셀 타입 그리고 SSD의 기본적인 내부 아키텍처에 대해서 살펴보고, 추가로 SSD의 벤치마킹 방법과 벤치마킹 결과를 해석하는 부분도 살펴보도록 하겠다.SSD(Solid-State Drive)는 플래시 메모리를 기반으로한 저장 매체이다. 비트들은 Floating-Gate 트랜지스터로 구성된 셀에 저장된다. SSD는 모든 컴포넌트가 전기 장치이며, HDD와 같은 기계 장치를 가지고 있지 않다.Floating-Gate 트랜지스터에 전압이 가해지면서 셀의 비트가 쓰여지거나 읽혀지게 된다. 트랜지스터는 NOR 플래시 메모리와 NAND 플래시 메모리 두 종류가 있는데(여기에서는 NAND의 NOR 플래시 메모리의 차이에 대해서 깊이 있게 살펴보지는 않을 것이다), 이 게시물에서는 많은 제조사들이 채택하고 있는NAND 플래시 메모리에 대해서만 살펴보도록 하겠다. NAND와 NOR 플래시 메모리의 상세한 차이에 대해서 궁금하다면, Lee Hutchinson1의 문서를 살펴보도록 하자.NAND 플래시 메모리 모듈의 중요한 속성은 수명이 제한적(Wearing-off)이라는 것이다. 트랜지스터는 셀에 전자를 저장하면서 쓰기를 하게 되는데, 매번 P/E(Program & Erase, Program은 쓰기를 의미) 사이클마다 일부 전자가 오류로 인해서 트랜지스터에 갇히게 된다. 그리고 이렇게 갇힌 전자들이 쌓여서 일정 수준을 넘어서게 되면, 그 셀은 사용 불가능한 상태가 되는 것이다.각 셀은 최대 P/E 사이클을 가지는데, 이 사이클을 넘어서면 결함 셀로 간주된다. NAND 플래시 메모리는 수명 제한을  가지는데, 이 수명 제한은 NAND 플래시 메모리의 타입(SLC, MLC, TLC)에 따라서 조금씩 차이가 있다1.최근 연구에 따르면, NAND 플래시 메모리 칩에 높은 열이 가해지면 각 셀에 갇혀있던(프로그램되어 있던) 전자들이 사라진다는 것이 확인되었다2 3. 또한 아직 연구중이며 언제 시중에 이런 제품이 출시될지 모르지만, SSD의 수명을 상당히 높일 수 있는 방법도 있다. 현재 시중에 출시되는 SSD의 메모리 셀 타입은:SSD는 플래시 메모리 기반의 저장 매체이다. 비트는 셀에 저장되며, 메모리 셀은 3가지 타입이 있다. SLC는 1비트, MLC는 2비트 그리고 TLC는 3비트를 저장할 수 있다.표1은 각 NAND 플래시 셀 타입의 상세한 정보를 보여주고 있다. 비교를 위해서 HDD와 메인 메모리(RAM) 그리고 L1/L2 캐시도 같이 포함하였다.표1: 다른 메모리 컴포넌트와 NAND 플래시 메모리의 특성 및 레이턴시 비교동일 량의 트랜지스터로 더 많은 비트들을 저장할 수 있다면, 당연히 제조 단가는 낮아지게 된다. SLC 타입의 SSD는 MLC 타입보다 신뢰성이 높고 더 오랜 시간 사용할 수 있지만, 제조 비용이 크다. 그래서 대 부분의 SSD는 MLC 또는 TLC 타입이며, 엔터프라이즈급의 SSD만 SLC를 사용한다. 워크로드에 맞게 적절한 메모리 타입을 선정하는 것이 중요한데, 여기서 워크로드라 함은 얼마나 SSD에 데이터가 자주 기록되는지를 의미한다. 예를 들어서 쓰기 빈도가 아주 높다면 SLC 타입의 SSD가 최선이며, (동영상 스트리밍을 위한 저장소와 같이) 쓰기는 많지 않지만 읽기가 매우 많다면 TLC가 가장 적절한 선택이 될 것이다. 게다가 실제 서비스 수준의 워크로드로 수행된 벤치마크의 결과에 의하면, 실제 TLC 타입의 메모리 수명은 크게 문제되지 않는 것으로 보인다 12.셀들은 Block으로 그룹핑 되어 있으며, Block들은 다시 Plane으로 그룹핑되어 있다. SSD를 읽고 쓰기시에 최소 접근 단위는 Page라고 하며, Page는 개별로 삭제(Erase)될 수 없고 반드시 삭제는 Block 단위로만 수행될 수 있다. NAND 플래시 메모리의 Page 크기는 2KB, 4KB, 8KB, 16KB로 다양한데, 대 부분 SSD의 Block은 128개 또는 256개의 Page를 가진다. 이는 SSD 제조사별로 Block의 크기가 256KB에서 4MB까지 다양하다는 것을 의미한다. 예를 들어서 삼성 SSD 840 EVO는 2048KB의 Block 크기를 가지며 각 Block은 256개의 8KB 페이지를 가진다. Page와 Block의 접근 방법에 대해서는 섹션 3.1에서 자세히 살펴보도록 하겠다.아래의 그림 1은 SSD의 주요 컴포넌트들을 도식화한 것이다. 이는 이미 다양한 문서(13 14 15)들에서 공개된 내용들이며, 간단히 개요만 표시한 것이다.사용자의 요청은 호스트 인터페이스를 통해서 유입되는데, 이 글을 작성하는 시점에는 가장 일반적인 인터페이스 방식은 ATA(SATA)와 PCI Express(PCIe) 타입이다. SSD 컨트롤러에 장착된 프로세서가 명령을 받아서 플래시 컨트롤러로 전달하게 된다. SSD는 자체적으로 보드에 내장된 메모리(RAM)을 가지는데, 일반적으로 이 메모리는 맵핑 정보를 저장하거나 캐시 용도로 사용된다. 상세한 맵핑 정책에 대해서는 섹션 4에서는 살펴보도록 하겠다. SSD는 여러 개의 Channel을 통해서 서로 NAND 플래시 메모리 패키지로 구성된다. Channel에 대한 상세한 내용은 섹션 6에서 살펴보도록 하겠다.아래의 그림 2와 3(StorageReview.com의 게시물16 17을 참조)은 실생활에서 사용되는 SSD가 어떻게 생겼는지를 보여주고 있다. 그림 2는 2013년 8월에 출시된 512GB 삼성 840 Pro SSD이다. 기판에서 보이듯이, 주요 컴포넌트는:  그림 제공: StorageReview.com 16그림 3은 2013년 후반기에 출시된 마이크론(Micron) P420m Enterprise PCIe 이며, 주요 컴포넌트는:전체 메모리 공간은 2048GB이지만, 프로비저닝(over-provisioning) 영역을 제외하고 1.4TB 사용 가능.  그림 제공: StorageReview.com 17많은 SSD 제조사는 SSD 생산을 위해서 SMT(Surface-Mount Technology)를 사용하는데, SMT 생산 과정에서는 전자 부품들이 회로 기판(PCBs)위에 직접 장착된다. SMT 생산 라인은 기계들이 줄지어 있고, 각 기계들이 부품을 기판위에 놓거나 놓여진 부품들을 납땜하는 등의 각 작업들을 담당하게 된다. 전체 생산 공정에서 여러번의 품질 체크 과정도 수행된다. SMT 라인의 사진이나 동영상은 Steve Burke18 19의 글(캘리포니아 파운틴 밸리의 Kingston Technologies사를 방문했을 때 사진과 Cameron Wilmot이 작성한 타이완20의 Kingston 공장 사진)에서 참조할 수 있다.그 이외에도 2개의 참조할 만한 영상이 있는데, 첫번째 동영상은 Micron사의 “Crucial SSDs”21이며 두번째는 Kingston22에 관련된 것이다. 두번째 동영상은 “Steve Burke”가 작성한 글의 일부인데, 이 글의 하단에 포함시켜 두었다. Kingston사의 Mark Tekunoff는 SMT 라인 투어를 시켜 주었으며, 동영상의 모든 사람들은 즐겁게 정전기 방지용 파자마를 입고 있는 모습을 볼 수 있다.아래의 표2는 여러 SSD 드라이브들의 랜덤과 시퀀셜 워크로드에서 스루풋을 보여주고 있다. 비교를 위해서 2008년과 2013년에 출시된 SSD를 HDD와 메모리(RAM)과 함께 나열해 보았다.표2: 다른 저장 매체와 SSD 드라이브의 스루풋 및 특성 비교NotesMetricsSources호스트 인터페이스는 성능을 결정하는 중요한 요소중 하나이다. 최근에 출시되는 SSD의 일반적인 인터페이스는 SATA 3.0 또는 PCI Express 3.0이다. SATA 3.0 인터페이스는 6 Gbit/s 정도의 데이터 전송량을 낼 수 있는데, 이는 초당 550MB 정도의 성능이다. 그리고 PCIe 3.0 인터페이스에서는 레인(lane)당 8 GT/s(GT/s 는 초당 전송가능한 Giga를 의미, Gigatransfers/second) 데이터 전송이 가능한데, 이는 대략 1 GB/s 정도이다. PCIe 3.0 인터페이스는 최소 1개 이상의 레인(lane)을 가지고 있는데, 4개 레인을 가진 SSD는 SATA 3.0 인터페이스보다 8배나 빠른 4 GB/s 전송 속도를 낼 수 있다. 일부 엔터프라이즈 SSD중에는 SAS (Serial Attached SCSI) 인터페이스를 장착한 제품들도 있는데, 이들은 12 GBit/s정도의 전송 속도를 제공하지만 실제 SAS 인터페이스를 장착한 제품은 많지 않다.최근 출시되는 대 부분의 SSD들은 SATA 3.0의 최대 전송 속도인 550MB/s를 초과할 정도의 성능을 가지고 있으므로, 현재는 대부분 인터페이스가 병목 지점인 경우가 많다. PCI Express 3.0이나 SAS 인터페이스를 장착한 SSD는 엄청난 성능 향상을 제공할 것이다.26 SATA보다 빠른 PCI Express 와 SAS 인터페이스 제조사에서 주로 사용되는 호스트 인터페이스는 SATA 3.0 (550 MB/s)과 PCI Express 3.0 (레인당 1 GB/s, 다중 채널 사용)이다. SAS(Serial Attached SCSI) 또한 엔터프라이즈 SSD에 사용되는데, PCIe와 SAS 인터페이스는 SATA보다 훨씬 빠른 성능을 제공하지만, 그만큼 가격도 비싼 편이다.If you torture the data long enough, it will confess.— Ronald CoaseSSD 제조사가 제공하는 제품의 데이터 시트에는 놀라울 정도의 성능 메트릭들로 채워져 있다. 마케팅 효과를 위해서 제조사들은 항상 반짝이는 수치들을 보여주기 위해서 방법을 찾아내는 것처럼 보인다. 그 수치들이 진정으로 뭔가를 의미하는지 모르겠지만, 실제 데이터 시트의 수치와 운영 시스템에서 사용되는 제품의 성능 예측은 다른 문제이다.Marc Bevand가 작성한 문서27는 일반적인 SSD 벤치마크의 결함에 대해서 언급하고 있는데, 이 문서에서 Marc Bevand는 SSD의 LBA(Logical Block Addressing) 크기 설정에 대한 언급없이 랜덤 쓰기 성능을 명시하거나 Queue depth를 1로 설정하고 테스트한 결과를 레포팅하는 것은 적절하지 못하다고 이야기하고 있다. 또한 이 이외에도 벤치마크 도구의 버그나 잘못된 사용으로 인한 케이스들도 다양하다.SSD의 성능을 정확하게 예측하는 것은 어려운 부분이다. 많은 하드웨어 리뷰 블로그들이 10여분 정도의 테스트 실행 후, 그 결과를 두고 충분히 신뢰성 있다라고 이야기하고 있다. 그러나 SSD는 지속적인 랜덤 쓰기(SSD의 전체 공간이 30분에서 3시간 정도 저장할 수 있는 수준의 워크로드)가 발생하는 테스트 환경에서만 성능 저하를 보여준다. 그래서 어느정도의 쓰기 부하를 발생(이를 “pre-conditioning” 28라고 함)시킨 후, 벤치마크가 좀 더 신뢰성 있는 테스트라고 볼 수 있는 것이다. 아래의 그림 7은 StorageReview.com 16으로부터 가져온 것인데, 다양한 SSD에서 “pre-conditioning”의 효과를 잘 보여주고 있다. 좀더 명확한 성능 저하는 30분 정도 지난 이후 시점부터 나타나는데, 이때부터 모든 SSD 드라이브에 대해서 스루풋은 떨어지고 레이턴시(응답 속도)는 커지는 것을 확인할 수 있다. 그리고 4시간정도 경과한 후에는 성능이 더 떨어져서 최하 수준으로 수렴하는 것을 확인할 수 있다. 그림 제공: StorageReview.com 16그림 7에서 나타나는 현상은 섹션 5.2에서 설명된 것인데, 랜덤 쓰기가 많이 발생해서 SSD가 서스테이닝 모드(Sustaing mode)로 들어가면, SSD의 Garbage-collection이 사용자의 요청을 따라가지 못하게 된다. 사용자의 요청이 들어올때마다 Garbage-collection이 먼저 블록을 지워야(Erase)하기 때문에, 호스트로부터 오는 사용자 요청과 백그라운드로 실행되는 Garbage-collection이 서로 경합하게 된다. 모든 종류의 워크로드에서 SSD 드라이브가 어떻게 반응하고 어떤 성능을 보여주는지를 확인하는 적절한 모델인지 아닌지는 명확치 않지만, 사람들은 SSD가 보여줄 수 있는 최악의 상황을 만들어 내기 위해서 “Pre-conditioning”을 자주 사용한다.여러 제조사들의 다양한 모델들을 비교하기 위한 공통적인 방법과 SSD에서 가능한 최악의 상태 확인은 필요하다. 하지만 최악의 상황에서 가장 좋은 성능을 내는 SSD가 실제 운영 서버용으로 최적이라는 것을 보장하지는 않는다. 많은 운영 환경에서 SSD는 하나의 시스템에서만 사용된다. 그 시스템은 그 시스템만의 특정한 워크로드를 가지기 때문에, 여러 SSD 드라이브에 대해서 조금 더 정확한 비교를 위해서는 동일한 워크로드로 모두 테스트를 수행해야 한다. 지속적인 랜덤 쓰기를 이용한 “Pre-conditioning”이 여러 종류의 SSD에 대해서 적절한 비교 방법이라 할지라도, 가능하다면 대상 서비스의 워크로드를 직접 구현한 벤치마크로 주의해서 진행해야 하는 것이다. 실제 대상 서비스의 워크로드에 따라서 가장 좋은 성능의 SSD가 최적의 선택이 아닐 수도 있는데, 인하우스(in-house)로 개발된 벤치마크 도구는 이러한 오버 스펙을 방지하여 경제적인 절약 효과를 유도하기도 한다.결국 테스트도 사람이 수행하는 것이므로, 모든 벤치마킹이 에러를 회피할 수 있도록 해주는 것은 아니다. 그러므로 제조사나 써드파티(Third-party)에서 제공하는 벤치마크 결과를 참조할 때는 주의해야 하며, 여러 곳으로부터 테스트 결과를 참조하는 것이 좋다. 가능하다면 당신의 서비스 워크로드를 잘 표현할 수 있는 인 하우스 벤치마킹 도구로 사용하고자 하는 SSD를 테스트하도록 하자. 마지막으로 당신의 시스템이나 서비스에서 필요로 하는 성능 메트릭에 집중하도록 하자.성능 벤치마크들은 모두 다양하지만 동일한 파라미터를 사용하며, 결과 또한 동일한 메트릭으로 성능 정보를 제공한다. 이번 섹션을 통해서 이러한 파라미터와 결과 메트릭을 해석하는 데 있어서 인사이트를 제공해줄 수 있기를 바란다.일반적으로 사용되는 파라미터는 다음과 같다:벤치마크의 결과는 다른 메트릭으로 표시되는데, 가장 일반적인 메트릭은:스루풋(throughput)은 쉽게 이해되는 반면, IOPS는 조금 감을 잡기가 어려울 수도 있다. 예를 들어서, 디스크가 4KB 청크에 대해서 초당 1000 IOPS를 처리한다면 이를 스루풋(throughput)으로 계산하면 1000 x 4096 = 4 MB/s가 되는 것이다. 결과적으로 가능하면 청크 사이즈가 크면 클수록, 높은 IOPS는 높은 스루풋으로 환산될 수 있는 것이다.조금 더 이해를 돕기 위해서, 몇 천개의 파일에 아주 조금씩 업데이트하는 로깅 시스템에서 10k IOPS를 처리한다고 가정해보자. 업데이트는 매우 많은 파일에 걸쳐져 있기 때문에 스루풋은 20MB/s정도밖에 안될 것이다. 그런데 만약 이 로깅 시스템이 하나의 파일에만 시퀀셜하게 기록한다고 가정하면, 200MB/s 정도의 향상된 스루풋을 보이게 될 것이다. 이 예제는 랜덤과 시퀀셜 입출력을 비교 설명하기 위해서 만들어낸 수치이긴 하지만, 실제 서비스 환경에서 본인이 경험했던 것이기도 하다.스루풋과 IOPS의 차이를 이해하기 위한 또 하나의 예는, 높은 스루풋이 반드시 빠른 시스템을 의미하는 것은 아니다. 만약 레이턴시가 높다면, 아무리 스루풋이 높다고 하더라도 전체적인 시스템의 처리는 느린 것일 수 있다. 예를 들어서 25개 데이터베이스 접속해야 하는 단일 쓰레드 프로세스를 생각해보자. 각 컨넥션은 20ms의 레이턴시를 가질 때, 매번 컨넥션을 생성하는 데에 20ms가 소요되므로, 전체 25개의 컨넥션을 생성하는 데에는 25 x 20ms = 500ms가 소요될 것이다. 이때 우리 서버가 아무리 대역폭이 넓은 좋은 네트워크 카드를 장착하고 있다 하더라도, 이 가상의 프로세스는 레이턴시로 인해서 여전히 느리게 처리될 것이다.적어도 이 섹션에서 기억해야 할 중요한 부분은, 각각의 벤치마킹 메트릭은 시스템의 다른 면을 보여주기 때문에 모든 메트릭에 집중해야 한다는 것이다. 또한 이런 메트릭을 제대로 이해하고 있어야 시스템의 병목 현상이 발생했을 때, 정확한 원인을 찾을 수 있을 것이기 때문이다. 벤치마킹 결과를 분석하고 특정 SSD 모델을 선택할 때, SSD를 장착하고자 하는 시스템에서 어떤 메트릭이 가장 크리티컬한 요소인지를 파악해야 한다. 물론 섹션 2.2에서 소개된 바와 같이 인하우스로 개발된 벤치마킹 도구를 대체할 만한 테스트 도구는 없을 것이다. Jeremiah Peschka30 가 작성한 “IOPS are a scam”라는 문서도 많은 도움이 될 것이다.This articles are translated to Korean with original author’s(Emmanuel Goossaert) permission. Really appreciate his effort and sharing.Original articles : http://arstechnica.com/information-technology/2012/06/inside-the-ssd-revolution-how-solid-state-disks-really-work/ ↩ ↩2 http://en.wikipedia.org/wiki/Flash_memory ↩ http://www.theregister.co.uk/2012/12/03/macronix_thermal_annealing_extends_life_of_flash_memory/ ↩ http://centon.com/flash-products/chiptype ↩ Understanding Intrinsic Characteristics and System Implications of Flash Memory based Solid State Drives, Chen et al., 2009 ↩ http://www.anandtech.com/show/6337/samsung-ssd-840-250gb-review/2 ↩ http://en.wikipedia.org/wiki/Hard_disk_drive ↩ http://en.wikipedia.org/wiki/Hard_disk_drive_performance_characteristics ↩ http://www.storagereview.com/wd_black_4tb_desktop_hard_drive_review_wd4003fzex ↩ ↩2 http://www.storagereview.com/corsair_vengeance_ddr3_ram_disk_review ↩ ↩2 http://www.eecs.berkeley.edu/~rcs/research/interactive_latency.html ↩ ↩2 http://us.hardware.info/reviews/4178/10/hardwareinfo-tests-lifespan-of-samsung-ssd-840-250gb-tlc-ssd-updated-with-final-conclusion-final-update-20-6-2013 ↩ Parameter-Aware I/O Management for Solid State Disks (SSDs), Kim et al., 2012 ↩ ↩2 Essential roles of exploiting internal parallelism of flash memory based solid state drives in high-speed data processing, Chen et al, 2011 ↩ Design Patterns for Tunable and Efficient SSD-based Indexes, Anand et al., 2012 ↩ http://www.storagereview.com/samsung_ssd_840_pro_review ↩ ↩2 ↩3 ↩4 http://www.storagereview.com/micron_p420m_enterprise_pcie_ssd_review ↩ ↩2 ↩3 http://www.gamersnexus.net/guides/956-how-ssds-are-made ↩ http://www.gamersnexus.net/guides/1148-how-ram-and-ssds-are-made-smt-lines ↩http://www.tweaktown.com/articles/4655/kingston_factory_tour_making_of_an_ssd_from_start_to_finish/index.html ↩ http://www.youtube.com/watch?v=DvA9koAMXR8 ↩ http://www.youtube.com/watch?v=3s7KG6QwUeQ ↩ http://www.thessdreview.com/our-reviews/samsung-64gb-mlc-ssd/ ↩ http://www.storagereview.com/intel_x25-m_ssd_review ↩ http://www.anandtech.com/show/7594/samsung-ssd-840-evo-msata-120gb-250gb-500gb-1tb-review ↩ http://en.wikipedia.org/wiki/Serial_ATA ↩ http://blog.zorinaq.com/?e=29 ↩ http://searchsolidstatestorage.techtarget.com/feature/The-truth-about-SSD-performance-benchmarks ↩ http://en.wikipedia.org/wiki/IOPS ↩ http://www.brentozar.com/archive/2013/09/iops-are-a-scam/ ↩",http://tech.kakao.com/2016/07/14/coding-for-ssd-part-2/,0,kakao,,NULL,2016-07-14
개발자를 위한 SSD (Coding for SSD) - Part 1 : 목차,"현재 개발중인 Key/Value Store가 SSD를 최적으로 사용하도록 하기 위해서는 SSD의 내부적인 특성이나 작동 방식에 대해서 정확한 이해가 필요했다. 인터넷에는 이미 많은 SSD 관련 자료들이 있지만, 대 부분은 부족하거나 잘못된 정보들이 많으며, 제대로 정리된 문서를 찾기는 쉽지 않았다. 결국 내 프로그램이 SSD를 최적으로 사용하도록 하기 위해서는 상당히 많은 문서들과 벤치마크 자료들을 찾고 살펴 봐야 했다.내가 알게 된 사실들과 결론이, 다른 사람들에게도 많은 도움이 될 것이라는 생각을 하게 되었고 그래서 이미 온라인에 공개된 많은 정보들을 30 페이지 분량의 실용적인 지식을 담은 글을 쓰게 되었다. 단순히 블로그에 올릴 수 있는 분량이 아니어서, 좀 더 압축할 수 있는 수준으로 내용을 분류하여 5개의 챕터로 분류하였다. 전체 목차는 이 글의 아래에서 확인할 수 있다.“Coding for SSDs”의 요약 정보를 담고 있는 Part 6은 가장 중요한 부분인데, 이는 아마도 급하게 SSD 관련 프로그램을 작성해야 하는 사람에게는 큰 도움이 될 것으로 보인다. 요약 챕터에는 SSD의 기본적인 정보뿐만 아니라, SSD로부터 최적의 방법으로 데이터를 읽고 쓰기 위한 패턴에 대해서도 언급하고 있다.“Coding for SSDs”의 또다른 중요 포인트는 이 글의 내용이 내가 개발하고 있는 Key-Value 스토어 프로젝트와는 무관하기 때문에, Key-Value 스토리지에 대한 별도의 선행 지식이 필요치 않다는 것이다. 아직 날짜가 정확히 결정된 것은 아니지만, Key-Value 스토리지가 SSD의 장점을 최대한 발휘하기 위해서 어떻게 Hash table을 구현해야 하는지에 대한 포스트도 계획하고 있다.안타깝게도 내가 추천하는 최적의 SSD 액세스 패턴을 증명해줄 별도의 프로그램을 작성하지는 않았다는 것은 후회스러운 부분이긴 하다. 하지만 그런 코드가 있었다면, 나는 시중에 출시된 수 많은 SSD 드라이브들에 대해서 성능 테스트를 진행했어야 할 것이다. 이는 시간적인 부분뿐만 아니라 경제적으로도 많은 어려움이 있었을 것이다. 나는 내가 찾은 자료들을 아주 꼼꼼하고 비판적으로 검토하면서 이 자료를 작성했다. 혹시 내가 추천하는 내용중 잘못되거나 이상한 부분이나 궁금한 부분이 있다면 코멘트를 남겨 주길 바란다.마지막으로, 우측 상단의 Subscription 패널에 등록하면 Code Capsule에 게재되는 새로운 게시물에 대해서 E-mail을 수신을 할 수 있다.This articles are translated to Korean with original author’s(Emmanuel Goossaert) permission.     Really appreciate his effort and sharing.Original articles :",http://tech.kakao.com/2016/07/13/coding-for-ssd-part-1/,0,kakao,,NULL,2016-07-13
kakao 기술 블로그가 GitHub Pages로 간 까닭은,"kakao 기술 블로그는 올해 초 Ghost 블로깅 플랫폼을 사용해서 오픈했으나, 최근 GitHub Pages와 Jekyll으로 바뀌었습니다. 이 글에서는 kakao 기술 블로그를 GitHub Pages로 옮기면서 Jekyll에 위해 추가한 기능들 - 태그별 포스트 목록 페이지, 작성자별 포스트 목록 페이지, 사이트맵 - 을 소개합니다. 오픈 초기에는 kakao는 브런치, 티스토리, 다음블로그, 플레인까지 여러가지의 블로그스러운(?) 서비스를 하고 있으면서 정작 기술 블로그는 Ghost을 사용하는 것에 대해 사내외에서 많은 의문을 제기했었죠.티스토리, 브런치, 설치형 WordPress, 자체 개발까지 다양한 솔루션을 검토했지만, 생뚱맞게도 Ghost을 사용하기로 했습니다. Markdown 지원, 작성과 발행 권한 분리, 커스텀 디자인 그리고 기능 추가의 용이성(단순 블로그 외에도 많은 기능이 계획되어 있습니다)을 고려했습니다. 가장 결정적인 이유는 운영자의 개취였는다는 설도 있습니다만…그러나, 운영 과정에서 블로그 외의 기능 개발이 보류되면서 Ghost를 선택한 가장 큰 이유였던 기능 추가의 용이성은 의미가 없어졌고, 운영자의 개취만이 남았습니다. 무엇보다도(!) 기술 블로그 만의 Geek스러움이 부족했습니다.그래서… 바꿨습니다!GitHub Pages는 아시다시피 GitHub 저장소의 내용을 웹 페이지로 서비스해주는 기능입니다. 공짜로 웹 서버를 구축할 수 있지만, 스태틱 컨텐츠만 서비스할 수 있어서 제한적인 용도(예: 뻔한 오픈소스 소개/문서 사이트)에 주로 사용됩니다. 그러나, 여기에 정적 사이트 생성기가 결합되면 활용의 폭이 훨씬 넓어집니다. 그 중에서도 Jekyll은 GitHub Pages가 기본으로 지원하는 정적 사이트 생성기로, 소스(주로 Markdown)를 깃헙에 올리면 Jekyll을 실행해서 정적 사이트를 생성하는 과정을 깃헙 서버가 자동으로 수행하고, 그것을 웹 페이지로 서비스합니다.자세한 내용은 GitHub Pages에서 Jekyll을 정적 사이트 생성기로 사용하기에게 맡기고, 이 글에서는 kakao 기술 블로그를 만들면서 추가한 기능들만 소개하겠습니다.Jekyll은 직접적으로 태깅(tagging)을 지원하지 않습니다. 이를 지원하는 여러가지 플러그인들을 테스트 해보았지만, 아쉽게도 GitHub Pages와 함께 쓸 수 없는 경우가 많았습니다. 그래서 Jekyll의 Collections 기능을 활용해서 간단하게 만들었습니다._tags 디렉토리 안에 있는 파일 목록을 수집해서 /tags/...로 서비스되도록 HTML 파일을 생성하라는 설정입니다. (디렉토리 이름 앞의 _는 오타가 아닙니다. 설정에는 _가 없고, 디렉토리 이름에는 _가 있습니다.)Front Matter의 내용을 살펴보면:주의: 새로운 태그가 추가되면 새로운 파일을 만들어줘야 합니다.이 부분이 이 글에서 소개하는 태깅 방식의 가장 큰 문제점인데… 플러그인 없이 해결하는 방법을 아직 찾지 못했습니다.태그별 포스트 목록 페이지를 생성하는 과정은 다음과 같습니다:레이아웃 템플릿(_layouts/tag.html)에서 핵심적인 Liquid 템플릿 코드를 살펴보면:모든 포스트 목록(site.posts)을 순회하면서, 포스트의 태그목록 배열(post.tags)에 지정한 태그를(page.name)가 포함되어 있으면 해당 포스트를 출력하는 코드가 눈에 들어올 겁니다. (주의: 여기서 page 변수에는 태그 파일의 데이터가 담겨있습니다.)단순무식한 O(포스트개수 x 태그개수) 풀스캔이지만, 이 과정은 정적 사이트 생성 과정에만 이루어지므로 실제 서비스에는 영향이 없습니다.Jekyll의 Data Files 기능을 이용하면 좀 더 쉽고 효율적으로 만들 수 있을것 같지만, 플러그인을 만들어야 해서 pass! (포스트가 수만개, 태그가 수만개라면, 그냥 데이터베이스 기반 블로그를 쓰시는 것이 정신 건강에 좋습니다.)Jekyll은 작성자라는 개념(author attribution)을 지원하지 않습니다. 애초에 흔한 웹UI도 없으니, 로그인도 없고, 작성자라는 개념도 없죠. 그래서 태그 분류하기에서 사용했던 방법을 조금 변형해서 작성자로 분류하기를 만들었습니다. 과정은 태깅과 거의 같습니다.설명이 필요없겠죠? 태깅과 거의 같습니다. ;)역시나 설명이 필요없겠죠? 태깅과 거의 같습니다. ;)작성자별 포스트 목록 페이지를 생성하는 과정은 다음과 같습니다:이하 동문 생략…Ghost를 선택한 이유 중의 하나가 검색 엔진 최적화였습니다. 별다른 설정없이도 페이지에 meta 태그들도 주렁주렁 많이 달아주고, 사이트맵도 자동으로 만들어 줍니다.물론 Jekyll에도 사이트맵을 지원하는 플러그인들이 많습니다만, 역시 GitHub Pages가 발목을 잡습니다. 그래서… 기본 테마에 포함된 feed.xml를 참조해서 간단하게 만들었습니다.파일 맨 앞에 Front Matter는 없어도 있어야 합니다(응?) 포스트(site.posts)는 모두 포함되고, 페이지(site.pages)중에서 sitemap속성이 있는 페이지만 포함됩니다. 그리고, 위에서 만든 태그별 포스트 목록과 작성자별 포스트 목록도 포함됩니다. 차~ㅁ 쉽죠?sitemap.xml 파일은 검색 엔진을 위한 것입니다만, 휴먼을 위한 최소한의 배려로, Ghost를 참고해서 sitemap.xsl도 추가했습니다.그 결과는 http://tech.kakao.com/sitemap.xml에서 확인하실 수 있습니다.기업의 기술 블로그에 이런 가벼운 내용이 올라가도 될까…라는 고민을 잠시했지만… 우아한형제들의 기술 블로그에 김범준 님이 쓰신 글을 보고 용기내어 올려봅니다.앞으로도 kakao 기술 블로그 많이 사랑해 주세요. 꾸벅~전하는 말씀(or 광고)kakao의 오픈소스 업무를 담당할 인재를 모십니다. 지원하기",http://tech.kakao.com/2016/07/07/tech-blog-story/,0,kakao,"css,react,frontend,javascript,bootstrap",NULL,2016-07-07
ADT 활용 예제1: MySQL Shard 데이터 재분배,"카카오의 많은 서비스들이 데이터베이스로써 MySQL을 사용합니다. 그리고 서비스 규모가 커지면 대용량 분산을 위해 샤딩을 합니다.카카오에서 많이 사용하는 샤딩 방법으로 크게 두 가지 방식이 있습니다.그러나 두 방법 모두 한계가 있습니다.특정 ID값을 기준으로, ID 범위에 따라 샤드를 나누는 방식입니다. ID값이 증가하는 추이를 보고서 새로운 샤드 추가가 쉽다는 장점이 있습니다. 반면에 디스크 사용량이나 쿼리 처리량의 밸런스가 많이 안 맞는 경우가 발생하기도 합니다.아래 그림과 같이 User ID 기준, Range 방식으로 샤딩을 적용한 어떤 서비스가 있다고 가정하겠습니다. 초창기 샤드는 데이터량이 아주 많고 최근에 추가된 샤드는 다른 쿼리 처리량이 매우 많습니다. 그리고 간혹 초창기 사용자들의 충성도가 높은 서비스의 경우, 초기에 추가한 샤드들도 쿼리량이 적지 않은 경우가 있습니다.[ID값] % [샤드 개수]의 결과 값으로 샤드 위치를 결정하는 방식입니다. Range 방식에 비해 리소스 사용 밸런스가 잘 맞다고 알려져 있습니다. 그러나 이 방식은 샤드 추가가 어렵습니다.아래 그림과 같이 3개의 샤드에서 4개의 샤드로 확장을 하려면 기존의 각 샤드마다 데이터 재배치가 필요합니다. 현재 샤드 개수의 배수로 확장하면 그나마 쉽게 샤드 추가를 할 수 있지만, 만약 현재 샤드 개수가 수십~수백이라면 적지 않은 낭비가 발생할 수도 있습니다.클라우드 서비스에서 제공하는 DB를 사용하는 서비스 경우, 간혹 이런 경우가 있습니다.피크 타임의 수많은 UPDATE 쿼리를 버티기 위해 shard 수를 늘렸습니다. 그런데 새벽에는 DB 머신이 거의 놀고 있어서 낭비가 발생하고 있습니다. 자유롭게 shard scale in/out할 수 있는 방법은 없을까요?이러한 기존 문제들을 해결하기 위해서는 각 샤드들의 데이터를 재분배가 필요합니다.지금부터 ADT를 활용해 하나의 Master를 여러 샤드로 재분배하는 방법을 소개드리겠습니다.본 글에서 예제로 구현할 handler의 소스는 여기에서 확인하실 수 있습니다.두 가지의 핸들러를 구현할 예정입니다.여기서는 Maven 기반으로 project를 생성하도록 하겠습니다. 생성 후 아래와 같이 parent를 지정합니다.다음과 같이 handler interface 구현체를 만듭니다.그리고 크롤링한 각 데이터를 INSERT IGNORE를 이용하여 target DB에 복사합니다.CrawlerHandler와 비슷하게, BinlogHandler용 interface 구현체를 만듭니다.각 binlog event 별로 다음과 같이 target에 적용합니다.보통 binary log를 이용하여 복구를 할 때 각 이벤트 별로 다음과 같이 DML을 사용할 것입니다.그러나 ADT를 사용할 때는 고려할 사항들이 있습니다.이러한 문제들에 대해, 여기서는 모든 쓰기 작업을 덮어쓰기 정책으로 풀어냅니다. 위의 이벤트별 DML은 아래와 같이 변환할 수 있습니다.빌드 및 실행 방법은 아래 링크를 참고하세요.이번 장에서는 위에서 만든 핸들러를 이용해, 샤드 재분배를 어떻게 할 수 있는지에 대한 내용을 다룹니다. 상황에 따라 적절한 전략이 필요합니다. 아래 나열된 방법들 외에도 여러 아이디어 있으면 공유 부탁드립니다.FOR UPDATE로 인해 락이 걸린 데이터들은 수정이 불가능하여 binlog에 남지 않음이번 장은 카카오 내부적으로도 아직 구현은 안 된, 이론 검증 단계에 있는 부분입니다. 따라서 간단하게 소개만 드리고 다음 기회에 좀 더 자세한 내용으로 다시 찾아뵙도록 하겠습니다. 적극적인 의견/비판은 언제든 환영입니다.위에서 구현한 핸들러가 제대로 작동하는지 확인하기 위해 단위 테스트, 통합 테스트 등도 필요하지만 실사용을 하다보면 미처 테스트에서 검증하지 못한 여러 문제가 발생하기도 합니다. 이러한 문제를 탐지하기 위해 이번 장에서는 샤드 재분배가 올바르게 진행되었는지를 검증하는 방법에 대해 지금까지 고민해온 내용들을 공유하고자 합니다.데이터의 일부만 비교하여 일정 신뢰도 이상이면 문제가 없는 것으로 간주할지, 아니면 전체 데이터를 조사해야할지부터 고민이 시작되었습니다. 데이터가 너무 많아서 전수조사가 힘든 경우도 있기 때문입니다. 하지만 사용자들의 소중한 데이터를 다루는 것에 있어, 100% 외에는 있을 수 없다는 판단에 전수 조사를 택하기로 했습니다.첫번째 방법은 source DB의 데이터 변화가 없을 경우에 가능한 방법입니다. 이 방법이 가능한 상황은 서비스 중단 상태(점검 등의 이유), source DB 자체가 다른 DB의 slave이면서 동시에 replication이 중단된 상태 등이 있습니다. 후자의 경우를 예로 들면 다음과 같이 검증이 가능합니다.이 방법은 서비스 영향없이 데이터 검증이 가능하다는 장점입니다.source DB 데이터가 끊임없이 바뀌는 중에 검증할 수 있는 방법입니다.이 방법의 특징은 실제 서비스되고 있는 데이터를 기준으로 검증을 할 수 있다는 점입니다.위의 방법들 외 다른 아이디어, 혹은 의견 등등 언제든 환영입니다.지금까지 ADT를 활용하여 MySQL Shard 데이터 재분배하는 방법에 대해 알아봤습니다. 아직 카카오 내부적으로 검증 단계인 부분도 있지만 많은 분들께 도움이 되길 바랍니다. 더불어 같이 고민이나 의견을 공유하는 것도 언제든 환영입니다.^^special thanks to 성동찬 (한국카카오 카카오뱅크)",http://tech.kakao.com/2016/07/01/adt-mysql-shard-rebalancing/,0,kakao,"spring,java,mysql,docker,backend,javascript,database,php",NULL,2016-07-01
kakao의 오픈소스 Ep5 - Almighty Data Transmitter,"“카카오의 오픈소스를 소개합니다” 다섯번째는 gordon.hahn과 동료들이 개발한 ADT - Almighty Data Trasmitter입니다.ADT는 샤드 구성이나 사딩 규칙이 바뀔 때 샤드를 재분배하는 용도로 만들기 시작했지만, MySQL에서 데이터를 수집하여 다른 MySQL로 데이터를 전송하는 - CDC와 ETL이 결합된 - 만능 데이터 전송 도구로 변모하고 있습니다.ADT는 그 자체로도 유용한 소프트웨어 도구지만, MySQL 기반의 CDC/ETL 시스템을 구축하기 위한 좋은 시작점이 될 것 입니다. ADT는 MySQL의 데이터를 수집하여 사용자가 원하는 형태로 가공하거나 다른 DB에 적재할 수 있는 툴입니다. 크게 나누면 두 가지 용도가 있습니다.각각에 대해 활용 예시는 다음과 같습니다.1일 1회 MySQL의 데이터를 OLAP DB로 복사이 외에도 여러 용도들이 있을 겁니다. 나머지는 여러분들의 상상력에 맡깁니다. 풀리퀘스트의 문은 활짝 열려있습니다 ^^;ADT 자체가 하는 일은 단순합니다. 용도에 따라 Custom Handler를 구현하는 게 허들이라면 허들일 수 있지만, 샤드 재분배용 커스텀 핸들러의 소스 코드를 참조하면 그렇게 어렵지 않….을 겁니다. 아마도…요. (이 부분에 대해서는 다른 글을 통해서 더 자세히 알아보겠습니다)현재는 MySQL에서만 데이터를 수집하지만, 인기가 많으면 더욱 다양한 DB가 추가될 수도 있습니다. 역시나! 풀리퀘스트의 문은 활짝 열려있습니다 ^^; 현재까지는 적용된 사례가 딱 하나 있습니다. 모 서비스의 테이블 스키마가 많이 변경되는 작업이었는데, 도저히 ALTER TABLE로 어떻게 할 수 있는 수준이 아니었다고 합니다. 테이블 스키마가 많이 바뀌어서 서비스 무정지 변경은 못했지만, ADT의 초기 버전을 이용해 무사히 마이그레이션 할 수 있었습니다.ADT를 만들게 된 이유이자 핵심 목표인 샤드 재분배용 커스텀 핸들러는 현재 DB 엔지니어들과 안정성/정합성을 검증하는 단계입니다.등등… 이 글에서 다루지 못한 많은 내용들이 README에 담겨있습니다. 현재까지 구현된 ADT 프레임웍 본체와 검증이 진행 중인 샤드 재분배용 커스텀 핸들러의 소스 코드는 아래 Github 사이트에서 확인할 수 있습니다:kakao 기술 블로그와 위키을 통해서 ADT의 활용 사례를 소개할 예정입니다. ADT가 이름처럼 전지전능한 도구가 될 수 있도록 여러분들의 많은 관심과 참여를 기대합니다.special thanks to 성동찬 (한국카카오 카카오뱅크)",http://tech.kakao.com/2016/06/27/opensource-5-adt/,0,kakao,"spring,python,java,docker,javascript,php",NULL,2016-06-27
Asynchronous Programming and Monad Transformers in Scala,"자바와 스프링으로 웹서버를 개발하고 있다면 아래와 같이 HTTP 프로그래밍을 했을것이라 생각이 됩니다.익숙한 이상할것이 없는 동기화 프로그래밍 코드입니다.동기화 방식은 아래와 같은 장점을 가지고 있습니다.하지만 동기화 방식으로 개발하고 운영하다 보면 thead pool hell이라 불리는 아래와 같은 현상을 자주 마주하게 됩니다. 이미지 출처:  The play framework at Linkedin비동기 프로그래밍을 구현하면 아래와 같이 IO로 인해서 blocking되는 구간이 사라지게 되기 때문에 서버의 리소스(CPU, Memory, Network, Disk)를 충분히 활용할수 있습니다.Spring 3.2버전 부터 비동기 프로그래밍을 지원하고 있고 AsyncRestTemplate.java API을 통해서 비동기 HTTP 프로그래밍을 지원하고 있지만 실제 개발 환경에서 여러개의 Future를 효율적으로 조합(flatMap, Monad Transformers) 할수 없다면 이를 효과적으로 사용할수 없습니다. 이로 인해 부분적으로만 비동기 프로그래밍으로 구현한다면 블록킹 IO로 인해 스레드 waiting현상, thread pool hell은 피할수 없게 됩니다.지난번 포스팅에서 이야기 했던 Monad Programming with Scala Future에 이어를 Future를 Monad Transformers와 함께 사용하며 실전 web server programing에서 활용하고 이를 통해서 thread pool hell을 막을수 있는 방법에 대해서 알아보도록 하겠습니다.이를 위해서 Fully async programming을 지원해주는 Finatra - Fast, testable, Scala services built on Twitter-Server and Finagle를 이용해서 NIO programming을 해보겠습니다.Finatra는 트위터에서 만드는 오픈소스 프로젝트로 Facebook의 React처럼 Twitter에서 Production환경에서 사용하고 있는 open source web framework입니다. Finatra 이름의 기원은 Twitter의 Finagle과 Ruby의 Sinatra를 합친 합성어입니다.Finatra = Finagle + SinatraFinatra는 Sinatra의 간결한 Routing DSL을 채용하였으며 finagle의 다양한 RPC 기능을 활용한 통신과 Twitter Server의 플래그 관리와 어드민 기능을 통합하여 직관적이며 빠르게 개발할수 있는 생산성 높은 web framework입니다.우선 Finatra로 개발하기 위해서는 두가지 핵심 코어 Finagle과 Twitter-Server에 대해서 잠깐 알아보겠습니다.Finagle은 트위터의 RPC 시스템으로 공식 문서에 나와 있는 프로토콜은 Thrift, Mux, Mysql가 있고 Github 프로젝트를 보면 fingle-memcached, finagle-redis, finagle-http, finagle-http2 등등 보다 다양한 프로토콜이 있습니다. Finagle을 활용하면 이들 프로토콜을 손쉽게 사용할수 있습니다. 아래 그림을 보면 finagle server와 finagle client들을 이용하여 이종의 client들을 연결하는 서비스를 제공하고 있는것을 확인할수 있습니다. 이제 finagle의 RPC Client를 코드를 내부를 좀 더 파해쳐 보겠습니다. 내부코드를 보면 finagle RPC의 구현의 기본은 com.twitter.finagle.Client[Req, Rep] trait을 mixin하는걸로 되어 있습니다.아래 소스 코드는 하위프로젝트 finagle-memcached의 com.twitter.finagle.Memcached.scala의 일부분입니다.Finagle은 이종 프로토콜간의 동일한 interface를 제공해주기 위해서 fingle.Client의 mixin을 강제하고 있습니다. MemcachedRichClient에서는 self: finagle.Client[Command, Response] => 표현을 사용하고 mixin하고 있습니다.Self type annotation에 대해서는 akka 창시자인 Jonas Bonér의 real-world scala: dependency injection (di)와 stackoverflow의 What is the difference between self-types and trait subclasses?를 참조하면 좋은 자료가 될것이라 생각합니다.이번엔 finagle-mysql의 com.twitter.finagle.Mysql.scala의 구현의 일부를 보겠습니다.MemcachedRichClient와 유사게 인터페이스가 설계되어 있으며 내부 구현은 mysql.Client로 숨겨져 있는것을 확인할수 있습니다.Finagle의 모든 하위 RPC 프로젝트는 fingle.Client를 구현하고 있어서 다양한 RPC 프로토콜이 모두 같은 interface를 가지는 장점이 있습니다.Finatra는 finagle의 하위 프로젝트 finagle-http의 HTTP 서버를 사용하여 web framework이 설계되어 있습니다. 그리고 finagle-http은 netty를 기반으로 구현 되어있어서 최종적으로 finatra < finagle < netty 순으로 의존도가 있다고 생각하시면 됩니다.Finatra의 BaseHttpServer.scala 소스 코드를 보면 finagle의 com.twitter.finagle.Http.Server를 이용하여 http server를 구성하고 있는것을 확인할수 있습니다.Finatra를 Twitter Server를 이용하여 엔터프라이즈급 서버에 필요한 다양한 모니터링 솔루션(어드민, 트래킹, 통계)과 설정 플래그와 같은 부분은 공통 컴포넌트화 해서 제공하고 있습니다.아래 그림은 Twitter Server 어드민 페이지에서 볼수 있는 서버 모니터링 화면입니다. 위의 순서로 실행하면 아래와 같은 화면이 브라우저에 뜹니다. finatra-mysql-seed 프로젝트를 이용하여 finatra를 개발하는 과정에 대하여 설명하겠습니다. finatra-mysql-seed project는 finatra를 이용해서 개발하면서  재사용되는 부분을 template화 해서 만들어 놓은 project입니다.설치 방법은 아래 3가지 방법중 1가지를 선택하여 설치하시면 됩니다.우선 로컬에 JDK8 그리고 mysql이 설치가 되어 있어야 합니다. Mysql에 seed project용 데이터베이스를 만들고 activator로 프로젝트를 실행합니다.Ping메시지를 보내면 pong 메시지를 응답하는 간단한 PingController를 구현해보겠습니다. 기본 구현은 아래와 같습니다. Sinatra 스타일의 HTTP 서버 개발 경험이 있다면 익숙한 표현 방식이라 생각이 됩니다.그리고 방금 정의한 PingController의 router를 FinatraServer에 등록합니다.이제 등록한 Controller에 request를 날리기 위해서 bin/activtor run 혹은 sbt run 을 통해서 프로젝트를 실행합니다. 실행후 브라우져나 curl로 command line에서 결과를 확인할 수 있습니다.Finatra는 Google Guice를 이용한 경량화 Dependency Injection 모듈을 이용하여 의존성 주입및 유닛 테스트, Mock 테스트를 할수 있습니다. Finagle Http Client를 의존성 주입하기 위해서는 접속할 서버의 정보(host:port)를 모듈을 생성하고 FinatraServer에 이를 등록해야 합니다. 이를 통해 Twitter Server Admin페이지에서 등록된 finagle client host의 에러를 감지 및 트래킹할 수 있습니다.Guice를 이용한 모듈을 만들기위해서는 TwitterModule을 상속 받아서 구현하면 됩니다.약간의 편의성을 위해서 Finatra HttpClient 기본 모듈을 상속받아 수정해 봅니다. finatra request builder를 사용할 경우 Host Header 정보가 빠져서 HTTP통신이 되지 않아 RequestBuilder를 생성할 때 마다 Host Header를 넣어줘야하는데 이를 피하기 위해 Header에 Host정보를 기본값으로 미리 설정합니다.이제 실제 HTTP 통신을 할 서버의 host명과 port정보를 이용해서 HttpClientModule을 만듭니다.위에서 만든 FakeHttpClientModule을 FinatraServer에 등록을 합니다.그리고 실제 비지니스 로직을 구현할 FakeService를 만들어 보겠습니다.FakeService를 FakeController를 만들어서 Guice를 통한 의존성 주입 & method 호출을 하고FakeController를 다시 FinatraServer의 라우터에 등록을 합니다.이제 간단히 동작할수 있는 비동기 프로그램이 완성이 되었습니다. 이를 간단한 벤치마크를 통해서 async와 sync의 결과값을 비교해보겠습니다.  위의 코드를 실행결과를 보면 4초의 IO Waiting이 걸리는 외부와 통신을 할때Async 코드에 대해서 Client의 Request를 50개까지 늘려서 성능을 측정해보겠습니다. 밴치마크에 사용한 코드는 ruby로 아래와 같이 작성하였습니다.아직은 단순한 케이스의 대해서만 비동기 프로그래밍을 했습니다. 실제 웹서비스를 개발하다 보면 다양한 복잡한 케이스에 만나게 됩니다.주문 서버에서 주문 리스트를 가져오고 아이템 서버로 각각의 주문의 상품에 대해서 데이터를 비동기로 가져오는 것을 구현해보겠습니다.여기서의 중요한 포인트는 Future안에 List가 들어있다는 것입니다. 주문의 상품내역을 가져오려면 List에서 다시 Order를 추출해내야합니다. 우선 scala의 for comprehension 만을 이용하여 데이터를 비동기로 가져와 보겠습니다.위의 코드는 로직이 복잡하고 가독성도 떨어집니다. 실제 사용이 거의 불가능한 코드라 생각이 됩니다. 기존의 for comprehension은 중첩된 모나드를 효율적으로 처리할수 없습니다. 하지만 Monad Transformers란 개념을 활용하면 새로운 flatMap(A => Future[List[B]]) 함수를 만들고 이를 간단하게 처리할수 있습니다. 😊Monad Transformer를 만들기위해서 FutureSeq라는 case class를 하나 만들고 인자로 Future[Seq[A]]를 받도록 합니다. List는 Seq를 상속 받기 때문에 Future[List[A]]도 인자로 받을수 있게 됩니다. 그리고 flatMap, map, filter 그리고 withfilter를 구현해주면 됩니다.이제 FutureSeq monad transformer를 만들었으니 위의 주문내역을 가져오는 코드를 리팩토링 해보겠습니다.Monad Transformer를 통해서 훨씬 가독성이 좋고 유지보수하기 좋은 코드로 바뀌었습니다.위의 코드를 scalaz에 있는 ListT Monad Transformers를 활용하면 아래와 같이 사용할수 있다.위에 직접 만든 Monad Transformer와 같은 역할을 하게 되고 코드량도 거의 같습니다.Web application을 개발하다보면 Database와의 연동 작업, 특정 키값으로 데이터를 조회하는 일이 많이 있습니다. Java에서는 데이터가 없는 경우에 null이 반환되지만 Scala에서는 nullable한 데이터에 대해서는 Option[T]로 표현을 합니다.특정 유저의 email을 가지고 그 유저의 현재 남아 있는 point를 조회하는 로직을 구현해보겠습니다. 우선 Quill과 finagle-mysql의 조합으로 Mysql에 들어있는 데이터를 조회해보도록 하겠습니다.Users Table 조회Point Table 조회이제 두개의 유저의 email을 가지고 point를 가져와 보겠습니다.Future안에 List가 있는 경우보다는 간단한 로직이지만 여전히 사용하기 불편합니다. 이부분도 Monad Transformer를 활용해서 수정해보겠습니다.특정값 A 를 받아서 Future[Option[B]]를 반환하는 flatMap(A => Future[Option[B]]) 함수를 만들고 이를 통해서 Option Monad Transformer를 만들어 보겠습니다. 기본 구조는 위의 FutureSeq 와 같습니다. 다만 내부 구현이 조금씩 차이가 납니다.이제 새롭게 만든 Option Monad Transformer를 활용해서 원래 코드를 수정해보겠습니다.코드가 훨씬더 간결해지고 편리하게 두개의 함수의 결과값을 조합할 수 있습니다. FutureOption 또한 scalaz의 OptionT Monad Transformer를 사용하면 동일하게 구현할 수 있습니다.비동기 프로그래밍을 하다 보면 Future안에 감싸져 있는 값을 처리하기 쉽지 않은 경우가 종종 생깁니다. Scalaz에는 자주쓰이는 Monad Transformers에 대해서 구현이 되어 있습니다. OptionT, EitherT, ListT, StreamT, StateT 이외에 다양한 Monad Transformers가 존재합니다. 이를 통해서 다양한 Moand의 조합을 하고 풍부한, 간결한 비동기 프로그래밍을 할수 있을것이라 생각됩니다. 또한 적절한 Monad Transformers를 찾아보고 없으면 직접 구현하는것도 또한 좋을것 방법이라 생각이 됩니다.카카오 선물하기 웹 프론트 & 서버 개발자를 채용 중입니다. 지원하기",http://tech.kakao.com/2016/05/04/asynchronous-programming-and-monad-transformers-in-scala/,0,kakao,"python,react,java,nodejs,bootstrap,vue,frontend,angular,scala,javascript,php",NULL,2016-05-04
루빅스(RUBICS) - kakao의 실시간 추천 시스템,"루빅스는 실시간으로 사용자 반응을 분석하여 콘텐츠를 추천하는 카카오의 추천 시스템입니다. 2015년 5월에 다음 포털 뉴스 서비스의 일부 사용자를 대상으로 뉴스 기사를 추천하기 시작했고, 한달 뒤인 6월부터 전체 사용자에게 확대 적용했습니다. 현재는 다음 뉴스 뿐 아니라 카카오톡 채널 등 다양한 콘텐츠 서비스에서 루빅스의 추천 서비스를 사용하고 있습니다. 다음 뉴스에 루빅스를 적용한 후에 나타난 긍정적인 효과와 지표 상승에 관한 이야기는 이전에 몇 차례 다룬 적이 있습니다.(관련 글 참고)이번 글에서는 루빅스가 실시간 추천 시스템으로서 어떤 특징을 가지고 있고 어떻게 구현하였는가를 이야기해 보려고 합니다. 루빅스의 첫 적용 사례는 다음 뉴스 서비스 였습니다. 그런 이유로 개발 초기부터 뉴스 서비스에 특화된 요구사항이 많이 반영 되었습니다. 뉴스 콘텐츠는 영화나 음악, 도서와 조금 다른 점이 있는데요, 다른 콘텐츠에 비해서 생명주기가 상당히 짧습니다. 이런 차이점을 고려하면, 뉴스 기사 추천은 사용자의 반응을 최대한 빠르게 수집 및 처리하여 추천 랭킹에 반영해야 합니다. 사용자의 피드백을 반영하기까지 너무 오래 걸린다면, 새롭게 추천된 기사가 뉴스로서 더이상 가치 없을 수도 있기 때문입니다.저희는 사용자로부터 전달되는 피드백을 최대한 신속하고 안전하게 처리할 수 있는 시스템을 만들어야 했습니다. 사용자 피드백 메시지가 대량으로 들어오는 환경에서도 안정적으로 동작하는 메시지 큐와 메시지 큐에 저장된 데이터를 빠른 속도로 처리할 수 있는 데이터 스트림 처리기를 이용하기로 했습니다.Apache Kafka 는 대량의 메시지를 안전하게 저장할 수 있는 분산 메시징 시스템입니다. 빠르고, 확장성이 있으며, 데이터 손실을 방지할 수 있도록 복제 기능을 제공합니다. 이미 검증된 적용 사례가 많이 있었으므로, 루빅스에도 Apache Kafka 를 메시지 큐 시스템으로 채택했습니다.메시지 큐에 저장된 데이터를 빠르게 읽어서 처리한 결과는 추천 랭킹을 위한 기계 학습에 사용됩니다. 실시간으로 데이터 스트림을 처리할 수 있는 여러 기술 중에서 루빅스는 Apache Spark Streaming 을 사용하고 있습니다. 이렇게 결정하게 된 이유로는 첫째, 개발할 당시에 Apache Spark 이 상당한 인기를 모으고 있었고, 둘째로는 무엇보다도 루빅스 개발팀 내에 스칼라 언어에 익숙한 개발자가 많이 있었기 때문입니다. Apache Spark 은 애플리케이션 개발을 위한 주요 언어로 스칼라를 잘 지원하며, 루빅스 개발자들은 익숙한 언어로 개발을 시작할 수 있었으므로 학습의 부담을 많이 줄일 수 있었습니다.데이터의 용도와 성격에 따라서 일부는 굳이 실시간으로 처리할 필요가 없습니다. 이런 종류의 데이터는 일정 기간동안 모아서 주기적으로 배치 처리를 합니다. 루빅스는 배치 처리를 위해서 Spark 과 Hive 을 사용하고 있는데, 이렇게 실시간과 배치로 처리된 데이터를 결합하여 최종 추천 서비스에서 사용하고 있습니다.루빅스에서는 사용자의 피드백이 수 초 이내에 새로운 추천 결과에 반영됩니다.루빅스에서 추천 결과를 반환하는 응답 속도는 콘텐츠 서비스 자체의 응답 속도에 직접 영향을 줍니다. 따라서 루빅스의 응답 속도는 빠르면 빠를수록 좋습니다.저희는 응답 속도를 빠르게 만들기 위해서 몇 가지 요소를 고려하여 시스템을 설계 했습니다. 이 중에서 3번 항목에 대해서 좀 더 이야기해 보겠습니다. 병렬로 실행되는 프로그램은 여러 개의 논리적인 쓰레드로 구성됩니다. 멀티 쓰레드 프로그래밍에서 가장 골치 아픈 문제는 공유 자원을 관리하는 것입니다. 여러 개의 쓰레드가 공유 자원을 한꺼번에 변경하다 보면 race condition 이 발생하기도 합니다. 대개는 이런 문제를 해결하기 위해서 공유 자원에 접근하기 전에 락(Lock)을 걸고, 접근이 끝나면 락을 풀어 버립니다. 그러나 락을 사용하는 것도 생각만큼 간단하지 않습니다. 한 쓰레드가 공유 자원에 접근하는 동안에 다른 쓰레드는 차례를 기다려야 하기 때문에 프로그램 실행 속도가 느려지곤 합니다. 또 락을 사용하는 순서가 꼬여 버리면 deadlock 문제가 발생하기도 합니다.요즘은 동시성 프로그래밍을 하기 쉽다는 장점 때문에 함수형 언어들이 많은 인기를 얻고 있습니다. 멀티 쓰레드 프로그래밍에서 공유 자원 관리가 어려운 이유는 공유 자원의 상태가 변하기(mutable) 때문입니다. 변하지 않는(immutable) 데이터는 락을 사용하지 않더라도 여러 개의 쓰레드에서 안전하게 접근할 수 있습니다. 함수형 언어에서 모든 데이터는 불변이므로 위에서 이야기한 멀티 쓰레드 프로그래밍의 어려움을 해결할 수 있습니다.저희는 이런 함수형 언어의 장점을 활용할 수 있는 스칼라를 사용하고 있습니다. 스칼라는 순수 함수형 언어는 아니지만, 여전히 함수형 언어로서의 특징을 가지고 있습니다. 앞에서도 이야기한 것처럼 루빅스 개발팀 내에는 이미 스칼라 언어에 익숙한 개발자가 많이 있었으므로, 스칼라를 주요 개발 언어로 채택할 수 있었습니다. 스칼라에서 지원하는 Future 와 Actor 를 이용하여 비동기/비차단 방식으로 병렬 실행되는 코드를 작성하기 한결 쉬워졌으며, 이 덕분에 루빅스의 응답 속도는 꽤 빠른 편입니다.현재 루빅스는 99% 요청을 3ms 이내에 처리하며, 99.9999% 요청을 150ms 이내에 처리하고 있습니다. 카카오의 다양한 콘텐츠 서비스에서 루빅스의 추천 서비스를 사용하게 되면서, 루빅스에서 처리하는 요청량도 급격히 증가했습니다. 저희는 프로젝트 초기부터 확장성을 염두에 두고 시스템을 설계 했으므로, 트래픽의 급격한 증가에 대응할 수 있었습니다.상태를 저장하는 구조는 확장하기 어렵습니다. 이전의 상태가 저장된 특정 인스턴스로 요청이 계속 전달된다면 단순히 인스턴스 수를 늘려도 트래픽이 골고루 분산되지 않기 때문입니다. 서비스에 영향을 주지 않으면서 수평으로 확장이 가능한 구조를 만들기 위해서 각 인스턴스는 상태가 없는 구조로 설계 되었습니다.분산 NoSQL 데이터베이스인 Couchbase 를 사용한 것도 확장성 있는 구조 설계를 가능하게 했습니다. Couchbase 에서는 노드를 추가하거나 제거하고 데이터를 재분배하는 기능이 쉽게 지원됩니다. 이런 특징 덕분에 트래픽의 증감에 따라서 노드 수를 쉽게 조절할 수 있었습니다.2016년 4월 기준으로 루빅스로 유입되는 요청량이 시스템 오픈 이후 60배 이상 늘었으며, 피크타임에 20만 QPS 요청을 처리하고 있습니다.서비스를 운영하다 보면 크고 작은 장애가 항상 발생합니다. 장애의 원인은 아주 다양합니다. 코드에 버그가 있거나, 급증하는 트래픽을 감당하지 못 해서 인스턴스가 죽기도 합니다. 때로는 네트워크 스위치나 서버의 메인보드가 고장 나는 경우도 있습니다.중요한 것은 예측하기 어려운 다양한 이유로 부분적인 장애는 발생할 수 있지만, 그것이 서비스 전체에 영향을 주는 장애로 이어져서는 안 된다는 점입니다. 루빅스는 서비스 장애를 최소화할 수 있는 구조를 만들기 위해서 많은 고민을 했습니다. 2016년 4월 현재 루빅스는 서비스 오픈 이후로 99.998% 가용성을 보이고 있으며, 작년 9월 이후로 루빅스의 장애시간은 0을 기록하고 있습니다.지금까지 루빅스의 주요 특징과 사용 중인 기술을 설명 드렸는데요, 이 글이 저희와 비슷한 문제를 해결하려고 고민하고 있는 사람들에게 도움이 되었으면 합니다.이 글은 카카오에서 루빅스TF를 이끌고 있는 sawyer.seo가 쓴 글입니다. 루빅스 덕분에 뉴스에도 등장하고, 국정감사 보고서도 만들고… 버라이어티한(?) 나날을 보내고 있는…(자세한 설명은 생략한다)기술 블로그를 통해서 카카오가 자체 개발한 다양한 기술들을 소개합니다. 현재로썬 카카오 내부에서만 사용할 수 있다는 점이 아쉽지만, 함께 나눌 수 있는 부분들은 지속적으로 발굴하고 공개할 계획이니, 관심을 갖고 지켜봐주세요.물론, 카카오 크루가 되시면 지금이라도 사용하실 수 있고 또 개발에 참여하실 수 있습니다 ^^;",http://tech.kakao.com/2016/04/27/rubics/,0,kakao,"python,java,docker,mysql,backend,frontend,javascript,database,mongodb",NULL,2016-04-27
Weekly Links #2 - 2016년 4월 넷째주,"Weekly Links에서는 지난 한 주, 카카오의 기술 블로그 담당자가 구독하는 기술 뉴스레터들에서 “인간의 눈”으로 선별한 링크들을 짧은 코멘트와 함께 공유합니다.포함된 뉴스레터 목록은 awesome-tech-newsletters에서 확인하실 수 있습니다.V8엔진을 5.0으로 업데이트해서 ES6 문법의 93%를 지원한다는 군요. v5와 v6로의 변경사항이 꽤 길지만, 눈에 띄는 것은 없습니다. 물론 기존 v4은 2017년 4월까지 계속 지원(LTS; Long Term Support).링크는 지디넷의 요약 기사구요, 영어 원문은 매우 길기 때문에… 꼭 보실 분 만 보세요. 리스닝에 자신 있으시면 동영상도 있습니다.요약하면, 리눅스에서 WINE이 하는 짓(?)과 비슷한 짓(!)을 한다~입니다. WINE은 윈도의 수많은 Undocumented API  때문에 고통받았었는데 좀 불공평?!결론은 광고지만, 거기까지 가는 과정에서 유익한 내용이 많습니다. 이런 광고라면 고맙죠~뷰티플코드, 디자인패턴, 클린코드, 컴파일러스(드래곤북??)… 주옥같은 책들이 많습니다. 안타까운 건… 번역이 안된 책도 많고, 그나마도 절판된 책이 많다는 것…국가, (미국내)지역, 나이, 업무… 등 다양한 기준으로 결과를 보여주는데요, 미국 평균 10만불, 아시아 평균 3만불… 흠… 차이가 많이 나네… 아프리카 평균 5만불?! OTL요약하면, 2초면 3%, 4초면 6%, 32초면 34%가 포기~한다는 군요. 생각보다 오래 버틴다고 생각하는 건 저 뿐인가요?같은 블로그의 이전 글 2016년의 웹 어플리케이션은 얼마나 빨라졌을까?도 재미있네요. 2초 내에 끝내지 못하면… 당신의 웹은 하위 8.5% ㄷㄷㄷ 열심히 해야겠습니다.다양한 모바일 관련 통계들을 보여주는데요, 개인적으로 가장 인상적인 통계는: 2015년에 모바일 상거래가 115조 달더인데, 데스크탑 52%, 태블릿 33,% 모바일 15%!자사의 제품인 Visual Studio에서 직접 지원하지 못하는 언어/플랫폼을 Code를 통해 지원하려는 전략일까요?  Node.js, Go, C++, PHP, Python… 점점 더 강력해지고 있습니다. 개인적으로는 시간이 지면서 느려지는 문제 때문에 당분간은 젯브레인에 머물러 있을 듯 ;)오픈 하드웨어 + 오픈 소프트웨어 전용 마이크로 컨트롤러는 20유료~ 정도. 뭔가 재밌는 걸 해볼 수 있을 것 같지만… 지금도 집에서 놀고 있는 아두이노와 라스베리파이와…요즘 한창인 프로그래밍언어 전쟁에서 swift가 거침없이 진격하고 있네요. 굴뚝에 연기가 나는 걸 보니… 누가 불을 때고 있긴 한가 본데…Kotlin이 구글의 평가에 자극받았는지, 안드로이드 지원 계획을 발표한데 이어서, 1.0 이후 계획도 발표했습니다. IMHO, 로드맵이 너무 현실적이다 못해 소박하네요.nix는 다양한 unix의 시스템콜을 래핑한 rust 라이브러리입니다. 개인적으로 C/C++의 대체자로 가장 유력한 후보는 rust가 아닐까 생각하고 있습니다만…. 돌 던지지 마세요!페이스북이 이번 F8 컨퍼런스의 공식 앱을 React Native로 만들었는데, 이걸 오픈소스로 공개했고, 만든 과정까지 친절하게 정리했습니다. 예제의 수준이 놀라울 따름~마이크로소프트도 윈도에서 구동되는 React Native를 공개했습니다.자바가 못 이룬 WORA(Write Once Run Anywhere)의 꿈이 react의 LOWA(Learn Once Write Anywhere)로 이어지는 듯…넥슨의 개발자 컨퍼런스 NDC 2016 이 글을 쓰는 지금도 NDC가 한창인데요, 김기웅님께서 벌써부터 발표 자료들을 정리해주고 계십니다. 타임라인에 올라오는 발표자료나 후기들 보고 있으니, 어떻게든 표를 구해볼껄~하는 아쉬움이… 마지막 발표자가 무려! Effective C++의 저자 Scott Meyers~분야가 분야인지라… 고퀄의 슬라이드들이 넘쳐나고 있는데요, 제 눈에 띄는 짤 두개만 소개하면:BTW, 카카오의 개발자 컨퍼런스는 언제 쯤?매주 쓸 수 있을까… 걱정은 했었지만… 시작하자마자 펑크라니… ㅠㅠ 핑계를 대자면, 지난 주에는 겨우내 준비했던 카카오의 앱들이 줄줄이 출시되면서 본업(?)으로 정신없이 바빴습니다. 그래도!! Weekly Links는 쭈욱~~ 계속되겠죠?포함된 뉴스레터 목록은 awesome-tech-newsletters에서 확인하실 수 있습니다.",http://tech.kakao.com/2016/04/27/weekly-links-2/,0,kakao,"objective-c,vue,frontend,angular,python",NULL,2016-04-27
CLOSE_WAIT & TIME_WAIT 최종 분석,"트래픽이 많은 웹 서비스를 운영하다보면 CPU는 여유가 있지만 웹서버가 응답을 제대로 처리하지 못하고 먹통이 되는 경우를 종종 보게 됩니다. 여러가지 이유가 있겠지만, 이 글에서는 가장 대표적인 경우인 CLOSE_WAIT 상태를 재현하고 원인과 문제점 그리고 해결책을 알아봅니다. 나아가 TIME_WAIT의 동작 과정을 직접 만든 예제와 리눅스 커널 소스를 통해 확인하고, 인터넷에 퍼진 낡은 그래서 더이상 유효하지 않은 정보들을 바로 잡습니다.서버 부하 테스트 과정 중 일정 시간이 경과하면 점점 더 느려지면서 행업 상태에 빠지는 경우가 생겼습니다. 부하가 높으면 느려지는건 당연한 일이지만, 더 골치아픈 문제는 테스트가 끝나도 행업 상태에서 복구되지 않았다는 점입니다. 이는 담당자가 매 번 상태를 확인하고 복구해야 함을 뜻하며 서비스에는 도입할 수 없을 정도로 치명적입니다. 분명히 특정한 원인이 있을 것이며 그에 따른 적절한 해결책이 존재할 것입니다.먼저 행업 직전, 8080으로 서비스 중인 포트 상황은 아래와 같습니다:ESTABLISHED 한 개를 제외한 나머지 모두가 CLOSE_WAIT 상태입니다. 이 상태에서 꾸준히 증가하다 해당 서버의 경우 4,023개 째에서 행업되었습니다.netstat 상태도 마찬가지인데 -o 옵션으로 networking timer를 살펴 봐도 거의 2시간이 설정되어 있어 의미가 없고, 이 상태에서 종료되지 않고 점점 증가합니다.먼저 네트워크 서적의 바이블격인 TCP/IP Illustrated 에 등장하는 TCP 커넥션 다이어그램은 아래와 같습니다.이 중 ESTABLISHED 이후 종료 과정에서 어플리케이션의 close() 호출 부분을 추가로 표시했습니다. Active Close 쪽이 먼저 close()를 수행하고 FIN을 보내면 Passive Close 쪽은 ACK을 보낸 후 어플리케이션의 close()를 수행합니다. 보다 상세한 과정은 다음과 같습니다:한 가지 주의할 점은 클라이언트와 서버 대신 Active Close와 Passive Close라는 표현을 사용한 것인데, 반드시 서버만 CLOSE_WAIT 상태를 갖는 것은 아니기 때문입니다. 서버가 먼저 종료하겠다고 FIN을 보낼 수 있고, 이런 경우 서버가 FIN_WAIT1 상태가 됩니다. 따라서, 클라이언트와 서버가 아닌 Active Close(또는 Initiator, 기존 클라이언트)와 Passive Close(또는 Receiver, 기존 서버)정도로 표현하는 것이 정확합니다.CLOSE_WAIT을 아래와 같이 Java 코드로 재현 했습니다.1 아래 예제에서도 서버가 먼저 FIN을 보내 클라이언트가 CLOSE_WAIT 상태에 빠지는 것을 보여줍니다.각각 양쪽의 서버/클라이언트를 실행하면 클라이언트가 CLOSE_WAIT 상태에 빠지고, 행업되어 있는 동안에는 이 상태가 사라지지 않습니다.아래는 위의 예제를 맥에서 실행하고, netstat를 실행한 모습이다. 참고로 맥(BSD 계열)과 리눅스의 netstat 옵션은 많이 다릅니다.10분이 지나도 CLOSE_WAIT 상태가 계속 변하지 않음을 확인할 수 있습니다.Passive Close 측이 CLOSE_WAIT 상태에 빠지면 Active Close 측은 FIN을 못 받는 상태이기 때문에 FIN_WAIT2에서 마찬가지로 대기하게 됩니다. 그러나 CLOSE_WAIT와 달리 FIN_WAIT2는  일정 시간이 경과하면 TIME_WAIT 상태가 됩니다.뒤에서 설명하겠지만, FIN_WAIT2는 net.ipv4.tcp_fin_timeout을 설정해서 변경할 수 있으며 CentOS의 경우에 60초로 설정되어 있습니다. TIME_WAIT는 2*MSL(Maximum Segment Lifetime)으로 60초로 고정되어 있으며 변경할 수 없습니다.커널 옵션으로 타임아웃 조절이 가능한 FIN_WAIT이나 재사용이 가능한 TIME_WAIT과 달리, CLOSE_WAIT는 포트를 잡고 있는 프로세스의 종료 또는 네트워크 재시작 외에는 제거할 방법이 없습니다. 즉, 로컬 어플리케이션이 정상적으로 close()를 요청하는 것이 가장 좋은 방법입니다.You can’t (and shouldn’t). CLOSE_WAIT is a state defined by TCP for connections being closed waiting for the counterpart to acknowledge this.2 No, there is no timeout for CLOSE_WAIT. I think that’s what the off means in your output. To get out of CLOSE_WAIT, the application has to close the socket explicitly (or exit).3 Since there is no CLOSE_WAIT timeout, a connection can stay in this state forever (or at least until the program does eventually close the connection or the process exists or is killed). If you cannot fix the application or have it fixed, the solution is to kill the process holding the connection open.4저마다 강조하는 바를 살펴봐도 CLOSE_WAIT는 커널 옵션이나 설정으로 타임아웃을 줄 수 없으며 로컬 어플리케이션의 문제이기 때문에 정상적인 문제 해결이 필요하다는 지적을 하고 있습니다.그렇다면 해당 서버의 CLOSE_WAIT 상태 원인은 무엇일까요? 문제가 된 것은 자바로 만든 웹 서비스이므로 행업 상태인 해당 JVM의 Thread Dumps를 분석했습니다.(참고: Java Thread Dump Analyzer를 사용하면 좀 더 쉽게 쓰레드 덤프를 분석할 수 있습니다.)그 결과 대부분의 쓰레드가 검색 결과를 받아오지 못하고 대기중(WAITING)인 것을 확인했습니다. 그런데 재밌게도 이 검색 결과는 로컬에서 받아오는 것입니다. 즉, 로컬은 행업 상태여서 검색 결과를 보내주지 못하는 상황이고, 쓰레드는 검색 결과를 받기 위해 대기하는 상황입니다.원래 일정 시간이 경과하면 타임아웃으로 끊어야 하는데, 행업 상태에 빠지다보니 이 조차도 처리되지 않고 서로가 서로를 기다리는 상황인 거죠.즉, 보낼 수도 없고 받을 수도 없는 일종의 교착 상태(deadlock)가 원인으로 지목됐습니다. 아울러 이 상태는 성능 테스트가 끝나도 정상으로 복구되지 않았습니다.이 부분을 좀 더 구체적으로 설명하면,요청과 응답을 받는 과정에서 recursive 한 호출이 교착 상태의 원인이었으며 별도 서버를 구성하여 상호 의존성 없이 호출 가능하도록 구성했다. 톰캣을 통한 동일한 WAS가 아닌, 별도의 nginx를 구성하고 다른 프로세스에서 HTML 파일을 내려주도록 처리해 문제를 해결했습니다.테스트 결과, 더 이상 문제가 발생하지 않음을 확인했습니다.TIME_WAIT 상태가 늘어나면 서버의 소켓이 고갈되어 커넥션 타임아웃이 발생한다는 얘기를 종종 듣습니다. 이 말이 올바른 얘기인지, TIME_WAIT은 어떠한 경우에 발생하고 어떤 특징이 있는지 살펴보겠습니다.TIME_WAIT 이란 TCP 상태의 가장 마지막 단계이며, 앞에서 살펴보았습니다. Active Close 즉, 먼저 close()를 요청한 곳에서 최종적으로 남게 되며, 2*MSL(Maximum Segment Lifetime)동안 유지됩니다.이 단순한 과정이 매번 어렵게 느껴지는 이유는 대부분은 고급언어로 소켓을 랩핑해서 사용하기 때문에(앞에서 예제로 제시한 Java 코드1도 accept() 이전 모든 과정이 라이브러리로 랩핑되어 있음) 소켓에 문제가 생기지 않는 한 로우 레벨로 내려가 확인할 일이 흔치 않고, 또한 확인하는 방법을 아는 이도 드물기 때문일 겁니다.구현 및 재현에 나름의 고급 기술이 필요하다보니 거의 대부분은 실제로 검증 과정을 거치지 못하고 문서로만 익히게 되는데, 그러다 보니 잘못된 정보, 오래된 정보로 더 이상 유효하지 않은 내용들이 무분별하게 전제됩니다.제대로 된 검증 과정도 거치지 않은 채, 또는 검증할 능력이 부족한 상태에서 계속 인용되면서 잘못된 정보가 지속적으로 확대 재생산됩니다. 심지어 스택오버플로우에도 절반 이상은 잘못된 정보입니다. 그나마 해외에는 제대로 된 문서가 일부 있지만 우리말로 된 문서 중에는 100% 정확한 문서가 전혀 없다고 봐도 틀리지 않습니다.잘못된 정보를 접한 이들은 서버 동작과 일치하지 않으니 계속 이해를 못하게 되고 점점 더 어렵게 느껴집니다. 그야말로 “진퇴양난”이죠.현재 시점에서 인터넷에 있는 가장 정확한 문서는 Vincent Bernat 가 작성한 Coping with the TCP TIME-WAIT state on busy Linux servers 입니다. 이외 대부분의 문서는 잘못된 내용을 담고 있는 경우가 대부분이므로 주의가 필요합니다.참고로 이 문서는 리눅스 커널 4.1 커널 소스를 직접 파악하여 리눅스의 TCP 동작을 정리한 내용입니다. TCP 는 몇년새 큰 변화가 없기 때문에 3.x 이상은 대부분 동일하지만, BSD나 윈도우의 동작 방식과는 다를 수 있으므로 유의하시기 바랍니다.TIME_WAIT 상태가 왜 필요하고, 왜 그렇게 길게 설정되어 있는지 이유를 살펴보도록 하겠습니다. 만일 TIME_WAIT이 짧다면 아래와 같은 두 가지 문제5가 발생합니다.첫 번째는 지연 패킷이 발생할 경우입니다.이미 다른 연결로 진행되었다면 지연 패킷이 뒤늦게 도달해 문제가 발생합니다. 매우 드문 경우이긴 하나 때마침 SEQ까지 동일하다면 잘못된 데이타를 처리하게 되고 데이타 무결성 문제가 발생합니다.두 번째는 원격 종단의 연결이 닫혔는지 확인해야 할 경우입니다.마지막 ACK 유실시 상대방은 LAST_ACK 상태에 빠지게 되고 새로운 SYN 패킷 전달시 RST를 리턴합니다. 새로운 연결은 오류를 내며 실패합니다. 이미 연결을 시도한 상태이기 때문에 상대방에게 접속 오류 메시지가 출력될 것입니다.따라서 반드시 TIME_WAIT이 일정 시간 남아 있어서 패킷의 오동작을 막아야 합니다.RFC 793 에는 TIME_WAIT을 2 MSL로 규정했으며 CentOS 6에서는 60초 동안 유지됩니다. 아울러 이 값은 조정할 수 없습니다.틀린 정보: net.ipv4.tcp_fin_timeout 을 설정하면 TIME_WAIT 타임아웃을 변경할 수 있다.TIME_WAIT의 타임아웃 정보는 커널 헤더 include/net/tcp.h 에 하드 코딩 되어 있으며 변경이 불가능합니다.이번에는 소켓의 로우 레벨까지 확인하기 위해 예제 서버 프로그램을 C 로 구현해보겠습니다. 리눅스를 포함한 모든 유닉스 기반 OS 의 API 가 C 로 구현되어 있고 특히 네트워크 프로그램에서 커널의 동작과 C 의 어플리케이션 API 는 정확히 1:1 로 대응됩니다. 따라서 구체적으로 네트워크가 어떻게 동작하는 지를 C 로 직접 구현해 하나씩 확인해보겠습니다.먼저, 서버 프로그램은 예전에 커넥션 테스트 용도로 개발해 깃헙에 공개한 CONTEST 서버를 기반으로 일부 코드를 추가해서 구현했습니다.Java에 비해 코드는 훨씬 더 길지만 동작 방식에는 큰 차이가 없습니다. 의도적으로 서버가 먼저 close()를 시도하는 점도 동일합니다. 즉, 서버측이 Active Close가 되고 TIME_WAIT 상태에 빠지게되는거죠.서버의 동작은 socket() - bind() - listen() - accept() 과정을 거쳐 클라이언트와 연결되며 위 코드에는 그 과정이 상세히 잘 나와 있습니다.accept() 이후 서버는 listen() 중인 소켓과 별도로 accept() 소켓을 추가로 생성해 클라이언트를 할당합니다. 서버가 클라이언트를 관리하는 방식은 크게 4가지로 구분할 수 있습니다.6이 중 대용량 처리에 3, 4번이 우세하며 특히 4번이 대세입니다. 하지만, 이 글에서 모두 언급하기엔 지나치게 방대하므로 추후 별도로 정리해보기로 하고, 자세한 사항은 C10K Problem을 참고하시기 바랍니다.이 글에서는 가장 간편한 방식인 2번, 클라이언트를 각각의 쓰레드에 할당하고 close() 될 때 쓰레드도 함께 종료되는 방식으로 구현했습니다.htop을 이용해 쓰레드 옵션을 켜고(H 키), 트리 모드(t 키)에서 요청이 있을 때마다 쓰레드가 하나씩 생성되는 모습을 직접 확인한 화면입니다.현재 2개의 요청을 처리 중이며, 물론 요청이 끝나면 쓰레드도 함께 종료됩니다. 만약 프로세스나 쓰레드를 할당하지 않았다면 요청이 끝날 때까지 다른 요청은 받지 못하는 말 그대로 blocking 상태가 유지됩니다.샘플 서버를 구동하고 클라이언트에서 FIN/ACK이 잘 전달되는지 확인합니다. 아울러 서버의 Active Close 후 서버측에 남게되는 TIME_WAIT 상태를 직접 확인합니다.TCP/IP Illustrated의 TCP 연결 종료 다이어그램은 아래와 같습니다:연결 종료의 4-way handshake 과정은 다음과 같습니다:서버 접속 후 tcpdump 로 패킷 상태를 덤프한 결과를 보면:포트 5000번이 서버입니다. 서버가 먼저 FIN을 보내며 Active Close를 시도했습니다. tcpdump 의 결과 Flags, 패킷 타입 플래그는 다음과 같습니다.[.]은 ACK를 뜻하며 [F.] 은 FIN+ACK 을 가리키는 싱글 패킷입니다. 이에 따라 실제 덤프 결과를 분석해보면,verbose 모드가 아니었기 때문에 ACK의 seq는 보이지 않습니다. 추가로 -vv 옵션을 부여하면 verbose 모드가 되며 확인할 수 있습니다.그런데 CentOS 6에서는 결과 중 두 번째 ACK의 ack 값과 마지막 ACK의 seq 값이 TCP/IP Illustrated 에서 명시된 숫자와 하나씩 다릅니다. OS 별로 커널 버전 별로 조금씩 다르게 동작하기도 하는데 이 부분은 추후에 보다 정확한 확인이 필요할 것 같습니다.이렇게 종료 handshake 과정이 정상적으로 끝나면 Active Close를 먼저 요청한 서버 쪽에 TIME_WAIT이 남게 됩니다.처리한 쓰레드도 이미 종료된 상태로 할당된 프로세스도 보이지 않습니다. 이미 커널로 소유권이 넘어 갔으며 프로세스를 종료해도 TIME_WAIT 상태는 사라지지 않습니다. 오히려 소켓이 해당 포트를 점유하고 있는 상태로 60초 동안 재시작을 할 수 없게 됩니다.재시작을 시도하면 bind() 단계에서 오류가 발생하며 시간이 지나 TIME_WAIT이 모두 사라진 후에야 가능합니다.만일 즉시 재시작이 필요하다면 setsockopt()의 SO_REUSEADDR 옵션을 적용하면 bind() 단계에서 커널이 가져간 소유권을 다시 돌려받으며 즉시 재시작 가능합니다.틀린 정보: SO_REUSEADDR 와 tcp_tw_reuse 는 동일하게 적용되는 옵션이다.커널 코드에서 SO_REUSEADDR은 socket 구조체 sk_reuse를 1로 설정하므로 tcp_tw_reuse를 설정하는 것과 동일한 역할을 합니다. 그러나 여기에는 결정적인 차이가 있는데, 전자는 커널(서버)의 역할이고 후자는 glibc(클라이언트)의 역할로 서로 다르다는 점이죠.클라이언트 소켓에 SO_REUSEADDR을 부여한다고 TIME_WAIT을 재사용할 수 있는게 아닙니다. tcp_tw_reuse 커널 설정이 필요합니다.반대로 서버 소켓에서 bind()시 tcp_tw_reuse 설정을 했다고 바인딩 되지 않습니다. SO_REUSEADDR 옵션을 부여해야 합니다.이후에 다시 자세히 설명하도록 하겠습니다.양쪽 모두 TIME_WAIT이 남는 재미있는(?) 현상도 발생할 수 있습니다. 양쪽 모두 동일 시점에 Active Close를 시도할 경우입니다.여기엔 특이한 경우가 두 번이나 발생했는데, 먼저 최초 SYN 이후 패킷 전달이 잘 끝나고 어플리케이션 종료 시점에 양쪽 모두 거의 동일한 시간에 FIN+ACK을 전달하며 Active Close를 시도했습니다.보통 이런 경우 한쪽에서만 ACK를 보내고 송신한 쪽이 TIME_WAIT 상태로 끝나게 되는데 공교롭게도 ACK 또한 양쪽 모두 동시에 전달을 시도했습니다.매우 특이한 경우지만 드물게 발생할 수 있는 경우입니다. 그리고 이런 경우 양쪽 모두 TIME_WAIT 상태에 빠지게 됩니다.그렇다면, 다수의 TIME_WAIT은 과연 시스템 성능 저하를 가져올까요?Each socket in TIME_WAIT consumes some memory in the kernel, usually somewhat less than an ESTABLISHED socket yet still significant. A sufficiently large number could exhaust kernel memory, or at least degrade performance because that memory could be used for other purposes.7 Because application protocols do not take TIME-WAIT TCB distribution into account, heavily loaded servers can have thousands of connections in TIME-WAIT that consume memory and can slow active connections. In BSD-based TCP implementations, TCBs are kept in mbufs, the memory allocation unit of the networking subsystem[9]. There are a finite number of mbufs available in the system, and mbufs consumed by TCBs cannot be used for other purposes such as moving data. Some systems on high speed networks can run out of mbufs due to TIME-WAIT buildup under high connection load. A SPARCStation 20/71 under SunOS 4.1.3 on a 640 Mb/s Myrinet[10] cannot support more than 60 connections/sec because of this limit.8스택오버플로우의 답변7이나 그렇다는 논문8이 있는데 특히 메모리 점유 문제를 심각하게 얘기합니다. 여기서 주의해야 할 점은 TIME_WAIT으로 인한 성능 저하 논문은 1997년에 출판됐다는 점이고, 지금은 2015년이라는 점입니다. 벌써 18년전 이야기죠. 그 당시 서버의 메모리는 512MB였고 지금 테스트를 진행하는 서버의 메모리는 64G입니다. 100배가 넘죠. 그런데 아직도 TIME_WAIT 때문에 메모리 점유가 심각하다고 말한다면 뭔가 이상하지 않나요?struct tcp_timewait_sock는 고작 168바이트에 불과한데요.5만약 4만 개의 TIME_WAIT 상태 인바운드 커넥션이 있다면 10MB 안쪽의 메모리를 차지하겠죠. 아웃바운드 커넥션도 고작 2.5MB가 더 필요할 뿐 입니다.5 요즘 서버 사양에서 TIME_WAIT 상태가 차지하는 메모리 용량은 아주 미미합니다.현재 서버의 소켓 상태는 아래 명령어로 확인할 수 있습니다.그렇다면 TIME_WAIT 상태가 증가하면 어떤 일이 발생할까요? 실제 부하 테스트를 통해 이를 확인해보기로 했습니다.여러 대의 클라이언트를 동원해 연속된 요청으로 9만개 가까운 TIME_WAIT 상태를 만들어 냈습니다.틀린 정보: 서버의 소켓 수는 할당 가능한 로컬 포트 만큼인 최대 65,535개이고 net.ipv4.ip_local_port_range 설정으로 변경할 수 있다.서버는 로컬 포트를 사용하지 않습니다.만일 많은 사람들이 오해하고 있는 것 처럼, 서버가 로컬 포트를 사용하고 로컬 포트는 단 하나의 소켓에만 바인딩된다고 가정하면,서버가 할당하는 것은 포트가 아닌 소켓이며 서버의 포트는 최초 bind()시 하나만 사용합니다. 로컬 포트를 할당하는 것은 클라이언트이며, 클라이언트가 connect()시 로컬 포트를 임의로(ephemeral port) 바인딩하면서 서버의 소켓과 연결됩니다.소켓은 <protocol>, <src addr>, <src port>, <dest addr>, <dest port> 이 5개 값이 유니크하게 구성됩니다. 따라서 서버 포트가 추가되거나 클라이언트의 IP가 추가될 경우 그 만큼의 새로운 쌍을 생성할 수 있어 TIME_WAIT가 많이 남아 있어도 별 문제가 없습니다.소켓의 수는 설정된 리눅스 파일 디스크립터만큼 생성할 수 있습니다. 아래 설정으로 서버가 이론적으로는 26만개가 넘는 클라이언트도 받을 수 있는 거죠.서버가 또 다른 서버에 클라이언트로 접속하지만 않는다면 자신의 로컬 포트는 사용할 일이 없으며, 리눅스의 로컬 포트 범위는 3만개 정도로 설정되어 있습니다. 마찬가지로 이론적으로는 3만개의 서버에 동시 접속이 가능한 거죠.만일 서버 투 서버로 1:1 대용량 접속이 발생할 경우 한 대의 클라이언트에서 가능한 최대 요청 수는 500 RPS(Requests Per Second) 정도입니다. 500 * 60 (TIME_WAIT 시간) = 3만개 이기 때문이죠. 이 수치를 넘어서지 않는다면 아무런 커널 설정도 변경할 필요가 없으며, 부하 테스트 등 특수한 용도여야 이 수치를 넘어설 수 있을 겁니다.그러나 이 수치를 넘어선다면 클라이언트의 로컬 포트가 고갈 될 것이며 TIME_WAIT 상태를 재사용 해야 합니다. 아래 3가지 경우로 분류할 수 있습니다:1번의 경우 클라이언트 입장에서는 서버에 남아 있는 TIME_WAIT 상태를 알 수 없습니다. 따라서 클라이언트는 계속해서 임의의 포트(ephemeral port)에 SYN 패킷을 내보냅니다. 임의의 포트는 순차 증가하는 형태이므로 FIFO 기준을 따르게 됩니다. 서버에는 TIME_WAIT 상태로 남아 있지만 동일 소켓이 SYN을 수신하면 재사용하게 됩니다. 양쪽 모두 별도 설정은 필요 없습니다다.2번은 오류가 발생하며 더 이상 접속할 수 없게 됩니다.소켓은 <protocol>, <src addr>, <src port>, <dest addr>, <dest port> 5개 값으로 구성되며 로컬 포트가 고갈되면 더 이상 유니크한 값을 만들어 낼 수 없게 됩니다. 클라이언트의 net.ipv4.tcp_tw_reuse 옵션을 설정하여 기존 클라이언트에 TIME_WAIT 상태로 남아 있던 소켓을 재사용해야 합니다.3번은 문제가 없습니다. 앞서 언급했듯 소켓은 5개 유니크 값이며 맨 마지막이 <dest port> 입니다. 이 말은 포트가 다를 경우 다시 그만큼의 새로운 소켓 쌍을 만들어낼 수 있다는 의미죠. 재사용이 필요 없습니다.위 상태는 실제 클라이언트 환경에서 동일한 로컬 포트에 하나는 TIME_WAIT, 하나는 ESTABLISHED 상태인 모습입니다. 상대방 포트는 다르기 때문에 이렇게 동일한 로컬 포트를 함께 쓰는 것도 가능합니다. 같은 원리로 서버도 하나의 포트에 여러 개의 소켓이 할당됩니다.그렇다면 리눅스 커널에서 로컬 포트가 어떤 알고리즘으로 바인드(bind()) 되는지 좀 더 자세히 살펴보겠습니다. 클라이언트가 패킷을 전송할때 아직 할당된 로컬 포트가 없다면 아래와 같이 오토 바인드를 진행합니다.inet_autobind()는 가능한 포트를 소켓 구조체 멤버 함수인 get_port()를 통해 찾는군요.get_port()는 inet_csk_get_port()로 선언되어 있는데, 이 함수에는 두 번째 인자가 0일때 선택 가능한 로컬 포트를 자동으로 찾아내는 알고리즘이 구현되어 있습니다.이 코드를 보면 먼저 inet_get_local_port_range() 함수에서 net.ipv4.ip_local_port_range로 선언된 가능한 포트 범위를 읽어들이고 이 중 랜덤으로 첫번째 값을 고릅니다. 그리고 해시 테이블의 정보와 비교하여 사용 가능한 상태인지 +1 씩 증가하면서 확인합니다. 마지막 값에 도달한 다음에는 다시 가장 낮은 값으로 돌아가 반복합니다. 이 과정을 통해 사용 가능한 포트를 찾아냅니다.그러나 sk->sk_reuse 즉, net.ipv4.tcp_tw_reuse가 선언되어 있고 타임스탬프가 더 크고, TIME_WAIT인 경우 혹시 현재 상태가 TCP_LISTEN 중일때가 아니라면 바로 재사용합니다. 따라서 반복하지 않고 바로 다음 포트를 사용하게 됩니다.물론 반복한다고 해도 더 이상 성능저하가 발생하진 않습니다. 2008년 크리스마스 이브(…)에 Evgeniy Polyakov가 빈 포트를 찾기 위해 전체 바인드 해시 테이블을 뒤지는 문제(traverse the whole bind hash table to find out empty bucket)에 대한 패치9를 제출했고 2009년 1월에 받아들여졌기 때문이죠.10그 전에는 바인딩 포트 수가 많아지면 오토 바인드가 점점 더 느려지는 성능 문제가 있었습니다. 특히 로컬 포트가 모두 고갈될 경우 성능 문제가 발생할 수 있었죠.우연찮게도 이 문제는 다른 테스트 도중 오래된 서버(RHEL 4)에서 직접 재현할 수 있었습니다.위 1번의 경우였는데,원래는 서버/클라이언트 양쪽 모두 아무런 설정 없이 문제가 없어야 되는 상황입니다. 그런데 부하 테스트 중 Cannot assign requested address 오류가 발생했습니다.포트 고갈로 발생하던 2번과 동일한 오류이며 시스템 전체가 과부하 상태에 빠졌습니다. 부하가 매우 높을 때만 간헐적으로 발생하는 걸로 봐서 위에서 언급한 빈 포트를 찾기 위해 전체 바인드 해시 테이블을 뒤지는 문제 비용이 높기 때문으로 보입니다. 이미 로컬 포트를 다 사용한 상태에서 매 번 스캔에 리소스를 허비하는 것 입니다.이 경우 해결책은 2번과 마찬가지로 클라이언트에서 net.ipv4.tcp_tw_reuse를 명시적으로 선언하면 간단히 해결됩니다. 커널이 비어 있는 포트를 매 번 스캔할 필요 없이 항상 다음 포트를 빠르게 재사용합니다.앞서 TIME_WAIT에 대해 설명할 때, 일정 시간 남아 있어서 패킷의 오동작을 막아야 한다고 언급했는데 어떻게 재사용이 가능한지 궁금할 것이다.비밀은 net.ipv4.tcp_timestamps에 있습니다.11 RFC 1323 에서 고성능 익스텐션으로 제안된 옵션 중 하나이며, 여기에는 두 개의 4 바이트 타임스탬프 필드가 있습니다. net.ipv4.tcp_tw_reuse를 활성화하면, 새로운 타임스탬프가 기존 커넥션의 가장 최근 타임스탬프보다도 큰 경우 TIME_WAIT 상태인 커넥션을 재사용하게 됩니다. tcp_tw_reuse가 비활성화 상태라면 매 번 비어 있는 포트를 스캔하게 되지만, 활성화 상태라면 바로 다음 포트를 사용 또는 재사용 하는 거죠.그렇다면 처음에 TIME_WAIT이 짧을 때 두 가지 문제가 발생할 수 있다고 언급했는데 이 문제에 대해서는 과연 안전할까요?첫 번째 문제는 쉽습니다. 동일한 SEQ라도 이미 지난 타임스탬프이므로 확인 후 그냥 버리면 됩니다.두 번째 문제도 타임스탬프로 해결됩니다. 서버가 ACK을 받지 못한 상태에서 새로운 커넥션이 SYN을 보내면 타임스탬프를 비교해 무시합니다. 그러는 사이 서버의 FIN이 재전송됩니다. 그러면 SYN_SENT 상태에 있던 클라이언트는 RST를 보냅니다. 이제 서버가 LAST_ACK 상태를 빠져나옵니다. 그러는 사이 ACK을 받지 못한 클라이언트는 1초 후 다시 SYN을 전송합니다. 이제 서버도 SYN+ACK을 보냅니다. 이제 둘은 정상적으로 ESTABLISHED 됩니다.5타임스탬프가 없었을 때는 오류를 내며 새로운 연결이 종료됐지만 이제 정상적으로 연결됐습니다. 단지 약간의 딜레이만 발생했을 뿐이죠.재사용을 위해서는 net.ipv4.tcp_timestamps 타임스탬프 옵션이 서버/클라이언트 양쪽 모두 반드시 켜져 있어야 합니다. 리눅스 커널의 기본 값이며 굳이 끌 필요가 전혀 없는 옵션입니다. 어느 한 쪽이라도 꺼져 있으면 더 이상 타임스탬프가 부여되지 않습니다. 옛날에는 CPU 자원을 절약하기 위해 끄기도 했지만 이제는 그런 시대가 아니죠.아래는 클라이언트가 타임스탬프를 부여했으나 일부러 tcp_timestamps를 꺼둔 서버에서 패킷이 어떻게 오고 가는지 재현한 모습입니다. 서버가 nop로 응답했고, 그 다음 패킷부터는 타임스탬프가 부여되지 않음을 확인할 수 있습니다.TIME_WAIT을 가장 효율적으로 재활용 하는 방법은 지금 소개하는 net.ipv4.tcp_tw_recycle 옵션이지만, NAT 환경에서 문제가 있습니다.5 서버가 로드 밸런서 뒤에 위치하는 서비스 환경에선 장비간 타임스탬프가 일치하지 않아 역전 현상이 발생하면 패킷 드롭이 발생할 수 있으므로 사용하면 안됩니다. 패킷은 마이크로세컨드 단위로 매우 빠르게 동작하고 장비간 시간을 마이크로 단위로 정확히 맞추기는 사실상 불가능에 가깝기 때문에 사용하기 힘듭니다.그러나, 성능은 월등합니다.tcp_tw_recycle 이 활성화 되어 있으면 TIME_WAIT 상태를 TCP_TIMEWAIT_LEN - 60초가 아닌 rto - retransmission timeout 값으로 적용합니다.rto 값이 얼마로 설정되었는지 쭈욱 따라가서 쉬프트 연산자를 계산해보면 1*(2^2) - 1/(2^1) 이므로 3.5초가 됩니다. tcp_tw_recycle 를 활성화 하는 것만으로 기존 60초에서 획기적으로 줄어든 셈입니다.그러나, 앞서 언급했듯 장비간 타임스탬프를 마이크로 세컨드 단위로 일치시키긴 힘드므로 NAT 환경등에선 사용할 수 없고 반드시 서버/클라이언트가 1:1로 직접 연결된 경우에만 사용해야 합니다.틀린 정보: net.ipv4.tcp_fin_timeout을 설정하면 TIME_WAIT 타임아웃을 변경할 수 있다.커널 헤더에 TIME_WAIT은 TCP_TIMEWAIT_LEN 이라는 상수로 60초 하드 코딩 되어 있으며 변경할 수 없습니다.커널 코드 주석에서 보듯, 예전에는 FIN_WAIT2와 TIME_WAIT을 합쳐 3분으로 관리했으나 옛날(deprecated) 이야기이며, 지금은 각각 60초로 관리합니다. 이 중 sysctl로 변경 가능한 값은 TCP_FIN_TIMEOUT 뿐이죠. TCP_FIN_TIMEOUT은 FIN_WAIT2의 대기 시간이며 TIME_WAIT과는 무관합니다.FIN_WAIT2는 Active Close를 했는데 Passive Close 쪽에서 close()를 처리하지 못하고 CLOSE_WAIT 상태에 빠졌을 때를 말합니다. 즉, 상대방에 문제가 있는 상태로, 일정 시간 기다려 주는게 좋습니다.TIME_WAIT의 대기 시간이 tcp_fin_timeout 설정에 영향을 받는다는 내용은 옛날 이야기이며, 지금은 오히려 그 반대인 TCP_TIMEWAIT_LEN 상수값이 FIN_WAIT2의 대기시간에 영향을 끼칩니다. 아래 커널 코드에서 확인할 수 있습니다.먼저 tcp.h 코드를 보면 tcp_fin_timeout 설정은 링거 옵션에 영향을 받습니다. 링거에 대해선 뒤에서 설명하겠습니다.그리고 tcp.c 코드에는 FIN_WAIT2 상태일 때 대기 시간 설정 로직이 있습니다. tcp_fin_time()을 호출한 tcp_fin_timeout 값이 만약 TCP_TIMEWAIT_LEN 상수보다 크면 그 시간을 뺀 만큼을 기다리게 되는데, 곧바로 timewait 타이머가 동작하는게 아니라 먼저 keepalive 상태는 그대로 두고 TCP_TIMEWAIT_LEN 값인 60초를 뺀만큼 타이머만 설정합니다. 이 시간이 종료된 다음 tcp_timer.c 에선 timewait 상태로 변환하고 다시 타이머를 구동하는데 마찬가지로 TCP_TIMEWAIT_LEN 60초 뺀 만큼 구동합니다. 따라서 keepalive / timewait 두 번의 FIN_WAIT2 타이머가 동작합니다.즉, 리눅스 커널의 TCP_TIMEWAIT_LEN의 상수값은 FIN_WAIT2의 대기 시간에 영향을 끼칩니다. TIME_WAIT은 항상 60초 이므로 만약 tcp_fin_timeout을 60 이상으로 설정한다면 위에서 언급한대로 keepalive 타이머가 먼저 동작합니다. 만약 60보다 작은 값을 설정하면 그냥 그 시간 만큼 timewait 타이머만 동작한다. 기본값은 60이므로 원래는 60초만큼 FIN_WAIT2 / timewait 상태로 기다리게 됩니다.그렇다면 tcp_fin_timeout을 90으로 설정하고 실제로 그렇게 동작하는지 확인해 보겠습니다. 90인 경우 60초를 뺀 FIN_WAIT2 / keepalive 로 30초, FIN_WAIT2 / timewait 으로 30초를 기다리겠죠. 서버는 정확히 45초 후에 ACK을 보내도록 설정했습니다. 그렇게 하면 45초 이후 TIME_WAIT 상태가 되어 다시 60초 간 유지되겠죠. 실제로 그렇게 동작하는지 확인해 보았습니다:정확하게 예상한대로 동작함을 확인할 수 있습니다.FIN_WAIT2에서 ACK을 받지 못하면 소켓은 곧바로 종료됩니다. 따라서 리눅스 커널은 FIN_WAIT2를 TIME_WAIT처럼 활용하고 있습니다. TIME_WAIT은 패킷의 오동작을 막아주는 역할을 하는데 FIN_WAIT2 / timewait 상태는 tcp_tw_recycle 처리와 일부 잘못된 패킷 처리 로직이 상단에 추가된 형태로 사실상 TIME_WAIT과 동일한 역할을 하게 됩니다.그래서 net.ipv4.tcp_fin_timeout 값은 90 정도로, FIN_WAIT2의 keepalive / timewait 이 모두 일정시간 동작할 수 있는 값으로 설정하는 것을 추천합니다.명칭이 비슷하여 혼동할 수 있으나 FIN_WAIT1은 FIN_WAIT2와 다른 상태입니다. FIN을 보내주길 하염없이 기다리기만 하는 FIN_WAIT2와 달리 FIN_WAIT1은 우리가 보낸 최초 FIN에 대해 아직 ACK 응답이 도달하지 않은 상태로, 일반적으로 상대방 OS에 문제가 있는 경우로 간주할 수 있습니다. 왜냐하면 최초 ACK 응답은 리눅스던 윈도우던 OS가 바로 보내야 하는 패킷이기 때문이죠.또한 기다리기만 하는게 아니라 지속적으로 FIN을 재시도합니다. 첫 패킷에는 2초, 그 다음 부터는 5초, 10초. 대기시간을 늘려가며, 따로 커널 설정을 변경하지 않은 서버에서 최대 8번까지 재시도 하는 것을 확인할 수 있었습니다.마지막 8번째가 55초 대기하는 것을 포함, 총 2분 정도 대기했으며 마지막까지 ACK을 수신하지 못할 경우 결국 소켓은 종료됩니다. 대기 시간이 길고, 재시도 횟수와 대기 시간을 조정할 수 있는 커널 설정까진 미처 확인하지 못했지만, 상대방 OS에 문제가 있는 상태인 만큼 새로운 연결 SYN에도 응답하지 않을 것이고, 해당 IP와는 더 이상 연결이 불가능해지겠죠.소켓에는 데이타가 아직 남아 있을때 종료 방식을 결정하는 링거 옵션이 있으며 아래 3가지 경우로 나뉩니다.RST 는 비정상 종료시 보내는 패킷입니다. 수신한 상대방은 Connection reset by peer 오류가 나게 되죠.양쪽 모두 바로 연결이 끊어지며, 양쪽 모두 TIME_WAIT 상태가 남지 않는다는 점에서 가장 빠르고 깔끔해 유용해보이지만 문제는 비정상 종료라는 점입니다. RST는 더 이상 연락하지 말자는 일방적인 이별 통보로, 또다른 side effects를 야기할 수 있습니다. 또한 양쪽 모두에 TIME_WAIT을 남기지 않기 때문에 패킷의 오동작을 막아줄 장치가 없습니다.어떠한 TIME_WAIT도 남아 있지 않아야 할 특수한 목적이 아니라면, 일반적으로는 링거 옵션을 사용하지 않아야 하고 RST 비정상 종료 패킷을 보내는 일이 없어야 합니다.TCP/IP Illustrated를 쓴 리차드 스티븐스의 또 다른 책 Unix Network Programming에는 이런 구절5이 있습니다.The TIME_WAIT state is our friend and is there to help us (i.e., to let old duplicate segments expire in the network). Instead of trying to avoid the state, we should understand it.TIME_WAIT은 우리를 도와주는 친구다. 네트워크에서 오래된 중복 세그먼트를 날려주는 훌륭한 역할을 한다. 자꾸 없애려고 노력하지 말고 이해해야 한다.TIME_WAIT은 패킷의 오동작을 막아주는 우리의 친구같은 존재입니다.수 많은 잘못된 정보들 사이에서 아래와 같은 올바른 정보를 반드시 기억해두길 바랍니다:이 글은 kaon.park이 블로그 likejazz.com에 포스팅한 글 CLOSE_WAIT 문제 해결과 TIME_WAIT 상태란 무엇인가?를 원저자의 동의를 얻어 엮은 글입니다.글의 내용도 유용하지만, 문제의 원인을 찾고 해결책을 찾기 위해 리눅스 커널 소스까지도 뒤질 수 있는 패기! 그것이 더 좋은 개발자가 되는 지름길이 아닐까요? 여러분도 도전해보세요! 책으로 배우는 지식과는 비교할 수 없이 값진 경험을 얻게 될 것입니다.편집자가 사족을 달자면, TCP/IP Illustrated 보세요. 두 번 보세요~ 스티븐스는 사랑입니다.카카오에서 통합 검색을 담당할 개발자를 채용 중입니다. 검색 서비스의 최상단에서 사용자의 검색 요청을 처리하는 시스템으로, 이 글의 내용처럼 TIME_WAIT을 포함한 다양한 네트워크 프로그래밍 및 문제 해결에 관심 있는 분들의 많은 지원 바랍니다. 지원하기http://www.codeitive.com/0xJeqqgPPW/reproduce-tcp-closewait-state-with-java-clientserver.html ↩ ↩2http://stackoverflow.com/questions/15912370/how-do-i-remove-a-close-wait-socket-connection#comment22663601_15912370 ↩http://unix.stackexchange.com/a/10132 ↩http://benohead.com/tcp-about-fin_wait_2-time_wait-and-close_wait/ ↩http://vincent.bernat.im/en/blog/2014-tcp-time-wait-state-linux.html ↩ ↩2 ↩3 ↩4 ↩5 ↩6http://www.quora.com/What-is-the-ideal-design-for-server-process-in-Linux-that-handles-concurrent-socket-I-O ↩http://stackoverflow.com/a/1854196 ↩ ↩2http://www.isi.edu/touch/pubs/infocomm99/infocomm99-web/ ↩ ↩2 ↩3https://github.com/torvalds/linux/commit/a9d8f9110d7e953c2f2b521087a4179677843c2a#diff-3973f2a099d75b1ec9f7fe686cd0796a ↩http://marc.info/?l=linux-netdev&m=123174371107238&w=2 ↩https://www.facebook.com/likejazz/posts/10153290132235837?comment_id=10153292111270837 ↩여기서 말하는 클라이언트란 일반적인 클라이언트가 아니라, 서버 투 서버로 대용량으로 접속하는 클라이언트를 말한다. ↩",http://tech.kakao.com/2016/04/21/closewait-timewait/,0,kakao,"docker,java,python",NULL,2016-04-21
모빌(MoBiL) - kakao의 모바일앱 CI/CD 플랫폼,"하나의 모바일 앱이 마켓에 출시되기까지는 수많은 빌드와 배포 과정을 거치게 됩니다. 더 자주, 더 빠르게, 더 높은 품질의 서비스를 출시하기 위해서는 효율적인 빌드와 배포는 필수적입니다. 카카오에는 모바일 앱을 지속적으로 통합(Continuous Integration)하고 지속적으로 배포(Continuous Delivery)하기 위해 자체 개발한 플랫폼 모빌(MobiL)이 있습니다.이 글에서는 모빌이 어떻게 개발되었고, 어떻게 활용되고 있는지를 소개합니다. 모빌의 초기 버전은 2013년에 개발이 시작되었습니다. 당시 서버 애플리케이션의 빌드와 배포는 자동화가 많이 적용된 상황이었지만 모바일 앱은 그렇지 않았습니다. 일부 조직에서는 Jenkins를 이용해 CI 환경을 구축했지만, 대부분은 로컬 빌드 후 수동 배포하는 경우가 많았습니다. 사내 배포 방식 또한 메일, 메신저, JIRA, 리모트 저장소 등 다양했습니다. 이렇게 빌드부터 배포까지 전체 릴리스 과정이 통합되어 있지 않다 보니 비효율적인 부분들이 많았고, 개발자와 QA담당자 사이의 커뮤니케이션 비용이 많이 발생하고 있었습니다.“빌드와 배포 과정에서 비효율적인 부분들을 제거하고 자동화를 통해 전체 릴리스 과정이 매끄럽게 진행될 수 있다면 높은 품질의 카카오 서비스들이 더 자주 사용자들을 만날수 있겠다.” 라는 생각이 모빌을 개발하게 된 시발점이었습니다.최근에는 Greenhouse CI, CircleCI 등의 모바일 앱을 위한 CI/CD 도구들이 속속 등장하고 있지만, 모빌을 개발하기 시작할 당시에는 모바일 앱에 특화된 도구는 전무했습니다. 그리고 애플에 인수된 TestFlight이나 Twitter Fabric에 통합된 Crashlytics Beta라는 도구도 있었지만, 앱 배포 과정에만 특화된 도구였습니다.빌드부터 배포까지 전체 릴리스 단계를 모두 포함하는 입맛에 맞는 도구는 찾지 못했고, 결국 직접 개발을 하기로 결정했습니다.개발자는 개발에만 집중할 수 있게 하고, QA와 테스터는 테스트에만 집중할 수 있도록 하자.비효율적인 부분이나 투명하지 않은 프로세스는 CI/CD를 적용하면 대부분 해소가 되는 부분이었습니다. 따라서 개발자와 테스터는 본연의 업무에 충실할 수 있게 되고 생산성과 품질은 높아지게 됩니다. 개발과 사용자 테스트 외의 모든 작업들은 모빌이 대신하도록 하고, 릴리스 과정의 모든 모든 부분을 자동화하는것을 목표로 모빌 개발을 시작했습니다.사용하기 쉽게 만드는 것은 모빌 개발을 시작하면서 세운 대원칙입니다.모빌을 통해 CI, CD를 적용하려고 할 때 최대한 쉽게 적용할 수 있도록 만들자.아무리 좋은 도구일지라도 도입하고 사용하기 위한 러닝커브가 높다면 좋은 도구가 아니라고 생각합니다. 빌드를 위한 최소한의 정보(저장소, 빌드 설정)만 입력하면 바로 모빌을 사용할 수 있게 만들었습니다.누구나 쉽게 빌드를 실행할 수 있도록 하자.CI에서는 모든 커밋에 대해 빌드를 하는 것이 원칙이지만, CD에서는 조금 달라집니다. 모든 커밋에 대한 빌드 산출물이 QA나 테스터에게 의미 있는 산출물은 아니기 때문입니다.모빌은 모든 커밋에 대해 빌드를 하고 사용자가 직접 원하는 빌드를 찾아서 사용하는 방식이 아닌, 누구나 쉽게 원하는 때에 원하는 코드로 빌드를 할 수 있는 방식을 선택했습니다. CI 빌드를 기본으로 하되, 다양한 방법으로 빌드를 실행할 수 있도록 설계되었습니다.모빌은 3가지 빌드 설정 타입과 6가지 빌드 실행 방법을 제공하고 있습니다.Manual Build는 담당 개발자가 아니더라도 코드의 변경사항을 확인하고 빌드 실행이 가능한 방법입니다. 이 빌드 방법은 Agile Testing을 가능하게 합니다.차기 릴리스를 위한 개발이 모두 완료되었을 때 QA가 진행되는 것이 아니라, 개발 진행 중에 담당 QA가 함께 참여해서 Feature 단위로 개발이 완료될 때마다 즉시 빌드를 하고, 테스트를 할 수 있는 환경을 제공합니다. 빌드 산출물을 쉽게 배포하고 설치할 수 있도록 하자.모빌은 빌드가 완료되면 빌드 정보를 쉽게 확인하고 배포할 수 있도록 설계되었습니다. 몇 번의 클릭만으로 사내 사용자에게 배포할 수 있는데요. 다양한 배포 유형을 제공함으로써 앱이 노출되는 방식이나 설치할 수 있는 대상 사용자가 달라지게 됩니다. 몇 번의 클릭이 귀찮을 경우에는 빌드 설정에서 자동 배포 설정을 활성화하기만 하면 빌드 완료와 동시에 자동으로 배포가 이루어집니다.모빌에서의 앱 배포는 OTA(Over The Air)방식으로 진행됩니다.애플 앱스토어나 구글 플레이스토어처럼 카카오앱센터(모빌 iOS/Android 클라이언트)라는 사내 전용 앱으로 배포가 이루어집니다. 카카오앱센터에서는 앱의 최신 배포 버전뿐만 아니라 지난 배포 이력을 확인할 수 있으며 특정 버전의 앱을 쉽게 설치할 수 있습니다. 또한 카카오톡을 이용하여 사내 사용자들끼리 쉽게 앱을 공유할 수 있는 기능도 제공하고 있습니다.이제 카카오에서는 아래와 같은 대화는 더 이상 없습니다. “모빌에서 받으세요” 한마디면 끝! 사실 이것도 필요 없긴 합니다. 모빌의 여러 이벤트(빌드 완료, 배포 등)발생 시 알림을 발송할 수 있고, 카카오앱센터의 앱 푸시 알람을 통해서도 사용자에게 알림이 전송되기 때문에 굳이 직접 커뮤니케이션을 하지 않아도 되지 말입니다.모빌은 크게 앱을 등록하고 빌드하고 배포하는 과정을 관리하는 웹 서비스와, 안드로이드&iOS용 클라이언트인 카카오앱센터로 구성되어 있습니다. 그리고 빌드 관리를 위한 Jenkins 서버와 실제 빌드가 실행되는 MacPro로 구성되어 있습니다.빌드 실행 이벤트 발생시 모빌에 등록된 빌드 설정으로 Jenkins에 BuildJob이 생성되고 빌드가 실행됩니다. 빌드 실행 과정에서 Jenkins는 일종의 Stub 역할만을 하게 됩니다. 실제 빌드는 Jenkins의 Slave Machine으로 등록되어 있는 MacPro 장비에서 통합 빌드 스크립트에 의해 빌드가 실행됩니다. 빌드가 완료되면 빌드 산출물은 케이지(KAGE - 카카오가 자체 개발한 분산 스토리지 플랫폼)에 저장되며, 카카오앱센터로 자동/수동으로 배포됩니다.그리고 모카(MOCA - 카카오가 자체 개발한 모바일앱 크래시 분석 시스템)로 빌드 산출물을 배포하게 됩니다. 모카는 Crashlytics 처럼 앱 크래시 분석을 위해 만들어진 사내 플랫폼으로 모카에서 앱 크래시 분석을 위해 필요한 빌드 산출물(iOS dSYM, android mapping.txt)을 매 빌드 시 모카로 자동으로 배포하게 됩니다.모빌은 사내 이슈 트래킹 시스템인 JIRA와도 연결을 하고 있습니다. 대부분의 서비스는 JIRA를 통해 버그나 개발 이슈들을 관리하고 있는데요. 모빌에서 코드<->빌드<->관련된이슈 정보를 한눈에 쉽게 파악할 수 있도록 하기 위해 JIRA와의 연결도 점차 확장해 나가고 있습니다. 모빌의 다음 단계는 UI Test Automation on Real Devices 입니다. 모빌에서 빌드 후 다양한 종류와 버전의 실제 기기에서 자동화된 테스트를 수행하고 테스트 결과물을 받아볼 수 있도록 하는 것이 목표입니다만, 아직 모빌의 대원칙인 “쉬운”방법을 찾지 못해서 열심히 찾아보고 있는 중입니다.함께 모빌의 미래를 만들어보고 싶으신 분을 모시고 있습니다. 특히 Android, iOS UI 테스트 자동화에 관심 있으신 분의 많은 지원 바랍니다. 지원하기모빌을 적용한 서비스 조직의 “훈훈한” 사용기로 마무리하겠습니다.이 글은 카카오에서 모빌을 포함한 다양한 개발 플랫폼을 개발&운영하면서 틈틈히 회사 텃밭을 일구고 있는 benedict.lee를 졸라서 쓴 글입니다. 저자가 2013년 데브온에서 발표한 Code Review - What, 2 Whys & How는 몇 년이 지난 지금 봐도 - 발표를 직접 듣고 싶은 - 훌륭한 자료입니다.기술 블로그를 통해서 카카오의 다양한 개발 플랫폼을 소개합니다. 현재로썬 카카오 내부에서만 사용할 수 있다는 점이 아쉽지만, 함께 나눌 수 있는 부분들은 지속적으로 발굴하고 공개할 계획이니, 관심을 갖고 지켜봐주세요.물론, 카카오 크루가 되시면 지금이라도 사용하실 수 있고 또 개발에 참여하실 수 있습니다 ^^;",http://tech.kakao.com/2016/04/21/mobil/,0,kakao,"bitcoin,blockchain,java,docker,bootstrap,frontend",NULL,2016-04-21
MySQL InnoDB의 Adaptive Hash Index 활용,"MySQL의 InnoDB에는 Adaptive Hash Index 기능이 있는데, 어떤 상황에서 효과가 있고 사용 시 반드시 주의를 해야할 점에 대해서 정리하도록 하겠습니다.MySQL의 InnoDB의 대표적인 인덱스는 B-Tree입니다.  데이터는 Primary Key 순으로 정렬되어 관리되고, Secondrary Key는 인덱스키+PK를 조합으로 정렬이 되어 있습니다.즉, 특정 데이터를 찾기 위해서는 Secondrary Key에서 PK를 찾고, 그 PK를 통해 다시 원하는 데이터로 찾아가는 형태로 데이터가 처리 됩니다. 트리의 가장 큰 강점은 데이터 접근 퍼포먼스가 데이터 증가량에 따라서도 결코 선형적으로 증가하지 않다는 점에 있습니다.참고로, PK 접근 시 데이터 접근에 소요되는 비용은 O(logN)이고,두번 트리에 접근하는 Secondrary Key에 소요되는 비용은 2 * O(logN)입니다.데이터가 아무리 많아져도, 데이터 접근에 소요되는 비용이 크게 증가되지 않음에도, 상황에 따라 효율이 좋지 않습니다. 자주 사용되는 데이터 탐색에도 매번 트리의 경로를 쫓아가야 한다는 것이죠. 게다가 Mutex Lock이 과도하게 잡히게 되면, 적은 데이터 셋에도 불구하고 DB 자원 사용 효율이 떨어지게 됩니다.InnoDB에서는 앞서 언급한 상황을 해결하기 위해, InnoDB Adative Hash Index 기능이 있습니다. 자주 사용되는 칼럼을 해시로 정의하여, B-Tree 를 타지 않고 바로 데이터에 접근할 수 있는 기능이죠. “Adaptive”라는 단어에서 예상할 수 있겠지만, 모든 값들이 해시로 생성이 되는 것이 아니라, 자주 사용되는 데이터 값만 내부적으로 판단하여 상황에 맞게 해시 값을 생성합니다.즉, 전체 데이터를 대상으로 해시값을 생성하지는 않는다는 말인데요, Adative Hash Index에 할당되는 메모리는 전체 Innodb_Buffer_Pool_Size의 1/64만큼으로 초기화됩니다.최소 메모리 할당은 저렇게 할당되나, 최대 사용되는 메모리 양은 알 수는 없습니다. 서버의 특성마다 다르겠지만, Apdaptive Hash Index를 활성화한 경우 반드시 현재 사용하고 있는 관련 메모리를 모니터링을 해야합니다. (서버마다 사용량이 다를 수 있습니다.)이 기능은 innodb_adaptive_hash_index라는 파라메터로 기능을 켜고 끌 수 있는데, MySQL 5.5 버전(엄밀하게 말하면 InnoDB Plugin 1.0.3 버전)부터는 동적으로 Global 변수를 변경할 수 있습니다.관련 통계 정보는 아래와 같이 확인하면 됩니다.MariaDB에서는 Global Status에서 현황을 파악해볼 수 있지만, Oracle MySQL에서는 관련 통계정보를 status로 관리하지 않습니다. 대신, 다음과 같이 엔진 상태 정보에서 관련 정보를 추출할 수 있습니다.자주 사용되는 자원을 해시를 통해서 직접 접근하기 때문에, 내부적인 락(이를테면 Mutex)으로 인한 지연이 줄어듭니다. 게다가 B-Tree의 데이터 접근 비용(O(LogN))에 비해, 해시 데이터 접근 비용인 O(1)으로 굉장히 빠른 속도로 데이터 처리가 가능한 것이죠. 단 자주 사용되는 자원 만을 해시로 생성하기 때문에, 단 건 SELECT로 인하여 반드시 해당 자원을 향한 직접적인 해시 값이 만들어지지 않습니다.아래와 같이 테스트 테이블을 생성 후 1300만 건 데이터를 만들고, PK로 접근하는 IN 쿼리를 발생시켜 효과를 확인해봅니다.IN 절에는 약 30개 정도의 파라메터를 넣고, 300개의 쓰레드에서 5ms 슬립을 줘가며 트래픽을 줍니다.하단 결과에서 Adaptive Hash Index를 사용하지 않는 경우 CPU가 100% 였으나, Adaptive Hash Index를 사용한 이후에는 60% 정도로 사용률이 내려갔습니다.CPU는 줄었으나, 쿼리 응답 시간이 줄었기에 처리량 또한 20,000에서 37,000으로 늘어났습니다.모든 데이터를 해시로 만들지 않기에, 해시가 켜진 상태에서도 여전히 B-Tree를 통해서 데이터 접근을 합니다. 이 수치는 장기간 테스트 쿼리를 날려보아도 변함이 없습니다.Semaphore도 크게 줄어들었습니다.빈번한 데이터 접근이 많은 환경에서는 대단히 효율이 좋은 결과를 나타내었으며, 실제 MySQL을 활용하여 앞선 테스트 환경과 비슷한 서비스에서 효율적으로 잘 활용하고 있습니다. 그러나, 주의를 해야할 점은 오래된 테이블인 경우에도 해시가 여전히 메모리에 남아있을 수 있으며, 이에 대한 제어는 불가합니다.얼마전, 수개월 전 pt-online-schema-change 유틸리티를 사용을 하여 스키마를 변경한 이후, 오래된 테이블을 정리하다가 대형 장애가 발생하였습니다.데이터 사이즈는 크지 않은 상태(1~2G)였으며, 파일시스템 또한 xfs였던 지라 디스크 I/O적인 이슈 없이 쉽게 테이블 정리가 가능할 것으로 판단하였으나, 해시 메모리 정리하는 과정에서 쿼리 응답 속도가 떨어지게 되어서 결과적으로 장애가 발생하게 되었습니다.하단은 해시 인덱스를 사용하던 환경에서 오래된 테이블을 정리하는 시점의 쿼리 처리량에 대한 결과입니다.수 개월동안 사용되지 않은 테이블일지라도, Adaptive Hash Index를 사용하고 있다면 테이블 정리 시 최대한 트래픽이 없는 시점에 진행을 해야 합니다.InnoDB Adaptive Hash Index는 B-Tree의 한계를 보완할 수 있는 좋은 기능입니다.특히 단일 랜덤 키 접근이 빈도있게 발생하는 경우라면, B-Tree 를 통하지 않고 데이터에 접근/처리가 가능하기에 좋은 퍼포먼스를 보입니다.그러나, 자주 사용되는 데이터를 옵티마이저가 판단하여 해시 키로 만들기 때문에 제어가 어려우며, 수 개월 동안 사용되지 않던 테이블일지라도 기존 해시 자료 구조에 데이터가 남아 있게 되면, 테이블 Drop 시 영향을 줄 수 있습니다. 해시 인덱스에 의존하여 트래픽이 주로 처리되는 서비스인 경우 이런 점을 염두해 두고 사용을 해야겠습니다.이 글은 카카오의 데이터베이스팀에서 운영하는 기술 블로그 small-dbtalk의 글 InnoDB Adaptive Hash Index을 옮긴 것입니다.데이터베이스에 관심이 있으신 분들이라면 small-dbtalk에서 카카오의 데이터베이스팀이 공유하는 다양한 사례들과 기술들을 만나보세요. 절대 후회하지 않으실 거예요~~ ;)",http://tech.kakao.com/2016/04/07/innodb-adaptive-hash-index/,0,kakao,"spring,sql,java,docker,mysql,backend,javascript,database,php",NULL,2016-04-07
Weekly Links #1 - 2016년 4월 첫째주,"Weekly Links에서는 지난 한 주, 카카오의 기술 블로그 담당자가 구독하는 기술 뉴스레터들에서 “인간의 눈”으로 선별한 링크들을 짧은 코멘트와 함께 공유합니다.포함된 뉴스레터 목록은 awesome-tech-newsletters에서 확인하실 수 있습니다. 개인적으로 이번 주에 가장 눈에 띄는 소식은 아무래도 npm게이트(a.k.a. leftpad 게이트)가 아닌가 싶습니다. 그래서, 창간 특집(?)으로 npm 게이트의 전말을 파헤쳐 보겠습니다.다음은 문제의 left-pad 코드(전체!)입니다:메신저 플랫폼 회사인 kik이 azer가 개발한 npm 모듈 kik의 이름을 바꾸라고 하면서 사건이 시작됩니다. kik의 무례한 요구, npm의 부적절한 중재, 그리고 azer의 성급한 행동(unpublish)이 결합되어 사건이 커집니다.    오픈소스를 생산(기여)하는 측, 사용하는 측, 그리고 이 과정을 중개하는 측이 외부의 도전(?)에 대처하는 방법에 대해서 많은 생각을 하게 만든 사건입니다만… (흠흠) 자세한 설명은 프렌즈의 표정으로 대신합니다.기술 블로그의 컨텐츠 수급에 어려움 때문에 시작하긴 했는데, 수십개의 뉴스레터에 소개된 수백개의 링크 중에서 몇 개만 선정하는 일이 만만치 않네요. Weekly Links는 쭈욱~~포함된 뉴스레터 목록은 awesome-tech-newsletters에서 확인하실 수 있습니다.",http://tech.kakao.com/2016/04/07/weekly-links-1/,0,kakao,,NULL,2016-04-07
kakao의 오픈소스 Ep4 - HBase Tools,"“카카오의 오픈소스를 소개합니다” 네번째는 terence.yoo와 동료들이 개발한 HBase Tools입니다.[HBase Tools]는 카카오에서 대규모 HBase 클러스터를 운영하면서 만들어진 도구들을 하나로 묶은 것입니다.​HBase 주요 버전별 빌드를 제공하고 있어서 가져도 쓰기도 좋지만, HBase의 부실한 도구들 때문에 고생하셨던 분들에겐 나만의 HBase 도구를 만드는 좋은 시작점이 될 것입니다.툴을 사용하면 HBase 운영 작업의 효율성이 좋아집니다. 카카오에서 사용하는 대표적인 툴 세 가지는 HBase Shell, HBase Web UI, Cloudera Manager Express Edition(이하 CM)입니다. 이 툴들은 매우 우수하지만, 꼭 필요한 기본적인 기능들만 제공합니다. 그래서 그런 기본적인 기능들을 코딩을 통해 이리저리 조합해서 사용해야 하는 경우가 많습니다. 심지어 어떤 기능들은 유료 버전에서만 사용가능 한 것들도 있습니다. 이런 부족한 부분을 채우기 위해서 툴을 하나, 둘 만들었습니다. 툴들이 여럿 쌓이다 보니 관리가 불편하게 되었고, 관리를 편하게 하기 위해서 하나로 모은 것이 hbase-tools입니다.hbase-tools는 세 가지 모듈로 이루어져 있고, 각 모듈 별 주요 기능은 다음과 같습니다.지금부터 위에 나열한 순서대로 각 모듈 별 기능들에 대해서 설명하겠습니다.참고: 이 글은 툴의 기능에 대해서 개념적인 소개에 대해서만 다루고 있습니다. 모듈의 구조와 툴의 구체적인 사용방법은 Introduction And Use Cases 문서를 참고하세요.HBase 클러스터의 상태는 메트릭을 통해서 확인이 가능합니다. 메트릭을 조회할 수 있는 방법은 두 가지가 있습니다. 첫번째가 HBase Web UI를 이용하는 것이고, 두번째가 CM을 이용하는 것입니다. HBase Web UI에서는 리전서버(region server) 중심의 메트릭을 텍스트 포맷으로 조회할 수 있습니다. CM에서는 CM 차트라는 기능으로 메트릭을 그래프 형태로 조회할 수 있습니다. CM 차트는 리전서버 레벨뿐만 아니라 테이블 레벨의 메트릭을 그래프로 조회할 수도 있습니다.성능 모니터링을 할 때는 작업 단위가 테이블일 경우가 많기 때문에 테이블 중심으로 메트릭을 조회해야 하는 경우가 많습니다. 하지만 위에서 언급한 툴들은 메트릭을 테이블 중심으로 조회하고자 할 때 어려움이 있습니다. 첫째로 테이블 중심의 메트릭을 조회하는 기능이 아예 없거나 있더라도 빈약합니다. HBase Web UI에는 테이블 별로 메트릭을 집계 하는 기능이 없고, CM에서는 테이블 별로 집계는 가능하나 여러 테이블의 여러 메트릭을 한 눈에 확인하기가 불편합니다. 둘째로 메트릭의 변화량을 민첩하게 보여주지 못합니다. HBase Web UI는 변화량을 보여주는 기능이 아예 없고, CM은 갱신 주기가 길어서 세밀한 변화를 빠르게 모니터링 하기에는 부족합니다.이러한 부족함을 해결하기 위해서 dstat, vmstat, iostat 류의 커맨드라인 툴들과 비슷한 hbase-table-stat을 만들었습니다. hbase-table-stat은 커맨드라인에서 작동하며 10초(기본값, 변경 가능) 간격으로 여러 개의 메트릭을 조회해서 보여 줍니다. 이때 모든 메트릭들은 테이블 중심으로 집계됩니다. 또한 매트릭의 절대값 뿐만 아니라, 변화량 까지 한 번에 보여주어서 한 눈에 여러 정보를 확인 할 수 있습니다. 그리고 각 메트릭 별로 소트도 가능합니다. 웹서버 기능을 내장하고 있어서 커맨드라인에서 보이는 내용 그대로를 웹브라우저를 통해서 다른 사용자들에게 공유할 수도 있습니다.HBase에서 데이터는 테이블(table)에 저장되고, 각 테이블은 리전(region)이라는 단위로 나뉘어져서 리전서버에서 서비스 됩니다. 그래서 HBase 운영 과정에서는 테이블과 리전을 잘 다루는 기술이 중요합니다. 테이블이나 리전 관리는 보통 쉘(HBase shell)에서 하게 되는데, 쉘에서는 split, merge, major compact, balance, move 등의 기본적인 기능들만 제공하고 있습니다. 복잡한 작업을 할 때는 이런 기본 기능들을 조합해서 사용해야 합니다.그래서 자주 하는 작업들에 대해서는 미리 효율적이면서 잘 테스트 된 툴을 만들어 두고, 그 툴을 이용하면 실수 없이 빠르게 작업을 진행할 수가 있습니다. 그렇게 해서 만들어진 것이 hbase-manager입니다. 현재 hbase-manager에서 제공하는 기능은 리전 배치 관리, 스플릿, 머지, 메이저 컴팩션 크게 네 가지 입니다.하드웨어 점검이나 HBase 설정 변경 등의 이유로 리전서버를 재시작 해야 하는 경우가 있습니다. 이런 경우 hbase-manager를 이용하면 서비스에 미치는 영향을 최소화 하면서 재시작을 할 수 있습니다. 리전서버 재시작 과정은 아래와 같습니다.이런 과정을 전체 RS에 적용하면 클러스터를 롤링리스타트(rolling restart) 할 수 있습니다. CM Express Edition에서는 롤링리스타트 기능을 제공하고 있지 않기 때문에, 카카오에서는 자체적으로 hbase-manager의 기능을 사용해서 롤링리스타트 툴을 만들어서 사용하고 있습니다.간혹 리전이 리전서버에 골고루 분포되지 않았거나, 어떤 테이블의 리전이 일부 리전서버에 몰려 있어서 클러스터가 비효율적으로 운영될 때가 있습니다. 이런 경우에는 운영자가 수동으로 밸런싱을 해야 합니다. HBase Shell에서 move 커맨드를 이용해서 특정 리전을 특정 리전서버로 옮겨주면 리전 불균형 문제를 해소할 수 있습니다. 하지만 옮겨야 할 리전이 많을 경우에는 이런 방법은 매우 비효율적입니다. 이런 경우에 hbase-manager를 이용하면 간단하고도 빠르게 밸런싱 작업을 할 수 있습니다.hbase-manager는 테이블 단위로 룰을 적용해서 밸런싱을 합니다. 사용할 수 있는 룰은 Round-robin, Random, Stochastic 세가지 입니다.간혹 리전서버가 비정상적으로 종료되는 경우가 있습니다. 이런 경우 해당 리전서버에서 서비스 중이던 리전은 다른 리전서버로 흩어지게 됩니다. 죽었던 리전서버를 재시작하면 디폴트 로드 밸런서가 임의로 리전을 할당해 줍니다. 이렇게 되면 클러스터 전체의 데이터 로컬리티가 저하됩니다. 이때 hbase-manager를 사용하면 리전서버가 죽기 전 시점의 리전 배치로 되돌릴 수 있습니다.리전의 배치 정보는 hbase:meta 테이블에 저장됩니다. meta 테이블은 최대 10개의 버전을 보관하고 있습니다. hbase-manager에서는 이 정보를 이용해서 특정 시점에 리전이 어떤 리전서버에서 서비스 중이었는지를 확인하고 그 리전서버로 다시 할당해 주고 있습니다.처음에 테이블을 생성하면서 바로 여러 리전으로 나누어 부하를 분산 시키려고 하거나, 사이즈가 큰 테이블을 마이그래이션 할 경우 프리스플릿(presplit)이 필요합니다. HBase Shell에서는 테이블을 처음 생성할 때 몇 가지 룰을 이용해서 프리스플릿을 할 수 있습니다. 하지만 이미 생성된 테이블에 대해서 동일한 룰을 적용해서 스플릿 할 수는 없습니다. 마이그래이션 할 소스 테이블과 동일한 스플릿키로 타겟 테이블을 스플릿 하는 방법도 쉘에 내장되어 있지는 않습니다.hbase-manager에서는 이미 생성된 테이블에 대해서도 룰 기반으로 스플릿하는 기능을 제공합니다. 스플릿 과정에서 1개의 리전이 스플릿 되면, 새로 생긴 2개의 리전에 대해서 메이저 컴팩션(major compaction)이 발생합니다. hbase-manager는 메이저 컴팩션이 끝날 때까지 기다리며 순차적으로 리전을 스플릿합니다. 그래서 이미 테이블에 데이터가 많이 들어가 있는 경우에는 스플릿에 오랜 시간이 걸릴 수도 있습니다. 이런 경우에는 위에서 소개한 밸런싱 기능을 중간중간 실행해 주어서 메이저 컴팩션이 여러 리전서버에서 동시에 진행될 수 있도록 해주면 작업 시간을 단축시킬 수 있습니다.또한 hbase-manager를 이용하면 마이그래이션할 소스 테이블의 스플릿 키를 파일로 저장하고, 그 정보를 바탕으로 타겟 테이블을 스플릿 해줄 수 있습니다. 이렇게 하면 마이그래이션 과정에서 발생하는 과도한 스플릿 및 그로 인한 메이저 컴팩션을 피할 수 있습니다. 이때 타겟 테이블의 hbase.hstore.compaction.max.size 속성까지 적절히 튜닝을 해 주어야 컴팩션 감소 효과를 제대로 얻을 수 있습니다.어떤 경우에는 리전이 불필요하게 많이 쪼개진 경우도 있을 수 있습니다. 특히 Rowkey에 타임스탬프가 들어가 있고 동시에 TTL이 세팅된 테이블의 경우에는, 어느 정도 시간이 지나면 사이즈가 0인 리전이 다수 발생하게 됩니다. 리전이 과도하게 많아질 경우 좋지 않기 때문에(링크), 이런 경우 hbase-manager를 이용해서 사이즈가 0인 리전들을 머지(merge)를 할 수 있습니다.현재 hbase-manager에는 사이즈가 0인 리전들만 머지 하는 기능이 있습니다. 리전 2개가 연속으로 사이즈 0일 경우에만 머지할 수도 있고, 연속 여부에 관계없이 사이즈 0인 리전을 머지할 수도 있습니다. 리전 머지도 스플릿과 마찬가지로 머지 후에 메이저 컴팩션이 발생합니다. 사이즈가 0인 리전들만 머지하는 이유는 머지로 인한 메이저 컴팩션이 클러스터에 주는 부하를 최소화 하기 위함 입니다. 특히 사이즈가 0인 리전 2개를 머지 할 경우 클러스터 성능에 미치는 영향은 거의 없습니다.메이저 컴팩션은 리전의 모든 스토어 파일을 읽어서 새로운 스토어 파일로 다시 기록하는 기능입니다. 이 과정에서 레코드의 물리적인 삭제, 데이터 로컬리티의 증가, 컬럼패밀리의 속성 변경 반영 등이 일어납니다. 그래서 운영자가 수동으로 메이저 컴팩션을 실행하는 경우가 있습니다. HBase Shell에서 메이저 컴팩션을 할 수 있는데, 테이블이나 리전 단위의 메이저 컴팩션을 실행할 수 있습니다.hbase-manager를 이용하면 HBase Shell을 이용하는 것보다 정교하게 메이저 컴팩션을 할 수 있습니다. 리전서버, 테이블 등의 필터링 조건을 사용해서 메이저 컴팩션 범위를 좁힐 수 있습니다. 그리고 HBase 1.0 이상의 클러스터에서는 일정 수준 이하의 데이터 로컬리티를 가지는 리전들만 메이저 컴팩션 할 수도 있습니다.HBase에 저장된 데이터를 백업 및 복구하는 방법은 몇 가지가 있습니다. 그 중 카카오에서 메인으로 사용하고 있는 방법은 HBase 스냅샷(snapshot)입니다. 스냅샷은 백업 대상 데이터 사이즈가 크더라도 클러스터에 부하를 거의 주지 않고, 저장 공간도 스냅샷을 생성한 스토어 파일이 변경될 때만 소비하는 특성을 가지고 있습니다.스냅샷은 세부적으로 DISABLED, FLUSH, SKIPFLUSH 세 가지 타입이 있습니다. DISABLED 스냅샷은 테이블이 disable 된 상태에서 만들어야 하는 것이라, 운영환경에서는 현실적으로 사용하기 어렵습니다. FLUSH 스냅샷은 테이블의 모든 리전의 멤스토어를 순차적으로 플러시 시켜서 스토어 파일을 추가로 생성하고 난 다음 스냅샷을 생성합니다. 하지만 모든 리전의 플러시가 동시에 이루어지는 것이 아니다 보니, 각 리전 별로 스냅샷 생성 시점이 수초에서 수분까지 다를 수 있습니다. 마지막은 SKIPFLUSH 스냅샷으로, 멤스토어 플러시를 생략하고 현재 존재하고 있는 스토어파일들만 가지고 스냅샷을 생성하는 방법입니다. 멤스토어는 기본적으로 1시간의 플러시 주기를 가지고 있기 때문에, 스냅샷에 최대 1시간 분량의 멤스토어에 있는 데이터가 누락 될 수 있다는 특성이 있습니다.스냅샷 생성 시점 이후의 데이터 복구를 위해서는, WAL 아카이빙(archiving)도 병행해야 합니다. 아카이빙된 WAL은 WALPlayer을 이용해서 복구할 수 있습니다. WAL 보관 주기는 hbase.master.logcleaner.ttl을 세팅해서 조정할 수 있는데, 보통 스냅샷 생성 주기보다 1~2 시간 정도 길게 잡아 주면 됩니다. 그러나 쓰기가 많은 클러스터인 경우 아카이빙된 WAL의 사이즈가 매우 커질 수 있으므로, 클러스터의 워크로드 특성을 적절히 파악해서 세팅해야 합니다.스냅샷 관리는 HBase Shell에서 할 수 있습니다. 하지만 생성, 복원, 조회, 삭제 등의 단위 기능만 가능하고, 대상 테이블 필터링, 유지할 스냅샷 갯수 설정, 스케줄링 등의 기능은 없습니다. 유료인 CM Enterprise Edition에서는 HBase 스냅샷 스케줄러 기능을 제공하고 있기는 하지만 CM Express Edition에서는 사용할 수가 없습니다. 그래서 스냅샷 생성 및 유지를 편리하게 하고자 hbase-snapshot을 만들었습니다.hbase-snapshot에서는 정규표현식을 이용한 스냅샷 대상 테이블 설정, 스냅샷 제외 테이블 설정 등이 가능합니다. 또한 일정한 갯수의 스냅샷만 보관하고, 그 이상의 스냅샷은 오래된 순서대로 삭제하는 기능도 있습니다. 그리고 SKIPFLUSH를 적용할 대상 테이블도 세팅할 수 있습니다. hbase-snapshot에도 자체적인 스케줄링 기능은 없기 때문에, crontab을 이용해서 hbase-snapshot 커맨드를 각 클러스터 별로 적절히 스케줄링해 주어야 합니다.hbase-tools는 어떻게 하면 HBase 클러스터를 사용자에 미치는 영향을 최소화 하면서 매끄럽게 운영할 수 있을까? 하는 고민을 해결하는 과정에서 만들어졌습니다. 앞으로도 이런 고민은 계속 될 것이고, 그에 따라 hbase-tools에 대한 기능 추가 및 개선도 계속될 것입니다.이 글과 hbase-tools가 HBase 이용자들에게 작으나마 도움이 되었기를 바라는 마음을 전하면서, 글을 마무리 하겠습니다. 감사합니다.참고: 이 글은 툴의 기능에 대해서 개념적인 소개에 대해서만 다루고 있습니다. 모듈의 구조와 툴의 구체적인 사용방법은 Introduction And Use Cases 문서를 참고하세요.",http://tech.kakao.com/2016/03/24/opensource-4-hbase-tools/,0,kakao,,NULL,2016-03-24
DNS 기반의 Redis HA 구현,"이번 글에서는 DNS 기반의 Redis HA에 대한 이야기를 해보려고 합니다. DNS TTL이 무엇인지 그리고 그것을 어떻게 이용해서 Redis HA를 구현했는지 살펴보겠습니다.먼저 도메인의 TTL에 대해 이야기해 보겠습니다. TTL은 Time To Live의 약자로 도메인을 캐싱하고 있는 시간을 의미합니다. 누군가 A라는 도메인에 대해 질의를 했다면 응답을 준 DNS 서버에서 해당 도메인에 대해 TTL 시간 동안 캐싱을 하고 있게 됩니다. 이렇게 동작하는 이유는 같은 도메인을 여러 사람이 질의할 수 있기 때문에 한 번 질의한 내용을 캐싱하고 있는 게 불필요한 동작을 방지할 수 있기 때문입니다.리눅스에서는 간단하게 dig 명령으로 TTL 시간을 알 수 있습니다.위 스크린샷은 www.kakao.com에 대한 도메인 질의 결과입니다.그렇다면 한 가지 가정을 해보겠습니다. TTL이 0이 되면 어떤 일이 일어날까요? DNS 서버는 해당 도메인에 대한 질의 요청을 사용자에게 해 주었지만 TTL이 0이 되기 때문에 캐싱하지 않고 바로 버립니다. 그럼 다른 사용자가 똑같은 도메인을 요청했을 경우 다시 한 번 상위 DNS 서버를 찾아서 해당 도메인에 대한 질의 결과를 받아오는 작업을 해야 합니다. 이렇게 되면 상위 DNS로의 요청이 많아지고 전체적으로 도메인 질의 요청을 처리하는 데에 많은 시간이 소요되게 됩니다. 하지만 매 요청마다 해당 도메인을 관리하고 있는 DNS 서버를 직접 찾아서 질의하기 때문에 항상 최신의 정확한 정보를 가지고 있게 됩니다.도메인 요청에 걸리는 시간은 늘어나지만 도메인 변경 등에 대한 대응은 정확하고 빠르게 할 수 있다는 장점이 있습니다.Redis HA에서도 이런 방식을 사용해보려고 합니다.원리는 이렇습니다. master 역할을 하는 Redis 서버에 대표 도메인을 설정합니다. 예를 들어 A라는 서비스에서 사용할 Redis라고 한다면 A.redis.domain.com과 같은 방식입니다. 모니터링 서버에서는 master 서버에 대한 connect 및 간단한 GET/SET 테스트를 해서 살아 있음을 확인합니다. 이렇게 모니터링하다가 master 서버에 이상이 생기게 된다면 A.redis.domain.com 에 바인딩되어 있던 IP를 slave 역할을 하는 Redis 서버로 바꾸게 됩니다. 클라이언트에서는 A.redis.domain.com이라는 도메인을 통해서 Redis 서버에 접속을 하기 때문에 master 서버가 죽는 순간 잠시 단절이 있긴 하겠지만 도메인에 매핑된 IP 주소가 slave 서버로 바뀌기 때문에 금방 다시 커넥션을 맺어서 Redis를 사용할 수 있습니다. 이것도 TTL이 0이기 때문에 클라이언트가 바뀐 IP 주소로 바로 붙을 수 있게 되는 원리입니다.Redis 명령어까지 포함된 세부 로직은 아래와 같습니다.3번의 경우 master 서버가 connect는 되고 GET/SET 같은 연산이 안될 경우를 대비해서 필요한 로직 입니다. 이를 통해서 확실하게 연결을 끊어줘야 클라이언트들이 새로운 마스터에 붙을 수 있습니다.5번의 경우 slave 서버가 master 서버가 되었지만 redis.conf에는 여전히 slave 설정이 되어 있는 것이 오해를 불러 일으킬 수 있기 때문에 승격된 후 config 파일을 다시 만들도록 하고 있습니다.하지만 몇 가지 주의할 점이 있습니다.첫 번째로는 TTL이 0으로 설정됨으로 인해 발생할 수 있는 DNS 서버의 부하 입니다. 이 경우 Redis HA를 구현하는 데에 사용되는 도메인을 별도의 전용 DNS 서버로 분리하는 것으로 해결할 수 있습니다. 또한, 실제 도메인 질의는 connect 할 때만 발생하기 때문에 클라이언트에서 connection pool 방식으로 구현한다면 평상시에 도메인 질의가 많아질 이유는 없습니다.다만 이 경우도 클라이언트에서 잘못 구현해서 연산 할 때 마다 connection을 맺는다면 문제가 될 소지가 있습니다.두 번째는 Java 기반으로 개발할 때 JVM이 도메인 캐싱을 하지 않도록 아래와 같이 옵션을 주어야 합니다.이 옵션을 주지 않으면 JVM이 도메인을 캐싱하기 때문에 (TTL과 상관없이) 도메인이 바뀌어도 여전히 마스터 쪽으로 붙을 수 있습니다.세 번째 경우는 twemproxy를 사용한다면 버전을 0.4.1로 써야 하는 이슈가 있습니다. 그 전 버전까지는 twemproxy 가 한번 socket resolve를 하고 나면 해당 IP를 기록해두고 재 접속을 위해서 그걸 이용하기 때문입니다. 이게 0.4.1 에서 기능이 들어갔다고 합니다. (강대명 님이 소중한 지식을 공유해 주셨습니다. ^^)도메인의 TTL 값을 활용한 Redis HA에 대해 설명했는데요,TTL 값을 잘만 이용하면 Redis 외에 다른 많은 솔루션들에도 HA를 적용할 수 있습니다.오늘 글이 읽으시는 분들에게 도움이 되었으면 합니다.이 글은 카카오에서 서비스 인프라 시스템을 담당하고 있는 aden.kang이 브런치에 올린 글을 저자의 동의를 얻어 다시 게재한 것입니다. 저자가 브런치에서 운영하는 All about Linux 매거진을 통해 리눅스에 대한 풍부한 꿀팁들을 보실 수 있습니다.",http://tech.kakao.com/2016/03/18/redis-ha-dns/,0,kakao,python,NULL,2016-03-18
kakao의 오픈소스 Ep3 - HBase Region Inspector,"“카카오의 오픈소스를 소개합니다” 세번째는 jg.choi와 동료들이 개발한 HBase Region Inspector입니다.HBase Region Inspector는 HBase의 여러 리젼에 분산된 데이터를 시각적으로 보여주는 실용적인 도구입니다.카카오에서도 대규모 HBase 클러스터 운영에 큰 도움이 되고 있는 유용한 소프트웨어입니다. 특히 Clojure 와 React으로 작성되어 Clojure를 공부하려는 개발자들에게 유용할 것입니다.카카오의 많은 서비스는 대용량의 데이터를 저장하고 서비스하기 위해 Apache HBase 를 사용하고 있습니다.HBase 는 이미 잘 알려져 있으니 긴 설명이 필요하진 않을 것 같은데요. 간단히 한 문장으로 요약하자면 HBase 는 데이터를 여러 서버에 분산 저장하고 처리하는 Hadoop 기반의 분산 데이터 저장소입니다.분산 데이터 저장소이니 당연히 데이터가 여러 서버에 잘 분산 되어 있어야 scalable 한 성능을 얻을 수 있죠. HBase 는 각 테이블 데이터를 여러 구간으로 나누는데 – RDBMS 의 range partitioning 과 동일한 방식 – 이렇게 나눈 각 구간의 데이터를 리젼 (region) 이라 부르고 분산의 기본 단위로 사용합니다. 다른 데이터 스토어에서는 유사한 개념을 partition, chunk 등의 명칭으로 부르기도 합니다.(이미지 출처: HBase Architecture Analysis Part1(Logical Architecture))HBase 클러스터 성능 관리의 핵심은 바로 이런 리젼들의 분산을 모니터링하고 관리하는 일입니다. 리젼들이 적절한 크기로, 또 적절한 범위로 나뉘어져 있는지, 모든 서버에 고르게 분산되어 있는지, 읽기나 쓰기가 몰린 리젼이 있지는 않은지, 특정 리젼 서버에 요청이 많은 리젼들이 다수 배치되어 있지는 않은지, 다양한 관점에서 살펴봐야 하죠.그런데 안타깝게도 HBase 의 Web UI 를 통해서는 이러한 사항들을 효과적으로 파악하기가 힘듭니다. 각 리젼 서버는 다음과 같은 단순한 화면만을 제공하거든요.지표들을 visual 하게 보여주지 않고 숫자로만 보여주니 상대적인 크고 작음이 머리 속에 잘 그려지지 않습니다. 읽기/쓰기 요청 수도 누적 횟수만 보여줄 뿐, 실제로 중요한 초당 요청 횟수를 보여주지는 않아요.가장 큰 문제는 모아서 볼 수 없다는 점입니다. HBase 클러스터를 구성하는 서버의 대수가 수십대, 수백대를 넘어가는 경우에, 그 모든 서버들의 페이지를 일일이 열어 가며 확인 할 수는 없는 노릇이죠. 클러스터 전체 리젼들의 상태를 한 눈에 조망할 수 있는 방법이 없었습니다.분명 비슷한 아쉬움을 느낀 사람들이 있었겠죠. Hannibal 이라는 오픈소스 모니터링 툴이 있습니다. 다음과 같이 각 리젼 서버에 위치한 리젼들의 크기를 visual 하게 보여줍니다.![Hannibal 리젼 모니터링 화면좋은 시도인 것은 분명하나 단순히 리젼의 크기 정보만을 보여줄 뿐이라 많은 통찰을 주지는 못합니다. 더 이상 업데이트 되지 않고 있기도 합니다.그래서 결국 hbase-region-inspector 라는 (밋밋한 이름의) 툴을 만들기로 했습니다. 목표로 했던 것은 다음과 같습니다.프로젝트는 빠른 개발을 위해 Clojure 와 React 을 이용해 구현되었습니다. Clojure 에 관심이 많은 분이라면 왜 Om 이나 Reagent 를 사용하지 않았는지 궁금해 하실 지도 모르겠네요. 그건 단순히 필자가 JavaScript 개발자가 아닌데다 React 도 처음 써보는 입장이라 추상화 계층을 하나 더 두기는 부담스러워서 그랬던 것이죠.hbase-region-inspector 는 실행 가능한 바이너리 또는 JAR 의 형태로 배포되고 있습니다. 사용하시는 클러스터에 맞는 바이너리 파일을 다운로드 하시고 실행 권한을 부여하신 후 (chmod +x ...), 다음과 같이 실행하시면 됩니다.쉽죠?지정한 포트를 브라우저에서 열어보시면 다음과 같은 화면을 보실 수 있습니다.각 리젼 서버별 리젼 분포와, 각 리젼의 크기, 누적 요청 수, 초당 요청 수, 스토어파일의 개수, 멤스토어의 크기 등 다양한 정보를 확인 할 수 있습니다.구체적인 동작은 아래의 영상에서 확인하세요.사용하기 쉽다 보니 카카오에서는 여러 팀에서 이 툴을 사용해 HBase 상태를 모니터링하고 있습니다. 웹서버의 형태로 실행되므로, 현재 상태를 공유하기에도 편리하죠. 다양한 문제 상황에 대한 진단과 파악도 용이해졌는데요, 실제로 다음과 같은 사례들을 진단하는데 활용했습니다.아직 몇 가지 아쉬운 점들이 있기는 합니다. hbase-region-inspector 는 현재 현황을 파악하는데는 도움이 되지만, 변화 이력을 추적하기에는 적합하지 않습니다 (3차원 그래프가 필요할까요?).또한 리젼의 개수가 수만개를 넘어가는 대형 클러스터를 대상으로 실행하는 경우, 브라우저가 무척이나 힘들어 하는 모습을 보게 됩니다.(미안 크롬 …)자랑할 만한 수준의 코드는 아니지만 – 아니 사실 그 반대이지만 – 다른 HBase 사용자 분들께도 유용하리라는 판단에 오픈소스로 공개하게 되었습니다. 소스코드와 바이너리는 아래 링크에서 보실 수 있습니다.사용해 보시고 피드백 주세요. 저의 비루한 JavaScript 코드를 다듬어 주실 분도 기다려 봅니다.",http://tech.kakao.com/2016/03/11/opensource-3-hri/,0,kakao,"react,webpack,java,vue,css,frontend,angular,html",NULL,2016-03-11
Redis의 SCAN은 어떻게 동작하는가?," Redis의 기능 중에 쓰면 안되지만, 그 단맛에 끌려 어쩔 수 없이 치게 되는 명령이 KEYS입니다. KEYS를 쓰는 순간, Redis는 이 명령을 처리하기 위해서 멈춰버립니다. 특히 트래픽이 많은 서버는 이 KEYS 명령 하나 때문에 많은 장애를 내게 됩니다. 그런데 어느 순간(!) Redis에 SCAN이라는 명령이 생겼습니다. KEYS의 단점을 없애면서도, 느리지 않은 SCAN, 어떻게 그것이 가능할까요? 이 글에서는 단순한 SCAN의 사용법을 넘어, 소스 코드를 통해 동작 원리까지 알아보겠습니다.대부분의 Redis 명령처럼 SCAN도 네가지 변형이 있습니다. SCAN은 전체 key 목록에서, SSCAN은 set 안에서, ZSCAN은 sorted set 안에서, HSCAN은 hash 안에서 키를 가져오는 명령입니다:cursor 값을 0으로 지정한 SCAN/SSCAN/ZSCAN/HSCAN 명령으로 순회가 시작되고, 이어지는 순회에 사용할 cursor 값과, 지정한 패턴(pattern)과 일치하는 키를 최대 지정한 갯수(count)만큼 반환합니다. 반환된 cursor 값이 0이면 순회가 종료됩니다. 이 과정을 전체 순회(full iteration)이라고 합니다. 다음은 CLI에서 SCAN 명령을 사용하여 전체 순회를 하는 예입니다:앞의 scan 명령의 결과에 따라 이어지는 scan 명령에 사용할 cursor 값이 바뀌고 이 값에 따라 순회 종료 여부를 판단해야 하므로 CLI보다는 스크립트에서 더욱 유용합니다. 다음은 Redis에서 모든 키 목록을 가져오는 파이썬 코드입니다:위 예제의 결과는 KEYS 명령과 기본적으로 동일하지만, 항상 그렇지는 않습니다 항상 그렇지는 않다뇨?! 뭐가 다른거죠? 왜 다른거죠? 그래서… Redis의 소스를 뒤져보았습니다.모든 스캔 명령(SCAN/SSCAN/ZSCAN/HSCAN)은 scanGenericCommand라는 공통 함수를 이용해서 처리가 됩니다:위의 코드에서 핵심적인 부분은, 찾아야 하는 key들을 keys라는 리스트에 추가하고, 이 리스트를 돌면서 패턴에 맞는 것들을 삭제한 결과를 돌려줍니다. 당연히 Redis는 다양한 자료구조를 지원하고 있고, 속도를 위해서 같은 자료구조라도 구현 방식이 여러가지입니다. 그러나 이것 전부라면 이 글을 쓰지 않았겠죠. 삽질을 계속하기 위해, 먼저 “Redis가 어떻게 데이터를 저장하는지”부터 다시 한번 살펴 보겠습니다.Redis의 가장 기초적인 자료구조는 KV 즉 Key/Value 형태를 저장하는 것입니다.(String 타입이라고도 합니다.) 이를 위해 Redis는 Bucket을 활용한 Chained Linked List 구조를 사용합니다. 최초에는 4개의 Bucket에서 사용하며, 같은 Bucket에 들어가는 Key는 링크드 리스트 형태로 저장하는 거죠. 즉 다음 그림과 같습니다.이 Chained Linked List에는 약점이 있습니다. 한 Bucket 안에 데이터가 많아지면 결국 탐색 속도가 느려집니다. 이를 위해서 Redis는 특정 사이즈가 넘을 때 마다 Bucket을 두 배로 확장하고, Key들을 rehash하게 됩니다. 먼저 이 때 Key의 Hash로 사용하는 해시함수는 다음과 같습니다. MurmurHash2를 사용합니다.그리고 hash 값이 들어가야 할 hash table 내의 index를 결정하는 방법은 다음과 같습니다.table에는 Key를 찾기위해 비트 연산을 하기 위한 sizemask가 들어가 있습니다. 초기에는 table의 bucket이 4개 이므로 sizemask는 이진수로 11 즉 3의 값이 셋팅됩니다. 즉 해시된 결과 & 11의 연산결과로 들어가야 하는 Bucket이 결정되게 됩니다.여기서 Key가 많아지면 Redis는 Table의 사이즈를 2배로 늘리게 됩니다. 그러면 당연히 sizemask도 커지게 됩니다. Table size가 8이면 sizemask는 7이 됩니다.먼저 간단하게 말하자면, SCAN의 원리는 이 Bucket을 한 턴에 하나씩 순회하는 것입니다. 그래서 아래 그림과 같이 처음에는 Bucket Index 0를 읽고 데이터를 던져주는 것입니다.이번에는 Redis SCAN의 동작을 더 분석하기 위해서 Redis Hash Table의 Rehashing과, 그 상황에서 SCAN이 어떻게 동작하는지 알아보도록 하겠습니다. 앞에서도 간단하게 언급했지만 Redis Hash Table은 보통 Dynamic Bucket에 충돌은 list로 처리하는 방식입니다.처음에는 4개의 Bucket으로 진행하면 Hash 값에 bitmask를 씌워서 Hash Table 내의 index를 결정합니다. 그런데, 이대로 계속 데이터가 증가하면, 당연히 충돌이 많고, List가 길어지므로, 탐색 시간이 오래걸리게 되어서 문제가 발생합니다. Redis는 이를 해결하기 위해서 hash table의 사이즈를 2배로 늘리는 정책을 취합니다.2배로 테이블이 늘어나면서, bitmask는 하나 더 사용하도록 됩니다. 이렇게 테이블이 확장되면 Rehash를 하게 됩니다. 그래야만 검색시에 제대로 찾을 수 있기 때문입니다. 먼저 Table을 확장할 때 사용하는 것이 _dictExpandIfNeeded 합수입니다. dictIsRehashing는 이미 Rehash 중인지를 알려주는 함수이므로, Rehashing 중이면 이미 테이블이 확장된 상태이므로 그냥 DICT_OK를 리턴합니다.먼저 hash table에서 hash table의 사용 정도가 dict_force_resize_ratio 값 보다 높으면 2배로 확장하게 됩니다.실제로 _dictExpandIfNeeded는 _dictKeyIndex 함수에서 호출하게 됩니다. 이렇게 테이블이 확장되면 Rehash를 해야 합니다. Rehash라는 것은 테이블의 Bucket 크기가 커졌고 bitmask가 달라졌으니… mask 0011이 전부 3번째 index였다면 이중에서 111은 7번째로, 011은 3번째로 옮기는 것입니다. 여기서 Redis의 특징이 하나 있습니다. 한꺼번에 모든 테이블을 Rehashing 해야 하면 당연히 시간이 많이 걸립니다. O(n)의 시간이 필요합니다. 그래서 Redis는 rehash flag와 rehashidx라는 변수를 이용해서, hash table에서 하나씩 Rehash하게 됩니다. 즉, 확장된 크기가 8이라면 이전 크기 총 4번의 Rehash 스텝을 통해서 Rehashing이 일어나게 됩니다. (이로 인해서 뒤에서 설명하는 특별한 현상이 생깁니다.)그리고 현재 rehashing 중인것을 체크하는 함수가 dictIsRehashing 함수입니다. rehashidx가 -1이 아니면 Rehashing 중인 상태입니다.그리고 위의 _dictExpandIfNeeded에서 호출하는 실제 hash table의 크기를 증가시키는 dictExpand 함수에서 rehashidx를 0으로 설정합니다.위의 함수를 잘 살펴보면 dict 구조체 안의 ht[1] = n으로 할당하는 코드가 있습니다. 이 얘기는 hash table이 두 개라는 것입니다. 먼저 dict 구조체를 살펴보면 다음과 같습니다.실제로, redis의 rehashing 중에는 Hash Table이 두개가 존재합니다. 이것은 앞에 설명했듯이… 한번에 rehash step이 끝나지 않고, 매번 하나의 bucket 별로 rehashing을 하기 때문입니다. 즉 hash table의 확장이 일어나면 다음과 같이 두 개의 hash table 이 생깁니다.그리고 한 스텝이 자나갈 때 마다 하나의 Bucket 단위로 해싱이 됩니다. 즉 첫번째 rehash step에서는 다음과 같이 ht[0]에 있던 데이터들이 ht[1]으로 나뉘어서 들어가게 됩니다.두 번째, 세 번째, 네 번째 rehash 스텝이 끝나면 완료되게 됩니다.그럼 의문이 생깁니다. Rehashing 중에 추가 되는 데이터는? 또는 삭제나 업데이트는? 추가 되는 데이터는 이 때는 무조건 ht[1]으로 들어가게 됩니다.(또 해싱 안해도 되게…) 두 번째로, 검색이나 업데이트는?? 이 때는 ht[0], ht[1]을 모두 탐색하게 됩니다.(어쩔 수 없겠죠?)dictRehash 함수에서 이 rehash step을 처리하게 됩니다. dictRehash 함수의 파라매터 n은 이 스텝을 몇 번이나 할 것인가 이고, 실제로 수행할 hash table의 index는 함수 중에서 ht[0]의 table이 NULL인 부분을 스킵하면서 찾게 됩니다. 그리고 ht[0]의 used 값이 0이면 rehash가 모두 끝난것이므로 ht[1]을 ht[0]로 변경하고 rehashidx를 다시 -1로 셋팅하면서 종료하게 됩니다.이제 다시 SCAN으로 돌아오면… Rehashing 중의 dictScan 함수는 다음과 같습니다.실제로 이미 Rehashing이 된 bucket의 경우는 ht[0] 작은 hash table에는 이미 index의 값이 NULL이므로 실제로 돌지 않지만, 아직 rehash되지 않은 bucket의 경우는 ht[0] 와 ht[1]의 두 군데, 즉 총 세 군데에 데이터가 존재할 수 있습니다. 그래서 먼저 ht[0]의 bucket을 돌고 나서, ht[1]을 찾게 됩니다. 여기서 당연히 ht[1]에서는 두 군데를 검색해야 하므로 두 번 돌게 됩니다.즉 위의 식은 만약 v가 0이고 m0 = 3, m1 = 7이라고 하면 (((0 | 3) + 1) & ~3) | (0 & 3)이 됩니다. ~3은 Bitwise NOT 3이 되므로 -4이고, (4 & -4) | 0이므로, 결론은 4 & -4 입니다. 3은 00000011, bitwise NOT하면 11111100이므로, 00000100 & 11111100 해서 00000100, 즉 4가 됩니다. 처음에는 index 0, 두번째는 index 4가 되는 거죠. 그래서 첫 루프를 돌게 됩니다. 다시 4 & (m0 ^ m1) == 4 이므로…이제 두 번째 루프에서 다시 (((4 | 3) + 1) & -4) | (4 & 3)이고 4 | 3 = 7, 4 & 3 = 0이고, 다시 한번 정리하면 ((7+1) & -4) | 0 이므로 결론은 8 & -4 = 4 가 되고, 00001000 & 111111100이 되므로 v 는 이번에는 00001000, 즉 8이 됩니다. 즉 한번 돌 때 마다, ht[0]의 size 만큼 증가하게 됩니다.(다들 한 방에 이해하실 텐데… 이걸 설명한다고 Orz) 그래서 그 다음번에는 8 & 4 가 되므로 루프가 끝나게 됩니다. 즉, 0, 4 이렇게 ht[1]에서 두 번 읽어야 하니, 두 번 읽는 코드를 만들어둔거죠.결국 Redis SCAN에서의 Cursor는 bucket 을 검색해야할 다음 index 값이라고 볼 수 있습니다. 그런데 실제로 실행시켜보면, 0, 1, 2 이렇게 증가하지 않습니다.그 이유 중에 하나는 실제 Cursor 값이 다음 index의 reverse 값을 취하고 있기 때문입니다. 이걸 보기 전에 먼저 다시 한번 SCAN의 핵심 함수인 dictScan을 살펴보도록 하겠습니다.(맨 뒤만 보면 됩니다.)한 이터레이션이 끝나고 나면 m0 의 bitwise NOT을 or 하고 reverse를 취한 다음 1을 더하고 다시 reverse를 취합니다. 일단 bucket이 4개만 있다고 가정하고, rehashing은 빼고 생각해보도록 합니다. 먼저 여기서 reverse는 비트를 쭈욱 세워놓고, 그걸 거꾸로 뒤집는 것입니다. 그래서 0의 rev(0) 은 그대로 0이고, rev(1)은 8000000000000000(16진수), rev(2)는 4000000000000000(16진수)가 됩니다.처음에는 v(cursor)가 0입니다. scan이 끝나고 (0 |= ~3) = -4, 그 뒤에 rev(-4)는 3fffffffffffffff(16진수) 가 됩니다. 여기에 1을 더하면 4000000000000000 여기서 다시 rev(4000000000000000)가 되면 2가 나오게 됩니다.그런데 왜 reverse를 취하는 것일까요? 이것은 실제 적으로 1씩 증가하는 형태라면… cursor가 언제 끝나는지 알려주기가 애매해서 입니다. 즉 끝났다는 값을 다시 줘야 하는데, 그것보다는 0으로 시작해서 다시 0으로 끝날 수 있도록 reverse 형태를 취하는 것이죠.Redis의 SCAN명령은 싱글쓰레드 아키텍쳐에서 KEYS와 SMEMBERS 명령이 가진 문제점을 해결한 유용한 명령입니다. 그러나, 빛이 있는 곳에는 그림자가 있기 마련! SCAN 명령도 여러가지 문제점이 있습니다: “Redis의 SCAN은 어떻게 동작할까”라는 단순한 호기심에서 출발해서 Redis의 코드를 여기저기 살펴보았습니다. 어떤가요? 별거 없죠? 부족한 글이지만 이 글을 통해서, 유명한 오픈소스라고 해서 기죽지 않고 소스 코드를 뒤져보고 직접 확인하는 재미를 발견하셨길 바랍니다.이 글은 자칭 “혀로그래머” clark.kang의 블로그  Scan/SScan/ZScan/HScan 이야기…와 “Redis Scan은 어떻게 동작할까?” 시리즈 1부, 2부, 3부를 원저자의 동의를 받아 엮은 글입니다.",http://tech.kakao.com/2016/03/11/redis-scan/,0,kakao,"docker,frontend,angular",NULL,2016-03-11
Monad Programming with Scala Future,"함수형 언어에 대해서 공부를 하다보면 언제나 Monad라는 녀석을 마주치게 됩니다. [Category Theory][1]의 수학적인 개념이 바탕이 되어 있는 Monad를 접하면 어렵고 난해해서, 많은 사람들이 Monad를 학습하는 과정에서 함수형 언어를 포기합니다. 하지만 Monad라는 장벽을 넘어서고 나면, 아니 조금만 이해하고 나면 함수형 언어를 개발하는데 있어서의 이해도와 생산성이 급속도로 높아지게 됩니다. Learning Curves (for different programming languages)라는 글에 보면 여러 언어의 학습과정에서 나타다는 다양한 특징을 그래프로 보여줍니다. 그 중에 Haskell의 경우 Monad의 대한 이해 과정을 거치기 전과 후가 확연하게 차이가 나는 것을 볼 수 있습니다.이 글에서는, 필자가 Monad를 이해하기 위해 겪었던 방황 - 혼돈, 의문, 좌절 - 과 적응, 마침내 갖고놀기에 이르는 과정을 소개하고, Scala의 Future를 이용한 예제를 통해 Monad에 한발짝 다가가 보려고 합니다.Monad 공부의 시작은 늘 그랬듯이 구글링을 통한 검색이었습니다. 구글의 페이지 랭크 알고리즘이 추천해주는 링크를 따라서 생각없이 위키피디아의 [Monad (category theory)][1]로 첫 문을 열었죠: 방황“이건 뭐지… 알 수 없는 말들 뿐… 내가 전공이 수학과가 아니라서 그런거야, 난 개발자니까 프로그래밍으로 된걸 보면 이해가 될거야”라고 생각했지만…Monad와 연관 검색어로 같이 등장하는 게 Haskell이었다. 이번엔 Haskell 공식 홈페이지의 Monad tutorial을 읽어 보았습니다: 혼돈“이 알 수 없는 화살표와 심볼들은 뭐지? 아직 내가 Haskell을 잘 몰라서 그런거야, 내가 조금 더 익숙한 언어로 된 설명을 보면 되겠지”라고 생각했지만…이번엔 Javascript를 활용한 Monad를 설명해 놓은 글(Monad in Javascript, 번역글)이 있었다. Javascript면 문법도 단순하고 쉽게 이해할 수 있을거라 생각했지만…의문 방황과 혼돈을 겪고나서 “unit과 bind는 어렴풋이 알겠는데 이걸가지고 뭘하라는거지? 어떻게 활용하고 이게 왜 필요한거지?” 라는 의문이 들기 시작했다.아직 내가 Monad에 대해서 이해를 못하고 있어서 그런 것 같아 더 쉬운 설명서를 찾아보기로 했습니다.이번엔 그림으로 설명하는 Monads(Functors, Applicatives, And Monads In Pictures, 번역글)를 보았습니다: 좌절“Monad에 대해서 이해하려고 여기까지 왔는데… Monad만 점령하면 될 줄 알았는데… Functor와 Applicative란 개념이 있었다니 ㅠㅠ 이 용어들은 또 뭐지? 아… 함수형 언어의 길은 멀고도 험난하구나…” OTL나름 많은 글과 자료를 보았지만 추상적인 Monad의 개념을 이해하기에는 역부족이었습니다. 선생님이 필요했죠.Scala 공부하는데 있어서 바이블로 불리는 Coursera의 두 개의 Scala 과정:을 통해서 Scala의 창시자인 Martin Ordersky와 Rx, Linq의 설계자인 Eric Meijer의 가르침을 받았습니다.Martin Ordersky는 대학 교수님답게 모나드의 수학적인 기초와 이를 Scala로 예를 들어가면서 차근차근 알려줍니다:또한 Eric Meijer는 어둠의 해커 출신답게, 개발자에게 좀 더 친숙하게 실용적인 측면에서의 모나드를 활용한 프로그래밍을 - 모나드를 사용하면 어떤게 좋아진다는 걸 - 알려줍니다:Eric Meijer는 MS에서 Haskell을 이용한 함수형 언어 강좌를 꾸준히 했었고, 현재 edx.org에서도 Introduction to Functional Programming이란 주제로 강의를 하고 있습니다.괴담 Cousera 강의를 듣고 과제를 풀고 실제 함수형 언어를 사용하면서 Monad의 문이 열리고 이해가 되기 시작했습니다. 정확하게 말하면 Monad를 이해했다기 보다는 사용할 줄 안다는 표현이 맞을 것 같네요. 이제 모나드 괴담은 괴담일 뿐~Monad에 대해서 몰라도 됩니다. Monad를 배운다는데 Monad에 대해서 몰라도 된다니 모순된 말이죠. 하지만 실제 Monad에 대한 이해가 없어도 Monad 프로그래밍을 할 수 있습니다.그럼 비동기 프로그램을 Monad를 이용해서 구현해보겠습니다. 구현에는 Scala의 Future[T]라는 타입을 사용합니다. Future를 활용한 다양한 함수를 조합하는 프로그래밍을 할 것이고 그것이 첫번째 Monad를 활용한 프로그래밍이 될 것입니다.이제 잠시 Monad란 용어를 쓰지 않겠습니다. 아니, 쓸 필요가 없을 겁니다.Scala 공식 API문서에 보면 Future에 대한 설명은 간단합니다.Future는 이름 그대로 미래의 값을 저장하고 있는 객체라 생각하면 됩니다. Future에 저장되어 있는 값은 특정 연산(IO, CPU)이 끝나고 반환되는 시점에 그 값을 얻을 수 있습니다. 설명은 이것으로 충분합니다. Future의 다른 부가적인 API들은 차근차근 알아가면 됩니다. 한 번에 다 알 필요가 없습니다.쇼핑몰에서 유저가 주문정보페이지를 통해 주문내역을 조회 할 수 있는 프로그램을 구현해보겠습니다. 실제 구현은 이보다 복잡하겠지만, 최소한의 핵심 기능과 동기화 프로그래밍에서 발생하는 Blocking I/O를 중심으로 그려보면 아래와 같습니다:이 Blocking I/O 구간을 Non Blocking I/O로 바꿔 보겠습니다.NIO를 활용하기 위해서는 다양한 라이브러리 혹은 프레임웍의 지원을 확인해보고 필요에 따라 선택하여 사용하면 됩니다:그 외 많은 오픈 소스 프로젝트가 NIO를 지원하고 정말 원한다면 Java의 NIO API를 직접 사용할 수도 있습니다.하지만… 참기로 했습니다.NIO로 데이터를 가져오기 때문에 모든 결과값은 Future에 담겨져서 옵니다:위에 정의된 함수들을 조합해서 주문 상품 내역을 가져와 보겠습니다. Future에 값이 들어 있기 때문에 이를 가져오기 위해서 Await#result를 활용했습니다:위의 코드를 보면 함수형 스타일이 아니라 절차 지향 스타일의 프로그래밍이 되었고 NIO Client를 사용하였지만 Await#result 함수 호출을 통해서 Blocking I/O가 발생했습니다. 아직은 비동기 프로그래밍이 아니죠.Await#result를 사용하지 않고 3개의 Future를 반환하는 함수를 엮어서 1개의 Future의 결과 Future[List[Item]]을 얻을 수 있습니다:여기서 flatMap은 Future에서 값이 들어올 때 해당 블록 { ... } 호출하여 비동기 연산이 연속적으로 가능하게 합니다. 이는 Javascript에서 자주 사용하는 Promise의 then 함수와 유사합니다. 결과 값이 반환될 때 동작할 함수, callback을 등록해 놓는 방식이죠:Callback? Callback!! Callback 패턴은 Callback Hell이라 불리는 악명 높은 Anti-pattern 아닌가?Scala는 for comprehension을 통해서 Callback hell에서 벗어날 멋진 방법을 제공해주고 있습니다. 관련 내용는 구글링을 통해서 금방 찾을 수 있습니다. 이제 flatMap의 callback(lambda) 방식을 사용하지 않고 코드를 고쳐 보겠습니다:위의 flatMap을 활용한 코드보다 간결해졌고 가독성 좋고, 유지보수 쉬운 좋은 코드로 바뀌었습니다.동기 코드를 작성할 때의 flow와 비슷하게 작성한 비동기 코드를 조금 더 개선하고 싶군요.Scala Async를 활용해보겠습니다. 이를 적용할려면 의존성이 추가되어야 하기때문에 build.sbt에 아래와 같이 추가해야 합니다:의존성 추가 후에 아래와 같이 async와 await 키워드를 사용하여 비동기 프로그래밍을 동기 프로그래밍과 비슷하게 할 수 있습니다:우리가 비동기 프로그램을 위해서 사용한 Future가 Monad의 일종입니다.이제 우리는 Monad를 활용한 프로그래밍을 할 수 있고, 이미 해봤습니다.위의 예제에서:이 코드는 Monad의 flatMap 혹은 for comprehension을 통한 합성을 통해서 아래와 같이 바뀌게 됩니다.Monad를 통한 함수 합성을 이미 한 거죠.특히 Scala는 Haskell의 do notation 과 유사한 for comprehension을 통해서 여러 개의 Monad를 연결하는 syntactic sugar을 제공하고 이것도 이미 활용했습니다.Monad가 되려면 위의 Martin Ordersky의 강의에 나오는 3가지 법칙을 만족해야 합니다. 하지만 Scala의 Future는 결합의 법칙을 만족하지 못합니다. Is Future in Scala a monad?란 Stackoverflow의 질문과 답변을 보면 결과적으로 Future는 return값을 cache하고, side-effect를 효과적으로 관리 못하며, 결합법칙을 만족하지 못해서 Monad가 아니므로 “Scala의 Future는 Monadic이라는 표현을 써야한다”는 군요.Monad의 법칙을 만족하기 위해서 Scalaz의 Task를 사용하면 됩니다.Scalaz의 Task와 Scala의 Future은 return 값을 cache 하는 방식 이외에도 callback에 대한 처리 방식도 차이가 납니다.벤치마크를 보면 trampoline과 그에 대한 optimize에 대해서 성능이 많이 차이나는 것을 확인할 수 있습니다.자세한 내용은 Higher Order 블로그의 Easy Performance Wins With Scalaz 포스트를 참조하세요.Monad 개념 때문에 어려워 말고, 다른 API처럼 사용하면 됩니다. 물론 개념을 자세히 알면 도움이 되겠지만 반대로 flatMap API를 사용하다 보면 Monad에 대한 이해가 늘어납니다.Scala에는 많은 타입이 flatMap과 for comprehention을 활용할 수 있는 Monad | Monadic 타입입니다:그 외 타입에 flatMap 함수가 있다면 Monad라 생각해도 크게 무리는 없을듯 합니다.Monad의 대한 보다 자세한 내용은 위에 언급한 Cousera 강좌 Learning Scalaz, 그리고 친철히 예제와 함께 자세히 한글로 설명해주신 오현석님의 enshahar/BasicFPinScala의 문서가 좋은 참고 자료가 될 것입니다. 또한 인터넷에서 MOOC 강좌를 열심히 들으면 Certification을 받을수 있습니다. :) [1]: https://en.wikipedia.org/wiki/Monad_(category_theory)이 글은 카카오톡 선물하기 개발팀의 liam.m이 사내 게시판에 올린 글을 저자의 동의를 얻어 옮긴 것입니다. 최근엔 페이스북 그룹 2^4+2에 자주 출몰해서 다양한 지식과 정보를 나눠주고 있습니다.",http://tech.kakao.com/2016/03/03/monad-programming-with-scala-future/,0,kakao,"scala,python,sql,react,webpack,java,backend,frontend,javascript,css,angular,database,html,xml",NULL,2016-03-03
"그래, 가끔 ""Vim에서"" GitHub을 보자!","vimrc 건드리기 좋은 목요일입니다. ;)기술 블로그 담당자가 글을 내놓으라고 닥달하니, 예전에 만들었던 플러그인이나 한번 꺼내볼까 합니다:https://github.com/junegunn/vim-github-dashboardVim 상에서 GitHub API를 이용해 dashboard 페이지를 보여주는 플러그인입니다. 왜 멀쩡한 브라우저를 놔두고 이런 짓을 한 것이냐 물으신다면 … 그것 참 좋은 질문이네요.Vimscript 만 가지고는 API 결과를 받아오는 것이 불가능하므로 Ruby interface를 이용합니다만 (:help ruby) OS X 의 시스템 디폴트 Vim 에서 기본적으로 지원하기 때문에 사용하시는데 문제는 없을 겁니다.제공하는 커맨드는 다음과 같습니다.Public GitHub 의 경우 조회만 하는 경우는 인증이 필요 없기 때문에 느낌표를 붙여서 실행하시면 되겠습니다.CTRL-N / CTRL-P 로 링크 사이를 이동할 수 있고, Enter key 나 o를 누르면 해당 페이지가 브라우저에서 열립니다.매번 본인의 ID 를 입력하는 것이 번거롭다면 다음과 같은 설정을 vimrc 에 추가하세요.GHA 커맨드도 마찬가지 방식으로 사용합니다.Linus 선생님이 무얼하며 지내시는지 볼 수도 있고요,Linux에 무슨 일들이 벌어지고 있는지도 간단히 확인할 수 있습니다.사내에서 사용하는 GitHub Enterprise에 접근하려면 프로파일을 지정해야 하는데요. g:github_dashboard#프로파일명 의 변수를 선언하면 GHD -프로파일명 과 같은 형태로 사용하실 수 있습니다.다음과 같은 식으로 foo 프로파일을 정의하면 됩니다.(Access token 은 https://your-github-enterprise-host-name/settings/applications 에서 발급 가능)이제 foo 프로파일을 사용하여 bar 사용자의 baz 프로젝트에서는 무슨 일이 벌어지고 있나 보려면 다음과 같이 하시면 됩니다. 인증이 필요하므로 ! 이 없는 커맨드를 실행합니다.멀쩡한 브라우저 놔두고 왜 vim에서 이런 짓(?)을 하냐는 최초의 질문에 대한 답변은 Emacs 아저씨의 말씀으로 대신하도록 하죠.Playfully doing something difficult, whether useful or not, that is hacking.그래도 굳이 사용해야 할 이유를 찾아 보자면, 내가 아닌 다른 사람의 대시보드 화면이나 특정 저장소의 활동 정보를 목록으로 볼 수 있는 페이지가 GitHub 에 없기 때문에 그런 용도로 사용해 보실 수는 있겠습니다.이 글은 ranked.in 선정 한국 개발자 인기 1위, 한국 저장소 인기 1위 2관왕에 빛나는 “빔신” jg.choi가 사내 게시판에 올린 글을 저자의 동의를 얻어 옮긴 것입니다. 저자의 깃헙을 방문하시면 다양한 vim 플러그인과 유틸리티들, 그리고 빔신의 vimrc를 보실 수 있습니다.",http://tech.kakao.com/2016/03/03/vim-github-dashboard/,0,kakao,"python,react,java,docker,backend,frontend,angular,typescript,xml",NULL,2016-03-03
kakao의 오픈소스 Ep2 - MRTE(MySQL Realtime Traffic Emulator),"“카카오의 오픈소스를 소개합니다” 두번째는 matt.lee와 동료들이 개발한 MySQL Realtime Traffic Emulator(MRTE)입니다.MRTE는 실서비스용 MySQL 서버의 트래픽을 수집하는 MRTE-Collector와, 수집한 데이터를 테스트용 MySQL 서버에서 재현하는 MRTE-Player 두 개의 툴로 구성되어 있습니다.카카오에서도 효율적인 MySQL 운영에 큰 도움이 되고 있는 유용한 소프트웨어입니다. 특히 MRTE-Collector는 Go로 작성되어 Go로 네트웍 프로그래밍을 하려는 개발자들에게 유용할 것입니다.MySQL 서버를 사용하면서, 가끔씩 실 서비스용 MySQL 서버(Production mysql server)로 유입되는 쿼리들을 똑같이 흉내낼 수 없을까 하는 생각들을 많이 했습니다.실 서비스용 MySQL 서버에서는 MySQL 시스템 변수 하나도 조정해보기 어려운 경우가 많고, 때로는 업그레이드나 통합 또는 하드웨어 테스트를 하는 경우에는 이런 도구들이 절실했죠.이를 위해서 MRTE (MySQL Real Traffic Emulator) 도구를 생각하기 시작했는데, 조금만 고민해보니 사실 이는 그다지 어려운 일이 아니었다. 여기에서는 MRTE에 대한 간략한 아키텍쳐와 사용법을 간단히 소개하도록 하겠습니다.MRTE는 크게 유저 트래픽을 수집하는 MRTE-Collector와 수집된 SQL을 재현하는 MRTE-Player로 구성되어 있는데, MRTE-Collector와 MRTE-Player는 Message Queue (Rabbit MQ)를 이용해서 통신하도록 설계되었습니다.이 도구는 크게 아래와 같은 2가지 제약 사항을 가집니다:1번 제약 사항을 위해서 MRTE-Collector는 최소한의 자원을 사용하면서도 빠르게 작동할 수 있도록 설계했으며, 이를 위해서 GO 언어를 사용해서 Native code로 컴파일해서 실행할 수 있도록 개발되었습니다.실제 초당 35000개의 패킷을 캡쳐해서 외부의 Message Queue로 전송하는 경우에도 2~3%의 CPU만 사용하는 것으로 관측되었다. 하지만 일반적인 서비스 환경의 MySQL 서버에서 초당 몇 만정도의 쿼리를 처리하는 경우는 그다지 많지 않다는 것을 감안하면, MRTE-Collector를 MySQL 서버와 동일 장비에 실행한다는 것은 그다지 큰 제약 사항이 아닐 수도 있어 보인다. 또한 MRTE-Collector는 10~15MB 정도의 물리 메모리만 사용했었다. GO 프로그램의 특성상 Virtual memory는 700MB 정도로 꽤 점유하는 편이지만, 사실 Virtual memory 확보는 그다지 시스템의 자원 사용이나 성능에 영향을 미치지 않는다는 것이 Google의 의견입니다.아래 그래프는 MRTE-Collector가 실행중인 MySQL 서버의 CPU 사용량인데, 잠깐 MRTE-Collector를 멈췄을 때 CPU 사용량이 얼마나 떨어지는지를 보여주고 있습니다:그리고 MRTE-Collector는 tcpdump나 ngrep 명령과 같이 pcap 라이브러리를 이용하기 때문에 매우 안정적으로 패킷을 캡쳐할 수 있다. 실제 sysbench로 초당 35000 쿼리가 실행되는 환경에서도 MRTE-Collector 시작 및 종료(패킷 캡쳐 시작 및 종료)시에도 서비스에 특별한 성능 악 영향은 보이지 않았다. 또한 Message Queue나 MRTE-Collector가 문제를 일으켜 제대로 처리하지 못할 때에는, pcap 라이브러리는 MRTE-Collector의 처리를 기다리지 않고 수집된 패킷을 버리고 무시하기 때문에 유저의 네트워크 패킷을 블록킹하지는 않습니다.2번 제약 사항(Server side prepared statement) 제약 사항에 대해서 조금 살펴보겠습니다. MySQL 서버에서는 2종류의 PreparedStatement를 지원하고 있습니다:초기 MySQL 서버에서는 Text protocol(Text protocol이라고 해서 문자가 전송되는 프로토콜을 의미하는 것이 아니라 SQL 문장이 그대로 전달된다는 의미에서 Text protocol이라 함)만 지원했었는데, Server side prepared statement를 위해서는 새로운 프로토콜(Binary protocol)이 도입되었습니다. 현재 MRTE-Collector에서는 Binary protocol을 사용하는 경우는 지원하지 않고 있는데, 이는 패킷 분석의 어려움이 문제가 아니라 MRTE-Collector에서 PreparedStatement의 Hash Id를 알아낼 수 있는 방법이 없기 때문에 어려움이 있습니다. 만약 MySQL 서버에서 Connection별로 만들어진 PreparedStatement의 dump가 가능하다면 향후 Binary protocol도 지원이 가능할 것으로 보입니다.하지만 다행스럽게도, JDBC Client에서 server prepared statement의 사용 여부를 명시적으로 활성화하지 않으면 기본적으로는 Client side prepared statement가 사용되고 아직 MySQL 서버에서는 PreparedStatement의 장점이 그다지 크지 않아서 대부분의 경우 Statement 또는 Client side prepared statement를 사용하고 있는 상태입니다.MRTE 도구의 안정성과 성능 확인을 위해서 서버 4대를 아래와 같이 할당해서 테스트를 수행했습니다. 모두 2 소켓 12 코어 CPU를 사용하는 DELL 장비를 사용했습니다.테스트는 대략 60개 정도의 Connection을 이용해서 초당 30000 QPS(22000 SELECT, 5000 UPDATE, 1600 INSERT, 1600 DELETE) 정도의 SQL을 처리하고 있었으며, MRTE-Collector와 MRTE-Player 모두 Internal queue가 평균 0~1개 정도만 쌓일 정도로 무리 없이 처리하고 있는 상태로 진행되었습니다. 아래 그래프는 테스트 도중 Source와 Target MySQL 서버의 Query activity를 보여주는 그래프입니다. (Source와 Target MySQL 서버 모두 그래프의 스파이크 현상은 MRTE와는 무관한 것임)이 테스트 환경으로 대략 3주 정도 계속 sysbench 트래픽을 Target MySQL 서버로 전송하는 테스트중에도 별다른 문제가 발생하지 않았으며, MRTE-Collector를 10분 단위로 종료했다가 재시작하는 테스트도 대략 1주일 정도 진행했었는데 특별히 문제 상황은 발생하지 않았습니다.Rabbit MQ가 정상적으로 설치(모니터링 플러그인까지)되었다면 http://rabbtmq_host:15672/ 웹 사이트를 이용해서 MRTE-Collector와 MRTE-Player가 정상적으로 통신을 하고 있는지 그리고 각각의 모듈들이 제대로 작동하고 있는지 바로 확인이 가능합니다.MRTE-Collector와 MRTE-Player 소스 코드는 아래 Github 사이트에서 참조해볼 수 있습니다:이 글은 카카오 DB팀의 기술 블로그 DB Smalltalk에 포스팅한 MRTE를 이용한 MySQL Real Service 트래픽 테스트 환경 구축을 옮긴 것입니다.",http://tech.kakao.com/2016/02/16/opensource-2-mtre/,0,kakao,"spring,python,swift,java,mysql,docker,backend,database,javascript,tcp,php",NULL,2016-02-16
"카카오스토리 팀의 코드 리뷰 도입 사례 - 코드 리뷰, 어디까지 해봤니?","얼마 전, 렘(Realm)의 기술 블로그에 올라온 코드리뷰, Github로 바로 적용하기 - Realm에서의 코드리뷰 소개라는 글이 많이 회자되었죠.카카오는 어떻게 하고 있을까~ 궁금해서 수소문을 했더니, 사내에서도 깃헙 잘 쓰기로 소문 난 카카오스토리 웹 클라이언트팀은 코드 리뷰도 잘하더군요 @..@그들의 코드 리뷰 경험을 “날 것” 그대로 공유합니다. 우리끼리 보려고 쓴 글이라, 표현은 조금 거칠지만 더 쉽게 와 닿네요.웹 클라이언트 개발팀 내에선 코드 리뷰가 굉장히 활성화되어 있는데요, 얼마 전에 문득, 코드 리뷰를 도입하면서 경험했던 내용을 공유해보면 좋을 것 같단 생각이 들어서, 짬짬이 예전 기억을 되살리면서 노트에 정리했습니다.지금은 리뷰 문화가 정착돼서 그저 당연한 거라고 생각하고 있었는데, 돌이켜보면 도입 과정에서 탈도 많았고 여러 이슈를 극복하려고 멤버들 모두 고생했던 게 떠오르더군요. 다른 팀이 어떻게 일하고 있는 지 모르고, 작은 조직 내에서의 얕은 경험일 수도 있겠지만, 개인적으론 코드 리뷰를 도입하고 유지하고 있는 게 굉장히 값진 경험이라고 생각하고 있습니다.처음엔 그냥 웹 클라이언트 멤버들끼리만 돌려보려고 했는데, 아직 코드 리뷰를 도입하지 않은 팀들도 있는 것 같고, 정리하다 보니 다른 분들이 보셔도 좋은 내용일 것 같아 조심스레 공유해봅니다.거창하게 “이렇게 저렇게 했다”라고 공유하는 것보단, 쓱~ 부담없는 메모 형식으로 공유합니다. 좀 러프해도 이해해주세요^^;어떠신가요? 두서없이 나열했지만 입에 착착감기고 눈에 속속 들어오지 않나요?카카오에서는 개발 문화의 일부로 코드 리뷰를 정착시키기 위해 Crucible 같은 전용 소프트웨어도 도입하고, 의무화하는 등 여러가지 방법을 동원했지만 아직도 온전히 자리잡지  못했습니다.여기에서 공유한 경험이 모든 회사나 조직에 그대로 적용되지는 않겠지만, 시행착오를 줄이고 더 좋은 개발 문화를 만들어가는데 보탬이 되길바랍니다. 앞으로도 완벽하지는 않지만, 실제로 돌아가는 카카오의 개발 문화를 지속적으로 소개하겠습니다.",http://tech.kakao.com/2016/02/04/code-review/,0,kakao,,NULL,2016-02-04
"kakao의 오픈소스 Ep1 - 대용량 분산 그래프DB ""S2Graph""","“카카오의 오픈소스를 소개합니다” 첫번째는 shon.0와 동료들이 개발한 S2Graph입니다.S2Graph는 카카오에서 1년 여의 개발을 거쳐 카카오톡, 카카오스토리, 카카오뮤직, 선물하기, 다음앱, 다음뉴스, 다음쇼핑 등 20여개 이상의 서비스에 적용된 대용량 분산 그래프 데이터베이스입니다.[스칼라] 언어와 Play 프레임웍으로 작성된 그래프 API 서버와 HBase, Kafka, Spark 등 최근 가장 주목받는 기술들로 구성되어, 호기심으로 똘똘뭉친 개발자들에게 많은 도움이 될 것입니다.“그래프”라고 하면, 보고서나 발표자료에 막대 그래프, 파이 챠트,…를 떠올리지만, 이 글에서 언급하는 그래프는 수학자 오일러에서 시작된 그래프 이론의 그래프입니다.그래프 이론은 “유한 개의 점들로 이루어진 집합과 점들 간의 연결(관계)를 다루는” 학문입니다. 예를 들면, “어떤 지역과 지역을 최단거리로 이동하려면 어떻게 해야 되는가? 어떤 지점들이 있는데 이 지점들을 중복으로 지나지 않고 한번에 이동할 수 있는가?” 같은 문제를 연구하는 거죠.이런 “그래프 구조”를 저장하고 표현하기 위해 만들어진 도구가 그래프 데이터베이스 (graph database; 이하 그래프DB)입니다.카카오의 많은 서비스들은 사용자 사이의 관계(relation)와 사용자 개인의 활동(activity)를 기반으로 합니다.예) 덕선이 선우와 택이는 서로 친구입니다. 덕선이는 카카오 뮤직에서 음악을 듣습니다. 택이는 바둑 게임을 즐깁니다. 보라와 선우는 카카오 스토리를 사용합니다:이러한 문장들을 단어 그대로 그림으로 표현하면 아래와 같은 “소셜 그래프”가 됩니다:위의 그림에서 선(edge)으로 표현된 관계와 활동에 속성(property)을 추가하면 더 의미있는 정보를 표현할 수 있습니다.예) 덕선이와 보라는 가족(보라가 덕선이의 언니)입니다. 덕선이는 이승환의 광팬입니다(play count). 택이는 카카오 바둑 만렙입니다(play level). 선우는 보라가 카카오 스토리에 올린 글을 좋아합니다.실제 카카오의 소셜 그래프도 규모와 속성이 다를 뿐, 아래의 그림과 크게 다르지 않습니다:이런 그래프가 저장되어 있고, 필요할 때 즉시 조회할 수 있다면, 우리는 사용자들을 위해 더 많은 일들을 할 수 있습니다.예) 덕선이가 즐겨듣는 이승환의 음악을 택이에게 추천합니다. 선우의 타임라인에 보라의 글을 바로 보여줍니다. 보라에게 선우를 친구로 추천합니다.카카오는 S2Graph를 개발하기 전까지 애플리케이션 레벨의 수동 샤딩(sharding)된 MySQL를 사용해 왔습니다. 그러나, 계속 늘어나는 서비스와 데이터량을 코드와 설정과 운영으로 극복하는 것은 말처럼 간단한 일이 아니었습니다. 물리적인 한계로 인해 포기할 수 밖에 없는 데이터들도 계속 늘어났습니다.카카오도 (페이스북과 트위터가 그랬던 것처럼) 근본적인 해결책으로 2014년부터 그래프 데이터베이스 도입을 검토하기 시작했습니다. 오랜 시간동안 다양한 그래프 데이베이스를 검토하고 고치고 시험했습니다. 그리고, (페이스북과 트위터가 그랬던 것처럼) 기존의 그래프 데이터베이스로 해결할 수 없는 기술적 도전에 직면했습니다.RDB를 사용하면 2억 행을 가진 사용자 테이블과 20억 행을 가진 관계 테이블(m:n)과 매일 1000만 행이 늘어나는 활동 테이블이 필요합니다. 32비트 정수의 최대 범위가 21억이므로, 기본 키(primary key; PK)와 외래 키(foreign key; FK)도 64비트 정수가 되어야겠죠. 이 숫자가 주는 압박감은…기존의 그래프 데이터베이스들은 미리 확보된 정적인 데이터에 대한 의미 추론을 목적으로 만들어져서 극단적인 규모의 데이터량과 빈번한 데이터 변경에는 상대적으로 취약합니다. 애초에 그러라고(?) 만든 물건이 아니었던 거죠.RDB로 너비 우선 탐색을 구현하려면 대규모의 “JOIN”과 “GROUP BY”가 불가피합니다. 시간 내에 한 개의 응답을 내는 - OLAP에서 OLTP의 성능을 뽑아내는 - 것만 해도 쉽지 않은 일인데, 동시에 2000개의 응답을 내야 합니다.  카카오가 그랬던 것처럼 규모의 한계를 극복하기 위해 수동 샤딩을 했다면 쿼리도 상당 부분 수동으로 해야 합니다.기존의 그래프DB들은 전체 데이터를 대상으로 하는 깊이 우선 탐색 (Depth First Search; DFS)에 최적화되어 있고, 부분 데이터를 대상으로 하는 너비 우선 탐색 (breadth First Search; BFS)에는 상대적으로 취약합니다. 카카오를 비롯한 대부분의 소셜 서비스에게 필요한 것은 몇시간 걸려서 나오는 수학적인 최단 경로(Shortest Path)가 아닙니다.또한, 서비스 트래픽가 폭증하더라도 서버 규모를 선형 확장(linear scalability)해서 대응할 수 있어야 합니다.소셜과 모바일의 결합이 가져온 가장 큰 변화가 “실시간성”입니다.매일 혹은 매시간 배치(batch)로 데이터를 분석하고, 이렇게 분석된 정보를 기반으로 추천해서는 사용자들의 소비 속도에 맞출 수 없습니다. 지금 이 시간 사람들이 많이 본 뉴스를 내일 추천하면 “철지난 핫(?) 뉴스”가 됩니다. 그 뉴스를 톡으로 공유하면…진짜 실시간(hard real-time)은 아니더라도 거의 실시간(soft real-time) 처리가 가능해야 유혈사태(?)를 막을 수 있을 것입니다.아시는 바와 같이 페이스북이나 트위터에서는 사용자마다 컨텐츠의 내용와 순서가 다릅니다. 카카오 스토리도 마찬가지입니다. 과거에는 “시간순”이라는 의미로 “타임라인”이라는 단어를 사용했지만, 최근에는 조작된 타임라인, 즉, 사용자 맞춤형 “피드”라는 의미로 사용됩니다.트위터는 피드를 구현하기 위해서 푸시 방식을 사용합니다. 이 방식은 사용자가 컨텐츠를 생산할 때(tweet, retweet, follow/unfollow…) 그 컨텐츠를 소비할 사용자(팔로어)들의 피드에 해당 컨텐츠를 추가합니다. 이런 특성 때문에 write fanout 방식이라고도 합니다. 푸시 방식은 컨텐츠 소비(타임라인을 읽을 때) 처리가 간편하고 빠르다는 장점이 있지만, 피드의 내용과 순서를 변경하기 어렵다는 문제점이 있습니다. 불필요한 데이터 추가(트위터를 접은 팔로어의 피드에도 새 트윗을 추가…)로 인한 자원 낭비도 큰 문제입니다.반면, 페이스북은 풀 방식을 사용합니다. 이 방식은 사용자들이 볼 때 컨텐츠의 내용과 순서를 결정합니다. 이런 특성 때문에 read fanout 방식이라고도 합니다. 풀 방식은 컨텐츠 생산(post, like, friend/unfriend…) 처리가 간편하고 빠르다는 장점이 있지만, 컨텐츠 소비 처리가 어렵고 느립니다. 그러나, 피드의 내용과 순서를 변경할 수 있어서 최근에는 더 널리 사용되고 있습니다.가능하다면 풀 방식이 좋겠지만, 서비스의 특성에 따라 푸시 방식이 불가피한 경우도 있습니다. 실제 서비스에서는 풀과 푸시, 둘 다 필요합니다.S2Graph를 적용하기 전, 수동 샤딩과 상호 연결로 얽히고설켜 확장성 없던 아키텍쳐가:S2Graph를 적용한 후, 깔끔하고 무한 확장가능한 아키텍쳐가 되었습니다:S2Graph를 처음 공개할 당시만 해도 매일 10억 건 정도의 활동이 추가되었지만, 최근엔 적용한 서비스가 늘면서 매일 30 억 건 정도의 활동이 추가되고 있습니다. 그럼에도 불구하고, 코어의 지속적인 개선을 통해 피크 타임 QPS는 20,000에서 65,000으로, 최대 응답 시간은 100ms에서 50ms이하로 더욱 빨라졌습니다.S2Graph를 한 문장으로 표현하면:즉, 실시간 너비 우선 탐색을 위한 그래프 데이터 저장소와 그래프 API 서버입니다.HBase를 그래프 데이터 저장소로  사용합니다. HBase/HDFS/Hadoop이 가진 성능, 확장성, 가용성을 그대로 흡수하면서, 실시간 너비 우선 탐색에 최적화된 형태로 그래프 데이터를 저장합니다. 저장소 레이어는 물리적 구현체에 독립적으로 설계되어 MySQL을 저장소로 사용할 수도 있습니다.[스칼라]와 Play 프레임웍로 구현된 선형 확장가능한 그래프 API 서버를 포함하고 있습니다. 최근에는 Netty 기반의 고성능 REST 서버도 실험적으로 개발되고 있습니다.그 밖에도 Kafka와 Spark 기반의 배치 처리, Top카운터, A/B 테스트 등을 포함한 소셜 그래프 기반 서비스에 유용한 여러가지 기능을 포함하고 있습니다.단일 머신에 설치하고 실행할 수 있으므로 개발과 테스트가 용이합니다. Vagrant와 VirtualBox 등이 설치되어 있다면, 아래의 간단한 명령 몇 개 만으로 S2Graph를 체험할 수 있습니다:지난해 11월 아파치 재단의 인큐베이터 프로젝트로 선정되었습니다(관련 소식).아파치 인큐베이터 프로그램에 맞춰 현재 소스 코드와 이슈 트래커의 이전, 빌드, 문서화 등의 작업이 한창 진행 중입니다. 카카오에서도 다수의 개발자들이 풀타임으로 S2Graph 개발에 전념하고 있지만, 이 글을 읽는 분들도 언제든지 참여할 수 있습니다.이 글은 그래프 데이터베이스가 생소한 분들에게 S2Graph를 소개하기 위해 의도적으로 기술적인 세부사항을 생략했지만, 앞으로는 이 곳, kakao 기술 블로그와 브런치의 Apache S2Graph 매거진 등을 통해 S2Graph의 활용과 내부 구조를 포함한 다양한 기술 자료를 지속적으로 공유하겠습니다. S2Graph가 더 좋은 오픈소스 소프트웨어가 될 수 있도록 여러분들의 지속적인 관심과 참여를 기대합니다.HBaseCon 2015 발표 자료 & 발표 동영상",http://tech.kakao.com/2016/01/29/opensource-1-s2graph/,0,kakao,"spring,java,docker,machine,backend,javascript,machinelearning,tcp,php",NULL,2016-01-29
L4 장비의 동작과 서비스 배포시 유의점,"현재 카카오에서 대부분의 웹서버는 L3DSR (Direct Server Return)구성의 L7 HealthCheck 방식을 사용 중입니다. L7 HealthCheck 방식은 앞서 블로그에서 기술한적이 있는 것처럼 OSI 7Layer 중 Layer7 계층의 어플리케이션 응답을 체크하는 방식입니다. 카카오에서는 L4장비가 주기적으로 서버와 TCP 세션을 맺고 GET /health_check.html 의 Request로 응답코드를 확인 하는 방식입니다. 그러나 최근 여러개의 서비스에서 HTTP Keep-Alive 를 사용중이고 이에 따라 배포시 의도하지 않은 문제점이 발생할 수 있어 이에 대한 회피에 대해 기술하도록 하겠습니다. 카카오에서 몇몇 서비스의 서버개발자 분들께서 웹서버 배포, 서비스에서 제외시 L4장비의 GET /health_check.html Request에 대해 404 응답코드를 내려주려고 health_check.html 파일을 리네임하거나 이동, 삭제 하는등의 방법을 사용중입니다. 쉽게 생각해서 L4 장비의 Request에 대해 404 응답코드를 내려줌으로써 VIP로 묶인 바인딩 서버리스트에서 제거 될것이라 생각하고 위와 같은 과정으로 서비스에서 제외 후 배포하는 경우가 많습니다.위의 말씀드린 것처럼 health_check.html 파일에 대해서만 작업을 하고 배포를 진행하려고 할 경우에 서비스에서 제외 시킨 서버로 지속적으로 요청이 들어오고 트래픽이 빠지지 않는 경우가 있습니다. 이럴 경우 배포하고자 하는 서버에 지속적으로 사용자 트래픽이 인입되고 있는 상태라서 배포에 영향이 있거나 서버쪽의 문제로 생각을해서 살펴보게 되는 경우가 있습니다. 이는 L4 장비의 동작과 관련이 있는 것으로 L4 장비 동작 방법에 대해 살펴볼 필요가 있습니다.L3DSR 구성에서 L4장비는 클라이언트로부터 인입되는 요청에 대해서 해당 VIP에 대한 바인딩 서버리스트를 갖고 있고 IP헤더의 IP주소변경 후 리스트의 서버로 패킷을 던져주는 역할을 합니다.이 때 L4장비에서는 해당 세션에 대한 세션테이블을 장비에 설정된 Idle session timeout (Session table aging time)시간동안 유지하게 됩니다. 이 시간을 카카오에서는 별도 요청이 없을 경우 default 로 600초로 설정해서 서비스하고 있습니다. (120초 ~ 3600초까지 변경 가능) 위와 같은 문제가 이 부분에서 발생을 하게 됩니다. 쉽게 그림으로 표현하면 아래 그림과 같습니다.즉, 서버측에서 GET /health_check.html에 대한 응답코드를 404로 내려준다 하더라도 L4장비에서는 설정된 600초라는 시간동안 Session Table을 유지하게 됩니다. 그리고 클라이언트로부터 오는 요청을 Session Table을 보고 서버로 포워딩해주게 됩니다. 이때문에 기존 Keep-Alive 상에서 동작했던 클라이언트는 health_check.html 파일을 제거했다고 하더라도 기존에 접속했던 서버로 요청이 계속 인입되게 되는 것입니다. 이때 기존 서버에 웹서버 프로세스가 유지되고 있는 상태라면 클라이언트-서버는 Keep-Alive 세션상에서 Request, Response가 가능합니다. 그러나 VIP가 설정된 lo:0 인터페이스를 Down 시킨 경우라면 클라이언트는 TCP Timeout 으로 “연결시간초과” 페이지를 보게 됩니다.또한, L4장비에서는 서버상태의 HealthCheck을 대부분 설정된 10초 간격으로 하도록 되어 있는데 HealthCheck 을 한 바로 직후의 시간이라면 최초 10초정도의 Sleep time이 필요합니다. 그 10초 사이의 시간동안은 서비스에서 제외하고자 health_check.html 파일을 삭제했다 하더라도 L4장비에서는 바인딩리스트에 포함시키고 있기 때문에 클라이언트로부터의 Request가 인입될 수 있습니다.위와 같이 L4장비에 Session Table 이 남아있어 서비스에서 제외하고자 하는 서버군으로 지속적인 Request 인입을 방지하기 위해 서버 배포시 아래의 Flow에 따라 진행합니다.",http://tech.kakao.com/2014/05/30/l4/,0,kakao,"docker,java,python",NULL,2014-05-30
kakao의 Anycast 활용 사례,"네트워크 기술 하나 중 Anycast 는 DNS 서비스에서 주로 사용하고 있지만 KAKAO는 Anycast 기술을 확장하여 여러가지 어플리케이션 서비스에 사용되고 있습니다.특히 서버에서 Quagga 오픈소스를 이용하여 KAKAO 자체 망을 이용한 각 글로벌 POP 에 비용 절감 및 고 가용성 용도로도 많이 사용되고 있습니다. Anycast 라는 용어가 매우 생소한데요. Anycast 란 용어는 네트워크 용어 입니다. 우리가 보통 알고 있는 IP주소는 Unicast IP이며 이것은 고유한 IP주소입니다. Anycast IP는 서로 다른 곳, 서로 다른 호스트 끼리 동일한 IP주소를 가질 수 있는 개념입니다. 그런데 이때의 문제점은 가끔 사무실에 출근하면 누군가 내 IP를 써서 IP충돌나듯이 IP가 충돌나겠죠^^.그러나 이 충돌된 IP들의 회피 방법은 BGP와 같은 라우팅 프로토콜에 의해서 해결합니다. 라우팅 프로토콜에 의해 이 충돌난 IP에 대해서 가장 최적의 경로의 IP를 가진 서버를 1개 선택해서 라우팅 해줍니다. (사무실과 같은 L2 에서는 IP가 충돌나면 사용이 불가능하지만 라우터 같은 L3 에서는 충돌나도 가능합니다. 같은 IP를 각 라우터들이 어나운스 하며 가장 가까운 곳으로 판된되는 쪽으로 사용합니다.)Anycast 는 주로 DNS 서비스에 많이 활용 됩니다. Anycast 기법을 사용하여 DNS 서버를 지역별 분산 구성하여 DNS 질의를 요청한 클라이언트와 가장 근접한 DNS 서버가 처리하도록 하여 응답속도와 안정성을 향상 시킨 DNS를 말합니다. 항상 네트워크 경로상 가장 가까운 DNS 서버가 응답합니다. 또한 가장 가까운 DNS가 장애가 발생되면 라우터에서 어나운스가 되지 않아 자동으로 빠지며 그 다음 가까이 위치에 있는 DNS가 대신 처리합니다.Anycast 가 도입된 이유는 2002년 10월 root DNS DDoS공격으로 전 세계 13개 root DNS중 8개가 다운, 2003년 1.25 인터넷 대란때 5개의 root DNS가 웜으로 DDoS공격당하여 전세계 DNS가 마비되어서 개선안으로 Anycast 기술을 사용하게 되었습니다. Anycast IP를 이용하여  DNS를 적절히 분산구성하여 한쪽 지역이 무너지더라도 다른 지역에서 서비스를 받을 수 있도록 하였습니다.가장 좋은 예제로는 우리가 잘 알고 있는 Google public DNS의 IP 8.8.8.8 도 Anycast로 구성되어있으며 전세계 국가에 분산 되어있고 그 규모는 엄청 납니다. Google public DNS를 쓰면 자신이 속한 지역에서 라우팅 경로가 가장 최적인 지역의 DNS 서비스를 받고 Google 서비스에 대한 서비스도 최적에 있는 지역에 서버에 서비스 받습니다. 아시아에선 대만과 홍콩에 있네요.Anycast 는 주로 connectionless UDP 프로토콜에 최적화된 DNS에 주로 쓰이고 있습니다. 그 이유는 상황에 따라서 네트워크 경로가 바뀔 수 있으므로 한쪽 서버로 세션을 지속적으로 상태 보존이 필요한 TCP 프로토콜에는 부적합하다는 판단 때문입니다. 그러나 Web Cache 등의 경우엔 트랜잭션을 보장해야 되는 부분이 없어 KAKAO는 이러한 부분에 TCP 프로토콜인 Contents Cache 서비스 부분에도 활용하기로 했습니다. 또한 Floating IP Address 용으로 Anycast 관련된 기술을 활용하여 Virtual IP 방식으로 동작시켜 원래 Anycast 목적과는 다른 용도로 사용하고 있습니다.KAKAO 도메인을 전세계 알리기 위한 각 지역별 KAKAO 글로벌 POP에 배치하여 국내 인터넷 사이트 중 가장 빠른 DNS 서비스를 제공합니다.구성하게 된 계기는 해외에서 국내 사이트를 호출하면 굉장히 느린데 그 느린 이유 하나가 도메인 응답만 수 초가 소요됩니다. 대부분 국내 웹 사이트들은 글로벌하게 사용하지 않으므로 각 지역의 사용자가 사용하는 지역 DNS에 도메인 Cache가 되지 않고 모두 한국에 각 도메인 소유의 권한 DNS 서버까지 왕복하는 시간이 걸리며 이로 인해 DNS 응답만 수 초가 걸릴 수 도 있습니다.또한 GSLB 장비의 사용으로 GSLB 헬스체크로 인한 TTL이 짧은 GSLB 주소로 CNAME 위임을 하게 되는데 이러면 위임된 GSLB 장비까지 질의가 왕복 되고, 짧은 도메인 TTL로 인한 각 사용자 지역의 DNS에 Cache가 잘되지 않아 시간은 더 소요됩니다.GSLB CNAME 위임은 DNS 응답 속도 측면에서 매우 안 좋은 방법입니다. 또한 속도를 빠르게 하기 위해서 고가의 GSLB 장비를 각 글로벌 POP 지역에 배치하면 비용이슈가 있습니다.따라서 KAKAO는 GSLB Edge DNS Cache를 각 글로벌 POP에 배치해 Anycast로 구성하여 이러한 경우에도 가장 빠른 응답을 줄 수 있도록 노력하고 있습니다.KAKAO는 가장 빠른 DNS 응답을 위해 노력하고 있습니다.KAKAO는 여러 IDC를 사용하고 있는데  IDC 내부에 서버들이 가장 빠른 내부 DNS 서비스를 받기 위해서 사용됩니다. IDC 마다 Anycast 방식으로 구성해 한쪽 IDC가 무너져도 안정적인 내부 DNS 서비스를 위한 용도 입니다. 또한 서버의  /etc/resolv.conf의 nameserver 주소를 통합시켜 OS DNS 정책을 표준화 할 수 있습니다.DNS 뿐만 아니라 각 글로벌 지역에 분산된 KAKAO 자체 글로벌 POP 을 이용하여 사용자가 가장 빠른 지역으로 Cache 서비스를 받기 위해서 사용됩니다.  KAKAO는 GSLB + Anycast 함께 조합으로 사용자가 사용하는 지역 DNS IP Source 기반인 GSLB 으로만 부정확한 부분을 최소화 하고 있습니다.동남아 국가 모바일에서는 사용자가 Google public DNS, OpenDNS 및 정책 필터링으로 지정된 DNS로 사용 하는 부분이 있어 이 부분을 제대로 컨트롤 할 수 없는 부분이 있는데 Google public DNS source Physical IP의 정확한 위치 추적 및 Anycast 조합으로 사용자가 가장 가까운 Contents Cache Server 를 만나게 해줍니다.또한 블랙베리의 BIS망을 분석하고 최적화 하여 블랙베리에서도 KAKAO는 빠른 응답을 주도록 노력하고 있습니다.서버에 Physical IP를 사용되면 잦은 IP 변경시 네트워크 VLAN 변경등 어려움이 따르므로 손쉽게 컨피그 수준으로 IP 를 조정하여 이용합니다. 이것은 Anycast 의 기본 목적과는 다른 목적으로 Virtual IP 용으로 사용됩니다.장점은단점은KAKAO에서는 오픈소스를 이용하여 구성하였는데요, 그 구체적인 예제는 아래 링크에 잘 설명되어 있습니다.대략적인 예제 토폴로지는 아래와 같습니다.서버 측면에서 구성 방법을 설명 드립니다. (모든 서버는 동일한 설정을 갖습니다.)ex) CentOS(RedHat) 기준이후, 라우터 세팅동작 순서1) Anycast Loopback IP up2) BGP upex) 서버에서 라우터와 BGP 연결 상태를 보는 예제ex) 예제에서는 DNS 응답이 이상하면 bgp 데몬을 자체적으로 내려서 서비스 제외합니다.마지막으로 Quagga 를 이용하면서 실제 구현하면서 알게된 몇가지 팁을 소개합니다.ex) KAKAO는 bgpd 데몬만 올려서 사용합니다.ex) KAKAO는 bgpd 데몬을 내려 서비스를 안전하게 제외합니다.Anycast 는 글로벌 서비스에서 매우 유용하고 필수적인 기술이라고 판단되며 일반적으로 DNS로만 사용하지만 KAKAO에서 실험과 실제 서비스에 적용결과 DNS외에 Contents Cache 서비스에서도 문제 없이 동작하였습니다.특히 사용자가 사용하고 있는 지역 DNS source IP 기반으로 하는 GSLB 만으로는 일부 모바일 및 사용자가 지정한 Google public DNS 사용 및 일부 국가의 필터링을 위해 지정된 DNS 사용등 으로 정확한 타케팅을 할 수 가 없습니다.Anycast 로 이러한 부분을 어느정도 해소 할수 있을것이란 판단이 들며 서버에서 올릴 수 있는 Quagga 외 ExaBgp 등 다양한 오픈소스네트워크 라우팅 프로토콜 데몬으로 전용 네트워크 장비 없이 손쉽게 구현할 수 있겠습니다.",http://tech.kakao.com/2014/05/29/anycast/,0,kakao,"docker,tcp,backend,java,python",NULL,2014-05-29
kakao의 L3DSR 구성 사례,"서비스 웹서버 Load Balancing을 위한 메커니즘으로 KAKAO에서는 L3DSR 방식을 사용하고 있습니다. 멀티IDC에서 L3DSR 방식을 활용, IDC 위치나 서버의 물리적인 위치에 따른 제한없이 서비스 웹서버 Load Balancing이 가능하도록 구성하고 있습니다. 보통 서비스에서는 Inbound traffic 대비 Outbound traffic이 월등히 높은데 Outbound traffic을 SLB에서 모두 수용하게 될 경우 리소스 소모가 커질 수 밖에 없습니다. 그래서 Outbound traffic을 서버가 SLB에 전달하지 않고 직접 클라이언트에게 전달해 SLB의 리소스 소모 방지를 위해 사용하는 구성이 DSR(Direct Server Return) 구성입니다. 그리고 클라이언트의 Request를 서버로 전달함에 있어 어떤 헤더를 이용하는지에 따라 L2/L3 DSR로 구분하게 됩니다. L3DSR 은 Load Balancing 을 위한 메커니즘 중 DSR 방식에서 기존 L2 Layer 의 DSR 방식의 한계를 개선하기 위해 사용하는 기술입니다. L3DSR 구성은 IP 헤더중 어떠한것을 이용하는지에 따라 IP Tunnel 기반과 TOS(DSCP) 기반으로 구분되는데 카카오는 DSCP 기반의 L3DSR 방식을 사용하고 있습니다.L2DSR은 L2 Layer 헤더인 MAC 주소 변경을 통해 클라이언트의 Request가 전달되는 반면 L3DSR은 IP헤더를 변조하여 서버에 Request를 전달하는 구성입니다. L2DSR의 경우는 MAC 주소 변경을 위해 서버와 ADC 모두 동일한 Broadcast 도메인에 포함되어야 했고, 그로인한 물리적 회선, 위치등의 한계성이 있었습니다. 그러나 L3DSR의 경우 SLB에서 IP 주소 변경을 통해 클라이언트의 Request가 서버로 전달되기 때문에 L2DSR에서의 물리적인 한계성을 극복 할 수 있습니다. 카카오는 서로 다른곳에 각각 위치한 IDC라도 L3DSR 구성을 통해 Load Balancing이 가능하도록 사용하고 있습니다.위 그림을 보면 클라이언트는 Destination IP가 211.115.115.100 인 서버로 Request를 보낸것이므로 동일한 IP로부터 Response를 받아야 합니다.  LB장비에서는 211.115.115.100 에 바인딩된 Real Server호스트들의 IP정보를 갖고 있고 IP헤더의 Destination IP를 변조 후 실제 서버로 전달합니다. L2DSR의 경우는 L2 Layer의 Destination MAC 주소를 변조 후 서버로 전달하는데 이 부분이 L2DSR과 L3DSR의 차이점입니다. 이때 서버에서는 Destination IP가 211.115.115.100 으로 들어온 패킷을 자신의 IP가 아니라고 판단하고 버리게 되므로 서버의 lo:0 인터페이스에 VIP를 설정하여 사용합니다.위와 같은 설정으로 211.115.115.100 의 주소로 들어온 패킷도 서버에서는 버리지 않고 Loopback Interface에 할당된 IP로 응답하게 됩니다. 이때 서버에서는 LB장비를 거칠필요 없이 Direct로 클라이언트로 응답을 하게 되는것이  L3DSR 방식입니다.카카오에서는 Least connection 의 단점을 회피하고자 Round Robin 방식을 사용중입니다.HTTP 예: L2/L3 헬스 체크 성공 => L4 헬스 체크 성공 => 리얼서버 업 => L7 헬스 체크 성공 => 리얼서버 업 유지Layer 4 계층의 TCP/UDP 서비스 port를 체크하는 방식.TCP 서비스 경우  LB 장비에서는  바인딩된 서버의 포트로 TCP SYN 을 전송하여 SYN+ACK 응답이 오는지를 확인하며 응답이 없다면 서버의 서비스 상태에 문제가 있다고 인식을 하고 바인딩을 하지 않습니다. 그리고 기본적으로 서버가 SYN+ACK을 응답할 경우 서버의 Socket 낭비를 막기 위해 바로 RST을 통해 세션을 끊습니다. 이방법은 LB장비의 부하가 적고 서버의 Socket 낭비가 없는 이점이 있는 반면 실제 서비스 어플리케이션단은 체크를 할수 없는 문제점이 있습니다.Layer7 계층의 어플리케이션 응답을 체크하는 방식.기본적으로 서버와 TCP 세션을 맺고 Request를 (ex. GET /health_check.html) 통해 응답 코드 확인하는 방식입니다. 주기적으로 서버와 세션을 맺기 때문에 부하가 발생하지만 어플리케이션 상태까지 체크할 수 있기 때문에 L4 Health Check 보다 확실한 헬스체크가 가능합니다.카카오 웹서버군은 거의 대부분 L7 Health Check 방식을 사용합니다. 그로인해 보다 확실한 서비스 안정성을 유지할 수 있도록 합니다.L2DSR 구성은 이미 여러곳에서 사용되어 오고 있습니다. L3DSR구성도 이미 많이 소개가 되고 보편화 되어 여러사이트에서 사용중인것으로 알고 있습니다. 그러나 L2DSR의 한계점을 극복하기 위해, L3DSR 구성이 서비스의 확장과 멀티 IDC에서의 운영, 확장, 안정성에서도 더 나은 구성임이 분명하기에 조금이나마 도움이 되었으면 하는 바램으로 글을 작성하게 되었습니다.",http://tech.kakao.com/2014/05/28/l3dsr/,0,kakao,,NULL,2014-05-28
